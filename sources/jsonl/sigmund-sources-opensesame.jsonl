{"content": "# Touch response\n\ntitle: Touch response\n\nThe `touch_response` plug-in allows you to work with touch responses (or mouse clicks) in an easy way, by dividing the display into rows and columns. Each response is encoded by a single number, which corresponds to the position counting from left-to-right and top-down. For example, if you have specified 2 columns and 3 rows, the display is divided into the following response regions:\n\n```bash\n1\t2\n3\t4\n5\t6\n```\n\nSimilarly, if you have specified 4 columns and 1 row, the display is sliced horizontally into the following response regions:\n\n```bash\n1\t2\t3\t4\n```", "url": "https://osdoc.cogsci.nl/4.0/items/touch_response", "title": "Touch response"}
{"content": "# Advanced_delay\n\ntitle: Advanced_delay\n\nThe `advanced_delay` plug-in delays the experiment for a pre-specified average duration plus a random margin.\n\n- *Duration* is the average duration of the delay in milliseconds.\n- *Jitter* is the size of the variation in the delay in milliseconds.\n- *Jitter mode* is the how the jitter is calculated:\n\t- *Standard deviation* will draw the variation from a Gaussian distribution with Jitter as the standard deviation.\n\t- *Uniform* will draw the variation in duration from a uniform distribution.", "url": "https://osdoc.cogsci.nl/4.0/items/advanced_delay", "title": "Advanced_delay"}
{"content": "# Quest staircase next\n\ntitle: Quest staircase next\n\nProcesses a response and updates the Quest test value.", "url": "https://osdoc.cogsci.nl/4.0/items/quest_staircase_next", "title": "Quest staircase next"}
{"content": "# Repeat_cycle\n\ntitle: Repeat_cycle\n\nThis plug-in allows you to repeat cycles from a `loop`. Most commonly, this will be to repeat a trial when a participant made a mistake or was too slow.\n\nFor example, to repeat all trials on which a response was slower than 3000 ms, you can add a `repeat_cycle` item after (typically) the `keyboard_response` and add the following repeat-if expression:\n\n```bash\nresponse_time > 3000\n```\n\nYou can also force a cycle to be repeated by setting the variable `repeat_cycle` to 1 in an `inline_script`, like so:\n\n```python\nrepeat_cycle = 1\n```", "url": "https://osdoc.cogsci.nl/4.0/items/repeat_cycle", "title": "Repeat_cycle"}
{"content": "# Reset_feedback\n\ntitle: Reset_feedback\n\nThis plug-in has the same effect as presenting a FEEDBACK item with a duration of 0 ms\n{: .page-notification}\n\nIf you do not reset feedback variables, you may confound your feedback with responses that are not relevant to the task. For example, the key presses made during the instruction phase may affect the feedback during the first block of the experiment. Therefore, you will need to reset the feedback variables at appropriate moments.\n\nThis plug-in will reset the following variables to 0:\n\n- `total_response_time`\n- `total_response`\n- `acc`\n- `accuracy`\n- `avg_rt`\n- `average_response_time`", "url": "https://osdoc.cogsci.nl/4.0/items/reset_feedback", "title": "Reset_feedback"}
{"content": "# Quest staircase init\n\ntitle: Quest staircase init\n\nInitializes a new Quest staircase procedure.", "url": "https://osdoc.cogsci.nl/4.0/items/quest_staircase_init", "title": "Quest staircase init"}
{"content": "# Runners\n\ntitle: Runners\n\n\n[TOC]\n\n\n## About runners\n\nThere are several technically different ways in which you can execute your experiment. Each of these corresponds to a *runner*. You can select a runner under Menu \u2192 Tools \u2192 Preferences \u2192 Runner.\n\nUnless you have a reason not to, you should use the *multiprocess* runner. However, if OpenSesame sometimes crashes, you can try whether selecting a different runner resolves this.\n\n\n## Available runners\n\n### Multiprocess\n\nThe *multiprocess* runner executes your experiment in a different process. The benefit of this approach is that your experiment can crash without bringing the user interface down with it. Another advantage of the *multiprocess* runner is that it allows the variable inspector to show your experimental variables while the experiment is running.\n\n### Inprocess\n\nThe *inprocess* runner executes the experiment in the same process as the user interface. The benefit of this approach is its simplicity. The downside is that the user interface may crash if the experiment crashes, and vice versa.\n\n### External\n\nThe *external* runner executes the experiment by launching opensesamerun as a separate application. The benefit of this approach is that your experiment can crash without bringing the user interface down with it.", "url": "https://osdoc.cogsci.nl/4.0/manual/runners", "title": "Runners"}
{"content": "# OpenSesame script\n\ntitle: OpenSesame script\nreviewed: false\n\n[TOC]\n\n## About OpenSesame script\n\nOpenSesame script is a simple definitional language that defines an experiment. It is not a full fledged programming language, and does not include features such a `for` loops. The OpenSesame script is interpreted by an OpenSesame runtime environment.\n\nOpenSesame script is different from the Python scripts that are used in inline_script items. Python is a real programming language with all the flexibility and complexities that this entails. In contrast, OpenSesame script is used to define experiments in a simple, human-readable way.\n\n## General remarks\n\n### Keywords\n\nSome items, such as form_base and sketchpad accept keywords. Keywords are of the form `keyword=value`. Keywords are optional and should fall back to a default value.\n\n### Comments\n\nStrings preceded by a hash should be interpreted as comments.\n\n*Example*\n\n\t# This is a comment\n\n### Quotation\n\nQuotation is not necessary, except around strings that contain spaces or other forms of punctuation. So the following lines should be interpreted as identical:\n\n\tset my_var 'my_value'\n\tset my_var \"my_value\"\n\tset my_var my_value\n\nHowever, the following lines are not. In fact, the first line is not valid, because it has an unexpected third parameter.\n\n\tset my_var my value\n\tset my_var \"my value\"\n\n### Types\n\nThere are no types. No distinction is made between strings, integers, etc.\n\n### Item-specific syntax\n\nSome items have a specific syntax. This is indicated in the \u201cApplies to\u201d section for each of the keywords discussed below.\n\n### Resolving path names\n\nTODO\n\n## *define* statement\n\nStarts the definition of an item. After a define statement, all lines are indented by a single tab. The end of the item definition is the first string that is no longer indented. Nested define statements are not allowed.\n\n*Applies to*\n\nAll items\n\n*Format*\n\n\tdefine [item name] [item type]\n\t\t[item definition]\n\n*Parameters*\n\n|`item name`\t|the name of the item\t|\n|`item type`\t|the type of the item\t|\n\n*Example*\n\n\tdefine get_key keyboard_response\n\t\tset allowed_responses \"a;x\"\n\t\tset description \"Collects keyboard responses\"\n\t\tset timeout \"infinite\"\n\t\tset flush \"yes\"\n\n## *draw* statement\n\nDefines a visual element of a sketchpad or feedback item.\n\n*Applies to*\n\nsketchpad, feedback\n\n*Format*\n\nThe format depends on the element.\n\n\tdraw ellipse [left] [top] [width] [height] [keywords]\n\tdraw circle [x] [y] [radius] [keywords]\n\tdraw line [left] [right] [top] [bottom] [keywords]\n\tdraw arrow [left] [right] [top] [bottom] [keywords]\n\tdraw textline [x] [y] [text]\n\tdraw image [x] [y] [path]\n\tdraw gabor [x] [y]\n\tdraw noise [x] [y]\n\tdraw fixdot [x] [y]\n\n*Parameters*\n\n|`left` \t\t|the left-most x-coordinate\t\t|\n|`right`\t\t|the right-most x-coordinate\t|\n|`top`\t\t\t|the top y-coordinate\t\t\t|\n|`bottom`\t\t|the bottom y-coordinate\t\t|\n|`x` \t\t\t|the x-coordinate\t\t\t\t|\n|`y`\t\t\t|the y-coordinate\t\t\t\t|\n|`text` \t\t|text string\t\t\t\t\t|\n|`path` \t\t|the path to an image file\t\t|\n\n*Keywords*\n\nTODO\n\n*Example*\n\n\tdraw fixdot 0 0\n\n## *log* statement\n\nIndicates that a variable should be written to the log-file.\n\n*Applies to*\n\nlogger\n\n*Format*\n\n\tlog [variable name]\n\n*Parameters*\n\n|`variable name`\t\t|the name of a variable\t|\n\n*Example*\n\n\tlog response_time\n\n## *run* statement\n\nIndicates that an item should be run. In the case of the sequence, the order of the run statements determines the order in which items are called. In the case of the coroutines plugin all items are called at the same time.\n\n*Applies to*\n\nsequence\n\n*Format*\n\n\trun [item name] [optional: condition] [optional: disabled]\n\n*Parameters*\n\n|`item name`\t\t\t|the name of the item to run\t|\n|`condition` (optional)\t|the conditional statement, which determines the item is actually called. If no condition is provided, the item is always called.|\n\n*Example*\n\n\trun correct_feedback '[correct] = 1'\n\n## *set* statement\n\nDefines single-line variables.\n\n*Applies to*\n\nAll items\n\n*Format*\n\n\tset [variable name] [value]\n\n*Parameters*\n\n|`variable name`\t|the variable name\t|\n|`value`\t\t\t|the variable value\t|\n\n*Example*\n\n\tset timeout 1000\n\n*Notes*\n\nMulti-line variables are defined using the `__[variable name]__` notation. This is mostly useful for items that require large blocks of text. Within an item definition, each line is preceded by a single tab, which should not be interpreted as part of the text. `__end__` indicates the end of the variable.\n\n*For example:*\n\n\t__my_variable__\n\tThis is the first line.\n\tThis is the second line.\n\t__end__\n\n## *setcycle* statement\n\nSimilar to the regular \u201cset\u201d statement, but sets a variable only during a specific cycle of a loop. This is the script equivalent of the loop table.\n\n*Applies to*\n\nLoop\n\n*Format*\n\n\tsetcycle [cycle #] [variable name] [variable value]\n\n*Parameters*\n\n|`Cycle #`\t\t\t|the number of the cycle, where 0 is the first\t|\n|`variable name` \t|the variable name\t\t\t\t\t\t\t\t|\n|`value`\t\t\t|the variable value\t\t\t\t\t\t\t\t|\n\n*Example*\n\n\tsetcycle 0 cue valid\n\n## *widget* statement\n\nAdds a widget (buttons, labels, etc.) to a form. Valid keywords depend on the type of widget. The widget statement is not strictly part of the core OpenSesame syntax, but is used by the form_base plugin.\n\n*Applies to*\n\nform_base (plugin)\n\n*Format*\n\n\twidget [column] [row] [column span] [row span] [widget type] [keywords]\n\n*Parameters*\n\n|`column`\t\t|the widget's column position in the form, where 0 is left-most\t\t\t\t\t\t\t\t|\n|`row`\t\t\t|the widget's row position in the form, where 0 is top\t\t\t\t\t\t\t\t\t\t|\n|`column span`\t|the number of columns that the widget occupies\t\t\t\t\t\t\t\t\t\t\t\t|\n|`row span`\t\t|the number of rows that the widget occupies\t\t\t\t\t\t\t\t\t\t\t\t|\n|`widget type`\t|'button', 'checkbox', 'image', 'image_button', 'label', 'rating_scale', or 'text_input'\t|\n\n*Keywords*\n\nTODO\n\n*Example*\n\n\twidget 0 0 1 1 label text='This is a label'", "url": "https://osdoc.cogsci.nl/4.0/manual/opensesame-script", "title": "OpenSesame script"}
{"content": "# Counterbalancing\n\ntitle: Counterbalancing\n\nCounterbalancing is a way to remove confounding factors from an experiment by having slightly different tasks for different groups of participants. This sounds abstract, so let's consider two examples.\n\n[TOC]\n\n### Example 1: Counterbalancing response rule\n\nConsider a lexical-decision experiment in which participants classify words as verbs by pressing 'z' with their left hand, or as nouns by pressing 'm' with their right hand. This design has a problem: If you find that participants respond faster to nouns than to verbs, this could be because nouns are processed faster than verbs, or because participants respond faster with their right hand than with their left hand. You can fix this problem by counterbalancing the response rule.\n\nFor even participant numbers:\n\n- verb \u2192 z\n- noun \u2192 m\n\nFor uneven participant numbers:\n\n- verb \u2192 m\n- noun \u2192 z\n\n### Example 2: Rotating stimulus conditions\n\nConsider a masked-priming experiment in which participants read target words aloud. On each trial, the target word is preceded by one of three types of priming words:\n\n- An unrelated prime, e.g. priming with 'berry' for target 'house'.\n- An ortoghraphically related prime, e.g. priming with 'mouse' for target 'house'\n- A semantically related prime, e.g. priming with 'garden' for target 'house'\n\nTo avoid repetition effects, you only want to show target words only once per participant. Therefore, you create three different sets of target words, one for each prime type. This is a between-word design, which has less statistical power than a within-word design, in which each target word occurs in each condition. (For the same reason that between-subject designs are less powerful than within-subject designs.)\n\nYou can use counterbalancing to change this experiment into a within-word design by 'rotating' the condition in which each word occurs between participants. We have three conditions, and we therefore have three groups of participants:\n\n- Participants 1, 4, 7, etc.\n    - Word A in condition 1\n    - Word B in condition 2\n    - Word C in condition 3\n- Participants 2, 5, 8, etc.\n    - Word A in condition 2\n    - Word B in condition 3\n    - Word C in condition 1\n- Participants 3, 6, 9, etc.\n    - Word A in condition 3\n    - Word B in condition 1\n    - Word C in condition 2\n\n\n## Implementing counterbalancing\n\n\n### Using the subject number\n\nWhen you run an experiment in OpenSesame on the desktop, you are asked for a subject number. When you run an experiment online, a subject number is randomly selected from the list of possible subject numbers that you have specified in the [OSWeb extension](%url:osweb). (This means that for online experiments you cannot ensure that the number of participants is exactly equal for the different conditions that you want to counterbalance, at least not if you rely on the subject number.)\n\nThis subject number is available as the experimental variable `subject_nr`. In  addition, the experimental variable `subject_parity` has the value 'odd' or 'even', depending on whether the subject number is odd or even. Now say that you want to counterbalance the response rule as in Example 1, you could add the following INLINE_SCRIPT to the start of the experiment.\n\n```python\nif subject_parity == 'odd':\n    verb_response = 'z'\n    noun_response = 'm'\nelse:\n    verb_response = 'm'\n    noun_response = 'z'\n```\n\nOr, when creating an OSWeb experiment, add the following INLINE_JAVASCRIPT to the start of the experiment:\n\n```javascript\nif (subject_parity === 'odd') {\n    verb_response = 'z'\n    noun_response = 'm'\n} else {\n    verb_response = 'm'\n    noun_response = 'z'\n}\n```\n\nNow, in your *block_loop*, instead of setting `correct_response` to a fixed value, you set it to a variable: `{verb_response}` or `{noun_response}`. You can take a look at the *lexical-decision task* example to see how this works (Menu -> Tools -> Example experiments).\n\n\n### Using Batch Session Data (JATOS and OSWeb only)\n\nWhen running an OSWeb experiment that is hosted on JATOS, you can make use of [Batch Session Data](https://www.jatos.org/jatos.js-Reference.html#functions-to-access-the-batch-session). This is data that is shared between all experimental sessions that are part of the same worker batch. Therefore, you can use this data to define a list of conditions that should be distributed across participants. At the start of each experimental session, one condition is removed from this list and used for the current session. This is the most sophisticated way to implement counterbalancing for OSWeb experiments that are hosted on JATOS.\n\nYou can download a template experiment here:\n\n- %static:attachments/counterbalancing-osweb-jatos.osexp%\n\nWhen running from JATOS, the experiment retrieves a single condition from the Batch Session Data (see below) and registers this as the experimental variable `condition`. When doing a test run, `condition` is set to a default value specified at the end of *init_condition*.\n\nThe experiment itself should be implemented in the *experiment* SEQUENCE, which in the template contains only the *show_condition* SKETCHPAD (see %FigCounterbalancingOSWebJATOS).\n\n%--\nfigure:\n    source: counterbalancing-osweb-jatos.png\n    id: FigCounterbalancingOSWebJATOS\n    caption: |\n        The overview area of the template experiment for implementing counterbalancing with JATOS Batch Session Data.\n--%\n\nWhen importing the experiment into JATOS, all conditions should be specified in the Batch Session Data as the `pending` list (under Worker & Batch Manager; see %FigBatchSessionData). Each condition from `pending` corresponds to a single experimental session; therefore, if condition `a` should be used for two experimental sessions, then `a` needs to occur twice in the `pending` list. The conditions are used in the order in which they are defined.\n\n%--\nfigure:\n    source: batch-session-data.png\n    id: FigBatchSessionData\n    caption: |\n        The conditions should be specified in the Batch Session Data in JATOS.\n--%\n\nAt the start of an experimental session, a single condition is moved from `pending` to `started`. (When the `pending` list is empty, the participant is informed that he or she can no longer participate in the experiment.) At the end of the experimental session, the condition is appended to the `finished` list.\n\nTo make this more concrete, let's say that you've defined the Batch Session Data as shown in %FigBatchSessionData. Then, four experimental sessions are started, but the second experimental session, with condition `a`, never finishes, for example because the participant closes the browser halfway the experiment. The Batch Session Data will then look as in %FigBatchSessionAfter:\n\n%--\nfigure:\n    source: batch-session-data-after.png\n    id: FigBatchSessionAfter\n    caption: |\n        The Batch Session Data after all conditions have been consumed. One session, with condition `a`, never finished.\n--%\n\nYou can tell from the Batch Session Data that one experimental session started with condition `a` but never finished. To nevertheless collect an experimental session with this condition, you have to manually add a new `a` to the `pending` list and collect a new session.", "url": "https://osdoc.cogsci.nl/4.0/manual/counterbalancing", "title": "Counterbalancing"}
{"content": "# Variables\n\ntitle: Variables\n\n[TOC]\n\n## What is an experimental variable in OpenSesame?\n\nExperimental variables in OpenSesame are those variables that:\n\n- You can refer to in the user interface with the '{variable_name}' syntax.\n- Are available as global variables in a Python INLINE_SCRIPT.\n- Are available as global variables in a JavaScript INLINE_JAVASCRIPT.\n- Contain things like:\n\t- The variables that you have defined in a LOOP item.\n\t- The responses that you have collected.\n\t- Various properties of the experiment.\n\t- Etc.\n\n## The variable inspector\n\nThe variable inspector (`Ctrl+I`) provides an overview of available variables (%FigVariableInspector). When the experiment is not running, this overview is based on a best guess of which variables will become available during the experiment. However, when the experiment is running, the variable inspector shows a live overview of variables and their values. This is useful for debugging your experiment.\n\n%--\nfigure:\n id: FigVariableInspector\n source: variable-inspector.png\n caption: The variable inspector provides an overview of all variables that OpenSesame knows about.\n--%\n\n## Defining variables\n\nThe simplest way to define a variable is through the LOOP item. For example, %FigLoop shows how to define a variable named `gaze_cue`. In this example, *trial_sequence* item is called four times while `gaze_cue` is 'left' and another four times while 'gaze_cue' is 'right'.\n\n%--\nfigure:\n id: FigLoop\n source: defining-variables-in-a-loop.png\n caption: The most common way to define independent variables is using the LOOP table.\n--%\n\n## Built-in variables\n\nThe following variables are always available:\n\n### Experiment variables\n\n|Variable name\t\t\t|Description|\n|-----------------------|-----------|\n|`title`\t\t\t\t|The title of the experiment|\n|`description`\t\t\t|The description of the experiment|\n|`foreground`\t\t\t|The default foreground color. E.g., 'white' or '#FFFFFF'.|\n|`background`\t\t\t|The default background color. E.g., 'black' or '#000000'.|\n|`height`\t\t\t\t|The height-part of the display resolution. E.g., '768'|\n|`width`\t\t\t\t|The width-part of the display resolution. E.g., '1024'|\n|`subject_nr`\t\t\t|The subject number, which is asked when the experiment is started.|\n|`subject_parity`\t\t|Is 'odd' if `subject_nr` is odd and 'even' if `subject_nr` is even. Useful for counterbalancing.|\n|`experiment_path`\t\t|The folder of the current experiment, without the experiment filename itself. If the experiment is unsaved, it has the value `None`.|\n|`pool_folder`\t\t\t|The folder where the contents of the file pool have been extracted to. This is generally a temporary folder.|\n|`logfile`\t\t\t\t|The path to the logfile.|\n\n### Item variables\n\nThere are also variables that keep track of all the items in the experiment.\n\n|Variable name\t\t\t|Description|\n|-----------------------|-----------|\n|`time_[item_name]`\t\t|Contains a timestamp of when the item was last executed. For SKETCHPAD items, this can be used to verify the timing of display presentation.|\n|`count_[item_name]`\t|Is equal the number of times minus one (starting at 0, in other words) that an item has been called. This can, for example, be used as a trial or block counter.|\n\n### Response variables\n\nWhen you use the standard response items, such as the KEYBOARD_RESPONSE and MOUSE_RESPONSE, a number of variables are set based on the participant's response.\n\n|Variable name\t\t\t\t\t|Description|\n|-------------------------------|-----------|\n|`response`\t\t\t\t\t\t|Contains the last response that has been given.|\n|`response_[item_name]`\t\t\t|Contains the last response for a specific response item. This is useful in case there are multiple response items.|\n|`response_time`\t\t\t\t|Contains the interval in milliseconds between the start of the response interval and the last response.|\n|`response_time_[item_name]`\t|Contains the response time for a specific response item.|\n|`correct`\t\t\t\t\t\t|Is set to '1' if the last `response` matches the variable `correct_response`, '0' if not, and 'undefined' if the variable `correct_response` has not been set.|\n|`correct_[item_name]`\t\t\t|As `correct` but for a specifc response item.|\n\n### Feedback variables\n\nFeedback variables maintain a running average of accuracy and response times.\n\n|Variable name\t\t\t\t\t|Description|\n|-------------------------------|-----------|\n|`average_response_time`\t\t|The average response time. This is variable is useful for presenting feedback to the participant.|\n|`avg_rt`\t\t\t\t\t\t|Synonym for `average_response_time`|\n|`accuracy`\t\t\t\t\t\t|The average percentage of correct responses. This is variable is useful for presenting feedback to the participant.|\n|`acc`\t\t\t\t\t\t\t|Synonym for `accuracy`|\n\n\n## Using variables in the user interface\n\nWherever you see a value in the user interface, you can replace that value by a variable using the '{variable name}' notation. For example, if you have defined a variable `soa` in a LOOP item, you can use this variable for the duration of a sketchpad as shown in %FigSketchpad.\n\n%--\nfigure:\n id: FigSketchpad\n source: variable-duration.png\n caption: The duration '{soa}' indicates that the duration of the SKETCHPAD depends on the variable `soa`.\n--%\n\nThis works throughout the user interface. For example, if you have the defined a variable `my_freq`, you can use this variable as the frequency in a SYNTH item, as shown in %FigSynth.\n\n%--\nfigure:\n id: FigSynth\n source: variable-frequency.png\n caption: The frequency '{my_freq}' indicates that the frequency of the SYNTH depends on the variable `my_freq`.\n--%\n\nSometimes, the user interface doesn't let you type in arbitrary text. For example, the elements of a SKETCHPAD are shown visually, and you cannot directly change an X coordinate to a variable. However, you can click on the *Select view \u2192 View script* button on the top right, and edit the script directly.\n\nFor example, you can change the position of a fixation dot from the center:\n\n```text\ndraw fixdot x=0 y=0\n```\n\n\u2026 to a position defined by the variables `xpos` and `ypos`:\n\n```text\ndraw fixdot x={xpos} y={ypos}\n```\n\n\n## Using Python expressions in the user interface\n\nWhen referring to variables using the `{my_var}` notation, you are in fact using a so-called [f-string](https://peps.python.org/pep-0498/), which is a way to embed Python code in strings of text. You can also use f-strings to evaluate arbitrary Python code. For example, you can multiply the variables `width` and `height` and include the result in a SKETCHPAD, like so:\n\n%--\nfigure:\n id: FigFString\n source: fstrings.png\n caption: You can embed Python expressions using f-strings.\n--%\n\nf-strings are Python code, and are therefore only supported on the desktop, but see below for a JavaScript alternative for browser experiments.\n\n\n## Using JavaScript expressions in the user interface\n\nWhen using OSWeb, expressions included between curly braces are interpreted as [template literals](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Template_literals). This is very similar to f-strings in Python, with the important difference that it uses JavaScript.\n\nIn normal JavaScript, expressions inside template literals are prefixed with a `$`, like so: `${expression}`. This is allowed in OpenSesame but not necessary: the prefix is automatically added to improve compatibility between browser and desktop experiments. In most cases, as in the figure below, the exact same expression is valid as a Python f-string on the desktop and a JavaScript template literal in the browser.\n\n\n%--\nfigure:\n id: FigTempalteLiteral\n source: template-literals.png\n caption: You can embed JavaScript expressions using template literals.\n--%\n\n\n## Using variables in Python\n\nIn an INLINE_SCRIPT, experimental variables are available as global variables. For example, if you have defined `example_variable` in a LOOP, then the following will print the value `example_variable` to the debug window:\n\n~~~ .python\nprint(example_variable)\n~~~\n\nYou can set the experimental variable `example_variable` to the value 'some value' as follows:\n\n~~~ .python\nexample_variable = 'some value'\n~~~\n\n\n## Using variables in JavaScript\n\nIn an INLINE_JAVASCRIPT, experimental variables are available as global variables. For example, if you have defined `example_variable` in a LOOP, then the following will print the value `example_variable` to the browser console:\n\n```js\nconsole.log(example_variable)\n```\n\nYou can set the experimental variable `example_variable` to the value 'some value' as follows:\n\n```js\nexample_variable = 'some value'\n```\n\n\n## Using conditional (\"if\") statements\n\nConditional statements, or 'if statements', provide a way to indicate that something should happen only under specific circumstances, such when some variable has a specific value. Conditional statements are regular Python expressions.\n\nThe most commonly used if-statement in OpenSesame is the run-if statement of the SEQUENCE, which allows you to specify the conditions under which a particular element is executed. If you open a SEQUENCE item, you see that every item from the sequence has a 'Run if \u2026'' option. The default value is 'always', which means that the item is always run; but you can also enter a condition here. For example, if you want to show a green fixation dot after a correct response, and a red fixation dot after an incorrect response, you can create a SEQUENCE like the following (this makes use of the fact that a KEYBOARD_RESPONSE item automatically sets the `correct` variable, as discussed above) as shown in %FigRunIf.\n\n*Important:* Run-if statements only apply to the Run phase of items. The Prepare phase is always executed. See also [this page](%link:prepare-run%).\n\n%--\nfigure:\n id: FigRunIf\n source: run-if.png\n caption: |\n  'Run if' statements can be used to indicate that certain items from a SEQUENCE should only be executed under specific circumstances.\n--%\n\nYou can use more complex conditions as well. Let's take a look at a few examples:\n\n```python\ncorrect == 1 and response_time > 2000\ncorrect != 1 or response_time > max_response_time or response_time < min_response_time\n```\n\nThe same principle applies to 'Show if' fields in SKETCHPAD items. For example, if you want to draw a right-upwards-pointing arrow only if the variable `quadrant` has been set to 'upper right', simply type the proper condition in the 'Show if ...' field and draw the arrow, as in %FigShowIf. Make sure that you draw the arrow after you have set the condition.\n\n%--\nfigure:\n id: FigShowIf\n source: show-if.png\n caption: \"'Show if' statements can be used to indicate that certain elements from a SKETCHPAD or FEEDBACK item should only be shown under specific circumstances.\"\n--%\n\nImportant: The moment at which a conditional statement is evaluated may affect how your experiment works. This is related to the prepare-run strategy employed by OpenSesame, which is explained here:\n\n- %link:prepare-run%", "url": "https://osdoc.cogsci.nl/4.0/manual/variables", "title": "Variables"}
{"content": "# Examples\n\ntitle: Examples\n\nExample experiments are included with OpenSesame. A list of curated examples is available through Menu \u2192 Tools \u2192 Example experiments. You can also search for publicly available experiments on the OpenScienceFramework by using 'osexp' as search term.\n\n- <https://osf.io/search/?q=osexp>", "url": "https://osdoc.cogsci.nl/4.0/manual/examples", "title": "Examples"}
{"content": "# Mouse tracking\n\ntitle: Mouse tracking\n\nMousetrap is a third-party plugin, and is not maintained by the OpenSesame team.\n{: .alert .alert-info}\n\n## About\n\nPascal Kieslich and Felix Henninger have developed the [mousetrap plugins](https://github.com/PascalKieslich/mousetrap-os) for OpenSesame [(Kieslich & Henninger, 2017)](https://dx.doi.org/10.3758/s13428-017-0900-z). These plugins allow you to track the movement of the mouse cursor, which has been used to investigate the time course of cognitive processes in many psychological domains [(Freeman, Dale, & Farmer, 2011)](https://dx.doi.org/10.3389/fpsyg.2011.00059).\n\nMousetrap offers two plugins for mouse tracking in OpenSesame that can be included in the experiment via drag-and-drop.\nThe [mousetrap response plugin](https://github.com/PascalKieslich/mousetrap-os/blob/master/plugins/mousetrap_response/mousetrap_response.md) tracks mouse movements while another stimulus (e.g., a sketchpad) is shown, analogous to a keyboard or mouse response item.\nThe [mousetrap form plugin](https://github.com/PascalKieslich/mousetrap-os/blob/master/plugins/mousetrap_form/mousetrap_form.md) allows for tracking of mouse movements in [custom forms](%link:manual/forms/custom%).\nBesides, both plugins also provide Python classes, which can be used in Python inline scripts for maximum customizability.\n\nOnce data have been collected with the plugins, the data can be processed, analyzed and visualized using the [mousetrap R package](http://pascalkieslich.github.io/mousetrap/).\n\n## Installation\n\nInformation about how to install the mousetrap plugin can be found on its [GitHub page](https://github.com/PascalKieslich/mousetrap-os#installation). A number of example experiments that demonstrate the basic features are available in the [examples folder](https://github.com/PascalKieslich/mousetrap-os/tree/master/examples#example-experiments).\n\n\nSee also:\n\n- <https://rapunzel.cogsci.nl/manual/environment/>", "url": "https://osdoc.cogsci.nl/4.0/manual/mousetracking", "title": "Mouse tracking"}
{"content": "# Running experiments online\n\ntitle: Running experiments online\n\n\nThis page has been moved to:\n\n- %link:manual/osweb/workflow%", "url": "https://osdoc.cogsci.nl/4.0/manual/osweb", "title": "Running experiments online"}
{"content": "# Integration with the Open Science Framework\n\ntitle: Integration with the Open Science Framework\n\n[TOC]\n\n## About\n\nThe OpenScienceFramework extension connects OpenSesame to the [Open Science Framework](https://osf.io) (OSF), which is a web platform for sharing, connecting, and streamlining scientific workflows. To use this extension, [you need an OSF account](https://osf.io/login/?sign_up=True).\n\nWith the OpenScienceFramework extension, you can:\n\n- Automatically save your experiment to the OSF\n- Automatically upload data to the OSF\n- Open experiments from the OSF\n- Share your experiment and data with other researchers, by giving them access through the OSF\n\n## Logging in to the OSF\n\nTo log into the OSF:\n\n- Create an account on <https://osf.io>. (You cannot create an account from within OpenSesame.)\n- In OpenSesame, click on the log-in button in the main toolbar, and enter your credentials.\n- Once logged in, you can open the OSF Explorer by clicking on your name where the login button used to be, and selecting *Show explorer*. The explorer will show an overview of all your OSF projects, and all repositories/ cloud services that are linked to your projects.\n\n## Linking an experiment to the OSF\n\nIf you link an experiment to the OSF, each time that you save the experiment in OpenSesame, a new version is also uploaded to the OSF.\n\nTo link an experiment:\n\n- Save the experiment on your computer.\n- Open the OSF explorer and select a folder or repository where you would like your experiment to be stored on the OSF. Right-click on this folder and select *Sync experiment to this folder*. The OSF node to which the experiment is linked will be shown at the top of the explorer.\n- The experiment is then uploaded to the selected location.\n- If you check *Always upload experiment on save*, a new version is automatically saved to OSF on each save; if you don't enable this option, you will be asked every time whether or not you want to do this.\n\nTo unlink an experiment:\n\n- Open the OSF explorer, and click the *Unlink* button next to the *Experiment linked to* link.\n\n## Linking data to the OSF\n\nIf you link data to the OSF, each time that data has been collected (normally after every experimental session), this data is also uploaded to the OSF.\n\nTo link data to the OSF:\n\n- Save the experiment on your computer.\n- Open the OSF explorer, right-click on the folder that you want the data to be uploaded to, and select *Sync data to this folder*. The OSF node that the data is linked to will be shown at the top of the explorer.\n- If you check *Always upload collected data*, data files will be automatically saved to OSF after they have been collected; if you don't enable this option, you will be asked every time whether or not you want to do this.\n\nTo unlink data from the OSF:\n\n- Open the OSF explorer, and click the *Unlink* button next to the *Data stored to* link.\n\n## Opening an experiment stored on the OSF\n\nTo open an experiment from the OSF:\n\n- Open the OSF explorer, and find the experiment.\n- Right-click on the experiment and select *Open experiment*.\n- Save the experiment on your computer.\n\n## Handling non-matching versions\n\nIf you open an experiment on your computer that is linked to the OSF, but differs from the version on the OSF, you will be asked what you want to do:\n\n- Use the version from your computer; or\n- Use the version from the OSF. If you choose to use the version from the OSF, it will be downloaded and overwrite the experiment on your computer.\n\n## Installing the OpenScienceFramework extension\n\nThe OpenScienceFramework extension is installed by default in the Windows package of OpenSesame. If the extension is not installed, you can install it as follows:\n\nFrom PyPi:\n\n~~~\npip install opensesame-extension-osf\n~~~\n\nIn an Anaconda environment\n\n~~~\nconda install -c cogsci opensesame-extension-osf\n~~~\n\nThe source code of the extension is available on GitHub:\n\n- <https://github.com/dschreij/opensesame-extension-osf>\n\nAnd for the `python-qosf` module, which is used by the extension:\n\n- <https://github.com/dschreij/python-qosf>", "url": "https://osdoc.cogsci.nl/4.0/manual/osf", "title": "Integration with the Open Science Framework"}
{"content": "# Installing packages, plugins, and extensions\n\ntitle: Installing packages, plugins, and extensions\n\n\nThis page has moved to:\n\n- <https://rapunzel.cogsci.nl/manual/environment/>", "url": "https://osdoc.cogsci.nl/4.0/manual/environment", "title": "Installing packages, plugins, and extensions"}
{"content": "# Using the interface\n\ntitle: Using the interface\n\nOpenSesame has a powerful graphical interface that consists of several components (%FigInterface).\n\n%--\nfigure:\n id: FigInterface\n source: interface.png\n caption: The OpenSesame user interface.\n--%\n\n\n[TOC]\n\n## Toolbars and menubar\n\n### The menubar\n\nThe menubar (%FigMenubar) is shown at the top of the window, or, on some operating systems, is integrated into the border around the window. The menubar contains general functionality, such as saving and opening experiments, running experiments, etc.\n\n%--\nfigure:\n id: FigMenubar\n source: menubar.png\n caption: The menubar.\n--%\n\n### The main toolbar\n\nThe main toolbar (%FigMainToolbar) is (by default) shown at the top of the window, just below the menubar. The main toolbar contains a selection of the most relevant functionality from the menubar.\n\n%--\nfigure:\n id: FigMainToolbar\n source: main-toolbar.png\n caption: The main toolbar.\n--%\n\n### The item toolbar\n\nThe item toolbar (%FigItemToolbar) is (by default) shown at the left of the window. The item toolbar contains all items, that is, all building blocks of an experiment. You can add items to your experiment by dragging them from the item toolbar into the overview area.\n\n%--\nfigure:\n id: FigItemToolbar\n source: item-toolbar.png\n caption: The item toolbar.\n--%\n\n## The tab area\n\nThe tab area is the central part of the window (%FigTabArea). The tab area is where item controls, documentation, important messages, etc. are shown. The tab area can contain multiple tabs, and functions much like a tabbed web browser.\n\n%--\nfigure:\n id: FigTabArea\n source: tab-area.png\n caption: The tab area.\n--%\n\n## The overview area\n\nThe overview area (%FigOverviewArea) is (by default) shown at the left of the window, to the right of the item toolbar. The overview area shows the structure of your experiment as a tree. You can re-order the items in your experiment by dragging them from one position to another in the overview area.\n\n- Shortcut to hide/ show: `Ctrl+\\`\n\n%--\nfigure:\n id: FigOverviewArea\n source: overview-area.png\n caption: The overview area.\n--%\n\n## The file pool\n\nThe file pool (%FigFilePool) is (by default) shown at the right of the window. It provides an overview of all files that are bundled with the experiment.\n\n- Shortcut to hide/ show: `Ctrl+P`\n\n%--\nfigure:\n id: FigFilePool\n source: file-pool.png\n caption: The file pool.\n--%\n\n## The debug window\n\nThe debug window (%FigDebugWindow) is (by default) shown at the bottom of the window. It provides an [IPython interpreter](https://ipython.org/), and is used as the standard output while an experiment is running. That is, if you use the Python `print()` function, the result will be printed to the debug window.\n\n- Shortcut to hide/ show: `Ctrl+D`\n\n%--\nfigure:\n id: FigDebugWindow\n source: debug-window.png\n caption: The debug window.\n--%\n\n## The variable inspector\n\nThe variable inspector (%FigVariableInspector) is (by default) shown at the right of the window. It provides a list of all variables that are detected in your experiment. When you are running an experiment, the variable inspector also provides a real-time overview of variables and their values.\n\n- Shortcut to hide/ show: `Ctrl+I`\n\n%--\nfigure:\n id: FigVariableInspector\n source: variable-inspector.png\n caption: The variable inspector.\n--%\n\n## Keyboard shortcuts\n\nThe keyboard shortcuts listed below are default values. Many of them can be changed through *Menu \u2192 Tools \u2192 Preferences*.\n\n### General shortcuts\n\nThe following keyboard shortcuts are available everywhere:\n\n- Quick switcher: `Ctrl+Space`\n- Command palette: `Ctrl+Shift+P`\n- New experiment: `Ctrl+N`\n- Open experiment: `Ctrl+O`\n- Save experiment: `Ctrl+S`\n- Save experiment as: `Ctrl+Shift+S`\n- Undo: `Ctrl+Alt+Z`\n- Redo: `Ctrl+Alt+Shift+Z`\n- Run experiment fullscreen: `Ctrl+R`\n- Run experiment in window: `Ctrl+W`\n- Quick-run experiment: `Ctrl+Shift+W`\n- Test experiment in browser: `Alt+Ctrl+W`\n- Show/ hide overview area: `Ctrl+\\`\n- Show/ hide debug window: `Ctrl+D`\n- Show/ hide file pool: `Ctrl+P`\n- Show/ hide variable inspector: `Ctrl+I`\n- Focus overview area: `Ctrl+1`\n- Focus tab area: `Ctrl+2`\n- Focus debug window: `Ctrl+3`\n- Focus file pool: `Ctrl+4`\n- Focus variable inspector: `Ctrl+5`\n\n### Editor shortcuts\n\nThe following keyboard shortcuts are available in editor components, such as the INLINE_SCRIPT:\n\n- (Un)comment selected line(s): `Ctrl+/`\n- Find text: `Ctrl+F`\n- Replace text: `Ctrl+H`\n- Hide find/ replace dialog: `Escape`\n- Duplicate line: `Ctrl+Shift+D`\n- Undo: `Ctrl+Z`\n- Redo: `Ctrl+Shift+Z`\n- Copy: `Ctrl+C`\n- Cut: `Ctrl+X`\n- Paste: `Ctrl+V`\n\n### Tab-area shortcuts\n\nThe following keyboard shortcuts are available in the tab area:\n\n- Next tab: `Ctrl+Tab`\n- Previous tab: `Ctrl+Shift+Tab`\n- Close other tabs: `Ctrl+T`\n- Close all tabs: `Ctrl+Alt+T`\n- Close current tab: `Alt+T`\n\n### Overview-area and sequence shortcuts\n\nThe following keyboard shortcuts are available in the overview area and the SEQUENCE item:\n\n- Context menu: `+`\n- Copy item (unlinked): `Ctrl+C`\n- Copy item (linked): `Ctrl+Shift+C`\n- Paste item: `Ctrl+V`\n- Delete item: `Del`\n- Permanently delete item: `Shift+Del`\n- Rename: `F2`\n- Change run-if statement (if applicable): `F3`", "url": "https://osdoc.cogsci.nl/4.0/manual/interface", "title": "Using the interface"}
{"content": "# Runtime for Android\n\ntitle: Runtime for Android\n\n\n__Important note:__ The OpenSesame runtime for Android is based on software by others that is no longer developed. As a result, we are unable to make sure that the runtime works with recent versions of Android. Windows 10 tablets with Intel processors are a good alternative.\n{: .alert .alert-warning}\n\n\n[TOC]\n\n\n## OpenSesame runtime for Android\n\n### Download\n\nYou can download the OpenSesame runtime for Android through the Google Play Store:\n\n<a href=\"https://play.google.com/store/apps/details?id=nl.cogsci.opensesame\" style=\"border:none;\">\n  <img alt=\"Get it on Google Play\"\n       src=\"https://developer.android.com/images/brand/en_generic_rgb_wo_45.png\" />\n</a>\n\n### Usage\n\nWhen you start the OpenSesame runtime, you will be asked where your experiments are located. By default, OpenSesame assumes that they are in the `/sdcard/` folder, or (if it exists) in the `/sdcard/Experiments/` folder. If you have no experiments on your device, pressing `enter` will show the example experiments that are bundled with the `.apk`.\n\nThe `Back` button serves the same purpose as the `Escape` key on regular systems, and will exit OpenSesame.\n\n### Supported devices\n\nOpenSesame is developed with the Nexus 4 and 9 as reference devices. In general, any device that runs Android 2.2. 'Froyo' or later appears to work.\n\n### Disabling automatic updates\n\nIf you are using the OpenSesame runtime for Android in a production environment (e.g., while you are running an experiment), it is recommended to disable the Auto-update feature of the Google Play Store, at least for OpenSesame. This will prevent the app from being updated and potentially changing its behavior. In case you need to downgrade to a previous version of the Android runtime, you can find the `.apk` files for previous releases [here](https://github.com/smathot/OpenSesame/releases).\n\n### Automatically start an experiment\n\nIf you want to directly launch a specific experiment when the OpenSesame runtime for Android is started, you can create a file called `opensesame-autorun.yml` in the `/sdcard/` folder of your device. This is a YAML file with the following structure:\n\n~~~\nexperiment: /sdcard/experiments/my_experiment.opensesame\nsubject_nr: 3\nlogfile: /sdcard/data/subject03.csv\n~~~\n\n## Developing experiments for Android\n\n### backend\n\nThe OpenSesame runtime for Android requires the *droid* backend.\n\n### Design tips\n\nImplement most user interactions through the MOUSE_RESPONSE item or TOUCH_RESPONSE plugin. In general, screen touches are registered as mouse clicks. Using keyboard input will work as well, but it will show and hide the virtual keyboard after every key that is entered, which looks messy.\n\nThe resolution for the DROID backend is fixed at 1280x800 (landscape). On Android, your experiment will be automatically scaled up or down depending on the resolution of the device, but the resolution that you design with is always 1280x800.\n\n### Debugging\n\nDebug output is written to `/sdcard/opensesame-debug.txt`.\n\n### Limitations\n\n- The SYNTH item and `openexp.synth` module are not functional.\n- The SAMPLER item and `openexp.sampler` module will ignore panning and pitching.\n\n## Know issue: Frozen or misbehaving virtual keyboard\n\nOn some devices, the default virtual keyboard is unresponsive (i.e. it shows but doesn't respond to taps) or doesn't respond normally. This appears to happen on phones with recent versions of Android. To work around this issue, you can install a third-party keyboard. Keyboards that have been reported to work are:\n\n- [GO Keyboard](https://play.google.com/store/apps/details?id=com.jb.emoji.gokeyboard&hl=en)\n- [Smart Keyboard Trial](https://play.google.com/store/apps/details?id=net.cdeguet.smartkeyboardtrial&hl=en)\n\n## Available Python modules\n\nBelow is a list of Python modules that should be available in the OpenSesame runtime for android. (This list is copied from the pgs4a now-defunct website.)\n\n~~~\npygame\npygame.base\npygame.bufferproxy\npygame.colordict\npygame.color\npygame.compat\npygame.constants\npygame.cursors\npygame.display\npygame.draw\npygame.event\npygame.fastevent\npygame.font\npygame.gfxdraw\npygame.imageext\npygame.image\npygame.joystick\npygame.key\npygame.locals\npygame.mask\npygame.mouse\npygame.overlay\npygame.rect\npygame.rwobject\npygame.sprite\npygame.surface\npygame.surflock\npygame.sysfont\npygame.time\npygame.transform\npygame.version\n_abcoll\nabc\naliases\narray\nast\natexit\nbase64\nbisect\nbinascii\ncalendar\ncmath\ncodecs\ncollections\ncompileall\ncontextlib\ncopy\ncopy_reg\ncStringIO\ncPickle\ndatetime\ndifflib\ndis\ndummy_threading\ndummy_thread\nencodings\nencodings.raw_unicode_escape\nencodings.utf_8\nencodings.zlib_codec\nerrno\nfcntl\nfnmatch\nfunctools\n__future__\ngenericpath\ngetopt\nglob\ngzip\nhashlib\nheapq\nhttplib\ninspect\nitertools\nkeyword\nlinecache\nmath\nmd5\nmimetools\nopcode\noptparse\nos\noperator\nparser\npickle\nplatform\nposix\nposixpath\npprint\npy_compile\npwd\nQueue\nrandom\nrepr\nre\nrfc822\nselect\nsets\nshlex\nshutil\nsite\nsocket\nsre_compile\nsre_constants\nsre_parse\nssl\nstat\nStringIO\nstring\nstruct\nsubprocess\nsymbol\nsymtable\nstrop\ntarfile\ntempfile\ntextwrap\n_threading_local\nthreading\ntime\ntokenize\ntoken\ntraceback\ntypes\nurllib\nurllib2\nurlparse\nUserDict\nwarnings\nweakref\nwebbrowser\nzipfile\nzipimport\nzlib\n~~~\n\n[google-play]: https://play.google.com/store/apps/details?id=nl.cogsci.opensesame\n[forum]: http://forum.cogsci.nl/index.php?p=/discussion/333/a-video-of-opensesame-running-natively-on-android\n[droid]: /backends/droid\n[pgs4a]: http://pygame.renpy.org/", "url": "https://osdoc.cogsci.nl/4.0/manual/android", "title": "Runtime for Android"}
{"content": "# OpenSesameRun (no GUI)\n\ntitle: OpenSesameRun (no GUI)\n\n## About\n\n`opensesamerun` is a simple tool that allows you to execute OpenSesame experiments with a minimal GUI, or directly, by specifying all necessary options via the command line. A minimal GUI will automatically appear if not all command line options have been specified, notably the experiment file, the subject number, and the log file.\n\n~~~\nUsage: opensesamerun [experiment] [options]\n\nOptions:\n  --version             show program's version number and exit\n  -h, --help            show this help message and exit\n\n  Subject and log file options:\n    -s SUBJECT, --subject=SUBJECT\n                        Subject number\n    -l LOGFILE, --logfile=LOGFILE\n                        Logfile\n\n  Display options:\n    -f, --fullscreen    Run fullscreen\n    -c, --custom_resolution\n                        Do not use the display resolution specified in the\n                        experiment file\n    -w WIDTH, --width=WIDTH\n                        Display width\n    -e HEIGHT, --height=HEIGHT\n                        Display height\n\n  Miscellaneous options:\n    -d, --debug         Print lots of debugging messages to the standard\n                        output\n    --stack             Print stack information\n\n  Miscellaneous options:\n    --pylink            Load PyLink before PyGame (necessary for using the\n                        Eyelink plug-ins in non-dummy mode)\n~~~\n\n## Example\n\nLet's say that you want to run the gaze cuing example experiment, for subject #1, and save the log file in your Documents folder (this example assumes Linux, but it works analogously on other platforms):\n\n~~~\nopensesamerun /usr/share/opensesame/examples/gaze_cuing.opensesame.tar.gz -s 1 -l /home/sebastiaan/Documents/subject1.tsv -f \n~~~\n\n\n## Alternative `libopensesame`\n\nYou can also start experiments without using the GUI through the `libopensesame` Python module:\n\n- %link:manual/python/nogui%", "url": "https://osdoc.cogsci.nl/4.0/manual/opensesamerun", "title": "OpenSesameRun (no GUI)"}
{"content": "# Debugging\n\ntitle: Debugging\n\nWhile designing a new experiment, you will inevitably encounter bugs. Bugs can manifest as crashes accompanied by error messages, or as unexpected behaviors without any explicit error message.\n\nDebugging, the art and skill of diagnosing and rectifying these errors and unanticipated behaviors, is a critical part of the experimental design process.\n\n\n[TOC]\n\n\n## Debugging in the user interface\n\n### Using the variable inspector\n\nThe Variable Inspector in OpenSesame provides an overview of all variables that are currently active within your experiment. This includes:\n\n- Variables explicitly defined in the user interface, typically in a LOOP item.\n- Response variables, which are set by various response items such as a KEYBOARD_RESPONSE item.\n- Variables that are defined using Python INLINE_SCRIPT items.\n\nWhen an experiment is running, the Variable Inspector dynamically updates, providing a live overview of variables and their values. This feature allows you to monitor the behavior of your experiment in real-time, assisting you in identifying any potential issues or bugs.\n\nFor example, consider a situation where you have defined a variable `left_letter` to define which letter should appearing on the left side of a SKETCHPAD. However, during execution, you notice a mismatch in the Variable Inspector: `left_letter` is actually being shown on the right side of your display. This is indicates a bug such that you have misplaced the right and left letters on the SKETCHPAD.\n\n%--\nfigure:\n id: FigVariableInspector\n source: variable-inspector.png\n caption: You can use the variable inspector to check whether your experiment behaves as it should. In this example, there is a bug such that the letter that is defined through the variable `left_letter` actually appears on the right and vice versa.\n--%\n\nUsing the Variable Inspector regularly to monitor variables helps ensure that your experiment is behaving as expected and aids in identifying problems early on.\n\n\n### Printing debug messages to the IPython/ Jupyter console\n\nThe Python `print()` function is a simple-yet-powerful debugging tool when used inside INLINE_SCRIPT items, and serves a similar purpose to the Variable Inspector. For instance, you can print the values of the variables `left_letter` and `right_letter` during the Prepare phase of an INLINE_SCRIPT at the beginning of each trial.\n\nTo view these debug messages, open the Jupyter/ IPython console and monitor the output while running the experiment. By doing so, you can verify whether the output displayed in the console aligns with the experiment's actual behavior.\n\n%--\nfigure:\n id: FigPrintingOutput\n source: printing-output.png\n caption: The Python `print()` function can be used to output debug messages to the console.\n--%\n\nIn the above example, it becomes evident that the letter assigned to the `left_letter` variable (hence expected to appear on the left) is actually appearing on the right, and vice versa.\n\n\n### Interpreting user-interface error messages\n\nWhen a bug in your experiment causes a crash, OpenSesame displays an error message, also referred to as an 'Exception'. An error message typically consists of the following components:\n\n- **Error type:** Indicates the general class of error. In the example below this is an `FStringError`.\n- **Description:** Provides a more specific explanation of what triggered the error. In this case, 'Failed to evaluate \u2026'.\n- **Source:** Specifies the item that triggered the error and whether it occurred during the Run or Prepare phase.\n- **Traceback:** A detailed Python error message. This information is only shown if the error occurred while evaluating custom Python code, which includes INLINE_SCRIPT items, but also conditional expressions (e.g. run-if expressions), and text with embedded variable references.\n- **Learn more about this error:** An interactive button you can click to get more detailed information about the error message.\n\nLet's look at an example to better understand these components and learn how to fix a common error:\n\n%--\nfigure:\n id: FigFStringError\n source: fstring-error.png\n caption: An `FStringError` indicates an issue when trying to evaluate a text string containing a Python expression.\n--%\n\nThis is an `FStringError`, which means there was an issue while interpreting a text string that includes a Python expression. In this example, the problematic text is `{right_leter}`. Anything enclosed within curly braces is interpreted as a Python expression, and therefore in this case the Python expression is `right_leter`\u2014which is simply a variable name. Trying to evaluate the Python expression `right_leter` triggered a `NameError` because `right_leter` is not defined.\n\nThat's pretty technical, but what exactly went wrong here in simple terms? The issue arises from referring to a non-existent variable: `right_leter`. Looking at the variable name, it seems likely that there's a typo: the intended variable is likely `right_letter`, with a double 't'.\n\nWhere should we correct this mistake? The error message indicates that the source of the error is an item called *target*, which is a SKETCHPAD. To resolve the error, we need to open *target* and change the text from '{right_leter}' to '{right_letter}'. \n\n\n### Interpreting Python error messages\n\nIn Python, errors fall into two categories: syntax errors and exceptions (or runtime errors).\n\n\n#### Python syntax errors\n\nA syntax error occurs when the Python interpreter cannot parse code because it violates Python's syntax rules. This could be due to mismatched parentheses, missing commas, incorrect indentation, and so on. In OpenSesame, this results in a `PythonSyntaxError`.\n\n%--\nfigure:\n id: FigPythonSyntaxError\n source: python-syntax-error.png\n caption: A `PythonSyntaxError` is triggered when the code violates Python's syntax rules and cannot be parsed.\n--%\n\nThe error message above indicates that a syntax error has occurred on line 16 of the Prepare phase of an item named *constants*. Here's the problematic line:\n\n```python\ntarget_orientations = [('z', 0), ('/', 90]\n```\n\nThe message also hints at mismatched parentheses as the potential source of the error. Taking that into consideration, we can fix the issue by adding a missing parenthesis `)` before the closing bracket `]`:\n\n```python\ntarget_orientations = [('z', 0), ('/', 90)]\n```\n\n\n#### Python Exceptions\n\nWhen Python code is syntactically correct but encounters a problem during execution, an exception is raised. In OpenSesame, such exceptions result in a `PythonError`.\n\n%--\nfigure:\n id: FigPythonError\n source: python-error.png\n caption: A `PythonError` is triggered when an exception is raised during the execution of syntactically correct Python code.\n--%\n\nThe error message above indicates that a `NameError` was raised on line 2 of the Run phase of an item named *trial_script*. Specifically, the identifier 'clock_sleep' is not recognized. Looking at the error-causing line, it's apparent that we've used an underscore (`_`) instead of a dot (`.`), incorrectly implying that `clock_sleep()` is a function.\n\n```python\nclock_sleep(495)\n```\n\nTo rectify this, we should correctly reference the `sleep()` function as part of the `clock` object:\n\n```python\nclock.sleep(495)\n```\n\n## Debugging in a web browser (OSWeb)\n\n\n### Printing output to the browser console\n\nThe JavaScript `console.log()` function is a simple-yet-powerful debugging tool when used inside INLINE_JAVASCRIPT items. It serves a similar purpose to the Python `print()` function and the Variable Inspector, neither of which are available in OSWeb. For instance, you can print the values of the variables `left_letter` and `right_letter` during the Prepare phase of an INLINE_SCRIPT at the beginning of each trial.\n\nTo view these debug messages, you need to open the browser console. Here's how to do it in Chrome, Firefox, and Edge:\n\n- **Google Chrome:** Press Ctrl + Shift + J (Windows / Linux) or Cmd + Option + J (Mac).\n- **Mozilla Firefox:** Press Ctrl + Shift + K (Windows / Linux) or Cmd + Option + K (Mac).\n- **Microsoft Edge:** Press F12 to open the developer tools, then select the \"Console\" tab.\n\nOnce the console is open, you can monitor the output while running the experiment, allowing you to check whether the output displayed in the console aligns with the experiment's actual behavior.\n\n%--\nfigure:\n id: FigPrintingOutputOSWeb\n source: printing-output-osweb.png\n caption: The JavaScript `console.log()` function can be used to output debug messages to the browser console.\n--%\n\nIn the above example, it becomes evident that the letter assigned to the `left_letter` variable (which should appear on the left) is actually appearing on the right, and vice versa.\n\n\n### Understanding error messages\n\nWhen your browser-based experiment crashes, OSWeb will show an error message in the browser. An error message typically consists of the following components:\n\n- **Error type:** Indicates the general class of error. In this example below this is a `ReferenceError`.\n- **Description:** Provides a more specific explanation of what triggered the error. In this case, 'right_leter is not defined'.\n- **Source:** Specifies the item that triggered the error and whether it occurred during the Run or Prepare phase.\n- **Source script:** The JavaScript code that caused the error. This information is only shown if the error occurred while evaluating custom JavaScript, which includes INLINE_JAVASCRIPT items, but also conditional expressions (e.g. run-if expressions), and text with embedded variable references.\n\nLet's look at an example to better understand these components and learn how to fix a common error:\n\n%--\nfigure:\n id: FigOSWebError\n source: osweb-error.png\n caption: A `ReferenceError` indicates a reference to a non-existent variable or other non-existent object.\n--%\n\nThis is a `ReferenceError`, which indicates that the experiment refers to a non-existent variable or other non-existent object. In this example, the error arose from the text `${right_leter}`. Anything enclosed within curly braces and prefixed by a `$` is interpreted as JavaScript expression, and in this case, the JavaScript expression is `right_leter`\u2014which is simply a variable name. Trying to evaluate the JavaScript expression `right_leter` triggered a `ReferenceError` because `right_leter` is not defined.\n\nThat's pretty technical, but what exactly went wrong here in simple terms? The issue arises from referring to a non-existent variable: `right_leter`. Looking at the variable name, it seems likely that there's a typographical error: the intended variable is likely `right_letter`, with a double 't'.\n\nWhere should we correct this mistake? The error message indicates that the source of the error is an item called *target*, which is a SKETCHPAD. To resolve the error, we need to open *target* and change the text from '{right_leter}' to '{right_letter}'. \n\n\n### Using the `debugger` statement in INLINE_JAVASCRIPT items\n\nThe JavaScript `debugger` statement is a powerful tool for debugging `INLINE_JAVASCRIPT` items in OpenSesame/OSWeb experiments. It allows you to insert breakpoints in your code, causing the browser's JavaScript execution to pause at that point. This allows you to inspect the current state of the JavaScript workspace.\n\nUsing the `debugger` statement is straightforward. Simply insert the statement `debugger` on the line where you want to pause execution. For example:\n\n```javascript\nconsole.log(`left_letter = ${left_letter}`)\nconsole.log(`right_letter = ${right_letter}`)\ndebugger // Execution will pause here\n```\n\nOnce you've inserted the `debugger` statement into your code, you need to open the browser console as explained above. After you open the browser console, run your experiment. When the JavaScript interpreter reaches the `debugger` statement, it will pause execution, and the developer tools will switch to the \"Sources\" (Chrome/Edge) or \"Debugger\" (Firefox) tab, highlighting the breakpoint line.\n\n%--\nfigure:\n id: FigJavaScriptDebugger\n source: javascript-debugger.png\n caption: When the JavaScript interpreter reaches the `debugger` statement, it will pause execution and allow you to inspect the JavaScript workspace. The `debugger` statement only works when the browser console is open.\n--%\n\nWhile execution is paused, you can inspect variable values, step through the code line by line, and investigate the call stack to better understand the state of your program at the breakpoint.\n\nRemember to remove or comment out the `debugger` statements when you're finished debugging, as leaving them in can interfere with the normal operation of your experiment.\n\n\n## Handling ExperimentProcessDied errors\n\nOccasionally, you might encounter an `ExperimentProcessDied` error during an experiment.\n\n%--\nfigure:\n id: FigExperimentProcessDied\n source: experiment-process-died.png\n caption: The `ExperimentProcessDied` error generally indicates an issue with the underlying Python process or associated libraries, not your experiment's code.\n--%\n\nThis error implies that the Python process in which the experiment was running terminated unexpectedly. It typically doesn't indicate a bug in your experiment, but rather suggests a problem in one of the low-level libraries used by OpenSesame, or even a bug in Python itself.\n\nDetermining the exact cause of this error can be challenging, and fixing it may be even more so. However, there are a few workarounds you can try to mitigate the issue:\n\n- **Change the backend:** Select a different backend under 'Run Experiment' in the experiment properties. This might resolve the issue as different backends use different sets of low-level libraries.\n- **Update OpenSesame and relevant packages:** Regularly updating OpenSesame and all associated packages can potentially resolve this issue, as bugs are routinely fixed in new versions.", "url": "https://osdoc.cogsci.nl/4.0/manual/debugging", "title": "Debugging"}
{"content": "# Logging and reading data files\n\ntitle: Logging and reading data files\n\nAlways triple check whether your data has been logged correctly before running your experiment!\n{: .page-notification}\n\n[TOC]\n\n\n## Using the logger item\n\nOpenSesame will not log your data automatically. Instead, you need to insert a LOGGER item, typically at the end of your trial sequence.\n\n%--\nfigure:\n id: FigLogger\n source: logger.png\n caption: |\n  The LOGGER item.\n--%\n\nThe simplest way to use the LOGGER is by leaving the option 'Automatically log all variables' enabled. That way, all variables that OpenSesame knows about are written the log file, except for those that are explicitly excluded (see below).\n\nYou can explicitly *include* which variables you want to log. The main reason for doing so is when you find that some variables are missing (because OpenSesame did not automatically detect them), or if you have disabled the option 'Automatically log all variables', \n\nYou can also explicitly exclude certain variables from the log file. The main reason for doing so is to keep the log files clean by excluding variables that are generally not useful.\n\nIn general, you should create only one logger item, and reuse that LOGGER at different locations in your experiment if necessary (i.e. use linked copies of the same LOGGER item). If you create multiple LOGGERs (rather than using a single LOGGER multiple times), they will all write to the same log file, and the result will be a mess!\n\n## Using Python inline script\n\nYou can write to the log file using the `log` object:\n\n~~~ .python\nlog.write('This will be written to the log file!')\n~~~\n\nFor more information, see:\n\n- %link:log%\n\nYou should generally not write to the log file directly and use a LOGGER item at the same time; doing so will result in messy log files.\n\n## Format of the data files\n\nIf you have used the standard LOGGER item, data files are in the following format format (simply standard csv):\n\n- plain-text\n- comma-separated\n- double-quoted (literal double-quotes are escaped with backward slashes)\n- unix-style line endings\n- UTF-8 encoded\n- column names on the first row\n\n## Which variables are logged?\n\nBy default, variables that are defined in the user interface, such as columns in a `loop` table or response variables are always logged.\n\nBy default, variables that are defined in an `inline_script` or `inline_javascript` are logged if they are numbers (`int` and `float`), strings (`str` and `bytes`), and `None` values. This is to avoid log files from becoming unreasonably large due to logging of long lists and other large values. (As of OpenSesame 4.0, there is no longer a need to use the `var` (Python) or `vars` (JavaScript) object.)\n\nIf you want to explicitly log a variable that is not logged by default, you can use the 'Include' field in the LOGGER item.\n\n\n## Reading and processing data files\n\n### In Python with pandas or DataMatrix\n\nIn Python, you can use [pandas](http://pandas.pydata.org/) to read csv files.\n\n```python\nimport pandas\ndf = pandas.read_csv('subject-1.csv')\nprint(df)\n```\n\nOr [DataMatrix](https://datamatrix.cogsci.nl/):\n\n```python\nfrom datamatrix import io\ndm = io.readtxt('subject-1.csv')\nprint(dm)\n```\n\n### In R\n\nIn R, you can simply use the `read.csv()` function to read a single data file.\n\n~~~ .R\ndf = read.csv('subject-1.csv', encoding = 'UTF-8')\nhead(df)\n~~~\n\nIn addition, you can use the `read_opensesame()` function from the [readbulk](https://github.com/pascalkieslich/readbulk) package to easily read and merge multiple data files into one large data frame. The package is available on CRAN and can be installed via `install.packages('readbulk')`.\n\n~~~ .R\n# Read and merge all data files stored in the folder 'raw_data'\nlibrary(readbulk)\ndf = read_opensesame('raw_data')\n~~~\n\n### In JASP\n\n[JASP](http://jasp-stats.org/), an open-source statistics package, opens csv files straight away.\n\n### In LibreOffice Calc\n\nIf you open a csv file in LibreOffice Calc, you have to indicate the exact data format, as indicated in %FigLibreOffice. (The default settings are often correct.)\n\n%--\nfigure:\n source: libreoffice.png\n id: FigLibreOffice\n--%\n\n### In Microsoft Excel\n\nIn Microsoft Excel, you need to use the Text Import Wizard.\n\n### Merging multiple data files into one large file\n\nFor some purposes, such as using pivot tables, it may be convenient to merge all data files into one large file. With Python DataMatrix, you can do this with the following script:\n\n```python\nimport os\nfrom datamatrix import DataMatrix, io, operations as ops\n\n# Change this to the folder that contains the .csv files\nSRC_FOLDER = 'student_data'\n# Change this to a list of column names that you want to keep\nCOLUMNS_TO_KEEP = [\n    'RT_search',\n    'load',\n    'memory_resp'\n]\n\n\ndm = DataMatrix()\nfor basename in os.listdir(SRC_FOLDER):\n    path = os.path.join(SRC_FOLDER, basename)\n    print('Reading {}'.format(path))\n    dm <<= ops.keep_only(io.readtxt(path), *COLUMNS_TO_KEEP)\nio.writetxt(dm, 'merged-data.csv')\n```\n\n\n## Logging in OSWeb\n\nWhen you run an experiment in a browser with OSWeb, logging works differently from when you run an experiment on the desktop.\n\nSpecifically, when you launch an OSWeb experiment directly from within OpenSesame, the log file is downloaded at the end of the experiment. This log file is in `.json` format. When you launch an OSWeb experiment from JATOS, there is no log file as such, but rather all data is sent to JATOS from where it can be downloaded.\n\nSee also:\n\n- %link:manual/osweb/workflow%\n\n\n\n[libreoffice]: http://www.libreoffice.org/\n[openoffice]: http://www.openoffice.org/\n[gnumeric]: http://projects.gnome.org/gnumeric/\n[log-func]: /python/inline-script/#inline_script.log\n[codecs]: http://docs.python.org/2/library/codecs.html\n[ppa]: https://launchpad.net/~smathot/+archive/cogscinl/", "url": "https://osdoc.cogsci.nl/4.0/manual/logging", "title": "Logging and reading data files"}
{"content": "# Timing\n\ntitle: Timing\nreviewed: false\n\nThis page describes various issues related to timing, and provides benchmark results and tips for testing your own system. If you experience problems with timing, please take the time to read this page. Many issues are resolved by taking into account things such as stimulus preparation and the properties of your monitor.\n\n[TOC]\n\n## Is OpenSesame capable of millisecond precision timing?\n\nThe short answer is: yes. The long answer is the rest of this page.\n\n\n## Important considerations for time-critical experiments\n\n### Check your timing!\n\nOpenSesame allows you to control your experimental timing very accurately. But this does not guarantee accurate timing in every specific experiment! For any number of reasons, many of which are described on this page, you may experience issues with timing. Therefore, in time-critical experiments you should always check whether the timing in your experiment is as intended. The easiest way to do this is by checking the display timestamps reported by OpenSesame.\n\nEvery SKETCHPAD item has a variable called `time_[sketchpad name]` that contains the timestamp of the last time that the SKETCHPAD was shown. Therefore, if you want the SKETCHPAD *target* to be shown for 100 ms, followed by the SKETCHPAD *mask*, you should verify that `time_mask` - `time_target` is indeed 100. When using Python inline code, you can make use of the fact that `canvas.show()` returns the display timestamp.\n\n\n### Understanding your monitor\n\nComputer monitors refresh periodically. For example, if the refresh rate of your monitor is 100 Hz, the display is refreshed every 10 ms (1000 ms / 100 Hz). This means that a visual stimulus is always presented for a duration that is a multiple of 10 ms, and you will not be able to present a stimulus for, say, 5 or 37 ms. The most common refresh rate is 60 Hz (= 16.67 ms refresh cycle), although monitors with much higher refresh rates are sometimes used for experimental systems.\n\nIn %VidRefresh you can see what a monitor refresh looks like in slow motion. On CRT monitors (i.e. non-flatscreen, center) the refresh is a single pixel that traces across the monitor from left to right and top to bottom. Therefore, only one pixel is lighted at a time, which is why CRT monitors flicker slightly. On LCD or TFT monitors (flatscreen, left and right) the refresh is a 'flood fill' from top to bottom. Therefore, LCD and TFT monitors do not flicker. (Unless you present a flickering stimulus, of course.)\n\n%--\nvideo:\n id: VidRefresh\n source: vimeo\n videoid: 24216910\n width: 640\n height: 240\n caption: A slow-motion video of the refresh cycle on CRT (center) and LCD/ TFT monitors. Video courtesy of Jarik den Hartog and the VU University Amsterdam technical support staff.\n--%\n\nIf a new stimulus display is presented while the refresh cycle is halfway, you will observe 'tearing'. That is, the upper half of the monitor will show the old display, while the lower part will show the new display. This is generally considered undesirable, and therefore a new display should be presented at the exact moment that the refresh cycle starts from the top. This is called 'synchronization to the vertical refresh' or simply 'v-sync'. When v-sync is enabled, tearing is no longer visible, because the tear coincides with the upper edge of the monitor. However, v-sync does not change anything about the fact that a monitor does not refresh instantaneously and will therefore always, for some time, show both the old and the new display.\n\nAnother important concept is that of 'blocking on the vertical retrace' or the 'blocking flip'. Usually, when you send a command to show a new display, the computer will accept this command right away and put the to-be-shown display in a queue. However, the display may not actually appear on the monitor until some time later, typically until the start of the next refresh cycle (assuming that v-sync is enabled). Therefore, you don't know exactly when the display has appeared, because your timestamp reflects the moment that the display was queued, rather than the moment that it was presented. To get around this issue, you can use a so-called 'blocking flip'. This basically means that when you send a command to show a new display, the computer will freeze until the display actually appears. This allows you to get very accurate display timestamps, at the cost of a significant performance hit due to the computer being frozen for much of the time while it is waiting for a display to be shown. But for the purpose of experiments, a blocking flip is generally considered the optimal strategy.\n\nFinally, LCD monitors may suffer from 'input lag'. This means that there is an additional and sometimes variable delay between the moment that the computer 'thinks' that a display appears, and the moment that the display actually appears. This delay results from various forms of digital processing that are performed by the monitor, such as color correction or image smoothing. As far as I know, input lag is not something that can be resolved programmatically, and you should avoid monitors with significant input lag for time-critical experiments. \n\nFor a related discussion, see:\n\n- <http://docs.expyriment.org/Timing.html#visual>\n\n\n### Making the refresh deadline\n\nImagine that you arrive at a train station at 10:30. Your train leaves at 11:00, which gives you exactly 30 minutes to get a cup of coffee. However, if you have coffee for exactly 30 minutes, then you will arrive back at the platform just in time to see your train depart, and you will have to wait for the next train. Therefore, if you have 30 minutes waiting time, you should have a coffee for slightly less than 30 minutes, such as 25 minutes.\n\nThe situation is analogous when specifying intervals for visual-stimulus presentation. Let's say that you have a 100 Hz monitor (so 1 refresh every 10 ms) and want to present a target stimulus for 100 ms, followed by a mask. Your first inclination might be to specify an interval of 100 ms between the target and the mask, because that's after all what you want. However, specifying an interval of exactly 100 ms will likely cause the mask to 'miss the refresh deadline', and the mask will be presented only on the next refresh cycle, which is 10 ms later (assuming that v-sync is enabled). So if you specify an interval of 100 ms, you will in most cases end up with an interval of 110 ms!\n\nThe solution is simple: You should specify an interval that is slightly shorter than what you are aiming for, such as 95 ms. Don't worry about the interval being too short, because on a 100 Hz monitor the interval between two stimulus displays is necessarily a multiple of 10 ms. Therefore, 95 ms will become 100 ms (10 frames), 1 ms will become 10 ms (1 frame), etc. Phrased differently, intervals will be rounded up (and never rounded down!) to the nearest interval that is consistent with your monitor's refresh rate.\n\n\n### Disabling desktop effects\n\nMany modern operating systems make use of graphical desktop effects. These provide, for example, the transparency effects and the smooth window minimization and maximization effects that you see on most modern operating systems. Although the software that underlies these effects differs from system to system, they generally form an additional layer between your application and the display. This additional layer may prevent OpenSesame from synchronizing to the vertical refresh and/ or from implementing a blocking flip.\n\nAlthough desktop effects *may* cause problems, they usually don't. This appears to vary from system to system and from video card to video card. Nevertheless, when the operating systems allows it, it's best to disable desktop effects on systems that are used for experimental testing.\n\nSome tips regarding desktop effects for the various operating systems:\n\n- Under *Windows XP* there are no desktop effects at all.\n- Under *Windows 7* desktop effects can be disabled by selecting any of the themes listed under 'Basic and High Contrast Themes' in the 'Personalization' section.\n- Under *Windows 10* there is no way to completely disable desktop effects.\n- Under *Ubuntu and other Linux distributions using Gnome 3* there is no way to completely disable desktop effects.\n- Under *Linux distributions using KDE* you can disable desktop effects in the 'Desktop Effects' section of the System Settings.\n- Under *Mac OS* there is apparently no way to completely disable desktop effects.\n\n\n### Taking into account stimulus-preparation time/ the prepare-run structure\n\nIf you care about accurate timing during visual-stimulus presentation, you should prepare your stimuli in advance. That way, you will not get any unpredictable delays due to stimulus preparation during the time-critical parts of your experiment.\n\nLet's first consider a script (you can paste this into an INLINE_SCRIPT item) that includes stimulus-preparation time in the interval between `canvas1` and `canvas2` (%LstStimPrepBad). The interval that is specified is 95 ms, so--taking into account the 'rounding up' rule described in [Making the refresh deadline]--you would expect an interval of 100 ms on my 60 Hz monitor. However, on my test system the script below results in an interval of 150 ms, which corresponds to 9 frames on a 60 Hz monitor. This is an unexpected delay of 50 ms, or 3 frames, due to the preparation of `canvas2`.\n\n%--\ncode:\n id: LstStimPrepBad\n syntax: python\n source: stimulus-preparation-bad.py\n caption: \"In this script, the duration between `canvas1` and `canvas2` is confounded by stimulus-preparation time.\"\n--%\n\nNow let's consider a simple variation of the script above (%LstStimPrepGood). This time, we first prepare both `canvas1` and `canvas2` and only afterwards present them. On my test system, this results in a consistent 100 ms interval, just as it should!\n\n%--\ncode:\n id: LstStimPrepGood\n syntax: python\n source: stimulus-preparation-good.py\n caption: \"In this script, the duration between `canvas1` and `canvas2` is not confounded by stimulus-preparation time.\"\n--%\n\nWhen using the graphical interface, the same considerations apply, but OpenSesame helps you by automatically handling most of the stimulus preparation in advance. However, you have to take into account that this preparation occurs at the level of SEQUENCE items, and not at the level of LOOP items. Practically speaking, this means that the timing *within* a SEQUENCE is not confounded by stimulus-preparation time. But the timing *between* SEQUENCEs is.\n\nTo make this more concrete, let's consider the structure shown below (%FigStimPrepBad). Suppose that the duration of the SKETCHPAD item is set to 95 ms, thus aiming for a 100 ms duration, or 6 frames on a 60 Hz monitor. On my test system the actual duration is 133 ms, or 8 frames, because the timing is confounded by preparation of the SKETCHPAD item, which occurs each time that that the sequence is executed. So this is an example of how you should *not* implement time-critical parts of your experiment.\n\n%--\nfigure:\n id: FigStimPrepBad\n source: stimulus-preparation-incorrect.png\n caption: \"An example of an experimental structure in which the timing between successive presentations of SKETCHPAD is confounded by stimulus-preparation time. The sequence of events in this case is as follows: prepare SKETCHPAD (2 frames), show SKETCHPAD (6 frames), prepare SKETCHPAD (2 frames), show SKETCHPAD (6 frames), etc.\"\n--%\n\nNow let's consider the structure shown below (%FigStimPrepGood). Suppose that the duration of `sketchpad1` is set to 95 ms, thus aiming for a 100 ms interval between `sketchpad1` and `sketchpad2`. In this case, both items are shown as part of the same SEQUENCE and the timing will not be confounded by stimulus-preparation time. On my test system the actual interval between `sketchpad1` and `sketchpad2` is therefore indeed 100 ms, or 6 frames on a 60 Hz monitor.\n\nNote that this only applies to the interval between `sketchpad1` and `sketchpad2`, because they are executed in that order as part of the same sequence. The interval between `sketchpad2` on run *i* and `sketchpad1` on run *i+1* is again confounded by stimulus-preparation time.\n\n%--\nfigure:\n id: FigStimPrepGood\n source: stimulus-preparation-correct.png\n caption: \"An example of an experimental structure in which the timing between the presentation of `sketchpad1` and `sketchpad2` is not confounded by stimulus-preparation time. The sequence of events in this case is as follows: prepare `sketchpad1` (2 frames), prepare `sketchpad2` (2 frames), show `sketchpad1` (6 frames), show `sketchpad2` (6 frames), prepare `sketchpad1` (2 frames), prepare `sketchpad2` (2 frames), show `sketchpad1` (6 frames), show `sketchpad2` (6 frames), etc.\"\n--%\n\nFor more information, see:\n\n- [usage/prepare-run]\n\n### Differences between backends\n\nOpenSesame is not tied to one specific way of controlling the display, system timer, etc. Therefore, OpenSesame *per se* does not have specific timing properties, because these depend on the backend that is used. The performance characteristics of the various backends are not perfectly correlated: It is possible that on some system the [psycho] backend works best, whereas on another system the [xpyriment] backend works best. Therefore, one of the great things about OpenSesame is that you can choose which backend works best for you!\n\nIn general, the [xpyriment] and [psycho] backends are preferable for time-critical experiments, because they use a blocking flip. On the other hand, the [legacy] backend is slightly more stable and also considerably faster when using [forms].\n\nUnder normal circumstances the three current OpenSesame backends have the properties shown in %TblBackendInfo.\n\n%--\ntable:\n id: TblBackendInfo\n source: backend-info.csv\n caption: backend properties.\n--%\n\nSee also:\n\n- [backends]\n\n## Benchmark results and tips for testing your own system\n\n### Checking whether v-sync is enabled\n\nAs described in [Understanding your monitor], the presentation of a new display should ideally coincide with the start of a new refresh cycle (i.e. 'v-sync'). You can test whether this is the case by presenting displays of different colors in rapid alternation. If v-sync is not enabled you will clearly observe horizontal lines running across the monitor (i.e. 'tearing'). To perform this test, run an experiment with the following script in an INLINE_SCRIPT item (%LstVSync):\n\n%--\ncode:\n id: LstVSync\n syntax: python\n source: v-sync-check.py\n caption: A script that presents yellow and blue displays in rapid alternation. A lack of synchronization with the vertical refresh can be observed as horizontal lines running through the monitor.\n--%\n\n### Testing precision and accuracy of timing\n\nTiming is precise or consistent when you can present visual stimuli over and over again with the same timing. Timestamps are accurate when they accurately reflect when visual stimuli appear on the monitor. The script below shows how you can check precision and accuracy of timing. This test can be performed both with and without an external photodiode, although the use of a photodiode provides extra verification.\n\nTo keep things simple, let's assume that your monitor is running at 100 Hz, which means that a single frame takes 10 ms. The script then presents a white canvas for 1 frame (10 ms). Next, the script presents a black canvas for 9 frames (90 ms). Note that we have specified a duration of 85, which is rounded up as explained under [Making the refresh deadline]. Therefore, we expect that the interval between the onsets of two consecutive white displays will be 10 frames or 100 ms (= 10 ms + 90 ms).\n\nWe can use two ways to verify whether the interval between two white displays is indeed 100 ms:\n\n1. Using the timestamps reported by OpenSesame. This is the easiest way and is generally accurate when the backend uses a blocking flip.\n2. Using a photodiode that responds to the onsets of the white displays and logs the timestamps of these onsets to an external computer. This is the best way to verify the timing, because it does not rely on introspection of the software. Certain issues, such as TFT input lag, discussed above, will come out only using external photodiode measurement.\n\n%--\ncode:\n id: LstIntervalBenchmark\n syntax: python\n source: interval-benchmark.py\n caption: A Python script to test the timing consistency and accuracy of display timestamps. You can paste this code into an INLINE_SCRIPT item.\n--%\n\nI ran %LstIntervalBenchmark on Windows XP, using all three backends. I also recorded the onsets of the white displays using a photodiode connected to a second computer. The results are summarized in %TblBenchmarkResults.\n\n%--\ntable:\n id: TblBenchmarkResults\n source: benchmark-results.csv\n caption: Benchmark results for %LstIntervalBenchmark. Tested with Windows XP, HP Compaq dc7900, Intel Core 2 Quad Q9400 @ 2.66Ghz, 3GB, 21\" ViewSonic P227f CRT. Each test was conducted twice (i.e. two sessions). The column `Session` corresponds to different test runs. The column `Source` indicates whether the measurements are from an external photiodiode, or based on OpenSesame's internal timestamps.\n--%\n\nAs you can see, the [xpyriment] and [psycho] backends consistently show a 100 ms interval. This is good and just as we would expect. However, the [legacy] backend shows a 90 ms interval. This discrepancy is due to the fact that the [legacy] backend does not use a blocking flip (see [Understanding your monitor]), which leads to some unpredictability in display timing. Note also that there is close agreement between the timestamps as recorded by the external photodiode and the timestamps reported by OpenSesame. This agreement demonstrates that OpenSesame's timestamps are reliable, although, again, they are slightly less reliable for the [legacy] backend due to the lack of a blocking-flip.\n\n", "url": "https://osdoc.cogsci.nl/4.0/manual/timing", "title": "Timing"}
{"content": "# Timing\n\n## Expyriment benchmarks and test suite\n\nA very nice set of benchmarks is available on the Expyriment website. This information is applicable to OpenSesame experiments using the [xpyriment] backend.\n\n- <http://docs.expyriment.org/Timing.html>\n\nExpyriment includes a very useful test suite. You can launch this test suite by running the `test_suite.opensesame` example experiment, or by adding a simple INLINE_SCRIPT to your experiment with the following lines of code (%LstExpyrimentTestSuite):\n\n%--\ncode:\n id: LstExpyrimentTestSuite\n syntax: python\n source: expyriment-test-suite.py\n caption: A script to start the Expyriment test suite.\n--%\n\nFor more information, please visit:\n\n- <http://docs.expyriment.org/Testsuite.html>\n\n## PsychoPy benchmarks and timing-related information\n\nSome information about timing is available on the PsychoPy documentation site. This information is applicable to OpenSesame experiments using the [psycho] backend.\n\n- <http://www.psychopy.org/general/timing/timing.html>\n\n[psycho]: /backends/xpyriment/\n[xpyriment]: /backends/xpyriment/\n[legacy]: /backends/legacy/\n[miscellaneous/clock-drift]: /miscellaneous/clock-drift\n[usage/prepare-run]: /usage/prepare-run\n[backends]: /backends\n[forms]: /forms", "url": "https://osdoc.cogsci.nl/4.0/manual/timing", "title": "Timing"}
{"content": "# Backends\n\ntitle: Backends\n\nThe *backend* is the software layer that deals with input (keyboard input, mouse input, etc.) and output (display presentation, sound playback, etc.). There are many libraries that offer this type of functionality and OpenSesame could, in principle, use any one of them. For this reason, OpenSesame is backend-independent, in the sense that you can choose which backend should be used. Currently there are four backends: *legacy*, *psycho*, *xpyriment*, and *osweb*.\n\n[TOC]\n\n## Differences and some tips\n\nUsually, you won't notice which backend is used. The differences between backends are largely technical, and, as long as you use the graphical user interface, all backends work more ore less the same way. However, there are a few reasons to prefer one backend over another:\n\n- If you want to run the experiment in a browser, you need to select the *osweb* backend.\n- Backend differs in [temporal precision](%link:timing%).\n\t- Tip: If you care about millisecond temporal precision, use *xpyriment* or *psycho*.\n- Backends differ in how long stimulus preparation takes.\n\t- Tip: If [forms](%link:manual/forms/about%) are slow, use *legacy*.\n\t- Tip: If the intertrial interval is long (due to stimulus preparation), use *legacy*.\n- You can use backend-specific functionality when writing Python code.\n\t- Tip: If you want to use PsychoPy functionality, use *psycho*.\n\t- Tip: If you want to use Expyriment functionality, use *xpyriment*.\n\t- Tip: If you want to use PyGame functionality, use *legacy*.\n- Some backends are not available on all platforms.\n\n## Selecting a backend\n\nYou can select a backend in the general properties of the experiment (%FigSelect).\n\n%--\nfigure:\n id: FigSelect\n source: fig-select.png\n caption: \"Selecting a backend\"\n--%\n\nIf you view the general script (select \"Show script editor\"), you will see that there are actually six distinct backends: canvas, keyboard, mouse, sampler, color, and clock. The combobox-method automatically selects an appropriate, predefined combination of backends, but you could, in theory, mix and match.\n\nFor example, if you select the *xpyriment* backend, the following code will be generated:\n\n\tset sampler_backend legacy\n\tset mouse_backend xpyriment\n\tset keyboard_backend legacy\n\tset color_backend legacy\n\tset clock_backend legacy\n\tset canvas_backend xpyriment\n\n## xpyriment\n\nThe *xpyriment* backend is built on top of [Expyriment][], a library designed for creating psychology experiments. It is a light-weight hardware-accelerated backend with excellent timing properties. If you care about temporal precision, but do not plan on generating complex stimuli (i.e. Gabor patches, random-dot gratings, etc.) *xpyriment* is a good choice.\n\n### Using Expyriment directly\n\nYou can find extensive documentation on Expyriment at <http://www.expyriment.org/doc>. The following code snippet shows a line of text:\n\n~~~ .python\nfrom expyriment import stimuli\ntext = stimuli.TextLine('This is expyriment!')\ntext.present()\n~~~\n\n### Citation\n\nAlthough Expyriment is bundled with the binary distributions of OpenSesame, it is a separate project. When appropriate, please provide the following citation in addition to citing OpenSesame:\n\nKrause, F., & Lindemann, O. (in press). Expyriment: A Python library for cognitive and neuroscientific experiments. *Behavior Research Methods*.\n{: .reference}\n\n## psycho\n\nThe psycho backend is built on top of [PsychoPy][], a library designed for creating psychology experiments. It is hardware accelerated and provides high-level routines for creating complex visual stimuli (drifting gratings, etc.). If you care about timing and plan on creating complex stimuli, Psycho is a good choice.\n\n### Using PsychoPy directly\n\nYou can find extensive documentation on PsychoPy at <http://www.psychopy.org/>. When using PsychoPy in OpenSesame, it is important to know that the main window can be accessed as `self.experiment.window` or simply `win`. So the following code snippet draws a Gabor patch:\n\n~~~ .python\nfrom psychopy import visual\ngabor = visual.PatchStim(win, tex=\"sin\", size=256, mask=\"gauss\", sf=0.05, ori=45)\ngabor.draw()\nwin.flip()\n~~~\n\n### Tutorials\n\nA tutorial specifically for using PsychoPy from within OpenSesame:\n\n- <http://www.cogsci.nl/blog/tutorials/211-a-bit-about-patches-textures-and-masks-in-psychopy>\n\nAnd a more general PsychoPy tutorial:\n\n- <http://gestaltrevision.be/wiki/coding>\n\n### Citation\n\nAlthough PsychoPy is bundled with the binary distributions of OpenSesame, it is a separate project. When appropriate, please cite the following papers in addition to citing OpenSesame:\n\nPeirce, J. W. (2007). PsychoPy: Psychophysics software in Python. *Journal of Neuroscience Methods*, *162*(1-2), 8-13. doi:10.1016/j.jneumeth.2006.11.017\n{: .reference}\n\nPeirce, J. W. (2009). Generating stimuli for neuroscience using PsychoPy. *Frontiers in Neuroinformatics*, *2*(10). doi:10.3389/neuro.11.010.2008\n{: .reference}\n\n## legacy\n\nThe legacy backend is built on top of [PyGame][] in non-OpenGL mode. The downside of this is that there is no hardware acceleration, and the timing properties are not as good as that of the psycho or xpyriment backends. The upside is that PyGame is very easy to use, very reliable, and well supported on a wide range of platforms.\n\n### Mouse-cursor visibility\n\nOn some systems, the mouse cursor is not visible when using the *legacy* backend in fullscreen mode. You can work around this is the following ways:\n\n1. Open the *legacy* backend settings and set \"Double buffering\" to \"no\".\n\t- *Note:* This may disable v-sync, which can be important for time critical experiments, as discussed [here](%link:timing%).\n2. Open the *legacy* backend settings and set \"Custom cursor\" to \"yes\".\n3. Switch to another backend.\n\n### Using PyGame directly\n\nPyGame is well documented and you can find everything you need to know about using PyGame on <http://www.pygame.org/docs/>. Specific to OpenSesame is the fact that the display surface is stored as `self.experiment.window` or simply `win`. So the following code snippet, which you could paste into an INLINE_SCRIPT item, draws a red rectangle to the display:\n\n~~~ .python\nimport pygame # Import the PyGame module\npygame.draw.rect(self.experiment.window, pygame.Color(\"red\"),\n\t[20, 20, 100, 100]) # Draw a red rectangle. Not shown yet...\npygame.display.flip() # Update the display to show the red rectangle.\n~~~\n\n\n## osweb\n\nThe *osweb* backend is built on top of OSWeb and allows you run experiments in a browser. For more information, see:\n\n- %link:manual/osweb/workflow%", "url": "https://osdoc.cogsci.nl/4.0/manual/backends", "title": "Backends"}
{"content": "# The prepare-run strategy\n\ntitle: The prepare-run strategy\n\n[TOC]\n\n## About\n\nExperiments typically consist of short intervals ('trials') during which participants perceive stimuli and perform a task. Timing should be controlled during a trial, but some unpredictable variation in the duration of the interval between trials is acceptable. Therefore, a good strategy is to perform time-consuming tasks before a trial, and to keep the operations that are performed during a trial to a minimum.\n\nOpenSesame does this by calling each element from a SEQUENCE item twice. This is the *prepare-run strategy*:\n\n- During the Prepare phase, items are given the opportunity to prepare. For example, a SYNTH generates a sound (but doesn't play it); and a SKETCHPAD draws a canvas (but doesn't show it).\n- During the Run phase, items do as a little as possible. For example, a SYNTH plays back a previously prepared sound; and a SKETCHPAD shows a previously prepared canvas.\n\nThis reduces the risk of timing glitches. The prepare-run strategy is implemented at the level of SEQUENCE items, which typically contains the time-critical parts of an experiment. This means that before a SEQUENCE is started, there is some unpredictable temporal jitter.\n\n## Item-specific notes\n\n### loop items\n\nA LOOP item is not prepared in advance. It is important to take this into account when using a LOOP to implement time-critical parts. For example, you may be tempted to implement an RSVP stream using a LOOP item as follows:\n\n~~~text\nrsvp_loop item (4 cycles)\n- stimulus_item\n~~~\n\nIn this construction, *stimulus_item* will be prepared and run four times in alternation, like so:\n\n~~~text\nprepare stimulus_item\nrun stimulus_item\nprepare stimulus_item\nrun stimulus_item\nprepare stimulus_item\nrun stimulus_item\nprepare stimulus_item\nrun stimulus_item\n~~~\n\nTherefore, you need to verify that the preparation of *stimulus_item* does not cause any timing glitches.\n\n### sequence items\n\nAll items that are part of a SEQUENCE are prepared in advance. Therefore, the following construction ...\n\n~~~text\ntrial_sequence\n- fixation_sketchpad\n- target_sketchpad\n- keyboard_response\n- logger\n~~~\n\n... will be executed as follows ...\n\n~~~text\nprepare fixation_sketchpad\nprepare target_sketchpad\nprepare keyboard_response\nprepare logger\nrun fixation_sketchpad\nrun target_sketchpad\nrun keyboard_response\nrun logger\n~~~\n\n### sketchpad and feedback items\n\nSKETCHPAD and FEEDBACK items differ in when they are prepared. For SKETCHPADs preparation occurs during the Prepare phase; for FEEDBACK items, preparation occurs only during the Run phase.\n\nFor more information, see:\n\n- %link:manual/stimuli/visual%\n\n### synth and sampler items\n\nFor SYNTH and SAMPLER items, the sound is generated and preloaded during the Prepare phase.\n\n### inline_script items\n\nIn an INLINE_SCRIPT item, you can choose how you want to implement the run and prepare strategy. In general, it is good practice to adhere to the following guidelines:\n\n- Time-consuming, preparatory functionality goes in the Prepare phase. For example, creating canvas objects, and generating sounds.\n- A minimum amount of code is put in the run phase. For example, only showing a previously prepared canvas.\n\n### Other items and plugins\n\nIn general, items should follow the principle of performing as much as possible time-consuming preparation during the Prepare phase, and minimizing the Run phase. However, every plugin is implemented differently. If you are unsure about a specific case, please post a query on the forum.\n\n## Conditional expressions (run if, show if, break if, etc)\n\nIn SEQUENCE items, the 'Run if' condition is evaluated at the last moment, during the run phase. Therefore, you can use a condition like `correct == 0` which depends on the results of a KEYBOARD_RESPONSE item which has been called just before. It is important to take into account that the 'Run if' expression applies *only* to the run phase of an item\u2014The prepare phase is *always* executed.\n\nIn COROUTINES items, the 'Run if' condition is evaluated during the Prepare phase. Therefore, the conditions cannot depend on events that occur during the execution of the COROUTINES.\n\nIn SKETCHPAD items, the 'Show if' condition is evaluated during the Prepare phase, when the canvas is constructed. In FEEDBACK items, the 'Show if' condition is evaluated during the Run phase (because the canvas is only constructed in the Run phase).", "url": "https://osdoc.cogsci.nl/4.0/manual/prepare-run", "title": "The prepare-run strategy"}
{"content": "# Oculus rift (virtual reality)\n\n---\nlayout: osdoc\ntitle: Oculus rift (virtual reality)\ngroup: Devices\npermalink: /oculus-rift/\n---\n\n<iframe src=\"http://wl.figshare.com/articles/1394986/embed?show_title=1\" width=\"640\" height=\"861\" frameborder=\"0\"></iframe>\n\nHern\u00e1ndez-Sande, A., Lorca, J. A. (2015): OpenSesame: An example of stimulus presentation in Virtual Reality headsets (Oculus Rift DK1). *Figshare*. doi:10.6084/m9.figshare.1394986", "url": "https://osdoc.cogsci.nl/4.0/manual/devices/oculusrift", "title": "Oculus rift (virtual reality)"}
{"content": "# Ambulatory Monitoring System (VU-AMS)\n\ntitle: Ambulatory Monitoring System (VU-AMS)\n\nVU-AMS is a third-party plugin, and is not maintained by the OpenSesame team.\n{: .alert .alert-info}\n\n\nThe VU University Ambulatory Monitoring System (VU-AMS) is a device that can be used to measure a variety of factors related to heart rate, respiration, and body movement. The developers offer an OpenSesame template on their website.\n\nFor more information, see:\n\n- <http://www.vu-ams.nl> (product website)\n- <http://www.vu-ams.nl/support/downloads/extras/> (OpenSesame template)", "url": "https://osdoc.cogsci.nl/4.0/manual/devices/vuams", "title": "Ambulatory Monitoring System (VU-AMS)"}
{"content": "# StimSync\n\ntitle: StimSync\n\nStimSync is an open-source open-hardware device for handling input (e.g., button presses) and output (e.g., triggers) in psychological and neuroscientific experiments. StimSync offers examples for use with OpenSesame.\n\nFor more information, see:\n\n- <http://www.mccauslandcenter.sc.edu/crnl/stimsync-0>", "url": "https://osdoc.cogsci.nl/4.0/manual/devices/stimsync", "title": "StimSync"}
{"content": "# Serial port\n\ntitle: Serial port\n\nPySerial is an easy to use Python library for serial port communications, which is bundled with all OpenSesame packages. For more information, see:\n\n- <http://pyserial.sourceforge.net/>", "url": "https://osdoc.cogsci.nl/4.0/manual/devices/serial", "title": "Serial port"}
{"content": "# Parallel port (EEG triggers)\n\ntitle: Parallel port (EEG triggers)\nreviewed: false\n\nIn EEG/ ERP studies it is common to send triggers to mark the timestamp for significant events (e.g., the onset of a trial, presentation of a particular stimulus, etc.). Triggers are typically bytes that are sent via the parallel port to the EEG apparatus.\n\n[TOC]\n\n\n## Using the `parallel_port_trigger` plugin\n\nParallel_port_trigger is a third-party plugin and not maintained by the OpenSesame team.\n{: .page-notification}\n\nAn OpenSesame plug-in for sending stimulus synchronization triggers through the parallel port to data acquisition systems.\n\n- <https://github.com/dev-jam/opensesame-plugin-parallel_port_trigger/>\n\nYou can install the `parallel_port_trigger` plugin from PyPi:\n\n```\npip install pip install opensesame-plugin-parallel-port-trigger\n```\n\n\n## Using `dportio.dll` in a Python inline Script (Windows only)\n\nInstead of using the `parallel_port_trigger` plugin, it is also possible to send triggers with `dlportio.dll` through a Python inline script. This approach is Windows only. To do so, first add an INLINE_SCRIPT to the start of the experiment with the following code in the prepare phase:\n\n~~~ .python\ntry:\n\tfrom ctypes import windll\n\tglobal io\n\tio = windll.dlportio # requires dlportio.dll !!!\nexcept:\n\tprint('The parallel port couldn\\'t be opened')\n~~~\n\nThis will load `dlportio.dll` as a global object called `io`. Please note that failure will not crash the experiment, so make sure to check the debug window for error messages!\n\nNow use the following code in an INLINE_SCRIPT anywhere in the experiment to send a trigger:\n\n~~~ .python\nglobal io\ntrigger = 1\nport = 0x378\ntry:\n\tio.DlPortWritePortUchar(port, trigger)\nexcept:\n\tprint('Failed to send trigger!')\n~~~\n\nNote that this sends trigger 1 to port 0x378 (=888). Change these values according to your set-up.\n\n## Getting access to the parallel port\n\n### Linux\n\nIn Linux we use the `parport_pc` module (tested in Debian Wheezy) and we need to provide ourselves with permissions to do so. We can accomplish this by executing the following commands:\n\n\tsudo rmmod lp\n\tsudo rmmod parport_pc\n\tsudo modprobe parport_pc\n\tsudo adduser [user] lp\n\nHere, `[user]` should be replaced by your username. Next, logout and login, and you are ready to go!\n\n### Windows XP and Windows Vista (32 bit)\n\n1. Download the 32-bit DLPortIO driver from [here][win32-dll] and uncompress the zip archive.\n2. Go to `DriverLINX/drivers` folder and copy `dlportio.dll` and `dlportio.sys` to the `install` folder. This is the folder  where `install.exe` is located. Then run `install.exe`\n3. You need to copy `dlportio.dll` to the OpenSesame folder (that is, the same folder that contains `opensesame.exe`).\n\n### Windows 7 (32 and 64 bit)\n\n1. Download the 32-bit or 64bit DLPortIO driver [here][win7-dll] and uncompress the zip archive.\n2. As Windows 7 has a strengthened security system (at least compared to XP) one cannot simply install the DLPortIO driver. This won't work as Windows 7 will block all attempts of installing a not-officially-signed (by Microsoft) driver. Good for the security of an average user -- bad for us. To bypass this restriction one has to use a little helper program called \"Digital Signature Enforcement Overrider\" (DSEO) which can be downloaded [here][dseo] (of course there are other possible ways to do this but this program is mentioned in the DLPortIO `readme.txt` and one does not have to dive deeper into MS Windows 7 architecture specialities).\n3. Start DSEO with administrator privileges (right click on `dseo13b.exe`, select \"run as administrator\"). Now the DSEO window pops up. It just presents a list of options which operation to run next.\n4. Choose the option \"sign driver/sys-file\" and press ok. Now another window appears where you have to type in the absolute path to the `DLPortIO.sys` file (only this one, not the dll!). Remember to escape spaces in the path if you have any (don't ask how long that took me) otherwise your files will not be found. Pressing ok will sign the sys-file.\n5. Back in the DSEO list choose \"enable test mode\" and press ok. Then choose \"exit\" and restart your PC. Windows 7 wrongly complains that DSEO might not be installed correctly -- just click on \"yes, the software is installed correctly\".\n6. After boot-up is completed you'll see that something like \"Windows 7 test mode built #number#\" is written on the desktop just above the clock in the starter-bar. That's necessary. You have to be in test mode to run this unofficially signed driver.\n7. Now run `DLPortIO_install.bat` with administrator privileges (in Windows Explorer, right click the file, ...). Answer \"yes\" if Windows warns you about registry changes.\n8. Reboot.\n9. Copy `DLPortIO.dll` to the Opensesame folder, that is, the same folder that contains `opensesame.exe`.\n\nSource: [Forum post by Absurd][post-3]\n\n## Recommendations\n\n- Start your experiment with a 'zero' trigger to make sure all the pins are set to zero.\n- It's recommended to use the [psycho] or [xpyriment] backends instead of the [legacy] backend (using PyGame) for time-critical experiments. This is because [psycho] and [xpyriment] takes the refresh rate of the monitor into account when returning timestamps, whereas [legacy] does not. For more information, see [miscellaneous/timing].\n- Send the trigger code right after (instead of just before) the presentation of your stimulus (assuming that it's the stimulus onset you want to mark). By doing so you'll make sure that the time stamp is as accurately as possible and will not suffer from a small random jitter due to your monitor's refresh rate. [Source: lvanderlinden][post-2]\n\n## Troubleshooting\n\nThere are a number of relevant forum topics in which trigger-related problems are discussed (and, for the most, solved!).\n\n- A post about ghost triggers, i.e. unwanted triggers that are mysteriously registered by the EEG apparatus: [link][post-2]\n- A post with elaborate installation instructions for DLPortIO on Windows 7 ([Source: absurd][post-3]).\n\nPlease don't hesitate to post questions on the forum, or to let us know of your experiences (good or bad).\n\n[win32-dll]: http://files.cogsci.nl/misc/dlportio.zip\n[win7-dll]: http://real.kiev.ua/avreal/download/#DLPORTIO_TABLE\n[dseo]: http://www.ngohq.com/home.php?page=dseo\n[post-2]: http://forum.cogsci.nl/index.php?p=/discussion/comment/780#Comment_780\n[post-3]: http://forum.cogsci.nl/index.php?p=/discussion/comment/745#Comment_745\n[miscellaneous/timing]: /miscellaneous/timing\n[legacy]: /backends/legacy\n[xpyriment]: /backends/xpyriment\n[psycho]: /backends/psycho", "url": "https://osdoc.cogsci.nl/4.0/manual/devices/parallel", "title": "Parallel port (EEG triggers)"}
{"content": "# Emotiv EEG\n\n---\nlayout: osdoc\ntitle: Emotiv EEG\ngroup: Devices\npermalink: /emotiv/\n---\n\n[Emotiv](https://emotiv.com/) is a low-cost EEG headset. Dimitrios Adamos (Neuroinformatics.GRoup of the Aristotle University of Thessaloniki) has written a tutorial for using the Emotiv with OpenSesame:\n\n- <http://neuroinformatics.gr/node/37>\n\n%--\nfigure:\n source: emotiv.png\n id: FigEmotiv\n caption: Emotiv is a low-cost EEG headset.\n--%", "url": "https://osdoc.cogsci.nl/4.0/manual/devices/emotiv", "title": "Emotiv EEG"}
{"content": "# Using the form plugins\n\ntitle: Using the form plugins\n\nA number of commonly used forms are available as ready-made plugins. These allow you to use common forms, without any need for scripting.\n\n- FORM_CONSENT is a simple digital consent form (disclaimer: some journals may require *written* consent)\n- FORM_MULTIPLE_CHOICE allows you to present multiple choice questions\n- FORM_TEXT_DISPLAY is a simple text display that you can use to show instructions etc.\n- FORM_TEXT_INPUT is a simple text input display that allows you to ask a question and collect a multi-character response from the participant\n\nThe FORM_BASE plugin is special. It allows you to define custom forms using OpenSesame script, as described here:\n\n- %link:manual/forms/custom%\n\n%--\nfigure:\n id: FigFormPlugins\n source: form-plugins.png\n caption: The FORM plugins in the item toolbar.\n--%", "url": "https://osdoc.cogsci.nl/4.0/manual/forms/readymade", "title": "Using the form plugins"}
{"content": "# Form variables\n\ntitle: Form variables\n\n[TOC]\n\n## About form variables\n\nWhen you present a form with multiple `checkbox`es, you generally want to know which `checkbox` the user has checked. Similarly, when you present a form with two `button`s, you want to know which `button` the user has clicked. This information is available through variables that are automatically set when the user interacts with a form. You can specify yourself which response variables should be used. How this is done depends on how you have created your form.\n\n### In ready-made form plugins\n\nWhen you use one of the ready-made form plugins, such as FORM_TEXT_INPUT, you can specify the name of the response variable directly in the plugin controls.\n\n### In custom forms\n\nYou can use the `var` keyword to indicate which variable should be used. For example, the following OpenSesame script, which you can enter into a FORM_BASE plugin, indicates that the response from a `text_input` widget should be stored in a variable called `my_response_var`:\n\n```python\nwidget 0 0 1 1 text_input var=my_response_var\n```\n\nThe equivalent Python code is:\n\n~~~ .python\nmy_widget = TextInput(var='my_response_var')\n~~~\n\nSee also:\n\n- %link:manual/forms/widgets%\n\n## Widget-specific information\n\nEach widget uses its response variable in a slightly different way.\n\n### button\n\nThe `button` widget sets the response variable to 'yes' if it has been clicked and to 'no' if it has not.\n\n### checkbox\n\nThe `checkbox` widget sets the response variable to a semicolon-separated list of the text on all checkboxes that have been checked (for that variable), or 'no' if no `checkbox` has been checked (for that variable). This sounds a bit complicated, so let's see a few examples.\n\n```python\nwidget 0 0 1 1 checkbox group=\"1\" text=\"A\" var=\"my_response_var\"\nwidget 1 0 1 1 checkbox group=\"1\" text=\"B\" var=\"my_response_var\"\nwidget 1 1 1 1 button text=\"Next\"\n```\n\nHere there are two `checkbox`es with the text 'A' and 'B'. Both part of the same group, called '1'. Both have the same response variable, called `my_response_var`. If 'A' is checked, `my_response_var` will be 'A'. If 'B' is checked, `my_response_var` will be 'B'. If neither is checked, `my_response_var` will be 'no'. Note that only one `checkbox` in the same group can be checked, so `my_response_var` will *never* be 'A;B' in this example.\n\nNow let's consider the same script, with the sole difference that the two `checkbox`es are not part of a group:\n\n```python\nwidget 0 0 1 1 checkbox text=\"A\" var=\"my_response_var\"\nwidget 1 0 1 1 checkbox text=\"B\" var=\"my_response_var\"\nwidget 1 1 1 1 button text=\"Next\"\n```\n\nIn this case, the situation is much like described above, with the exception that both `checkbox`es can be checked at the same time, in which case `my_response_var` will be set to 'A;B'.\n\nYou cannot use the same response variable for `checkbox`es in different groups.\n\n### image\n\nVariables are not applicable to the `image` widget.\n\n### image_button\n\nThe `image_button` widget sets the response variable to 'yes' if it has been clicked and to 'no' if it has not.\n\n### label\n\nVariables are not applicable to the `label` widget.\n\n### rating_scale\n\nThe `rating_scale` widget sets the response variable to the number of the option that has been clicked, where '0' is the first option (zero-based indexing). If no option has been selected, the response variable is set to 'None'.\n\n### text_input\n\nThe `text_input` widget sets the response variable to the entered text.", "url": "https://osdoc.cogsci.nl/4.0/manual/forms/variables", "title": "Form variables"}
{"content": "# About forms\n\ntitle: About forms\n\nForms are simple interactive displays that can be used to implement questionnaires, instructions, text input displays, etc. You can use forms in four ways.\n\n- Use the form plugins, such as FORM_TEXT_INPUT, which offer ready-made forms. This is the easiest, but least flexible way of using forms. This works both on the desktop and in a browser.\n\t- %link:manual/forms/readymade%\n- Define custom forms using OpenSesame script and the form_base plugin. This offers considerable flexibility, and does not require any real programming skills. This only works on the desktop.\n\t- %link:manual/forms/custom%\n- Create custom forms using Python inline script. This offers the most flexibility, but requires some knowledge of Python programming. This only works on the desktop.\n\t- %link:manual/forms/custom%\n- Create custom forms using HTML code. This only works when running experiments in a browser with OSWeb.\n\t- %link:manual/forms/html%\n\n%--\nfigure:\n id: FigAbout\n source: about.png\n caption: An example form.\n--%", "url": "https://osdoc.cogsci.nl/4.0/manual/forms/about", "title": "About forms"}
{"content": "# Custom HTML forms\n\ntitle: Custom HTML forms\n\n\nThe INLINE_HTML item allows you to implement forms using custom HTML.\n\n- The `name` attribute of `input` tags corresponds to an experimental variable. Therefore, the text that is entered into the text input of Example 1 will be stored as the experimental variable `text_response`.\n- For `checkbox` and `radio` elements, you can use the `id` attribute to assign a specific value to the associated experimental variable.\n- You can use the `required` attribute to indicate that a form cannot be submitted before a field has been filled out.\n- The form is closed when the participant clicks on an input of type submit.\n- To include images from the file pool in a custom HTML form, first retrieve the URL to the file, assign it to an experimental variable, and then use this variable as the source for the `<img>` tag (see Example 3).\n\n\nExample 1:\n\nA very basic text input form:\n\n```html\n<input type='text' name='text_response'>\n<input type='submit' value='click here to continue'>\n```\n\nExample 2:\n\nA form with multiple radio buttons:\n\n```html\n<p>Please select your age:</p>\n<input type=\"radio\" id=\"age1\" name=\"age\" value=\"30\" required>\n<label for=\"age1\">0 - 30</label><br>\n<input type=\"radio\" id=\"age2\" name=\"age\" value=\"60\">\n<label for=\"age2\">31 - 60</label><br>  \n<input type=\"radio\" id=\"age3\" name=\"age\" value=\"100\">\n<label for=\"age3\">61 - 100</label><br><br>\n<input type=\"submit\" value=\"Submit\">\n```\n\nExample 3:\n\nYou can include variable references (except within `<script>` tags, where curly braces are simply interpreted as part of JavaScript code):\n\n```html\n<p>You age group is {age}</p>\n<input type='submit' value='ok'>\n```\n\nExample 4:\n\nYou can JavaScript through `<script>` tags. For example, you can get an image from the file pool and assign to an initially empty `<img>` tag like this:\n\n```html\n<img id='capybara'>\n<input type='submit' value='ok'>\n\n<script>\ndocument.getElementById('capybara').src = pool['capybara.png'].data.src\n</script>\n```", "url": "https://osdoc.cogsci.nl/4.0/manual/forms/html", "title": "Custom HTML forms"}
{"content": "# Form widgets and keywords\n\ntitle: Form widgets and keywords\n\n\n[TOC]\n\n\n## Screenshot\n\n%--\nfigure:\n id: FigWidgets\n source: widgets.png\n caption: A list of available FORM widgets.\n--%\n\n\n## Widgets and keywords\n\nAll keywords are optional, instead otherwise indicated.\n\n### Form\n\nThe `cols` and `rows` keywords can either be single `int` values, in which case they specify the number of equally sized columns and rows, or lists of `int`, in which case they specify the relative sizes of each column and row. For more information about form geometry, see:\n\n- %link:manual/forms/custom%\n\nThe `validator` keyword can be used to validate form input. For more information, see:\n\n- %link:manual/forms/validation%\n\n(In OpenSesame script, you do not need to explicitly create a form.)\n\nPython script:\n\n~~~ .python\nform = Form(\n    cols=2, rows=2, spacing=10, margins=(100, 100, 100, 100), theme='gray',\n    timeout=None, clicks=False, validator=None\n)\nbutton = Button(text='Ok!')\nform.set_widget(button, (0, 0))\nform._exec()\n~~~\n\n\n### button / Button\n\nOpenSesame script:\n\n~~~python\nwidget 0 0 1 1 button text=\"Click me!\" center=yes frame=yes var=response\n~~~\n\nPython script:\n\n~~~ .python\nform = Form()\nbutton = Button(text='Click me!', frame=True, center=True, var='response')\nform.set_widget(button, (0, 0))\nform._exec()\n~~~\n\n\n### checkbox / Checkbox\n\nIf a group is specified, checking one checkbox from that group will uncheck all other checkboxes from that group. Checkboxes that are part of a group cannot be unchecked, except by clicking on another checkbox in that group.\n\nThe `group` keyword also affects how variables are stored, as described here:\n\n- %link:manual/forms/variables%\n\nOpenSesame script:\n\n~~~python\nwidget 0 0 1 1 checkbox group=group text=\"Option 1\"\nwidget 0 1 1 1 checkbox group=group text=\"Option 2\"\n~~~\n\nPython script:\n\n~~~ .python\nform = Form()\ncheckbox1 = Checkbox(text='Option 1', group='group')\ncheckbox2 = Checkbox(text='Option 2', group='group')\nform.set_widget(checkbox1, (0, 0))\nform.set_widget(checkbox2, (0, 1))\nform._exec()\n~~~\n\n\n### image / ImageWidget\n\nThe Python object is called `ImageWidget` to distinguish it from the `Image` canvas element.\n\nOpenSesame script:\n\n~~~python\n# Only path is a required keyword\nwidget 0 0 1 1 image path=\"my_image.png\" adjust=yes frame=no\n~~~\n\nPython script:\n\n~~~ .python\n# Only path is a required keyword\nform = Form()\nimage = ImageWidget(path=pool['my_image.png'], adjust=True, frame=False)\nform.set_widget(image, (0, 0))\nform._exec()\n~~~\n\n\n### image_button / ImageButton\n\nThe `image_id` keyword is used to identify the image button when it is clicked. If no `image_id` is provided, the path to the image is used as id.\n\nOpenSesame script:\n\n~~~python\n# Only path is a required keyword\nwidget 0 0 1 1 image_button path=\"my_image.png\" adjust=yes frame=no image_id=my_image var=response\n~~~\n\nPython script:\n\n~~~ .python\n# Only path is a required keyword\nform = Form()\nimage_button = ImageButton(\n    path=pool['my_image.png'], adjust=True, frame=False,\n    image_id='my_image', var='response'\n)\nform.set_widget(image_button, (0, 0))\nform._exec()\n~~~\n\n\n### label / Label\n\nOpenSesame script:\n\n~~~python\nwidget 0 0 1 1 label text=\"My text\" frame=no center=yes\n~~~\n\nPython script:\n\n~~~ .python\nform = Form()\nlabel = Label(text='My text', frame=False, center=True)\nform.set_widget(label, (0,0))\nform._exec()\n~~~\n\n\n### rating_scale / RatingScale\n\nThe `nodes` keyword can be an `int` or a semicolon-separated list of labels. If `nodes` is an `int`, it specified the number of (unlabeled) nodes.\n\nThe `default` keyword indicates which node number is selected by default, where the first node is 0.\n\nOpenSesame script:\n\n~~~python\nwidget 0 1 1 1 rating_scale var=response nodes=\"Agree;Don't know;Disagree\" click_accepts=no orientation=horizontal var=response default=0\n~~~\n\nPython script:\n\n~~~ .python\nform = Form()\nrating_scale = RatingScale(\n    nodes=['Agree', u\"Don't know\", 'Disagree'], click_accepts=False,\n    orientation='horizontal', var='response', default=0\n)\nform.set_widget(rating_scale, (0, 0))\nform._exec()\n~~~\n\n\n### text_input / TextInput\n\nThe `stub` keyword indicates placeholder text that is shown when no text has been entered. The `key_filter` keyword, available only in Python, specifies a function to filter key presses. This is described in more detail under:\n\n- %link:manual/forms/validation%\n\nOpenSesame script:\n\n~~~python\nwidget 0 0 1 1 text_input text=\"Initial text\" frame=yes center=no stub=\"Type here \u2026\" return_accepts=yes var=response\n~~~\n\nPython script:\n\n~~~ .python\nform = Form()\ntext_input = TextInput(\n    text='Initial text', frame=True, center=False, stub='Type here \u2026',\n    return_accepts=True, var='response', key_filter=my_filter_function\n)\nform.set_widget(text_input, (0, 0))\nform._exec()\n~~~", "url": "https://osdoc.cogsci.nl/4.0/manual/forms/widgets", "title": "Form widgets and keywords"}
{"content": "# Creating custom forms\n\ntitle: Creating custom forms\n\n\n[TOC]\n\n\n## About forms, geometries, and widgets\n\nA form is a set of widgets (buttons, labels, text-input fields, etc.) arranged into a grid with a particular geometry. In the image below you see an example of a 2 (columns) \u00d7 3 (rows) form. A form geometry is simple, and consists of the following properties:\n\n- *margins* ensure that the widgets do not touch the edge of the display. You can have different margins for the top, right, bottom, and left.\n- *spacing* ensure that the widgets do not touch each other. The horizontal and vertical spacing is the same.\n- There are one or more *rows*, possibly of different sizes.\n- There are one or more *columns*, possibly of different sizes.\n\n%--\nfigure:\n id: FigGeometry\n source: geometry.png\n caption: A schematic of FORM geometries.\n--%\n\nOf course, an empty form is no fun. So let's add the following widgets to create a simple question form:\n\n- A `label` that spans the two columns of the top row. We use this label to give a title to the form.\n- Another `label` that spans the two columns of the middle row. This label contains the actual question.\n- A `button` in the bottom right widget area. This button allows the user to give the $0.05 response.\n- Another `button` in the bottom left widget area. This button allows the user to give the $0.10 response.\n\n%--\nfigure:\n id: FigSchematicExample1\n source: schematic-example1.png\n caption: A schematic example FORM.\n--%\n\nThe images above are schematic examples. How this form actually looks in OpenSesame depends on your settings (notably your font and colors), but it may look something like this:\n\n%--\nfigure:\n id: FigExample1\n source: example1.png\n caption: A example FORM.\n--%\n\n## Creating custom forms\n\nThere are two ways to create custom forms. You can:\n\n- Use the FORM_BASE item, and specify your form using OpenSesame script.\n- Using Python in an INLINE_SCRIPT item. The Python way is slightly more flexible, but for most purposes both ways can be used.\n\n### Creating forms using OpenSesame script\n\nWe will create the form described above using OpenSesame script. First, drag the FORM_BASE plugin into your experiment. Click on the newly created item to open its tab. Next, click on the 'Edit script' button (with the terminal icon), in the top-right of the tab area. This will open the script editor. Enter the following script to generate the form described above (see the comments for explanations).\n\n~~~\n# Margins are defined as \"top;right;bottom;left\". Each value corresponds to a\n# margin in pixels.\nset margins \"50;100;50;100\"\n# The spacing is simply a value in pixels.\nset spacing \"25\"\n# The sizes of the rows are relative. \"1;2;1\" means that there are three rows,\n# where the middle one is twice as large as the bottom and top ones. So \"1;2;1\"\n# means exactly the same thing as \"3;6;3\". Please note that \"3\" does not mean\n# that there are three equally-sized rows (but \"1;1;1\" does).\nset rows \"1;2;1\"\n# Columns are defined in the same way. \"1;1\" simply means that there\n# are two columns of the same size.\nset cols \"1;1\"\n# Widgets are defined as follows:\n# widget [column] [row] [column span] [row span] [widget type] [keywords]\n#\n# The columns and rows start counting at 0. If you do not want to have your widget\n# span multiple columns and rows, you simply set the column and row span to 1.\nwidget 0 0 2 1 label text=\"Question\"\nwidget 0 1 2 1 label center=\"no\" text=\"A bat and a baseball together cost $1.10. The bat costs one dollar more than the ball. How much does the ball cost?\"\nwidget 0 2 1 1 button text=\"$0.10\"\nwidget 1 2 1 1 button text=\"$0.05\"\n~~~\n\nIf you want a specific widget to receive the focus when the form is executed, you can apply the `focus=yes` keyword to one of the widgets:\n\n```\nwidget 0 0 1 1 text_input text=\"Initial text\" frame=yes center=no stub=\"Type here \u2026\" return_accepts=yes var=response focus=yes\n```\n\n\n### Creating forms using Python inline script\n\nThe exact same form can be created using an INLINE_SCRIPT and a bit of Python code. You will notice that the Python code somewhat resembles the OpenSesame script shown above. This is no wonder: The FORM_BASE plugin essentially translates the OpenSesame script into Python code.\n\nFirst, drag an INLINE_SCRIPT into your experiment. Select the newly created item to open its tab, and add the following script into the Run phase of the INLINE_SCRIPT item (see the comments for explanations).\n\n~~~ .python\n# Create a form\nform = Form(\n    cols=[1,1], rows=[1,2,1],\n    margins=(50,100,50,100), spacing=25\n)\n# Create four widgets\nlabelTitle = Label(text='Question')\nlabelQuestion = Label(\n    text='A bat and a baseball together cost $1.10. The bat costs one dollar more than the ball. How much does the ball cost?',\n    center=False\n)\nbutton5cts = Button(text='$0.05')\nbutton10cts = Button(text='$0.10')\n# Add the widgets to the form. The position in the form is indicated as a\n# (column, row) tuple.\nform.set_widget(labelTitle, (0,0), colspan=2)\nform.set_widget(labelQuestion, (0,1), colspan=2)\nform.set_widget(button5cts, (0,2))\nform.set_widget(button10cts, (1,2))\n# Execute the form! In this case, the form will return the text of the button that\n# was clicked. This is one way to get a return value out of the form. Another way\n# is to use the 'var' keyword, supported some of the widgets.\nbutton_clicked = form._exec()\n~~~\n\nIf you want a specific widget to receive the focus when the form is executed, you can use the `focus_wiget` keyword:\n\n~~~ .python\nbutton_clicked = form._exec(focus_widget=button5cts)\n~~~\n\n### Non-interactive forms\n\nUsually, a form will have an input field, a button, or some other interactive element. However, you can also use forms without having any interactive element. To do this in OpenSesame script, you set `only_render` to \"yes\":\n\n```python\nset only_render yes\n```\n\nTo this in a Python INLINE_SCRIPT, you call `form.render()`, instead of `form._exec()`.\n\n### Themes\n\nForms support theming. Currently, two themes are available: 'gray' and 'plain'. The 'gray' theme is the default. Although the 'gray' theme is already quite plain, the 'plain' theme is even more basic. You can choose a theme like this in OpenSesame script:\n\n```python\nset theme plain\n```\n\nAnd by using the `theme` keyword in Python inline script:\n\n~~~ .python\nform = Form(theme='plain')\n~~~\n\n### Available widgets and keywords\n\nFor a list of available widgets and keywords, see:\n\n- %link:manual/forms/widgets%\n\n### Validating input\n\nTo see how you can validate form input, see:\n\n- %link:manual/forms/validation%\n\n## Another example\n\nThe following OpenSesame script (in a FORM_BASE plugin) will produce a questionnaire of three rating scales plus a next button:\n\n```python\nset rows \"1;1;1;1;1\"\nset cols \"1;1\"\nwidget 0 0 2 1 label text=\"Indicate how much you agree with the following statements\"\nwidget 0 1 1 1 label center=\"no\" text=\"Forms are easy\"\nwidget 1 1 1 1 rating_scale var=\"question1\" nodes=\"Agree;Don't know;Disagree\"\nwidget 0 2 1 1 label center=\"no\" text=\"I like data\"\nwidget 1 2 1 1 rating_scale var=\"question2\" nodes=\"Agree;Don't know;Disagree\"\nwidget 0 3 1 1 label center=\"no\" text=\"I like questionnaires\"\nwidget 1 3 1 1 rating_scale var=\"question3\" nodes=\"Agree;Don't know;Disagree\"\nwidget 0 4 2 1 button text=\"Next\"\n```\n\nThe following Python inline_script will produce the same questionnaire.\n\n~~~ .python\nform = Form(cols=[1,1], rows=[1,1,1,1,1])\ntitle = Label(\n    text='Indicate how much you agree with the following statement'\n)\nquestion1 = Label(text='Forms are easy', center=False)\nquestion2 = Label(text='I like data', center=False)\nquestion3 = Label(text='I like questionnaires', center=False)\nratingScale1 = RatingScale(\n    var='question1',\n    nodes=['Agree', u\"Don't know\", 'Disagree']\n)\nratingScale2 = RatingScale(\n    var='question2',\n    nodes=['Agree', u\"Don't know\", 'Disagree']\n)\nratingScale3 = RatingScale(var='question3',\n    nodes=['Agree', u\"Don't know\", 'Disagree'])\nnextButton = Button(text='Next')\nform.set_widget(title, (0, 0), colspan=2)\nform.set_widget(question1, (0, 1))\nform.set_widget(question2, (0, 2))\nform.set_widget(question3, (0, 3))\nform.set_widget(ratingScale1, (1, 1))\nform.set_widget(ratingScale2, (1, 2))\nform.set_widget(ratingScale3, (1, 3))\nform.set_widget(nextButton, (0, 4), colspan=2)\nform._exec()\n~~~\n\nThe resulting form looks something like this. (The exact appearance depends on your font, colors, etc.)\n\n%--\nfigure:\n id: FigExample2\n source: example2.png\n caption: Another example FORM.\n--%", "url": "https://osdoc.cogsci.nl/4.0/manual/forms/custom", "title": "Creating custom forms"}
{"content": "# Validating form input\n\ntitle: Validating form input\n\n\nTo validate a form, pass a function with the `validator` keyword to `Form()`. In the example below, `my_form_validator()` is used in this way. A validator function should not expect any arguments, and should return a `bool` to indicate whether or not the form validates. If the form does not validate, no error message is shown, but the form simply stays open.\n\nIn addition, you can validate (or filter) input to a `TextInput` widget to exclude certain characters as input. To do so, pass a function with the `key_filter` keyword to `TextInput()`. In the example below, `filter_digits()` is used in this way. A key-filter function should accept a single argument, which corresponds to a single key press, and should return a `bool` to indicate whether or not the key is accepted as input.\n\n~~~ .python\ndef my_form_validator():\n    \"\"\"Checks whether both the gender and age fields have been filled out\"\"\"\n    return gender != 'no' and age != ''\n\n\ndef filter_digits(ch):\n    \"\"\"Allows only digit characters as input\"\"\"\n    return ch in '0123456789'\n\n\n# Define all widgets\nbutton_ok = Button(text='Ok')\nlabel_gender= Label('Your gender')\ncheckbox_male = Checkbox(text='Male', group='gender', var='gender')\ncheckbox_female = Checkbox(text='Female', group='gender', var='gender')\nlabel_age = Label('Your age')\n# Specify a key filter so that only digits are accepted as text input\ninput_age = TextInput(stub='Age here \u2026', var='age', key_filter=filter_digits)\n# Build the form. Specify a validator function to make sure that the form is\n# completed.\nmy_form = Form(validator=my_form_validator, rows=[1,1,1], cols=[1,1,1])\nmy_form.set_widget(label_gender, (0, 0))\nmy_form.set_widget(checkbox_male, (1, 0))\nmy_form.set_widget(checkbox_female, (2, 0))\nmy_form.set_widget(label_age, (0, 1))\nmy_form.set_widget(input_age, (1, 1), colspan=2)\nmy_form.set_widget(button_ok, (1, 2))\nmy_form._exec()\n~~~", "url": "https://osdoc.cogsci.nl/4.0/manual/forms/validation", "title": "Validating form input"}
{"content": "# CSV functions (csv-parse)\n\ntitle: CSV functions (csv-parse)\n\nThe synchronous `parse()` function from the `csv-parse` library is available. This allows you to parse CSV-formatted text, for example from a CSV file in the file pool, into an Object.\n\n__Example:__\n\n```js\nconst conditions = csvParse(\n    pool['attentional-capture-jobs.csv'].data,\n    {columns: true}\n)\nfor (const trial of conditions) {\n    console.log(trial.distractor)\n}\n```\n\nFor an overview, see:\n\n- <https://csv.js.org/parse/api/sync/#sync-api>", "url": "https://osdoc.cogsci.nl/4.0/manual/javascript/csv", "title": "CSV functions (csv-parse)"}
{"content": "# Python-like iterators (pythonic)\n\ntitle: Python-like iterators (pythonic)\n\nThe `pythonic` library provides Python-like functions for iterating over arrays. Available functions are: `range()`, `enumerate()`, `items()`, `zip()`, and `zipLongest()`.\n\n__Example:__\n\nDraw a five by five grid of incrementing numbers:\n\n```js\nlet positions = xy_grid(5, 50)\nconst cnv = Canvas()\nfor (const [i, [x, y]] of enumerate(positions)) {\n    cnv.text({text: i, x: x, y: y})\n}\ncnv.show()\n```\n\nFor an overview, see:\n\n- <https://www.npmjs.com/package/pythonic>", "url": "https://osdoc.cogsci.nl/4.0/manual/javascript/pythonic", "title": "Python-like iterators (pythonic)"}
{"content": "# About JavaScript\n\ntitle: About JavaScript\n\nIn OpenSesame you can create complex experiments using only the graphical user interface (GUI). But you will sometimes encounter situations in which the functionality provided by the GUI is insufficient. In these cases you can add JavaScript code to your experiment.\n\nJavaScript is for experiments that run in a browser with OSWeb. If you need to run your experiment on the desktop, you need to use [Python](%url:manual/python/about%) instead of JavaScript.\n\n__Version note:__ Desktop support for JavaScript was removed in OpeSesame 4.0. This is because JavaScript support on the desktop was incomplete and was perceived by users as confusing without adding much benefit.\n{: .page-notification}\n\n[TOC]\n\n\n## Learning JavaScript\n\nThere are many JavaScript tutorials available online. One good resource is Code Academy:\n\n- <https://www.codecademy.com/learn/introduction-to-javascript>\n\n\n## JavaScript in the OpenSesame GUI\n\n\n### Inline_javascript items\n\nIn order to use JavaScript code you need to add an INLINE_JAVASCRIPT item to your experiment. After you have done this you will see something like %FigInlineJavaScript.\n\n%--\nfigure:\n id: FigInlineJavaScript\n source: inline-javascript.png\n caption: The INLINE_JAVASCRIPT item.\n--%\n\nAs you can see, the INLINE_JAVASCRIPT item consists of two tabs: one for the Prepare phase and one for the Run phase. The Prepare phase is executed first, to allow items to prepare for the time-critical run phase. It is good practice to construct `Canvas` objects during the Prepare phase, so that they can be presented without delay during the Run phase. But this is only convention; you can execute arbitrary JavaScript code during both phases.\n\nFor more information about the prepare-run strategy, see:\n\n- %link:prepare-run%\n\n\n### Printing output to the console\n\nYou can print to the console with the `console.log()` command:\n\n```js\nconsole.log('This will appear in the console!')\n```\n\nWhen running on the desktop, the output will appear in the OpenSesame console (or: debug window). When running in a browser, the output will appear in the browser console.\n\n\n## Things to know\n\n### Common functions\n\nMany common functions are directly available in an INLINE_JAVASCRIPT item. For example:\n\n```js\n// `Canvas()` is a factory function that returns a `Canvas` object\nlet fixdotCanvas = Canvas()\nif (sometimes()) {  // Sometimes the fixdot is green\n    fixdotCanvas.fixdot({color: 'green'})\n} else {  // Sometimes it is red\n    fixdotCanvas.fixdot({color: 'red'})\n}\nfixdotCanvas.show()\n```\n\nFor a list of common functions, see:\n\n- %link:manual/javascript/common%\n\n\n### Declaring variables (let and var)\n\nINLINE_JAVASCRIPT items are executed in non-strict (or: sloppy) mode. This means that you can assign a value to a variable that was not explicitly declared. When you do this, the variable is implicitly declared using `var` if it wasn't already declared.\n\n```js\nmy_variable = 'my value'  // implicitly declared using var\n```\n\nVariables that are declared implicitly or explicitly using `var` are global, which primarily means that they may be logged by a LOGGER. Variables that are declared using `let` are not global, which primarily means that they are not logged by a LOGGER.\n\n```js\nthis_is_a_global_variable = 'my value'\nvar this_is_also_a_global_variable = 'my value'\nlet this_is_not_a_global_variable = 'my value'\n```\n\n\n### The `persistent` object: preserving objects across scripts\n\n__Version note__ As of OSWeb 2.0, all JavaScript code is executed in the same workspace and objects are therefore preserved across scripts. This means that you no longer need the `persistent` object.\n{:.page-notification}\n\nEach INLINE_JAVASCRIPT item is executed in its own workspace. This means\u2014and this is different from Python INLINE_SCRIPT items!\u2014that you cannot use variables or functions that you've declared in one script in another script. As a workaround, you can attach variables or functions as properties to the `persistent` object, which serves as a container of things that you want to preserve across scripts.\n\nThis way you can construct a `Canvas` in one INLINE_JAVASCRIPT ...\n\n```js\npersistent.myCanvas = Canvas()\npersistent.myCanvas.fixdot()\n```\n\n.. and show it in another INLINE_JAVASCRIPT:\n\n```js\npersistent.myCanvas.show()\n```\n\n\n### The `vars` object: Access to experimental variables\n\n__Version note__ As of OSWeb 2.0, all experimental variables are available as globals. This means that you no longer need the `vars` object.\n{:.page-notification}\n\nYou can access experimental variables through the `vars` object:\n\n```js\n// OSWeb <= 1.4 (with vars object)\n// Get an experimental variable\nconsole.log('my_variable is: ' + vars.my_variable)\n// Set an experimental variable\nvars.my_variable = 'my_value'\n\n// OSWeb >= 2.0 (without vars object)\n// Get an experimental variable\nconsole.log('my_variable is: ' + my_variable)\n// Set an experimental variable\nmy_variable = 'my_value'\n```\n\n\n### The `pool` object: Access to the file pool\n\nYou access 'files' from the file pool through the `pool` object. The most obvious use of this is to parse CSV files, for example with experimental conditions, from the file pool using the `csv-parse` library (described in more detail below).\n\n```js\nconst conditions = csvParse(\n    pool['attentional-capture-jobs.csv'].data,\n    {columns: true}\n)\nfor (const trial of conditions) {\n    console.log(trial.distractor)\n}\n```\n\nYou can also play sound files from the file pool directly. Assuming that there is a file called `bark.ogg` in the file pool, you can play it like so:\n\n```js\npool['bark.ogg'].data.play()\n```\n\n\n### The `Canvas` class: Presenting visual stimuli\n\nThe `Canvas` class is used to present visual stimuli. For example, you can show a fixation dot as follows:\n\n```js\nlet myCanvas = Canvas()\nmyCanvas.fixdot()\nmyCanvas.show()\n```\n\nA full overview of the `Canvas` class can be found here:\n\n- %link:manual/javascript/canvas%\n\n## Available JavaScript libraries\n\nThe following JavaScript libraries are included by default:\n\n- [random functions (`random-ext`)](%url:manual/javascript/random%)\n- [Color-conversion functions (`color-convert`)](%url:manual/javascript/color-convert%)\n- [CSV functions (`csv-parse`)](%url:manual/javascript/csv%)\n- [Python-like iterators (`pythonic`)](%url:manual/javascript/pythonic%)\n\nYou can include additional JavaScript libraries by URLs to the libraries in the 'External JavaScript' libraries field of the OSWeb control panel.\n\n\n## Debugging\n\nSee:\n\n- %link:debugging%", "url": "https://osdoc.cogsci.nl/4.0/manual/javascript/about", "title": "About JavaScript"}
{"content": "# Common functions\n\nThe provided API is a JavaScript API designed for use with OpenSesame, a software platform widely used for creating and conducting psychology experiments. This API consists of a suite of functions that can be employed within OpenSesame to add interactivity, collect data, and manipulate the experiment environment programmatically.\n\nThis API is particularly relevant for users who wish to enhance their psychology experiments with custom scripts and functionalities. It is designed to be used in conjunction with `Canvas` functions, which are part of OpenSesame's feature set for drawing stimuli and interfacing with the participant's visual input.\n\nUnfortunately, the actual list of functions and their parameters is not provided in the snippet above. The snippet indicates that there is a markdown document (likely containing the API documentation) included within the text, but the contents of this document are not directly visible. Normally, one would expect to see a bulleted list of functions here, each with a brief description of its purpose and the parameters it accepts.\n\nTo summarize, the API provides:\n\n- A set of JavaScript functions tailored for use in OpenSesame.\n- Capabilities that complement `Canvas` functions for visual stimuli presentation.\n- Tools to enhance the interactivity and data collection capabilities of psychology experiments.\n\nTo fully understand the API's capabilities, access to the included markdown document (javascript_workspace_api.md) would be necessary. That document would contain the specific details about each function, including their names, parameters, and descriptions of what they do.", "url": "https://osdoc.cogsci.nl/4.0/manual/javascript/common", "title": "Common functions"}
{"content": "# random functions (random-ext)\n\ntitle: random functions (random-ext)\n\n\nThe `random-ext` library is available as `random`. This library provides many convenient, higher-level functions for randomization.\n\n__Example:__\n\nDraw eight circle with a random color and a location that is randomly sampled from a five by five grid:\n\n```js\nlet positions = xy_grid(5, 50)\npositions = random.subArray(positions, 8)\nconst cnv = Canvas()\ncnv.fixdot()\nfor (const [x, y] of positions) {\n    cnv.circle({x: x, y: y, r: 20, fill: true, color: random.color()})\n}\ncnv.show()\n```\n\nFor an overview, see:\n\n- <https://www.npmjs.com/package/random-ext>", "url": "https://osdoc.cogsci.nl/4.0/manual/javascript/random", "title": "random functions (random-ext)"}
{"content": "# Canvas functions\n\nThe API described is a JavaScript-based Application Programming Interface (API) designed specifically for OpenSesame, which is a software platform used for conducting psychological experiments. The overall functionality of this API centers around providing a means for experiment designers to create, manipulate, and display visual content on a digital canvas as part of their experimental setups.\n\nTo utilize this API for visual experiments, one must first initialize a `Canvas` object. Initializing a `Canvas` typically involves specifying its dimensions and optionally, the initial content that should be displayed. The canvas acts as a drawing surface where visual elements can be added or modified.\n\nThe `styleArgs` parameter is used to define the styling of the canvas and its elements. This could include details such as color, font, line thickness, and more. By setting `styleArgs`, users can customize the appearance of text, shapes, and other graphical elements to match their experimental design.\n\nIn terms of coordinates, the API uses a coordinate system where x=0 and y=0 represent the center of the display. This central origin allows for a more intuitive placement of elements on the canvas, especially in psychology experiments where stimuli often need to be positioned relative to a participant's focal point.\n\nThe available functions in the API cover a range of operations related to the `Canvas` object, including but not limited to:\n\n- **Creation of a new Canvas**: This function would initialize a new canvas with specified dimensions.\n- **Drawing shapes**: Parameters would include shape type (e.g., rectangle, circle), position, size, and style arguments.\n- **Adding text**: Parameters would include the text string, position, font specifications, and styling options.\n- **Clearing the canvas**: This function would remove all elements from the canvas, possibly with parameters to specify a certain area to clear.\n- **Updating elements**: Parameters would include the identifier of the element to update and the new values for its properties, such as position or style.\n- **Saving the canvas state**: This would allow the current state of the canvas to be saved for later restoration.\n- **Restoring a saved state**: This function would revert the canvas to a previously saved state.\n- **Exporting the canvas content**: Parameters could include the file format and options for what part of the canvas to export.\n\nPlease note that the exact names and parameters of the functions cannot be provided, as the actual API documentation content is not included in the provided text snippet. The bullet points listed are generic descriptions of common functions that one might expect to find in a canvas-manipulation API for psychological experiments.", "url": "https://osdoc.cogsci.nl/4.0/manual/javascript/canvas", "title": "Canvas functions"}
{"content": "# Color conversion functions (color-convert)\n\ntitle: Color conversion functions (color-convert)\n\n\nThe `color-convert` library is available as `convert`. It provides convenient high level functions for converting from one color specification to another.\n\n__Example:__\n\n```js\nconsole.log('The RGB values for blue are ' + convert.keyword.rgb('blue'))\n```\n\nFor an overview, see:\n\n- <https://www.npmjs.com/package/color-convert>", "url": "https://osdoc.cogsci.nl/4.0/manual/javascript/color-convert", "title": "Color conversion functions (color-convert)"}
{"content": "# Downloading and converting data\n\ntitle: Downloading and converting data\n\nAfter collecting data with OSWeb through JATOS, you can download and process this data for analysis. To download, navigate to your study within JATOS, click on 'Results', select all Result entries, and then choose 'Export Results \u2192 JATOS Results Archive' (see %FigJatosExportResults).\n\n%--\nfigure:\n id: FigJatosExportResults\n source: jatos-export-results.png\n caption: Procedure for exporting results collected with OSWeb through JATOS.\n--%\n\nThe downloaded file, typically named in the format `jatos_results_<timestamp>.jzip`, contains various folders and files corresponding to metadata and participant data. This format can be difficult to work with directly for data analysis.\n\nTo simplify data analysis, you can convert this file to a more accessible format like `.csv` or `.xlsx`. This conversion can be easily achieved by using the 'Convert OSWeb results to csv/xlsx' option found in the OSWeb extension.", "url": "https://osdoc.cogsci.nl/4.0/manual/osweb/data", "title": "Downloading and converting data"}
{"content": "# Running experiments online with OSWeb\n\ntitle: Running experiments online with OSWeb\n\n\n[TOC]\n\n\n## The workflow\n\nFor an introduction to the workflow, see also:\n\nMath\u00f4t, S., & March, J. (2022). Conducting linguistic experiments online with OpenSesame and OSWeb. *Language Learning*. doi:10.1111/lang.12509\n<br /><small>[Related preprint (not identical to published manuscript)](https://doi.org/10.31234/osf.io/wnryc)</small>\n\n\n### Developing your experiment\n\nFirst, you develop your experiment as you ordinarily would, using the OpenSesame desktop application. Not all functionality is available in online experiments. Notably, you cannot use Python INLINE_SCRIPT items, but have to use JavaScript INLINE_JAVASCRIPT items instead. During the development of your experiment, it is therefore important to check that your experiment is compatible with OSWeb.\n\n- %link:manual/osweb/osweb%\n- %link:manual/javascript/about%\n\n\n### Uploading your experiment to JATOS\n\nOnce you have developed your experiment, you publish it to JATOS. JATOS is a web server that manages experiments: it allows you to generate links that you can distribute participants, and it stores data that has been collected.\n\nThere is not a single JATOS server. Rather, many institutions maintain their own JATOS server. In addition, <https://mindprobe.eu> is a free JATOS server, sponsored by ESCoP and OpenSesame.\n\n- %link:jatos%\n\n\n### Collecting data\n\nOne you have published your experiment to JATOS, you can start collecting data. You can do this by manually sending links to participants, for example through email. Or you can use a platform for participant recruitment, such as Prolific, Mechanical Turk, or Sona Systems.\n\n- %link:prolific%\n- %link:mturk%\n- %link:sonasystems%\n\n\n### Analyzing data\n\nOnce data collection is finished, you can download the data from JATOS and convert it to `.xlsx` or `.csv` format for further analysis:\n\n- %link:manual/osweb/data%\n\n\n## Tutorials\n\n- %link:tutorials/intermediate-javascript%\n- %link:wcst%", "url": "https://osdoc.cogsci.nl/4.0/manual/osweb/workflow", "title": "Running experiments online with OSWeb"}
{"content": "# JATOS\n\ntitle: JATOS\n\n\n[TOC]\n\n\n## Introduction to JATOS\n\n[JATOS](https://www.jatos.org/) is a system for managing online experiments. It allows you to create accounts for experimenters, upload experiments, and generate links that you can distribute to participants. OpenSesame integrates closely with JATOS.\n\nTo access a JATOS server, you have three main options:\n\n- Request a free account on [MindProbe](https://mindprobe.eu/), a public JATOS server sponsored by ESCoP and OpenSesame.\n- se a JATOS server provided by your institution.\n- Download JATOS and install it on your own server.\n\n## Linking OpenSesame with JATOS/MindProbe\n\nOpenSesame requires an API token to access your account on a JATOS server such as MindProbe. Follow these steps to generate an API token:\n\n1. **Log into JATOS.**\n2. **Open your user profile** by clicking on your name located in the top right corner of the page.\n3. **Create an API token** by clicking on 'API tokens' to view all your current tokens, and then click 'New Token'.\n4. **Assign a name to your token**. This name serves as a descriptor indicating its intended use, such as 'OpenSesame integration'.\n5. **Set an expiration for your token**. Tokens default to expire after 30 days, requiring you to generate a new token each month. You can select 'No Expiration' for convenience, but be aware that it is less secure. If someone gains access to a non-expiring token, they can use it indefinitely, or until you revoke the token.\n\n%--\nfigure:\n id: FigAPIToken\n source: api-token.png\n caption: API tokens can be generated within your JATOS user profile.\n--%\n\nNote: An API token always begins with `jap_`, followed by a series of characters and numbers. Keep your token secure!\n\nOnce you have your API token, open the OSWeb and JATOS control panel in OpenSesame. Enter your API token into the corresponding field and also adjust the JATOS server URL, if necessary.\n\n%--\nfigure:\n id: FigJATOSControlPanel\n source: jatos-control-panel.png\n caption: Specify the JATOS server and your API token in the OSWeb and JATOS control panel.\n--%\n\n\n## Publishing experiments to, and downloading from, JATOS/MindProbe\n\nAfter successfully connecting OpenSesame to JATOS, as explained above, you can publish your experiment to JATOS. To do this, select the 'Publish to JATOS/MindProbe' option from the File menu. Upon initial publication, your experiment will be assigned a unique identifier (UUID) that links it to a study on JATOS.\n\nYou can then visit your JATOS server and observe that the newly published experiment has been added to your list of studies.\n\nFrom that point forward, each time you publish the experiment, the existing JATOS study will be updated with the new version. If you wish to publish the experiment as a completely new study on JATOS, you will need to reset the JATOS UUID via the OSWeb and JATOS control panel.\n\nTo download an experiment from JATOS, select the 'Open from JATOS/MindProbe' option from the File menu. Please note, this function is only applicable if the corresponding JATOS study is compatible with OSWeb 2.", "url": "https://osdoc.cogsci.nl/4.0/manual/osweb/jatos", "title": "JATOS"}
{"content": "# Inline JavaScript\n\ntitle: Inline JavaScript\n\nThis page has moved to:\n\n- %link:manual/javascript/about%", "url": "https://osdoc.cogsci.nl/4.0/manual/osweb/javascript", "title": "Inline JavaScript"}
{"content": "# Sona Systems\n\ntitle: Sona Systems\n\n\n[TOC]\n\n\n## About Sona Systems\n\nSona Systems is an online tool that many universities use for recruiting participants, granting course credit to student participants, etc.\n\nSee also:\n\n- <https://www.sona-systems.com/help/integration_test.aspx>\n\n\n## Create a study on JATOS\n\nFirst, import your experiment into JATOS, as described above. Next, go the Worker & Batch Manager, activate the General Multiple Worker, get a URL by clicking on Get Link, and copy it.\n\n\n## Create a study on Sona Systems\n\nNext, create a study on Sona Systems. Insert the JATOS study URL in the field labeled \"Study URL\". This will tell Sona Systems how to start the experiment. Importantly, add the following to the end of the URL (this will pass the participant's Sona ID to your experiment):\n\n```bash\n?SONA_ID=%SURVEY_CODE%  \n```\n\nSona Systems does not use a Redirect URL. This means that Sona Systems will not automatically know whether or not the participant finished the study.\n\n\n## Register the Sona ID in your experiment\n\nEvery participant from Sona is identified by a unique ID. It's important to log this ID in your experiment, because this allows you to tell which participant from Sona corresponds to which entry in the JATOS results. You can do this by adding the script below in the Prepare phase of an `inline_javascript` item at the very start of your experiment.\n\nWhen running the experiment through Sona, this will make the Sona ID available as the experimental variable `sona_participant_id`. When the running the experiment in any other way (e.g. during testing), the variable `sona_participant_id` will be set to -1. \n\n\n```javascript\nif (window.jatos && jatos.urlQueryParameters.SONA_ID) {\n    console.log('Sona information is available')\n    var sona_participant_id = jatos.urlQueryParameters.SONA_ID\n} else {\n    console.log('Sona information is not available (setting value to -1)')\n    var sona_participant_id = -1\n}\nconsole.log('sona_participant_id = ' + sona_participant_id)\n```\n\n\n## Automatically grant credits on study completion\n\nSona Systems provides a completion URL (client-side), which should be called when a study is succesfully completed, so that Sona Systems can grant credit to the participant (see %FigCompletionURL).\n\n%--\nfigure:\n id: FigCompletionURL\n source: completion-url.png\n caption: The completion URL in the Sona Systems study information.\n--%\n\nThe completion URL (client side) has three arguments in it:\n\n- `experiment_id` which identifies the study and is the same for all participants\n- `credit_token` which (apparently) changes when you change the study information, but is otherwise the same for all participants\n- `survey_code` which corresponds to the Sona Participant ID, and is therefore different for each participant\n\nCopy the completion URL, and replace the `XXX` by `[SONA_ID]`. Go to Study Properties on JATOS, and insert the resulting URL into the End Redirect URL field.\n\n%--\nfigure:\n id: FigEndRedirectURL\n source: end-redirect-url.png\n caption: The end-redirect URL in the JATOS study properties.\n--%", "url": "https://osdoc.cogsci.nl/4.0/manual/osweb/sonasystems", "title": "Sona Systems"}
{"content": "# OSWeb\n\ntitle: OSWeb\n\n\n[TOC]\n\n\n## About OSWeb\n\nOSWeb is an online runtime for OpenSesame experiments. It is a JavaScript library that executes OpenSesame experiments in a browser. To use OSWeb, you need the `opensesame-extension-osweb` package, which comes pre-installed with the Windows and macOS distributions of OpenSesame.\n\n\n## Executing an experiment in a web browser\n\nTo run an experiment in a web browser using OSWeb, follow these steps:\n\n1. Open the Experiment Properties and select 'In a browser with OSWeb (osweb)' in the 'Run experiment' section.\n2. Click any of the 'Run' buttons to start the experiment.\n3. If the experiment is not compatible with OSWeb, an error message will appear that details the compatibility issues. (Refer to the 'supported functionality' section for more details.)\n4. If there are no compatibility issues, the experiment will open in a new browser window. Note that even though the experiment is running in a web browser, it is still executing locally on your own computer. To host the experiment online, you need to publish it to [JATOS](%url:jatos%).\n5. When the experiment is finished, the data will be downloaded in `.json` format. This data file can then be [converted to `.xlsx` or `.csv` format](%url:manual/osweb/data%) for further analysis.\n\n\n%--\nfigure:\n id: FigTestRun\n source: testrun.png\n caption: Open the Experiment Properties and select 'In a browser with OSWeb (osweb)' under 'Run experiment'.\n--%\n\n\n## OSWeb control panel\n\nFor more control over OSWeb experiments, you can access the OSWeb and JATOS control panel from the Tools menu. This panel offers a range of configuration options:\n\n- **Possible subject numbers:** When running an experiment from within JATOS, a subject number is randomly selected from this list. You can specify individual numbers using commas (e.g., '1,2,3') or number ranges (e.g., '1-10'). When running an experiment from within OpenSesame, this option does not apply, as the subject number is specified when the experiment starts.\n- **Make browser fullscreen:** This option determines whether the browser should switch to fullscreen mode when an experiment starts within JATOS. If you're running an experiment directly from OpenSesame, this option is ignored; instead, you can run the experiment fullscreen by using the regular Run button, while the Quick Run button does not enable fullscreen.\n- **Show OSWeb Welcome Screen:** This toggle controls whether participants will see a welcome screen before the experiment starts. The welcome screen can convey crucial information to participants. Additionally, it serves a technical purpose\u2014due to browser-security policies, media playback and certain functionality is only available if the experiment is initiated by a user action. Therefore, it is generally recommended to leave this option enabled.\n- **Bypass Compatibility Check:** Enabling this option allows you to run the experiment even when the OSWeb compatibility check fails. Note that doing so will not automagically resolve compatibility issues!\n- **Welcome Text:** This field allows you to customize the welcome message displayed to participants on the welcome screen.\n- **External Libraries:** This field lets you specify any external libraries that should be loaded with your experiment. The use of external libraries is explained in more detail in the section below.\n\n\n%--\nfigure:\n id: FigOSWebControlPanel\n source: osweb-control-panel.png\n caption: The OSWeb and JATOS control panel offers a range of configuration options for your OSWeb experiments.\n--%\n\n\n## Supported functionality\n\nWhen you run the experiment from within OpenSesame, a compatibility check is automatically performed. However, this check is fairly superficial. A more complete overview of supported functionality can be found below.\n\n\n- `advanced_delay`\n- `feedback`\n    - See `sketchpad`\n- `form_consent` (supported >= v1.4)\n- `form_text_display` (supported >= 1.4)\n- `form_text_input` (supported >= 1.4)\n    - Unsupported: fullscreen mode\n- `form_multiple_choice` (supported >= 1.4)\n- `inline_html` (supported >= 1.4)\n- `inline_javascript`\n- `keyboard`\n    - Unsupported: key release\n    - Unsupported: HSV, HSL, and CIELab color spaces\n- `logger`\n- `loop`\n    - Unsupported: resume after break\n    - Unsupported: Disabling of evaluate on first cycle\n    - Unsupported: constraints (pseudorandomization)\n    - Supported >= 1.4: file source\n- `mouse`\n    - Unsupported: mouse release\n    - Unsupported: linked sketchpad\n- `notepad`\n- `repeat_cycle`\n- `reset_feedback`\n- `sampler`\n    - Supported >= 1.4.12: panning, pitch, and fade in\n    - Supported >= 1.4.12: Sound playback on Safari on Mac OS or any browser on iOS\n    - Unsupported: stop after\n- `sequence`\n- `sketchpad`\n    - Unsupported: named elements\n    - Supported >= 1.4: image rotation\n    - Unsupported: HSV, HSL, and CIELab color spaces\n- `touch_response`\n\n\nThe compatibility check may also indicate errors of the following type:\n\n> The prepare phase for item new_logger is called multiple times in a row\n\nThis error results from how the experiment is structured, and specifically the use of linked copies. It's not always easy to understand where this error comes from, but you can read more about the prepare-run strategy in [this article](%url:prepare-run%). As a workaround, you can put the problematic items in a dummy LOOP, that is, a LOOP that simply calls the item once.\n\n\n## Including external JavaScript packages\n\nYou can include external JavaScript packages by entering URLs to these packages (one URL per line) in the input field labeled 'External JavaScript libraries'. These packages are then included with `<script>` tags in the head of the HTML.\n\nFor example, you can include [WebGazer](%url:webgazer%) for in-browser by entering the following link:\n\n```\nhttps://webgazer.cs.brown.edu/webgazer.js\n```\n\n\n## Debugging\n\nSee:\n\n- %link:debugging%", "url": "https://osdoc.cogsci.nl/4.0/manual/osweb/osweb", "title": "OSWeb"}
{"content": "# Questionnaires in OSWeb\n\ntitle: Questionnaires in OSWeb\n\n\n## Forms and custom HTML\n\nForms and custom HTML are supported as of OSWeb 1.4\n{:.page-notification}\n\nYou can use the form plugins as described here:\n\n- %link:manual/forms/about%\n\nThe FORM_BASE plugin is *not* supported in OSWeb. Instead, you can use the INLINE_HTML item to implement custom HTML forms, as described here:\n\n- %link:manual/forms/html%\n\n\n## Linking to a different platform\n\nAs an alternative, you can implement a questionnaire using another platform, such as [LimeSurvey](https://www.limesurvey.org/), and then link to this questionnaire from your OSWeb experiment. The video below shows how to do this in such a way that you can tell afterwards which questionnaire data belongs to which OSWeb data.\n\n%--\nvideo:\n source: youtube\n id: BeginnerTutorial\n videoid: 1WvTUQr0JL0\n width: 640\n height: 360\n caption: |\n  Combining OSWeb and LimeSurvey.\n--%", "url": "https://osdoc.cogsci.nl/4.0/manual/osweb/questionnaires", "title": "Questionnaires in OSWeb"}
{"content": "# Mechanical Turk\n\ntitle: Mechanical Turk\n\n\nThere is currently no information that is specific to running OSWeb experiments on Mechanical Turk. For general information about connecting JATOS to Mechanical Turk, see:\n\n- <http://www.jatos.org/Connect-to-Mechanical-Turk.html>", "url": "https://osdoc.cogsci.nl/4.0/manual/osweb/mturk", "title": "Mechanical Turk"}
{"content": "# Prolific\n\ntitle: Prolific\n\n\n[TOC]\n\n\n## About Prolific\n\n[Prolific](https://prolific.co/) is a commercial tool for recruiting participants for research. To run OSWeb experiments on Prolific, you need to follow the steps explained below.\n\nSee also:\n\n- <http://www.jatos.org/Use-Prolific.html>\n\n\n## Create a study on JATOS\n\nFirst, import your experiment into JATOS, as described above. Next, go the Worker & Batch Manager, activate the General Multiple Worker, get a URL by clicking on Get Link, and copy it (%FigJatosURL).\n\n\n%--\nfigure:\n id: FigJatosURL\n source: jatos-url.png\n caption: Get a study URL from JATOS.\n--%\n\n\n\n## Create a study on Prolific\n\nNext, create a study on Prolific. Under Study Details (%FigProlific), insert the JATOS study URL in the field labeled \"What is the URL of your study?\". This will tell Prolific how to start the experiment. Importantly, add the following to the end of the URL (this will pass important information from Prolific to your experiment):\n\n{% raw %}\n```bash\n&PROLIFIC_PID={{%PROLIFIC_PID%}}&STUDY_ID={{%STUDY_ID%}}&SESSION_ID={{%SESSION_ID%}}\n```\n{% endraw %}\n\nWhen the experiment is finished, Prolific needs to know about it. For this purpose, Prolific uses an End Redirect URL, which is listed in the field labeled \"To prove that participants have completed your study \u2026\". Copy this End Redirect URL. Also check the box labeled \"I've set up my study to redirect to this url at the end\".\n\n%--\nfigure:\n id: FigProlific\n source: prolific.png\n caption: Study details on Prolific.\n--%\n\n\n\n## Set an End Redirect URL in JATOS\n\nNow go back to JATOS, and open the Properties of your study (%FigJatosProperties). There, paste the End Redirect URL that you have copied from Prolific in the field labeled \"End Redirect URL\". This will tell JATOS that the participant should be redirected back to Prolific when the experiment is finished, so that Prolific knows that the participant completed the experiment.\n\n\n%--\nfigure:\n id: FigJatosProperties\n source: jatos-properties.png\n caption: Set the End Redirect URL in JATOS.\n--%\n\n\n## Register Prolific information in your experiment\n\nEvery participant from Prolific is identified by a unique ID. It's important to log this ID in your experiment, because this allows you to tell which participant from Prolific corresponds to which entry in the JATOS results. You can do this by adding the script below in the Prepare phase of an `inline_javascript` item at the very start of your experiment.\n\nWhen running the experiment through Prolific, this will make the Prolific ID available as the experimental variable `prolific_participant_id`. When the running the experiment in any other way (e.g. during testing), the variable `prolific_participant_id` will be set to -1. The same logic applied to the Prolific Study ID (`prolific_study_id`) and the Prolific Session ID (`prolific_session_id`).\n\n\n```javascript\nif (window.jatos && jatos.urlQueryParameters.PROLIFIC_PID) {\n    console.log('Prolific information is available')\n    var prolific_participant_id = jatos.urlQueryParameters.PROLIFIC_PID\n    var prolific_study_id = jatos.urlQueryParameters.STUDY_ID\n    var prolific_session_id = jatos.urlQueryParameters.SESSION_ID\n} else {\n    console.log('Prolific information is not available (setting values to -1)')\n    var prolific_participant_id = -1\n    var prolific_study_id = -1\n    var prolific_session_id = -1\n}\nconsole.log('prolific_participant_id = ' + prolific_participant_id)\nconsole.log('prolific_study_id = ' + prolific_study_id)\nconsole.log('prolific_session_id = ' + prolific_session_id)\n```\n\n\n## Test the study\n\nGo back to the Study Details page on Prolific. At the bottom of the page, there is a Preview button. This allows you to test the experiment by acting as a participant yourself. Don't forget to check the JATOS results to make sure that the experiment has successfully finished, and that all the necessary information (including the Prolific information) has been logged!", "url": "https://osdoc.cogsci.nl/4.0/manual/osweb/prolific", "title": "Prolific"}
{"content": "# Looping and independent variables\n\ntitle: Looping and independent variables\n\nThe LOOP item has two important functions:\n\n- It runs another item multiple times.\n- It is where you usually define your independent variables; that is, the variables that you manipulate in your experiment.\n\n[TOC]\n\n## The item to run\n\nA LOOP is always connected to a single other item: the item to run. You select the item to run in the box labeled \"Run\". In most cases, the item to run is a SEQUENCE, which runs multiple items sequentially.\n\nTwo common SEQUENCE-LOOP structures are:\n\n- If a SEQUENCE corresponds to a single trial (by convention called *trial_sequence*), then a LOOP that is connected to this sequence corresponds to multiple trials, or a block (by convention called *block_loop*).\n- If a SEQUENCE corresponds to a block of trials followed by a feedback display (by convention called *block_sequence*), then a loop that is connected to this sequence corresponds to multiple blocks, or a complete experimental session (by convention called *experimental_loop*).\n\n## Defining independent variables\n\nThe loop table is a powerful-yet-simple way to define independent variables. Every column in the table corresponds to a variable; every row corresponds to a cycle, that is, a level of the variable. For example, a simple loop with one variable (`animal`) that has two cycles (\"cat\" and \"dog\") looks like this:\n\nanimal |\n------ |\ncat    |\ndog    |\n\nThe loop has a few important options:\n\n*Repeat* indicates how often each cycle should be executed. In the example above, repeat is set to 2, which means that *trial_sequence* is called twice while the variable `animal` has the value \"cat\", and twice while `animal` has the value \"dog\" (so four times in total).\n\n*Order* indicates whether cycles should be executed sequentially or in random order. Randomization is complete, in the sense that the complete list of number-of-cycles \u00d7 repeat trials is randomized.\n\n## Reading independent variables from file\n\nIf you want to read independent variables from file, rather than entering them into the loop table, you can do so as follows:\n\n- Set *Source* to *file*.\n- Select an Excel (`.xlsx`) or CSV (`.csv`) file in the *File* entry.\n\nThe source file follows the same conventions as the loop table; that is, each column corresponds to a variable, and each row corresponds to a cycle.\n\nCSV files are expected to be in the following format:\n\n- plain-text\n- comma-separated\n- double-quoted (literal double-quotes are escaped with backward slashes)\n- UTF-8 encoded\n\n## Breaking the loop\n\nIf you want to break the loop before all cycles have been executed, you can specify a break-if expression. This break-if expression follows the same syntax as other conditional expressions, as described on:\n\n- %link:manual/variables%\n\nFor example, the following break-if statement would break the loop as soon as a correct response is given:\n\n```python\ncorrect == 1\n```\n\nThe *Evaluate on first cycle* option indicates whether the break-if statement should be evaluated before the first cycle, in which case no cycles may be executed at all, or only before the second cycle, in which case at least one cycle is always executed. In some cases, the break-if statement will refer to a variable that is only defined after the first cycle, in which case you should disable the 'Evaluate on first cycle' option to avoid a 'Variable does not exist' error.\n\n## Generating a full-factorial design\n\nBy clicking on the *Full-factorial design* you open a wizard that allows you to easily generate a full-factorial design, that is, a design in which each combination of factors occurs.\n\n## Pseudorandomization\n\nYou can add constraints for pseudorandomization to the script of the loop item. This shuffles the rows, even if Order is set to sequential. (Currently, this is not possible through the GUI.)\n\nExample: Make sure that repetitions of the same word (given by the `word` variable) are separated by at least 4 cycles:\n\n```python\nconstrain word mindist=4\n```\n\nExample: Make sure that the same word is not repeated:\n\n```python\nconstrain word maxrep=1\n```\n\n`constrain` commands must come *after* `setcycle` commands.\n\n## Advanced loop operations\n\nCommands for advanced loop operations must come *after* `constrain` and `setcycle` commands.\n\n### fullfactorial\n\nThe `fullfactorial` instruction treats the loop table as the input for a full-factorial design. For example, the following loop table:\n\ncue   | duration\n----- | --------\nleft  | 0\nright | 100\n      | 200\n\nWould result in:\n\ncue   | duration\n----- | --------\nleft  | 0\nleft  | 100\nleft  | 200\nright | 0\nright | 100\nright | 200\n\n### shuffle\n\n`shuffle` without argument randomizes the entire table. When a column name is specified (`shuffle cue`), only that column is randomized.\n\n### shuffle_horiz\n\n`shuffle_horiz` shuffles all columns horizontally. When multiple columns are specified, only those columns are shuffled horizontally.\n\nFor example, when `shuffle_horiz word1 word2` is applied to the following table:\n\nword1 | word2 | word3\n----- | ----- | -----\ncat   | dog   | bunny\ncat   | dog   | bunny\ncat   | dog   | bunny\n\nThe result could be (i.e. values are randomly swapped between `word1` and `word2`, but not `word3`):\n\nword1 | word2 | word3\n----- | ----- | -----\ndog   | cat   | bunny\ndog   | cat   | bunny\ncat   | dog   | bunny\n\n### slice\n\n`slice [from] [to]` selects a slice from the loop. It requires a start and an end index, where 0 is the first row, and negative values are counted from the end backwards. (Just like list slicing in Python, in other words.)\n\nFor example, when `slice 1 -1` is applied to the following table:\n\nword  |\n----- |\ncat   |\ndog   |\nbunny |\nhorse |\n\nThe result would be:\n\nword  |\n----- |\ndog   |\nbunny |\n\n### sort\n\n`sort [column]` sorts a single column, without changing any of the other columns.\n\n### sortby\n\n`sortby [column]` sorts the entire table by a single column.\n\n### reverse\n\n`reverse` reverses the order of the entire table. If a column name is specified (e.g. `reverse word`), only that column is reversed, without changing any of the other columns.\n\n### roll\n\n`roll [value]` rolls the entire table forward (for positive values) or backward (for negative values). If a column name is specified (e.g. `roll 1 word`), only that column is rolled, without changing any of the other columns.\n\nFor example, if `roll 1` is applied to the following table:\n\nword  |\n----- |\ncat   |\ndog   |\nbunny |\nhorse |\n\nThe result would be:\n\nword  |\n----- |\nhorse |\ncat   |\ndog   |\nbunny |\n\n### weight\n\n`weight [column]` repeats each row by a weighting value specified in a column.\n\nFor example, if `weight w` is applied to the following table:\n\nword  | w\n----- | -\ncat   | 0\ndog   | 0\nbunny | 2\nhorse | 1\n\nThe result would be:\n\nword  | w\n----- | -\nbunny | 2\nbunny | 2\nhorse | 1\n\n## Previewing the loop\n\nIf you have specified constraints, or have used advanced loop operations, then it is a good idea to check that the result is as expected. To do so, you can generate a preview of the loop table as it will be (or could be, in case of randomization) when you run the experiment.\n\nTo generate a preview, click on the *Preview* button.\n\n\n## Accessing the loop table in Python inline script\n\nThe original LOOP table, as you see it in the OpenSesame user interface, is a [`DataMatrix`](http://datamatrix.cogsci.nl/) object called `dm`, and is a property of the LOOP item.\n\nThis original LOOP table is usually transformed in various ways; for example, the order of the rows can be randomized, and rows can be repeated multiple times. The transformed LOOP is also a `DataMatrix` object, and is called `live_dm`. `live_dm` is created just before the loop is executed and is set to `None` when the loop is finished; that is, `live_dm` is only available during the *run* phase of the LOOP.\n\nFinally, the index of the current row is stored as the experimental variable `live_row`. That is, `live_row` indicates the currently active row of `live_dm`.\n\nSo let's say that we have a LOOP called *block_loop*. We could then access the LOOP table in a Python inline script as follows:\n\n~~~ .python\nprint('The original loop table:')\nprint(items['block_loop'].dm)\n\nprint('The transformed loop table:')\nprint(items['block_loop'].live_dm)\n\nprint('The current row:')\nprint(items['block_loop'].live_dm[var.live_row])\n~~~\n\nYou can even programatically define the LOOP table. You have to do this in the Prepare phase of an INLINE_SCRIPT that precedes the LOOP.\n\n```python\nfrom datamatrix import DataMatrix\n\nitems['block_loop'].dm = DataMatrix(length=4)\nitems['block_loop'].dm.cue_side = 'left', 'right', 'left', 'right'\nitems['block_loop'].dm.cue_validity = 'valid', 'valid', 'invalid', 'invalid'\n```\n\n`DataMatrix` objects are powerful structures for working with tabular data. For more information, see:\n\n- <https://pydatamatrix.eu/>", "url": "https://osdoc.cogsci.nl/4.0/manual/structure/loop", "title": "Looping and independent variables"}
{"content": "# Doing things in parallel\n\ntitle: Doing things in parallel\n\n\nCoroutines run multiple items in parallel\u2014or, to be more exact, they run items in rapid alternation in a way that looks parallel. Not all items support coroutines.\n\n\n[TOC]\n\n\n## Using coroutines\n\nYou can use coroutines through the COROUTINES plugin (see %FigCoroutinesInterface).\n\n\n%--\nfigure:\n source: FigCoroutinesInterface.png\n caption: The interface of the coroutines plugin.\n id: FigCoroutinesInterface\n--%\n\n\nAs you can see, the COROUTINES plugin looks similar to the SEQUENCE item, but has a few extra options:\n\n- *Duration* indicates the total duration of the coroutines.\n- *End after item (optional)* indicates that the coroutines should end when a specific item has ended. This allows you, for example, to indicate that the coroutines should end when a key press has been collected, by selecting a KEYBOARD_RESPONSE item here.\n- Each item has a *Start time*. Most items also have an *End time*. The end time does not apply to one-shot items; for example, SKETCHPADs show a display and terminate immediately, so they have no end time.\n\nSpecifically, the example from %FigCoroutinesInterface (from the stop-signal-task example) does the following:\n\n- It shows a target display immediately.\n- If the `stop_after` variable is not empty, it shows the stop_signal display after an interval specified by the `stop_after` variable.\n- During the entire (2000 ms) interval, a keyboard response is collected.\n\nThe temporal flow is controlled by the COROUTINES plugin. Therefore, the timeout and duration values specified in the items are not used. For example, in %FigCoroutinesInterface, the KEYBOARD_RESPONSE will run for 2000 ms, regardless of the timeout that is specified in the item.\n\n\n## Supported items\n\nCurrently, the following items are supported (this list may not be exhaustive):\n\n- FEEDBACK\n- INLINE_SCRIPT\n- KEYBOARD_RESPONSE\n- LOGGER\n- MOUSE_RESPONSE\n- SAMPLER\n- SYNTH\n- SKETCHPAD\n\n\n## Using inline_script items in coroutines\n\nWhen you use an INLINE_SCRIPT item in a COROUTINES, the Run phase works a little differently from what you might be used to. Specifically, the Run phase is executed on every iteration of the COROUTINES. In addition, the Run phase should only contain code that takes very little time to execute; this is because time-consuming operations will block the COROUTINES, thus interfering with the timing of other items in the COROUTINES as well. To end the COROUTINES, you can raise an `AbortCoroutines()` exception.\n\nFor example, say that you have a COROUTINES with two KEYBOARD_RESPONSE items, *kb1* and *kb2*, and you want to run the COROUTINES until two key presses have been collected, with a timeout of 5000 ms. You could then create the following COROUTINES structure:\n\n\n%--\nfigure:\n source: FigCoroutinesTwoResponses.png\n caption: A coroutines that collects two keypress responses\n id: FigCoroutinesTwoResponses\n--%\n\nThe *check_responses* INLINE_SCRIPT would then first set both responses variables to an empty string in the Prepare phase:\n\n```python\n# This is executed at the start of the coroutines\nresponse_kb1 = ''\nresponse_kb2 = ''\n```\n\nAnd then, in the Run phase, check if both variables have been set, and abort the coroutines if this is the case:\n\n```python\n# Values that are not an empty string are True for Python\n# This code will be executed many times!\nif response_kb1 and response_kb2:\n    raise AbortCoroutines()\n```\n\n## Run-if expressions\n\nThe behavior of run-if expressions in COROUTINES is a bit different from that in SEQUENCE items. Specifically, run-if expressions in COROUTINES are evaluated during the prepare phase. See also:\n\n- %link:prepare-run%", "url": "https://osdoc.cogsci.nl/4.0/manual/structure/coroutines", "title": "Doing things in parallel"}
{"content": "# Doing things in sequence\n\ntitle: Doing things in sequence\n\nThe SEQUENCE item has two important functions:\n\n- It runs multiple other items one after another.\n- It determines which items should, and which shouldn't, be run.\n\nSEQUENCEs are run from top to bottom; that is, the item at the top is run first. The order of a SEQUENCE is always sequential.\n\n## Run-if expressions\n\nYou can use run-if expressions to determine whether or not a particular item should be run. For example, if you want a display to be presented only if a participant has made an incorrect response, you can set the run-if expressions for that item to:\n\n```python\ncorrect == 0\n```\n\nIf you leave the run-if expressions empty or enter `True`, the item will always be run. Run-if expressions use the same syntax as other conditional expressions. For more information, see:\n\n- %link:manual/variables%\n\nRun-if expressions only affect which items are run, not which items are prepared. Phrased differently, the Prepare phase of all items in a SEQUENCE is always executed, regardless of the run-if expressions. See also:\n\n- %link:prepare-run%\n\n\n## Disabling items\n\nTo completely disable an item in a SEQUENCE, right-click on it and select 'Disable'. This is mostly useful during development of your experiment, for example to temporarily bypass the instructions.", "url": "https://osdoc.cogsci.nl/4.0/manual/structure/sequence", "title": "Doing things in sequence"}
{"content": "# GazePoint / OpenGaze\n\ntitle: GazePoint / OpenGaze\n\nPyGaze offers *experimental* support for GazePoint eye trackers through the OpenGaze API as of OpenSesame 3.3.11. For more information, see:\n\n- %link:pygaze%\n- <https://www.gazept.com/>", "url": "https://osdoc.cogsci.nl/4.0/manual/eyetracking/gazepoint", "title": "GazePoint / OpenGaze"}
{"content": "# WebGazer.js\n\ntitle: WebGazer.js\n\nRequires OSWeb v1.4.6.1\n{:.page-notification}\n\n[TOC]\n\n\n## About WebGazer\n\nWebGazer.js is an eye-tracking library written in JavaScript. You can include it with OSWeb to perform eye tracking in online experiments.\n\n- <https://webgazer.cs.brown.edu/>\n\n\n## Including WebGazer.js in the experiment\n\nWebGazer.js is not bundled with OSWeb by default. However, you can include it as an external library by entering a link to `webgazer.js` under External JavaScript libraries. Currently, a functional link is:\n\n```\nhttps://webgazer.cs.brown.edu/webgazer.js\n```\n\nSee also:\n\n- %link:manual/osweb/osweb%\n\n\n## Example experiment\n\nBelow you can download an example experiment that uses WebGazer.js. Participants are first asked to click on and look at a set of dots; this will cause WebGazer.js to automatically perform something akin to a calibration procedure. Next, the experiment shows a simple screen to test the accuracy of gaze-position recording. In general, fine-grained eye tracking is not feasible, but you can tell which quadrant of the screen a participant is looking at. To run this experiment, you need include WebGazer.js in the experiment, as described above. \n\n- %static:attachments/webgazer.osexp%\n\nYou can also launch the experiment directly in the browser:\n\n- <https://jatos.mindprobe.eu/publix/BowSAFY2VWl>", "url": "https://osdoc.cogsci.nl/4.0/manual/eyetracking/webgazer", "title": "WebGazer.js"}
{"content": "# Tobii\n\ntitle: Tobii\n\nPyGaze offers *experimental* support for Tobii eye trackers.\n\n`tobii-research` is the Python library for Tobii support. As of July 2023, `tobii-research` requires Python 3.10, whereas OpenSesame by default uses Python 3.11. Therefore, until `tobii-research` is updated for Python 3.11, the easiest way to install OpenSesame with Tobii support is by building a Python 3.10 environment through Anaconda.\n\nThis sounds complicated, but it is really not. To do so, first read the general procedure for installing OpenSesame through Anaconda as described on the Downloads page:\n\n- %link:download%\n\nNext, once you understand the general procedure, start by creating a Python 3.10 environment, continue with the instructions from the Downloads page, and then install `tobii-research`:\n\n```\n# Start by creating a Python 3.10 environment\nconda create -n opensesame-py3 python=3.10\nconda activate opensesame-py3\n# Now follow the instructions from the downloads page\n# ...\n# Then install Tobii support\npip install tobii-research\n# And now launch OpenSesame!\nopensesame\n```\n\nFor more information, see:\n\n- %link:pygaze%\n- <https://rapunzel.cogsci.nl/manual/environment/>\n- <http://www.tobii.com/en/eye-tracking-research/global/>", "url": "https://osdoc.cogsci.nl/4.0/manual/eyetracking/tobii", "title": "Tobii"}
{"content": "# EyeTribe\n\ntitle: EyeTribe\n\nThe EyeTribe is supported through PyGaze. For more information, see:\n\n- %link:pygaze%", "url": "https://osdoc.cogsci.nl/4.0/manual/eyetracking/eyetribe", "title": "EyeTribe"}
{"content": "# Eyelink\n\ntitle: Eyelink\n\n[TOC]\n\n## About EyeLink\n\nThe Eyelink series of eye trackers, produced by SR Research, are one of the most commonly used eye trackers in psychological research. SR Research provides Python bindings for the Eyelink (called PyLink), which are used by PyGaze. The license of PyLink is incompatible with the license used by OpenSesame. For that reason, PyLink is not included in the default distribution of OpenSesame, and needs to be installed separately.\n\n\n## Windows\n\n### Installing the EyeLink Developers Kit\n\nThe Eyelink Developers Kit (sometimes called Display Software) provides the libraries that are required to communicate with the Eyelink PC. You can find it here (free registration required):\n\n- <https://www.sr-research.com/support/thread-13.html>\n\nIf you extract the `.zip`, and then run the `.exe` installer, the EyeLink display will be installed in one of the following folders (depending on your version of Windows:\n\n```\nC:\\Program Files\\SR Research\\EyeLink\\\nC:\\Program Files (x86)\\SR Research\\EyeLink\n```\n\nIn this folder, there is a `libs` subfolder, which you need to add to the system Path (this may have been added to the path automatically, but check to make sure). You can do this by opening \"My Computer\", clicking on \"View system information\", opening the \"Advanced\" tab, clicking on \"Environment Variables\" and appending `;C:\\Program Files\\SR Research\\EyeLink\\libs` or (depending on your system) `;C:\\Program Files (x86)\\SR Research\\EyeLink\\libs` to the Path variable (under System variables).\n\n\n### Installing OpenSesame with PyLink\n\nPyLink is the Python library for EyeLink support. PyLink can be installed from the SR Research PyPi repository through `pip install`:\n\n```\npip install --index-url=https://pypi.sr-research.com sr-research-pylink\n```\n\nYou can find more information about PyLink on the SR Research forum (free registration required):\n\n- <https://www.sr-research.com/support/thread-8291.html>\n\n\n## Ubuntu\n\nThe EyeLink display software can be installed directly from a repository. This also installs PyLink and various convenient tools, such ast the `edf2asc` converter.\n\n```bash\nsudo add-apt-repository 'deb [arch=amd64] https://apt.sr-research.com SRResearch main'\nsudo apt-key adv --fetch-keys https://apt.sr-research.com/SRResearch_key\nsudo apt-get update\nsudo apt-get install eyelink-display-software\n```\n\nFor more information, please visit:\n\n- <https://www.sr-support.com/thread-13.html>\n\n\n## PyGaze\n\nAfter you have install the EyeLink display software and PyLink per the instructions above, you can use the EyeLink with PyGaze! See:\n\n- %link:pygaze%", "url": "https://osdoc.cogsci.nl/4.0/manual/eyetracking/eyelink", "title": "Eyelink"}
{"content": "# PyGaze (eye tracking)\n\ntitle: PyGaze (eye tracking)\n\n[TOC]\n\n## About\n\nPyGaze is a Python library for eye tracking. A set of plugins allow you to use PyGaze from within OpenSesame. For more information on PyGaze, visit:\n\n- <http://www.pygaze.org/>\n\nPlease cite PyGaze as:\n\nDalmaijer, E., Math\u00f4t, S., & Van der Stigchel, S. (2014). PyGaze: An open-source, cross-platform toolbox for minimal-effort programming of eyetracking experiments. *Behavior Research Methods*. doi:10.3758/s13428-013-0422-2\n{: .reference}\n\n## Supported eye trackers\n\nPyGaze supports the following eye trackers:\n\n- [EyeLink](%link:eyelink%)\n- [EyeTribe](%link:eyetribe%)\n\nFor the following eye trackers, there is experimental support:\n\n- [EyeLogic](%link:eyelogic%)\n- [GazePoint / OpenGaze](%link:gazepoint%)\n- [SMI](%link:smi%)\n- [Tobii](%link:tobii%)\n\nYou can also perform basic eye tracking in online experiments with WebGazer.js:\n\n- [WebGazer.js](%link:webgazer%)\n\nPyGaze also includes two dummy eye trackers for testing purposes:\n\n- __Simple dummy__ \u2014 Does nothing.\n- __Advanced dummy__ \u2014 Mouse simulation of eye movements.\n\n## Installing PyGaze\n\n### Windows\n\nIf you use the official Windows package of OpenSesame, PyGaze is already installed.\n\n### Ubuntu\n\nIf you use Ubuntu, you can get PyGaze from the Cogsci.nl PPA:\n\n```\nsudo add-apt-repository ppa:smathot/cogscinl\nsudo apt-get update\nsudo apt-get install python-pygaze\n```\n\nOr, if you are using Python 3, change the last comment to:\n\n```\nsudo apt-get install python3-pygaze\n```\n\n## pip install (all platforms)\n\nYou can install PyGaze with `pip`:\n\n```\npip install python-pygaze\n```\n\n### Anaconda (all platforms)\n\n```\nconda install python-pygaze -c cogsci\n```\n\n## PyGaze OpenSesame plugins\n\nThe following PyGaze plugins are available:\n\n- PYGAZE_INIT \u2014 Initializes PyGaze. This plugin is generally inserted at the start of the experiment.\n- PYGAZE_DRIFT_CORRECT \u2014 Implements a drift correction procedure.\n- PYGAZE_START_RECORDING \u2014 Puts PyGaze in recording mode.\n- PYGAZE_STOP_RECORDING \u2014 Puts PyGaze out of recording mode.\n- PYGAZE_WAIT \u2014 Pauses until an event occurs, such as a saccade start.\n- PYGAZE_LOG \u2014 Logs experimental variables and arbitrary text.\n\n## Example\n\nFor an example of how to use the PyGaze plugins, see the PyGaze template that is included with OpenSesame.\n\nBelow is an example of how to use PyGaze in a Python INLINE_SCRIPT:\n\n~~~ .python\n# Create a keyboard and a canvas object\nmy_keyboard = Keyboard(timeout=0)\nmy_canvas = Canvas()\nmy_canvas['dot'] = Circle(x=0, y=0, r=10, fill=True)\n# Loop ...\nwhile True:\n\t# ... until space is pressed\n\tkey, timestamp = my_keyboard.get_key()\n\tif key == 'space':\n\t\tbreak\n\t# Get gaze position from pygaze ...\n\tx, y = eyetracker.sample()\n\t# ... and draw a gaze-contingent fixation dot!\n\tmy_canvas['dot'].x = x + my_canvas.left\n\tmy_canvas['dot'].y = y + my_canvas.top\n\tmy_canvas.show()\n~~~\n\n## Function overview\n\nTo initialize PyGaze in OpenSesame, insert the PYGAZE_INIT plugin into your experiment. Once you have done this, an `eyetracker` object will be available, which offers the following functions:\n\n%-- include: include/api/eyetracker.md --%", "url": "https://osdoc.cogsci.nl/4.0/manual/eyetracking/pygaze", "title": "PyGaze (eye tracking)"}
{"content": "# SMI\n\ntitle: SMI\n\nPyGaze offers *experimental* support for SMI eye trackers. (SMI no longer exists as a company, but its eye trackers are still used in some labs.) For more information, see:\n\n- %link:pygaze%", "url": "https://osdoc.cogsci.nl/4.0/manual/eyetracking/smi", "title": "SMI"}
{"content": "# EyeLogic\n\ntitle: EyeLogic\n\nPyGaze offers *experimental support* for EyeLogic eye trackers as of OpenSesame 3.3.11. For more information, see:\n\n- %link:pygaze%\n- <https://www.eyelogicsolutions.com/>", "url": "https://osdoc.cogsci.nl/4.0/manual/eyetracking/eyelogic", "title": "EyeLogic"}
{"content": "# Button box\n\ntitle: Button box\n\nThere are many different types of button boxes, and they all work in different ways. Therefore, there is no single OpenSesame item that works with all button boxes. (This is different from keyboards, which are standard devices that all work with the KEYBOARD_RESPONSE item.)\n\nCommon types of button boxes:\n\n- Some button boxes *emulate keypresses*. This is easy, because you can use the normal KEYBOARD_RESPONSE item.\n\t- %link:manual/response/keyboard%\n- Some button boxes *emulate a joystick*. This is also easy, because you can use the JOYSTICK plugin.\n\t- %link:joystick%\n- Some button boxes are compatible with the *Serial Response Box* that is developed by Psychology Software Tools. These button boxes are supported by the SRBOX plugin.\n\t- %link:srbox%\n- Some button boxes have their own Python libaries. In this case, you should be able to find example scripts of how to use the button box in Python, that is, in an OpenSesame INLINE_SCRIPT item.", "url": "https://osdoc.cogsci.nl/4.0/manual/response/buttonbox", "title": "Button box"}
{"content": "# Mouse responses\n\ntitle: Mouse responses\n\nMouse responses are collected with the MOUSE_RESPONSE item. The MOUSE_RESPONSE is primarily intended to collect individual mouse clicks. If you want to collect mouse-cursor trajectories, take a look at the MOUSETRAP plugins:\n\n- %link:mousetracking%\n\n[TOC]\n\n\n## Response variables\n\nThe MOUSE_RESPONSE sets the standard response variables as described here:\n\n- %link:manual/variables%\n\n\n## Mouse-button names\n\nMouse buttons have a number (`1`, etc.) as well as a name (`left_button`, etc.). Both can be used to specify correct and allowed responses, but the `response` variable will be set to a number.\n\n- `left_button` corresponds to `1`\n- `middle_button` corresponds to `2`\n- `right_button` corresponds to `3`\n- `scroll_up` corresponds to `4`\n- `scroll_down` corresponds to `5`\n\n\n## Correct response\n\nThe *Correct response* field indicates which response is considered correct. After a correct response, the `correct` variable is automatically set to 1; after an incorrect response or a timeout (i.e. everything else), `correct` is set to 0; if no correct response is specified, `correct` is set to 'undefined'.\n\nYou can indicate the correct response in three main ways:\n\n- *Leave the field empty.* If you leave the *Correct response* field empty, OpenSesame will automatically check if a variable called `correct_response` has been defined, and, if so, use this variable for the correct response.\n- *Enter a literal value.* You can explicitly enter a response, such as 1. This is only useful if the correct response is fixed.\n- *Enter a variable name.* You can enter a variable, such as '{cr}'. In this case, this variable will be used for the correct response.\n\nNote that the correct response refers to which mouse button was clicked, not to which region of interest was clicked (ROI); see the section below for more information about ROIs.\n\n## Allowed responses\n\nThe *Allowed responses* field indicates a list of allowed responses. All other responses will be ignored, except for 'Escape', which will pause the experiment. The allowed responses should be a semicolon-separated list of responses, such as '1;3' to allow the left and right mouse buttons. To accept all responses, leave the *Allowed responses* field empty.\n\nNote that the allowed responses refer to which mouse button can be clicked, not to which region of interest can be clicked (ROI); see the section below for more information about ROIs.\n\n\n%--include: include/timeout.md--%\n\n## Coordinates and regions of interest (ROIs)\n\nThe `cursor_x` and `cursor_y` variables hold the location of the mouse click.\n\nIf you indicate a linked SKETCHPAD, the variable `cursor_roi` will hold a comma-separated list of names of elements that contain the clicked coordinate. In other words, elements on the SKETCHPAD automatically serve as regions of interest for the mouse click.\n\nIf the correctness of a response depends on which ROI was clicked, you cannot use the `correct_response` variable for this, because this currently refers only to which mouse button was clicked. Instead you need to use a simple script.\n\nIn a Python INLINE_SCRIPT you can do this as follows:\n\n```python\nclicked_rois = cursor_roi.split(';')\ncorrect_roi = 'my_roi'\nif correct_roi in clicked_rois:\n    print('correct!')\n    correct = 1\nelse:\n    print('incorrect!')\n    correct = 0\n```\n\nWith OSWeb using a INLINE_JAVASCRIPT you can do this as follows:\n\n```js\nclicked_rois = cursor_roi.split(';')\ncorrect_roi = 'my_roi'\nif (clicked_rois.includes(correct_roi)) {\n    console.log('correct!')\n    correct = 1\n} else {\n    console.log('incorrect!')\n    correct = 0\n}\n```\n\n\n%--\nvideo:\n source: youtube\n id: VidMouseROI\n videoid: 21cgX_zHDiA\n width: 640\n height: 360\n caption: |\n  Collecting mouse clicks and using regions of interest.\n--%\n\n## Collecting mouse responses in Python\n\nYou can use the `mouse` object to collect mouse responses in Python:\n\n- %link:manual/python/mouse%", "url": "https://osdoc.cogsci.nl/4.0/manual/response/mouse", "title": "Mouse responses"}
{"content": "# Keyboard responses\n\ntitle: Keyboard responses\n\nKeyboard responses are collected with the KEYBOARD_RESPONSE item.\n\n[TOC]\n\n\n## Response variables\n\nThe KEYBOARD_RESPONSE sets the standard response variables as described here:\n\n- %link:manual/variables%\n\n## Key names\n\nKeys are generally identified by their character and/ or their description (depending on which is applicable). For example:\n\n- The `/` key is named 'slash' and '/'. You can use either of the two names.\n- The `a` is named 'a'.\n- The left-arrow key is named 'left'.\n\nIf you don't know what a particular key is named, you can:\n\n- Click on the 'List available keys' button; or\n- Create a simple experiment in which a KEYBOARD_RESPONSE is immediately followed by a FEEDBACK item with the text '{response}' on it. This will show the name of the previously collected response.\n\n\n## Correct response\n\nThe *Correct response* field indicates which response is considered correct. After a correct response, the `correct` variable is automatically set to 1; after an incorrect response (i.e. everything else), `correct` is set to 0; if no correct response is specified, `correct` is set to 'undefined'.\n\nYou can indicate the correct response in three main ways:\n\n- *Leave the field empty.* If you leave the *Correct response* field empty, OpenSesame will automatically check if a variable called `correct_response` has been defined, and, if so, use this variable for the correct response.\n- *Enter a literal value.* You can explicitly enter a response, such as 'left' in the case of a KEYBOARD_RESPONSE item. This is only useful if the correct response is fixed.\n- *Enter a variable name.* You can enter a variable, such as '{cr}'. In this case, this variable will be used for the correct response.\n\n\n## Allowed responses\n\nThe *Allowed responses* field indicates a list of allowed responses. All other responses will be ignored, except for 'Escape', which will pause the experiment. The allowed responses should be a semicolon-separated list of responses, such as 'a;left;/' for a KEYBOARD_RESPONSE. To accept all responses, leave the *Allowed responses* field empty.\n\n\n%--include: include/timeout.md--%\n\n## Collecting keyboard responses in Python\n\nYou can use the `keyboard` object to collect keyboard responses in Python:\n\n- %link:manual/python/keyboard%", "url": "https://osdoc.cogsci.nl/4.0/manual/response/keyboard", "title": "Keyboard responses"}
{"content": "# Sound recording\n\ntitle: Sound recording\n\n[TOC]\n\n\n## Audio Low Latency plugins\n\nThe Audio Low Latency plugins, developed by Bob Rosbag, are the recommended way to record sound input. The main goal of this set of plugins is to play and record audio with minimal and predictable latencies to achieve a high accuracy and precision. The `PyAlsaAudio` package which uses the Linux ALSA audio system provided the best results within Python. `PortAudio` and `sounddevice` are cross-platform and work on both Windows as Linux.\n\nThe plugins are not installed by default, but can be installed through pip:\n\n```bash\npip install opensesame-plugin-audio-low-latency\n```\n\nSee also:\n\n- <https://pypi.org/project/opensesame-plugin-audio-low-latency/>\n\n\n## Sound recorder plugins\n\nThe sound recorder plugins, developed by Daniel Schreij, are no longer under active development and are therefore no longer recommended. More information about this set of plugins can be found on previous version of this page:\n\n- <https://osdoc.cogsci.nl/3.2/manual/response/soundrecording/>", "url": "https://osdoc.cogsci.nl/4.0/manual/response/soundrecording", "title": "Sound recording"}
{"content": "# Joystick and gamepad\n\ntitle: Joystick and gamepad\n\nJoysticks and gamepads are supported through the JOYSTICK plugin.\n\n[TOC]\n\n%-- include: include/api/joystick.md --%", "url": "https://osdoc.cogsci.nl/4.0/manual/response/joystick", "title": "Joystick and gamepad"}
{"content": "# SR Box\n\ntitle: SR Box\n\n[TOC]\n\n## About the srbox plugin\n\nThe serial response (SR) box is a button box, specifically designed for response collection in psychological experiments. The original version, developed by Psychology Software Tools, has 5 buttons, 5 lights, and is connected to the PC trough the serial port. There are also SR Box compatible devices by other manufacturers, which may differ in the number of buttons and lights and often use a USB connection, which emulates a serial port.\n\nThe SRBOX plugin for OpenSesame allows you to use the SR Box or compatible device in your OpenSesame experiments.\n\n## Screenshot\n\n%--\nfigure:\n  source: srbox.png\n  id: FigSrbox\n  caption: The srbox plugin in OpenSesame.\n--%\n\n## Setting the device name\n\nBy default, the plugin tries to autodetect your SR Box. If this works, you don't have to change it. If your experiment freezes, OpenSesame has chosen the wrong serial port and you must enter the device name manually. Under Windows, the device is probably called something like\n\n```text\nCOM4\n```\n\nUnder Linux the device is probably called something like\n\n```text\n/dev/tty0\n```\n\n## Requirements\n\nAn SR Box or compatible button box. Not all button boxes are compatible, see:\n\n- %link:buttonbox%\n\n## Using the SR Box from Python inline code\n\nThe `srbox` object does *not* exist when the plug-in is in dummy mode.\n\n%-- include: include/api/srbox.md --%", "url": "https://osdoc.cogsci.nl/4.0/manual/response/srbox", "title": "SR Box"}
{"content": "# Access the file pool\n\ndummy", "url": "https://osdoc.cogsci.nl/4.0/manual/python/pool", "title": "Access the file pool"}
{"content": "# Sampler functions\n\ndummy", "url": "https://osdoc.cogsci.nl/4.0/manual/python/sampler", "title": "Sampler functions"}
{"content": "# Clock functions\n\ndummy", "url": "https://osdoc.cogsci.nl/4.0/manual/python/clock", "title": "Clock functions"}
{"content": "# Access response history\n\ndummy", "url": "https://osdoc.cogsci.nl/4.0/manual/python/responses", "title": "Access response history"}
{"content": "# Mouse functions\n\ndummy", "url": "https://osdoc.cogsci.nl/4.0/manual/python/mouse", "title": "Mouse functions"}
{"content": "# Log functions\n\ndummy", "url": "https://osdoc.cogsci.nl/4.0/manual/python/log", "title": "Log functions"}
{"content": "# About Python\n\ntitle: About Python\n\nIn OpenSesame you can create complex experiments using only the graphical user interface (GUI). But you will sometimes encounter situations in which the functionality provided by the GUI is insufficient. In these cases you can add Python code to your experiment.\n\nPython is not supported in online experiments with OSWeb. If you need to run your experiment online, you have to use [JavaScript](%url:manual/javascript/about%) instead.\n\n[TOC]\n\n## Learning Python\n\nYou can find a set of basic tutorials and exercises to get you started with Python at <https://pythontutorials.eu/>.\n\n\n## Python in the OpenSesame GUI\n\n### A single Python workspace\n\nAll Python code is executed in a single Python workspace. This means that variables that have been defined in one INLINE_SCRIPT are accessible in all other INLINE_SCRIPTs, as well as in Python statements that are embedded in run-if statements and text strings. The same principle applies to modules: once `import`ed, they are available everywhere.\n\nFor example, you can simply construct the `Canvas` in one INLINE_SCRIPT ...\n\n~~~ .python\nmy_canvas = Canvas()\nmy_canvas.fixdot()\n~~~\n\n... and show it in another INLINE_SCRIPT ...\n\n~~~ .python\nmy_canvas.show()\n~~~\n\n### Inline_script items\n\nIn order to use Python code you need to add an INLINE_SCRIPT item to your experiment. You can do this by dragging the Python icon (the blue/yellow icon) from the item toolbar into the experiment sequence. After you have done this you will see something like %FigInlineScript.\n\n%--\nfigure:\n id: FigInlineScript\n source: inline-script.png\n caption: The INLINE_SCRIPT item.\n--%\n\nAs you can see, the INLINE_SCRIPT item consists of two tabs: one for the Prepare phase and one for the Run phase. The Prepare phase is executed first, to allow items to prepare for the time-critical run phase. It is good practice to construct `Canvas` objects, `Sampler` objects, etc. during the Prepare phase, so that they can be presented without delay during the Run phase. But this is only convention; you can execute arbitrary Python code during both phases.\n\nFor more information about the prepare-run strategy, see:\n\n- %link:prepare-run%\n\n\n### Conditional (\"if\") expressions\n\nYou can use single-line Python expressions in conditional expressions. For example, you can use the following Python script as a run-if expression (see also %FigRunIf):\n\n~~~ .python\ncorrect == 1 and response_time < 1000\n~~~\n\n%--\nfigure:\n id: FigRunIf\n source: run-if.png\n caption: Using Python script in the run-if statement of a SEQUENCE item.\n--%\n\nFor more information about conditional (\"if\") expressions, see:\n\n- %link:manual/variables%\n\n\n### Python in text strings\n\nYou can embed Python statements in text strings using the `{...} syntax. This works for simple variable references, but also for single-line expressions. For example, you could the following text to a SKETCHPAD:\n\n```text\nThe resolution is {width} x {height} px, which is a total of {width * height} pixels\n```\n\nDepending on your experiment's resolution, this might evaluate to:\n\n```text\nThe resolution is 1024 x 768 px, which is a total of 786432 pixels\n```\n\nFor more information about variables and text, see:\n\n- %link:manual/variables%\n- %link:manual/stimuli/text%\n\n\n### The Jupyter console (debug window)\n\nOpenSesame reroutes the standard output to the console (or: debug window), which you can activate using Control + D or through the menu (Menu -> View -> Show debug window; see %FigDebugNormal). You can print to the console using `print()`.\n\n~~~ .python\nprint('This will appear in the debug window!')\n~~~\n\nThe console is also an interactive Python interpreter powered by [project Jupyter](https://jupyter.org).\n\n\n## Things to know\n\n### Common functions\n\nMany common functions are directly available in an INLINE_SCRIPT item, without the need to import anything. For example:\n\n~~~ .python\n# `Canvas()` is a factory function that returns a `Canvas` object\nfixdot_canvas = Canvas()\nif sometimes(): # Sometimes the fixdot is green\n    fixdot_canvas.fixdot(color='green')\nelse: # Sometimes it is red\n    fixdot_canvas.fixdot(color='red')\nfixdot_canvas.show()\n~~~\n\nFor a list of common functions, see:\n\n- %link:manual/python/common%\n\n\n### The `var` object: Access to experimental variables\n\n__Version note__ As of OpenSesame 4.0, all experimental variables are available as globals. This means that you no longer need the `var` object.\n{:.page-notification}\n\nYou can access experimental variables through the `var` object:\n\n~~~ .python\n# OpenSesame <= 3.3 (with var object)\n# Get an experimental variable\nprint('my_variable is: %s' % var.my_variable)\n# Set an experimental variable\nvar.my_variable = 'my_value'\n\n# OpenSesame >= 4.0 (without var object)\n# Get an experimental variable\nprint('my_variable is: %s' % my_variable)\n# Set an experimental variable\nmy_variable = 'my_value'\n~~~\n\nA full overview of the `var` object can be found here:\n\n- %link:manual/python/var%\n\n\n### The `clock` object: Time functions\n\nBasic time functions are available through the `clock` object:\n\n~~~ .python\n# Get the current timestamp\nt = clock.time()\n# Wait for 1 s\nclock.sleep(1000)\n~~~\n\nA full overview of the `clock` object can be found here:\n\n- %link:manual/python/clock%\n\n\n### The `log` object: Data logging\n\nData logging is available through the `log` object:\n\n~~~ .python\n# Write one line of text\nlog.write('My custom log message')\n# Write all variables\nlog.write_vars()\n~~~\n\nA full overview of the `log` object can be found here:\n\n- %link:manual/python/log%\n\n\n### The `pool` object: Access to the file pool\n\nYou get the full path to a file in the file pool through the `pool` object:\n\n~~~ .python\n# Show an image from the file pool\npath = pool['img.png']\nmy_canvas = Canvas()\nmy_canvas.image(path)\nmy_canvas.show()\n~~~\n\nA full overview of the `pool` object can be found here:\n\n- %link:manual/python/pool%\n\n\n### The `responses` object: Access to participant responses\n\nThe `responses` object keeps track of all participant responses that have been collected during the experiment. For example, to list the correctness of all responses so far:\n\n~~~ .python\nfor response in responses:\n\tprint(response.correct)\n~~~\n\nA full overview of the `responses` object can be found here:\n\n- %link:manual/python/responses%\n\n\n### The `Canvas` class: Presenting visual stimuli\n\nThe `Canvas` class is used to present visual stimuli. For example, you can show a fixation dot as follows:\n\n~~~ .python\nmy_canvas = Canvas()\nmy_canvas.fixdot()\nmy_canvas.show()\n~~~\n\nA full overview of the `Canvas` class can be found here:\n\n- %link:manual/python/canvas%\n\n\n### The `Keyboard` class: Collecting key presses\n\nThe `Keyboard` class is used to collect key presses. For example, to collect a key press with a timeout of 1000 ms:\n\n~~~ .python\nmy_keyboard = Keyboard(timeout=1000)\nkey, time = my_keyboard.get_key()\n~~~\n\nA full overview of the `Keyboard` class can be found here:\n\n- %link:manual/python/keyboard%\n\n\n### The `Mouse` class: Collecting mouse clicks and screen touches\n\nThe `Mouse` class is used to collect mouse clicks and screen touches. (OpenSesame makes no distinction between the two.) For example, to collect a mouse click with a timeout of 1000 ms:\n\n~~~ .python\nmy_mouse = Mouse(timeout=1000)\nbutton, position, time = my_mouse.get_click()\n~~~\n\nA full overview of the `Mouse` class can be found here:\n\n- %link:manual/python/mouse%\n\n\n### The `Sampler` class: Sound playback\n\nThe `Sampler` class is used to play back sound samples. For example, to play back a simple beep:\n\n~~~ .python\nmy_sampler = Sampler()\nmy_sampler.play()\n~~~\n\nA full overview of the `Sampler` class can be found here:\n\n- %link:manual/python/sampler%\n\n\n## Alternative modules for display presentation, response collection, etc.\n\n\n### `psychopy`\n\nIf you are using the *psycho* backend, you can directly use the various [PsychoPy] modules. For more information, see:\n\n- %link:backends%\n\n\n### `expyriment`\n\nIf you are using the *xpyriment* backend, you can directly use the various [Expyriment] modules. For more information, see:\n\n- %link:backends%\n\n### `pygame`\n\nIf you are using the *legacy*, *droid*, or *xpyriment* (only with \"Use OpenGL\" set to \"no\") backend, you can directly use the various [PyGame] modules. For more information, see:\n\n- %link:backends%\n\n\n[python]: http://www.python.org/\n[backends]: /backends/about-backends\n[ipython]: http://ipython.org/\n[swaroop]: http://www.swaroopch.com/notes/Python\n[swaroop-direct]: http://www.ibiblio.org/swaroopch/byteofpython/files/120/byteofpython_120.pdf\n[downey]: http://www.greenteapress.com/thinkpython/\n[downey-direct]: http://www.greenteapress.com/thinkpython/thinkpython.pdf\n[opensesamerun]: /usage/opensesamerun/\n[psychopy]: http://www.psychopy.org/\n[expyriment]: http://www.expyriment.org/\n[pygame]: http://www.pygame.org/", "url": "https://osdoc.cogsci.nl/4.0/manual/python/about", "title": "About Python"}
{"content": "# Common functions\n\ndummy", "url": "https://osdoc.cogsci.nl/4.0/manual/python/common", "title": "Common functions"}
{"content": "# Canvas functions\n\ndummy", "url": "https://osdoc.cogsci.nl/4.0/manual/python/canvas", "title": "Canvas functions"}
{"content": "# Access items\n\ndummy", "url": "https://osdoc.cogsci.nl/4.0/manual/python/items", "title": "Access items"}
{"content": "# Keyboard functions\n\ndummy", "url": "https://osdoc.cogsci.nl/4.0/manual/python/keyboard", "title": "Keyboard functions"}
{"content": "# Access experimental variables\n\ndummy", "url": "https://osdoc.cogsci.nl/4.0/manual/python/var", "title": "Access experimental variables"}
{"content": "# OpenSesame as a Python library (no GUI)\n\ntitle: OpenSesame as a Python library (no GUI)\n\nYou can also write experiments fully programmatically by using OpenSesame as a Python module. This is mainly suited for people who prefer coding over using a graphical user interface.\n\nUsing OpenSesame as a Python module works much the same way as using Python `inline_script` items in the user interface, with two notable exceptions:\n\n- Functions and classes need to be explicitly imported from `libopensesame.python_workspace_api`. All functions and classes described under [Common functions](%url:manual/python/common%) are available.\n- An `experiment` object needs to be explicitly created using the `Experiment()` factory function.\n\nA simple Hello World experiment looks like this:\n\n```python\nfrom libopensesame.python_workspace_api import \\\n  Experiment, Canvas, Keyboard, Text\n\n# Initialize the experiment window using the legacy backend\nexp, win, clock, log = Experiment(canvas_backend='legacy')\n# Prepare a stimulus canvas and a keyboard\ncnv = Canvas()\ncnv += Text('Hello world')\nkb = Keyboard()\n# Show the canvas, wait for a key press, and then end the experiment\ncnv.show()\nkb.get_key()\nexp.end()\n```\n\nYou can also programmatically open a `.osexp` experiment file and execute it:\n\n```python\nfrom libopensesame.python_workspace_api import Experiment\nexp, win, clock, log = Experiment(osexp_path='my_experiment.osexp',\n                                  subject_nr=2)\nexp.run()\n```", "url": "https://osdoc.cogsci.nl/4.0/manual/python/nogui", "title": "OpenSesame as a Python library (no GUI)"}
{"content": "# Sound\n\ntitle: Sound\n\nThe most common way to play sound is using the SAMPLER item, for playback of audio files, or the SYNTH item, for playback of simple beeps, etc.\n\n[TOC]\n\n## The sampler\n\nThe SAMPLER plays back a single sound file, typically from the file pool.\n\nSound files are always played back at the sampling rate that is used by the OpenSesame sampler backend. If your sample appears to be sped up (high pitch) or slowed down (low pitch), you can adjust the sampling rate of your sound file in a sound editor, or change the sampling rate used by the OpenSesame sampler backend (under 'Show backend settings and info' in the General tab).\n\nThe SAMPLER has a few options:\n\n- *Sound file* indicates the file to be played.\n- *Volume* between 0 (silent) and 1 (normal volume).\n- *Pan* turns the right (negative values) or left (positive values) channel down. For full panning, enter 'left' or 'right',\n- *Pitch* indicates the playback speed, where 1 corresponds to the original speed.\n- *Stop after* indicates for how long the sound file should be played. For example, a value of 100 ms means that playback will be stopped after 100 ms, regardless of how long the sound file is. A value of 0 ms means that the sound file will be played back completely.\n- *Fade in* indicates the fade-in time for the sound file. For example, a value of 100 ms means that the sound file will start silent, and build up to maximum value in 100 ms.\n- *Duration* indicates the duration of the sampler item, before the next item is presented. This doesn't need to match the length of the sound file. For example, if the duration of the sampler is set to 0 ms, OpenSesame will advance directly to the item that follows the SAMPLER (e.g., a sketchpad), *while the sound file continues playing in the background*. In addition to a numeric value, you can set duration to:\n\t- 'keypress' to wait for a key press\n\t- 'mouseclick' to wait for a mouse click\n\t- 'sound' to wait until the sampler has finished playing.\n\n## The synth\n\nThe SYNTH is a basic sound synthesizer.\n\nYou can specify a\nnumber of options:\n\n- *Waveform* can be set to sine, sawtooth, square, or white noise\n- *Attack* is the time it takes for the sound the reach maximum volume (i.e. fade in).\n- *Decay* is the time it takes for the sound to die out (i.e. fade out). Note that the decay occurs within the length of the sound.\n- *Volume* between 0 and 100%\n- *Pan* turns the right (negative values) or left (positive values) channel down. Setting pan to -20 or 20 completely mutes the right or left channel, respectively.\n- *Length* indicates the length of the sound (in milliseconds).\n- *Duration* indicates the duration of the SYNTH item, before the next item is presented. This doesn't need to match the length of the sound. For example, the duration of the SYNTH may be set to 0ms, in order to advance directly to the next item (e.g., a SKETCHPAD), while the sound continues playing in the background. In addition to a numeric value, you can set the duration to 'keypress', to wait for a keyboard press, 'mouseclick', to wait for a mouse click, or 'sound', to wait until the SYNTH has finished playing.\n\n## Sound playback in Python\n\nYou can use the SAMPLER object and the SYNTH function to present visual stimuli in Python:\n\n- %link:sampler%\n- %link:manual/python/common%\n\n\n## Audio Low Latency plugins\n\nThe main goal of the Audio Low Latency plugins, developed by Bob Rosbag, is to play and record audio with minimal and predictable latencies to achieve a high accuracy and precision. The `PyAlsaAudio` package which uses the Linux ALSA audio system provided the best results within Python. `PortAudio` and `sounddevice` are cross-platform and work on both Windows as Linux.\n\nThe plugins are not installed by default, but can be installed through pip:\n\n```bash\npip install opensesame-plugin-audio-low-latency\n```\n\nSee also:\n\n- <https://pypi.org/project/opensesame-plugin-audio-low-latency/>", "url": "https://osdoc.cogsci.nl/4.0/manual/stimuli/sound", "title": "Sound"}
{"content": "# Text\n\ntitle: Text\n\n[TOC]\n\n## How can I present text?\n\nThe most common way to show text is using a SKETCHPAD or FEEDBACK item. These allow you to enter text and other visual stimuli. For a questionnaire-like way to show text, you can use [forms](%link:manual/forms/about%).\n\n\n## HTML formatting\n\nYou can use a HTML tags, which you can simply insert into your text. You can use these tags everywhere: In SKETCHPAD items, in INLINE_SCRIPTs (provided you use the `Canvas` class), in forms, etc.\n\nExample:\n\n~~~ .html\nOpenSesame supports a sub-set of HTML tags:\n- <b>Bold face</b>\n- <i>Italic</i>\n- <u>Underline</u>\n\nIn addition, you can pass 'color', 'size', and 'style' as keywords to a 'span' tag:\n- <span style='color:red;'>Color</span>\n- <span style='font-size:32px;'>Font size</span>\n- <span style='font-family:serif;'>Font style</span>\n\nFinally, you can force newlines with the 'br' tag:\nLine 1<br>Line 2\n~~~\n\n\n## Variables and inline Python\n\nYou can embed variables in text using the `{...}` syntax. For example, the following:\n\n~~~ .python\nThe subject number is {subject_nr}\n~~~\n\n... might evaluate to (for subject 1):\n\n~~~ .python\nThe subject number is 1\n~~~\n\nYou can also embed Python expression. For example, the following:\n\n~~~ .python\nThe subject number modulo five is {subject_nr % 5}\n~~~\n\n... might evaluate to (for subject 7)\n\n~~~ .python\nThe subject number modulo five is 2\n~~~\n\n\n## Fonts\n\n### Default fonts\n\nYou can select one of the default fonts from the font-selection dialogs (%FigFontSelect). These fonts are included with OpenSesame and your experiment will therefore be fully portable when you use them.\n\n%--\nfigure:\n id: FigFontSelect\n source: font-selection-dialog.png\n caption: \"A number of default fonts, which are bundled with OpenSesame, can be selected through the font-selection dialogs.\"\n--%\n\nThe fonts have been renamed for clarity, but correspond to the following open-source fonts:\n\n|__Name in OpenSesame__\t\t|__Actual font__\t\t|\n|---------------------------|-----------------------|\n|`sans`\t\t\t\t\t\t|Droid Sans\t\t\t\t|\n|`serif`\t\t\t\t\t|Droid Serif\t\t\t|\n|`mono`\t\t\t\t\t\t|Droid Sans Mono\t\t|\n|`chinese-japanese-korean`\t|WenQuanYi Micro Hei\t|\n|`arabic`\t\t\t\t\t|Droid Arabic Naskh\t\t|\n|`hebrew`\t\t\t\t\t|Droid Sans Hebrew\t\t|\n|`hindi`\t\t\t\t\t|Lohit Hindi\t\t\t|\n\n### Selecting a custom font through the font-selection dialog\n\nIf you select 'other ...' in the font selection dialog, you can select any font that is available on your operating system. If you do this, your experiment is no longer fully portable, and will require that the selected font is installed on the system that you run your experiment on.\n\n### Placing a custom font in the file pool\n\nAnother way to use a custom font is to put a font file in the file pool. For example, if you place the font file `inconsolata.ttf` in the file pool, you can use this font in a SKETCHPAD item, like so:\n\n\tdraw textline 0.0 0.0 \"This will be inconsolata\" font_family=\"inconsolata\"\n\nNote that the font file must be a truetype `.ttf` file.", "url": "https://osdoc.cogsci.nl/4.0/manual/stimuli/text", "title": "Text"}
{"content": "# Video playback\n\ntitle: Video playback\n\n[TOC]\n\n\n## media_player_mpy plugin\n\nThe MEDIA_PLAYER_MPY plugin is based on MoviePy. It is included by default with the Windows and Mac OS packages of OpenSesame. If it is not installed, you can get it by installing the `opensesame-plugin-media-player-mpy` package, as described here:\n\n- <https://rapunzel.cogsci.nl/manual/environment/>\n\nThe source code is hosted at:\n\n- <https://github.com/dschreij/opensesame-plugin-mediaplayer>\n\n\n## OpenCV\n\nOpenCV is a powerful computer vision library, which contains (among many other things) routines for reading video files.\n\n- <http://docs.opencv.org/3.0-beta/doc/py_tutorials/py_tutorials.html>\n\nThe following example shows how to play back a video file, while drawing a red square on top of the video. This example assumes that you're using the legacy backend.\n\n~~~ .python\nimport cv2\nimport numpy\nimport pygame\n# Full path to the video file in file pool\npath = pool['myvideo.avi']\n# Open the video\nvideo = cv2.VideoCapture(path)\n# A loop to play the video file. This can also be a while loop until a key\n# is pressed. etc.\nfor i in range(100):\n    # Get a frame\n    retval, frame = video.read()\n    # Rotate it, because for some reason it otherwise appears flipped.\n    frame = numpy.rot90(frame)\n    # The video uses BGR colors and PyGame needs RGB\n    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n    # Create a PyGame surface\n    surf = pygame.surfarray.make_surface(frame)\n    # Now you can draw whatever you want onto the PyGame surface!\n    pygame.draw.rect(surf, (255,0,0), (100, 100, 200, 200))\n    # Show the PyGame surface!\n    exp.surface.blit(surf, (0, 0))\n    pygame.display.flip()\n~~~", "url": "https://osdoc.cogsci.nl/4.0/manual/stimuli/video", "title": "Video playback"}
{"content": "# Visual stimuli\n\ntitle: Visual stimuli\n\nThe most common way to present visual stimuli is using the SKETCHPAD item, or, for non-time-critical stimuli, the FEEDBACK item.\n\n\n[TOC]\n\n\n## Using the sketchpad and feedback items\n\nThe SKETCHPAD and FEEDBACK item offer basic what-you-see-is-what-you get drawing tools (%FigSketchpad).\n\n%--\nfigure:\n id: FigSketchpad\n source: sketchpad.png\n caption: The SKETCHPAD provides built-in drawing tools.\n--%\n\n\n## Using show-if expressions\n\nYou can use show-if expressions to determine whether or not a particular element should be shown. For example, if you have an image of a happy face that should be shown only when the variable `valence` has the value 'positive', then you can set the show-if expression for the corresponding image element to:\n\n```python\nvalence == 'positive'\n```\n\nIf you leave a show-if expression empty or enter `True`, element will always be shown. Show-if expressions use the same syntax as other conditional expressions. For more information, see:\n\n- %link:manual/variables%\n\nShow-if expressions are evaluated at the moment that the display is prepared. This means that for SKETCHPAD items, they are evaluated during the prepare phase, whereas for FEEDBACK items, they are evaluated during the run phase (see also the section below).\n\n\n## The difference between sketchpad and feedback items\n\nThe SKETCHPAD and FEEDBACK items are identical in most ways, except for two important differences.\n\n\n### Sketchpad items are prepared in advance, feedback items are not\n\nThe contents of a SKETCHPAD are prepared during the prepare phase of the SEQUENCE that it is part of. This is necessary to ensure accurate timing: It allows the SKETCHPAD to be shown right away during the run phase, without any delays due to stimulus preparation. However, the downside of this is that the contents of a SKETCHPAD cannot depend on what happens during the SEQUENCE that it is part of. For example, you cannot use a SKETCHPAD to provide immediate feedback on the response time collected by a KEYBOARD_RESPONSE item (assuming that the SKETCHPAD and KEYBOARD_RESPONSE are part of the same sequence.)\n\nIn contrast, the contents of a FEEDBACK item are only prepared when they are actually shown, that is, during the run phase of the SEQUENCE that it is part of. This makes it possible to provide feedback on things that just happened--hence the name. However, the FEEDBACK item should not be used to present time-critical stimuli, because it suffers from delays due to stimulus preparation.\n\nFor more information about the prepare-run strategy, see:\n\n- %link:prepare-run%\n\n\n### Feedback variables are (by default) reset by feedback items\n\nThe FEEDBACK item has an option 'Reset feedback variables'. When this option is enabled (it is by default), feedback variables are reset when the FEEDBACK item is shown.\n\nFor more information about feedback variables, see:\n\n- %link:manual/variables%\n\n\n## Presenting visual stimuli in Python inline script\n\n### Accessing a SKETCHPAD in Python\n\nYou can access the `Canvas` object for a SKETCHPAD as the items `canvas` property. For example, say that your SKETCHPAD is called *my_sketchpad*, and contains an image elements with the name 'my_image'. You could then have this image rotate with the following script:\n\n~~~ .python\nmy_canvas = items['my_sketchpad'].canvas\nfor angle in range(360):\n\tmy_canvas['my_image'].rotation = angle\n\tmy_canvas.show()\n~~~\n\n\n### Creating a Canvas in Python\n\nYou can use the `Canvas` object to present visual stimuli in Python:\n\n- %link:manual/python/canvas%", "url": "https://osdoc.cogsci.nl/4.0/manual/stimuli/visual", "title": "Visual stimuli"}
{"content": "# Intermediate tutorial (JavaScript): visual search\n\ntitle: Intermediate tutorial (JavaScript): visual search\n\n[TOC]\n\n## About OpenSesame\n\nOpenSesame is a user-friendly program for the development of behavioral experiments for psychology, neuroscience, and experimental economy. For beginners, OpenSesame has a comprehensive graphical, point-and-click interface. For advanced users, OpenSesame supports Python (desktop only) and JavaScript (desktop and browser).\n\nOpenSesame is freely available under the [General Public License v3][gpl].\n\n## About this tutorial\n\nThis tutorial shows how to create a basic visual-search experiment using OpenSesame [(Math\u00f4t, Schreij, & Theeuwes, 2012)][references]. We will use both the graphical interface and JavaScript to develop an experiment that you can run online in a browser. Some experience with OpenSesame and JavaScript is recommended. This tutorial takes approximately one hour.\n\nA Python-based version of this tutorial is also available. If you don't need to run your experiments online, then the Python tutorial is likely what you need:\n\n- %link:tutorials/intermediate%\n\n\n## Resources\n\n- __Download__ \u2014 This tutorial assumes that you are running OpenSesame version 4.0.0 or later and OSWeb 2.0 or later. You can download the most recent version of OpenSesame from:\n\t- %link:download%\n- __Documentation__ \u2014 A dedicated documentation website can be found at:\n\t- <http://osdoc.cogsci.nl/>\n- __Forum__ \u2014 A support forum can be found at:\n\t- <http://forum.cogsci.nl/>\n\n\n## The experiment\n\nIn this tutorial, you will create a basic visual-search experiment. The experiment resembles the classic visual-search studies of [Treisman and Gelade (1980)][references], but it is not identical.\n\nBefore starting to *build* the experiment for yourself, you can already *participate* in it. This will give you a good idea of what you're working towards in this tutorial.\n\n<a role=\"button\" class=\"btn btn-success btn-align-left\" href=\"https://jatos.mindprobe.eu/publix/1938/start?batchId=2191&generalMultiple\">Participate in the experiment!</a>\n\nIn this experiment, participants search for a target object, which can be a yellow square, a yellow circle, a blue square, or a blue circle; the identity of the target is varied between blocks of trials. Participants indicate whether the target is present or not by pressing the right (present) or left (absent) arrow key.\n\nIn addition to the target, zero or more distractor objects are shown. There are three conditions, and the condition determines what kind of distractors there are:\n\n- In the *Conjunction* condition, distractors can have any shape and color, with the only restriction that distractors cannot be identical to the target. So, for example, if the target is a yellow square, then distractors are yellow circles, blue circles, and blue squares.\n- In the *Shape Feature* condition, distractors have a different shape from the target, but can have any color. So, for example, if the target is a yellow square, then distractors are yellow circles and blue circles.\n- In the *Color Feature* condition, distractors can have any shape, but have a different color from the target. So, for example, if the target is a yellow square, then distractors are blue squares and blue circles.\n\nImmediate feedback is shown after each trial: a green dot after a correct response, and a red dot after an incorrect response. Detailed feedback on average response times and accuracy is shown after each block of trials.\n\n%--\nfigure:\n id: FigVisualSearch\n source: visual-search.svg\n caption: |\n  The visual-search experiment that you will implement in this tutorial.\n--%\n\nExperiments like this show two typical findings:\n\n- It takes more time to find the target in the Conjunction condition than in the two Feature conditions.\n- In the Conjunction condition, response times increase as the number of distractors increases. This suggests that people search for the target one item at a time; this is called *serial search*.\n- In the Feature conditions (both shape and color), response times do not, or hardly, increase as the the number of distractors increases. This suggests that people process the entire display at once; this is called *parallel search*.\n\nAccording to Treisman and Gelade's feature-integration theory, these results reflect that the Conjunction condition requires that you combine, or *bind*, the color and shape of each object. This binding requires attention, and you therefore need to shift your attention from one object to the next; this is slow, and explains why response times depend on how many objects there are. In contrast, in the Feature conditions, color and shape do not need to be bound, and therefore the whole display can be processed in a single sweep without attention being directed at each and every object.\n\n## Experimental design\n\nThis design:\n\n- Is *within-subject*, because all participants do all conditions\n- Is *fully-crossed* (or full factorial), because all combinations of conditions occur\n- Has three conditions (or factors):\n\t- Varied within blocks:\n\t\t- `set_size` with three levels (1, 5, 15), or SS<sub>3</sub>\n\t\t- `condition` with three levels (conjunction, feature_shape, feature_color), or CN<sub>3</sub>\n\t\t- `target_present` with two levels (present, absent), or TP<sub>2</sub>\n\t- Varied between blocks:\n\t\t- `target_shape` with two levels (square, circle), or TS<sub>2</sub>\n\t\t- `target_color` with two levels (yellow, blue), or TC<sub>2</sub>\n- Has N subjects, or <u>S</u><sub>N</sub>\n\nYou can write this design as <u>S</u><sub>N</sub>\u00d7SS<sub>3</sub>\u00d7CN<sub>3</sub>\u00d7TP<sub>2</sub>\u00d7TS<sub>2</sub>\u00d7TC<sub>2</sub>\n\nFor more information about this notation for experimental design, see:\n\n- %link:experimentaldesign%\n\n## Step 1: Create the basic structure of the experiment\n\nStart OpenSesame and, in the 'Get started!' tab, select the Extended template. This template provides the basic structure that is common to many cognitive-psychology experiments, such as the one that we will create here.\n\nThe Extended template contains a few items that we don't need. Delete the following items:\n\n- *about_this_template*\n- *practice_loop*\n- *end_of_practice*\n\nWhen you have deleted these items, they are still visible in the 'Unused items' bin. To permanently delete these items, click on the 'Unused items' bin, and then click on the 'Permanently delete unused items' button.\n\nFinally, give the experiment a good title, such as 'Visual search'. To do this, open the general-properties tab (by clicking on 'Extended template' in the overview area) and click on the experiment name to edit it.\n\nAlso configure OpenSesame to run the experiment in a browser, rather than on the desktop.\n\nThe overview area should now look like %FigStep1:\n\n%--\nfigure:\n id: FigStep1\n source: step1.png\n caption: |\n  The overview area at the end of step 1.\n--%\n\n\n## Step 2: Define experimental variables that are varied between blocks\n\nAs described above, two variables are varied between blocks in our experiment: `target_shape` and `target_color`. We therefore need to define these variables in the *experimental_loop*. To understand why, consider the structure shown in %FigStep1, starting from the bottom (i.e. the most indented level).\n\n- *trial_sequence* corresponds to a single trial\n- *block_loop* corresponds to a block of a trials\n\t- Therefore, variables defined here vary for each run of *trial_sequence*; in other words, variables defined in *block_loop* are varied __within blocks__.\n- *block_sequence* corresponds to a block of trials, preceded by resetting of the feedback variables, and followed by participant feedback\n- *experimental_loop* corresponds to multiple blocks of trials\n\t- Therefore, variables defined here vary for each run of *block_sequence*; in other words, variables defined in *experimental_loop* are varied __between blocks__.\n- *experiment* corresponds to the entire experimental, which is an instruction screen, followed by multiple blocks of trials, followed by an end-of-experiment screen\n\nClick on experimental loop, and define:\n\n- `target_shape`, which can be 'square' or 'circle'; and\n- `target_color`, which can be 'yellow' or 'blue'.\n\nWe have a full-factorial design, which means that all 2 \u00d7 2 = 4 combinations must occur. The table of *experimental_loop* should now look like %FigStep2:\n\n%--\nfigure:\n id: FigStep2\n source: step2.png\n caption: |\n  The table of *experimental_loop* at the end of step 2.\n--%\n\n## Step 3: Give instructions at the start of each block\n\nRight now, the experiment starts with a single *instructions* screen. In our case, we want to give instructions before each block of trials, to tell the participant what target to look for (because the identity of the target varies between blocks).\n\n__Move the instructions into block_sequence__\n\nTherefore, pick up the *instructions* item and drag it onto *block_sequence*. A pop-up will appear, asking you if you want to:\n\n- Insert the item into *block_sequence*, in which case *instructions* would become the first item of *block_sequence*; or\n- Insert the item after *block_sequence*, in which case *instructions* would move to a position after *block_sequence*.\n\nSelect the first option ('Insert into'). Now *block_sequence* starts with an instructions screen, which is what we want.\n\n__Add instructional text__\n\nClick on *instructions* to open it, and add a good instructional text, such as:\n\n```text\nINSTRUCTIONS\n\nSearch for the {target_color} {target_shape}\n\nPress the right-arrow key if you find it\nPress the left-arrow key if you don't\n\nPress any key to begin\n```\n\nThe curly braces brackets around '{target_color}' and '{target_shape}' indicate that these are not literal text, but refer to the variables that we have defined in *experimental_loop*. When the experiment runs, the values of these variables will appear here, and the participant will see (for example), 'Search for the yellow circle'.\n\n__Give a visual preview of the target__\n\nIt also good to show the participant the actual stimulus that she needs to find. To do this:\n\n- Draw a filled circle at the center of the display (make sure it doesn't overlap with the text);\n- Change the color of the circle to '{target_color}'. This means that the color of the circle depends on the value of the variable `target_color`; and\n- Change the show-if expression to `target_shape == 'circle'`. This is a Python expression that checks if the variable `target_shape` has the value 'circle'. Note that even though you *cannot* use full-fledged Python `inline_script` items when running experiments in a browser, you *can* use Python for these simple conditional expressions.\n\nIn other words, we have drawn a circle of which the color is determined by `target_color`; furthermore, this circle is only shown when the variable `target_shape` has the value 'circle'. For more information about variables and show-if statements, see:\n\n- %link:manual/variables%\n\nWe use the same trick to draw a square:\n\n- Draw a filled square at the center of the display;\n- Change the color of the square to '{target_color}'; and\n- Change the show-if statement to `target_shape == 'square'`\n\nThe *instructions*  screen should now look like %FigStep3:\n\n%--\nfigure:\n id: FigStep3\n source: step3.png\n caption: |\n  The *instructions* screen at the end of step 3.\n--%\n\n\n## Step 4: Define experimental variables that are varied within blocks\n\nThree variables are varied within blocks in our experiment: `condition`, `set_size`, and `target_present`. As described under Step 2, we need to define these variables in the *block_loop* so that they vary for each run of *trial_sequence*.\n\nThe three variables make a total of 3 \u00d7 3 \u00d7 2 = 18 different combinations. We can type these into the table manually, but, because we have full-factorial design, we can also use the full-factorial-design wizard. To do this, first open *block_loop* and click on the 'Full-factorial design' button.\n\nIn the table that appears, put the variable names on the first row, and the values on the rows below, as shown in %FigFullFactorial.\n\n%--\nfigure:\n id: FigFullFactorial\n source: fullfactorial.png\n caption: |\n  The *instructions* screen at the end of step 3.\n--%\n\nNow click on 'Ok' to generate the full design. The table of *block_loop* should now look like %FigStep4.\n\n%--\nfigure:\n id: FigStep4\n source: step4.png\n caption: |\n  The table of *block_loop* at the end of step 4.\n--%\n\n## Step 5: Create the trial sequence and add an initialization script\n\nWe want our trial sequence to look as follows:\n\n- A fixation dot, for which we will use a SKETCHPAD.\n- A search display, which we will create in JavaScript with a custom INLINE_JAVASCRIPT.\n- Response collection, for which we will use a KEYBOARD_RESPONSE.\n- Data logging, for which we will use a LOGGER.\n- (We also want immediate feedback after each trial, but we will get back to this later.)\n\nSo the only thing that is missing from *trial_sequence* is an INLINE_JAVASCRIPT.\n\n- Insert a new INLINE_JAVASCRIPT after *sketchpad* and rename it to *search_display_script*.\n- Rename *sketchpad* to *fixation_dot*, so that its function is clear; and\n- Change the duration of *fixation_dot* to 500, so that the fixation dot is shown for 500 ms. (There should already be a fixation dot drawn; if not, draw one in the center of *fixation_dot*.)\n\nWe also need to add a initialization script to start of the experiment. We will use this only to define (`let`) a variable that will hold the `Canvas` object on which we will draw. In JavaScript, you have to define a variable exactly once, which is why we cannot do that in the *trial_sequence*.\n\n- Insert a new INLINE_JAVASCRIPT at the top of the *experiment* sequence and rename it to *init*.\n\nThe overview area should now look like %FigStep5.\n\n%--\nfigure:\n id: FigStep5\n source: step5.png\n caption: |\n  The overview area at the end of step 5.\n--%\n\n## Step 6: Generate the search display\n\n__Top-down and defensive programming__\n\nNow things will get interesting: We will start programming in JavaScript. We will use two guiding principles: *top-down* and *defensive* programming.\n\n- *Top-down programming* means that we start with the most abstract logic, without bothering with how this logic is implemented. Once the most abstract logic is in place, we will move down to a slightly less abstract logic, and so on, until we arrive at the details of the implementation. This technique helps to keep the code structured.\n- *Defensive programming* means that we assume that we make mistakes. Therefore, to protect us from ourselves, we build sanity checks into the code.\n\n*Note:* The explanation below assumes that you're somewhat familiar with JavaScript. If concepts like `Array`, `for` loop, and functions don't mean anything to you, then it's best to first walk through an introductory JavaScript tutorial. You can find links to JavaScript tutorials here:\n\n- %link:manual/javascript/about%\n\nThe logic of the code is shown in %FigHierarchy. The numbers indicate the order in which we will implement the functionality, starting at the abstract level.\n\n%--\nfigure:\n id: FigHierarchy\n source: hierarchy.svg\n caption: |\n  The logic of the code to draw a visual-search display.\n--%\n\n__Declaring variables with let, var, and const__\n\nIn JavaScript, you have to 'declare' a variable before you can use it. (In Python, this is not necessary.) In our case, we will use a variable called `c`, which we therefore need to declare. To do so, open the Prepare tab of the *init* script and use the `let` keyword to declare the variable `c`:\n\n```js\nlet c\n```\n\nThere are three different ways to declare variables:\n\n- Using `let`, as we've done here. In OpenSesame, this makes the variable available in JavaScript but not as an experimental variable in the user interface.\n- Using `var`. In OpenSesame, this makes the variable also available as an experimental variable in the user interface. (We will do that later for the variable `correct_response`.)\n- Using `const`. This is like `var` with the important difference that the variable cannot be re-assigned later.\n\n\n__The Prepare and Run phases__\n\nOpen *search_display_script* and switch to the Prepare tab. OpenSesame distinguishes two phases of execution:\n\n- During the Prepare phase, each item is given the opportunity to prepare itself; what this means depends on the item: For a SKETCHPAD, it means drawing a canvas (but not showing it); for a SAMPLER, it means loading a sound file (but not playing it); etc.\n- During the Run phase, each item is actually executed; again, what this means depends on the item: For a SKETCHPAD, it means showing the previously prepared canvas; for a SAMPLER, it means playing a previously loaded sound file.\n\nFor an INLINE_JAVASCRIPT, you have to decide yourself what to put in the Prepare phase, and what to put in the Run phase. The distinction is usually quite clear: In our case, we put the code for drawing the canvas in the Prepare phase, and the code for showing the canvas (which is small) in the Run phase.\n\nSee also:\n\n- %link:prepare-run%\n\n\n__Implement the abstract level__\n\nWe start at the most abstract level: defining a function that draws a visual-search display. We don't specify *how* this is done; we simply assume that there is a function that does this, and we will worry about the details later\u2014that's top-down programming.\n\nIn the Prepare tab, enter the following code:\n\n```js\nc = draw_canvas()\n```\n\nWhat happens here? We \u2026\n\n- Call `draw_canvas()`, which returns a `Canvas` object that we store as `c`; in other words, `c` is a `Canvas` object that corresponds the search display. This assumes that there is a function `draw_canvas()`, even though we haven't defined it yet.\n\nA `Canvas` object is a single display; it is, in a sense, the JavaScript counterpart of a SKETCHPAD. See also:\n\n- %link:manual/javascript/canvas%\n\nWe now go one step down by defining `draw_canvas()` (above the rest of the script so far):\n\n```js\n/**\n * Draws the search canvas.\n * @return A Canvas\n **/\nfunction draw_canvas() {\n    let c = Canvas()\n    let xy_list = xy_random(set_size, 500, 500, 75)\n    if (target_present === 'present') {\n        let [x, y] = xy_list.pop()\n        draw_target(c, x, y)\n    } else if (target_present !== 'absent') {\n        throw 'Invalid value for target_present ' + target_present\n    }\n    for (let [x, y] of xy_list) {\n        draw_distractor(c, x, y)\n    }\n    return c\n}\n```\n\n\nWhat happens here? We \u2026\n\n- Create an empty canvas, `c`, using the factory function `Canvas()`.\n- Generate an array of random `x, y` coordinates, called `xy_list`, using another common function, `xy_random()`. This array determines where the stimuli are shown. Locations are sampled from a 500 \u00d7 500 px area with a minimum spacing of 75 px.\n- Check if the experimental variable `target_present` has the value 'present'; if so, `pop()` one `x, y` tuple from `xy_list`, and draw the target at this location. This assumes that there is a function `draw_target()`, even though we haven't defined it yet.\n- If `target_present` is neither 'present' nor 'absent', we `throw` an error; this is defensive programming, and protects us from typos (e.g. if we had accidentally entered 'presenr' instead of 'present').\n- Loop through all remaining `x, y` values and draw a distractor at each position. This assumes that there is a function `draw_distractor()`, even though we haven't defined it yet.\n- Return `c`, which now has the search display drawn onto it.\n\nThere are several common functions, such as `Canvas()` and `xy_random()`, which are always available in an INLINE_JAVASCRIPT item. See:\n\n- %link:manual/javascript/common%\n\nExperimental variables are global variables. That's why you can refer to `set_size`, which is defined in *block_loop*, even though the variable `set_size` is never explicitly defined in the script. The same is true for `target_shape`, `target_color`, `condition`, etc. See:\n\n- %link:var%\n\n\n__Implement the intermediate level__\n\nWe now go one more step down by defining `draw_target` (above the rest of the script so far):\n\n```js\n/**\n * Draws the target.\n * @param c A Canvas\n * @param x An x coordinate\n * @param y A y coordinate\n **/\nfunction draw_target(c, x, y) {\n    draw_shape(c, x, y, target_color, target_shape)\n}\n```\n\nWhat happens here? We \u2026\n\n- Call another function, `draw_shape()`, and specify the color and shape that needs to be drawn. This assumes that there is a function `draw_shape()`, even though we haven't defined it yet.\n\nWe also define `draw_distractor` (above the rest of the script so far):\n\n```js\n/**\n * Draws a single distractor.\n * @param c A Canvas\n * @param x An x coordinate\n * @param y A y coordinate\n **/\nfunction draw_distractor(c, x, y) {\n    if (condition === 'conjunction') {\n        draw_conjunction_distractor(c, x, y)\n    } else if (condition === 'feature_shape') {\n        draw_feature_shape_distractor(c, x, y)\n    } else if (condition === 'feature_color') {\n        draw_feature_color_distractor(c, x, y)\n    } else {\n        throw 'Invalid condition: ' + condition\n    }\n}\n```\n\nWhat happens here? We \u2026\n\n- Call another function to draw a more specific distractor depending on the Condition.\n- Check whether `condition` has any of the expected values. If not, we `throw` an error. This is defensive programming! Without this check, if we made a typo somewhere, the distractor might simply not be shown without causing an error message.\n\nNow we define the function that draws distractors in the Conjunction condition (above the rest of the script so far):\n\n```js\n/**\n * Draws a single distractor in the conjunction condition: an object that\n * can have any shape and color, but cannot be identical to the target.\n * @param c A Canvas.\n * @param x An x coordinate.\n * @param y A y coordinate.\n **/\nfunction draw_conjunction_distractor(c, x, y) {\n    let conjunctions = [\n        ['yellow', 'circle'],\n        ['blue', 'circle'],\n        ['yellow', 'square'],\n        ['blue', 'square']\n    ]\n    let [color, shape] = random.pick(conjunctions)\n    while (color === target_color && shape === target_shape) {\n        [color, shape] = random.pick(conjunctions)\n    }\n    draw_shape(c, x, y, color, shape)\n}\n```\n\nWhat happens here? We \u2026\n\n- Define a list, `conjunctions`, of all possible color and shape combinations.\n- Randomly select one of the color and shape combinations from `conjunctions`.\n- Check if the selected color and shape are both equal to the color and shape of the target. If so, keep selecting a new color and shape until this is no longer the case. After all, the distractor cannot be identical to the target!\n- Call another function, `draw_shape()`, and specify the color and shape of the to-be-drawn distractor. This assumes that there is a function `draw_shape()`, even though we haven't defined it yet.\n\nIn addition, we \u2026\n\n- Use the `random` library, which is corresponds to the `random-ext` package. This library contains useful randomization functions (such as `random.pick()`) and is one of the non-standard JavaScript libraries that is included with OSWeb.\n\nNow we define the function that draws distractors in the Shape Feature condition (above the rest of the script so far):\n\n```js\n/**\n * Draws a single distractor in the feature-shape condition: an object that\n * has a different shape from the target, but can have any color.\n * @param c A Canvas.\n * @param x An x coordinate.\n * @param y A y coordinate.\n **/\nfunction draw_feature_shape_distractor(c, x, y) {\n    let colors = ['yellow', 'blue']\n    let color = random.pick(colors)\n    let shape\n    if (target_shape === 'circle') {\n        shape = 'square'\n    } else if (target_shape === 'square') {\n        shape = 'circle'\n    } else {\n        throw 'Invalid target_shape: ' + target_shape\n    }\n    draw_shape(c, x, y, color, shape)\n}\n```\n\nWhat happens here? We \u2026\n\n- Randomly select a color.\n- Choose a square shape if the target is a circle, and a circle shape if the target is square.\n- If `target_shape` is neither 'circle' nor 'square', `throw` an error\u2014more defensive programming!\n- Call another function, `draw_shape()`, and specify the color and shape of the to-be-drawn distractor. This assumes that there is a function `draw_shape()`, even though we haven't defined it yet.\n\nNow we define the function that draws distractors in the Color Feature condition (above the rest of the script so far):\n\n```js\n/**\n * Draws a single distractor in the feature-color condition: an object that\n * has a different color from the target, but can have any shape.\n * @param c A Canvas.\n * @param x An x coordinate.\n * @param y A y coordinate.\n **/\nfunction draw_feature_color_distractor(c, x, y) {\n    let shapes = ['circle', 'square']\n    let shape = random.pick(shapes)\n    let color\n    if (target_color === 'yellow') {\n        color = 'blue'\n    } else if (target_color === 'blue') {\n        color = 'yellow'\n    } else {\n        throw 'Invalid target_color: ' + target_color\n    }\n    draw_shape(c, x, y, color, shape)\n}\n```\n\nWhat happens here? We \u2026\n\n- Randomly select a shape.\n- Choose a blue color if the target is yellow, and a yellow color if the target is blue.\n- If `target_color` is neither 'yellow' nor 'blue', `throw` and error\u2014more defensive programming!\n- Call another function, `draw_shape()`, and specify the color and shape of the to-be-drawn distractor. This assumes that there is a function `draw_shape()`, even though we haven't defined it yet.\n\n__Implement the detailed level__\n\nNow we go all the way down to the details by defining the function that actually draws a shape to the canvas (above the rest of the script so far):\n\n```js\n/**\n * Draws a single shape.\n * @param c A Canvas.\n * @param x An x coordinate.\n * @param y A y coordinate.\n * @param color A color (yellow or blue)\n * @param shape A shape (square or circle)\n **/\nfunction draw_shape(c, x, y, color, shape) {\n    if (shape === 'square') {\n        // Parameters are passed as an Object!\n        c.rect({x:x-25, y:y-25, w:50, h:50, color:color, fill:true})\n    } else if (shape === 'circle') {\n        // Parameters are passed as an Object!\n        c.circle({x:x, y:y, r:25, color:color, fill:true})\n    } else {\n        throw 'Invalid shape: ' + shape\n    }\n    if (color !== 'yellow' && color !== 'blue') {\n        throw 'Invalid color: ' + color\n    }\n}\n```\n\nWhat happens here? We \u2026\n\n- Check which shape should be drawn. For squares, we add a `rect()` element to the canvas. For circles, we add a `circle()` element.\n- Check if the the shape is either a square or a circle, and if not `throw` and error. This is another example of defensive programming! We're making sure that we haven't accidentally specified an invalid shape.\n- Check if the the color is neither yellow nor blue, and if not `throw` and error.\n\nImportantly, `Canvas` functions accept a single object (`{}`) that specifies all parameters by name, like so:\n\n```js\n// Correct: pass a single object that contains all parameters by name\nc.rect({x:x-25, y:y-25, w:50, h:50, color:color, fill:true})\n// Incorrect: do not pass parameters by order\n// c.rect(x-25, y-25, 50, 50, color, true)\n// Incorrect: named parameters are not supported in JavaScript\n// c.rect(x=x-25, y=y-25, w=50, h=50, color=color, fill=true)\n```\n\n__Implement the Run phase__\n\nBecause we have done all the hard work in the Prepare phase, the Run phase is just:\n\n```js\nc.show()\n```\n\nThat's it! Now you have drawn a full visual-search display. And, importantly, you have done so in a way that is easy to understand, because of top-down programming, and safe, because of defensive programming.\n\n", "url": "https://osdoc.cogsci.nl/4.0/tutorials/intermediate-javascript", "title": "Intermediate tutorial (JavaScript): visual search"}
{"content": "# Intermediate tutorial (JavaScript): visual search\n\n## Step 7: Define the correct response\n\nTo know if the participant responds correctly, we need to know the correct response. You can define this explicitly in the *block_loop* (as done in the beginner tutorial); but here we're going to use some simple JavaScript that checks whether the target is present or not, and defines the correct response accordingly.\n\nTo do this, we first need to declare the variable in the Prepare tab of the *init* script, just below `let c`. This time, we use the `var` keyword to declare `correct_response`, because this makes the variable available in the user interface (whereas `let` does not do this):\n\n```js\nvar correct_response\n```\n\nNext, insert a new INLINE_JAVASCRIPT at the start of *trial_sequence*, and rename it to *correct_response_script*. In the Prepare phase, enter the following code:\n\n```js\nif (target_present === 'present') {\n    correct_response = 'right'\n} else if (vars.target_present === 'absent') {\n    correct_response = 'left'\n} else {\n    throw 'target_present should be absent or present, not ' + target\n}\n```\n\nWhat happens here? We \u2026\n\n- Check whether the target is present or not. If the target is present, the correct response is 'right' (the right arrow key); if the target is absent, the correct response is 'left' (the left arrow key). The experimental variable `correct_response` is automatically used by OpenSesame; therefore, we don't need to explicitly indicate that this variable contains the correct response.\n- Check if the target is either present or absent, and if not `throw` an error\u2014another example of defensive programming.\n\n## Step 8: Give per-trial feedback\n\nFeedback after every trial can motivate participants; however, per-trial feedback should not interfere with the flow of the experiment. A good way to give per-trial feedback is to briefly show a green fixation dot after a correct response, and a red fixation dot after an incorrect response.\n\nTo do this:\n\n- Insert two new SKETCHPADs into *trial_sequence*, just after *keyboard_response*.\n- Rename one SKETCHPAD to *green_dot*, draw a central green fixation dot onto it, and change its duration to 500.\n- Rename the other SKETCHPAD to *red_dot*, draw a central red fixation dot onto it, and change its duration to 500.\n\nOf course, only one of the two dots should be shown on each trial. To accomplish this, we will specify run-if statements in *trial_sequence*:\n\n- Change the run-if statement for *green_dot* to 'correct == 1', indicating that it should only be shown after a correct response.\n- Change the run-if statement for *red_dot* to 'correct == 0', indicating that it should only be shown after an incorrect response.\n\nThe variable `correct` is automatically created if the variable `correct_response` is available; that's why we defined `correct_response` in step 7. For more information about variables and run-if statements, see:\n\n- %link:manual/variables%\n\nThe *trial_sequence* should now look like %FigStep8.\n\n%--\nfigure:\n id: FigStep8\n source: step8.png\n caption: |\n  The *trial_sequence* at the end of step 8.\n--%\n\n\n## Finished!\n\nCongratulations, the experiment is complete! You can give it a test run by pressing on the toolbar button that shows a green circle with a gray play button inside (shortcut: `Alt+Ctrl+W`).\n\nIf the experiment doesn't work on the first try: Don't worry, and calmly figure out where the mistake comes from. Crashes are part of the normal development process. But you can save yourself a lot of time and headache by working in a structured way, as we have done in this tutorial.\n\n## References\n\n<div class='reference' markdown='1'>\n\nMath\u00f4t, S., Schreij, D., & Theeuwes, J. (2012). OpenSesame: An open-source, graphical experiment builder for the social sciences. *Behavior Research Methods*, *44*(2), 314-324. doi:10.3758/s13428-011-0168-7\n\nTreisman, A. M., & Gelade, G. (1980). A feature-integration theory of attention. *Cognitive Psychology*, 12(1), 97\u2013136. doi:10.1016/0010-0285(80)90005-5\n\n</div>\n\n[references]: #references\n[gpl]: http://www.gnu.org/licenses/gpl-3.0.en.html", "url": "https://osdoc.cogsci.nl/4.0/tutorials/intermediate-javascript", "title": "Intermediate tutorial (JavaScript): visual search"}
{"content": "# Beginner tutorial: gaze cuing\n\ntitle: Beginner tutorial: gaze cuing\n\n[TOC]\n\n## About OpenSesame\n\nOpenSesame is a program for easy of development of behavioral experiments for psychology, neuroscience, and experimental economy. For beginners, OpenSesame has a comprehensive graphical, point-and-click interface. For advanced users, OpenSesame supports Python scripting (not covered in this tutorial).\n\nOpenSesame is freely available under the [General Public License v3][gpl].\n\n## About this tutorial\n\nThis tutorial shows how to create a simple but complete psychological experiment using OpenSesame [(Math\u00f4t, Schreij, & Theeuwes, 2012; Math\u00f4t & March, 2022)][references]. You will use mainly the graphical user interface of OpenSesame (i.e., no Python inline coding), although you will make small modifications to the OpenSesame script. This tutorial takes approximately one hour.\n\n## Resources\n\n- __Download__ -- This tutorial assumes that you are running OpenSesame version 4.0.0 or later. To check which version you are running, see the bottom right of the 'Get started' tab (see %FigGetStarted). You can download the most recent version of OpenSesame from:\n\t- %link:download%\n- __Documentation__ -- A dedicated documentation website can be found at:\n\t- <http://osdoc.cogsci.nl/>\n- __Forum__ -- A support forum can be found at:\n\t- <http://forum.cogsci.nl/>\n\n## The experiment\n\nIn this tutorial, you will create a gaze-cuing experiment as introduced by [Friesen and Kingstone (1998)][references]. In this experiment, a face is presented in the center of the screen (%FigGazeCuing). This face looks either to the right or to the left. A target letter (an 'F' or an 'H') is presented to the left or right of the face. A distractor stimulus (the letter 'X') is presented on the other side of the face. The task is to indicate as quickly as possible whether the target letter is an 'F' or an 'H'. In the congruent condition, the face looks at the target. In the incongruent condition, the face looks at the distractor. As you may have guessed, the typical finding is that participant respond faster in the congruent condition than in the incongruent condition, even though the direction of gaze is not predictive of the target location. This shows that our attention is automatically guided by other people's gaze, even in situations where this doesn't serve any purpose. (And even when the face is just a smiley!)\n\n%--\nfigure:\n id: FigGazeCuing\n source: gaze-cuing.png\n caption: |\n  The gaze-cuing paradigm [(Friesen and Kingstone, 1998)][references] that you will implement in this tutorial. This example depicts a trial in the incongruent condition, because the smiley looks at the distractor ('X') and not at the target ('F').\n--%\n\nThe experiment consists of a practice and an experimental phase. Visual feedback will be presented after every block of trials. A sound will be played after every incorrect response.\n\n## Experimental design\n\nThis design:\n\n- is *within-subject*, because all participants do all conditions\n- is *fully crossed* (or full-factorial), because all combinations of conditions occur\n- has three factors (or factors):\n    - *gaze side* with two levels (left, right)\n    - *target side* with two levels (left, right)\n    - *target letter* with two levels (F, H)\n- has N subjects\n\n\nSee also %DesignScreencast for an explanation of the logic and design of the experiment:\n\n\n%--\nvideo:\n source: youtube\n id: DesignScreencast\n videoid: aWvibRH6D4E\n width: 640\n height: 360\n caption: |\n  An explanation of the experimental logic and design.\n--%\n\n\n## Step 1: Create the main sequence\n\nWhen you start OpenSesame, you see the 'Get started!' tab (%FigGetStarted). A list of templates is shown below 'Start a new experiment'. These templates provide convenient starting points for new experiments. After you saved an experiment the first time, recently opened experiments are shown under 'Continue with a recent experiment'. At the bottom of the page there are links to the documentation (which includes this tutorial), the community forum, and a page with professional (paid) support options. And of course a link where you can buy us a cup of coffee to help us stay awake while we are working on providing the best free software!\n\n%--\nfigure:\n id: FigGetStarted\n source: get-started.png\n caption: |\n  The 'Get started' dialog on OpenSesame start-up.\n--%\n\nClick on 'Default template' to start with a minimal experimental template.\n\nBy default there is a main SEQUENCE, which is simply called *experiment*. Click on *experiment* in the overview area (by default on the left side, see %FigInterface) to open its controls in the tab area. The *experiment* SEQUENCE consists of two items: a `notepad` called *getting started* and a SKETCHPAD called *welcome*.\n\nWe don't need these two items. Remove *getting_started* by right-clicking on it in the overview area and selecting 'Delete' (shortcut: `Del`). Remove *welcome* in the same way. The *experiment* SEQUENCE is now empty.\n\n%--\nfigure:\n id: FigInterface\n source: interface.png\n caption: \"The default layout of the OpenSesame interface.\"\n--%\n\n<div class='info-box' markdown='1'>\n\n__Background box__\n\n__Names vs types__ -- Items in OpenSesame have a name and a type. The name and type can be the same, but they are usually not. For example, a SKETCHPAD item can have the name *my_target_sketchpad*. To make this distinction clear, we will use `monospace` to indicate item types, and *italics* to indicate names.\n\n__Tip__ -- The 'Extended template' is a good starting point for many experiments. It already contains the basic structure of a trial-based experiment.\n\n__Tip__ -- You can click on the Help icons in the top right of an item's tab to get context-sensitive help.\n\n__Tip__ -- Save (shortcut: `Ctrl+S`) your experiment often! In the unfortunate (and unlikely) event of data loss, you will often be able to recover your work from the back-ups that are created automatically, by default, every 10 minutes (Menu \u2192 Tools \u2192 Open backup folder).\n\n__Tip__ -- Unless you have used 'Permanently delete' (shortcut: `Shift+Del`), deleted items are still available in the 'Unused items' bin, until you select 'Permanently delete unused items' in the 'Unused items' tab. You can re-add deleted items to a SEQUENCE by dragging them out of the 'Unused items' bin to somewhere in your experiment.\n\n__Tip__ -- %FigExperimentStructure schematically shows the structure of the experiment that you will create. If you get confused during the tutorial, you can refer to %FigExperimentStructure to see where you are.\n\n%--\nfigure:\n id: FigExperimentStructure\n source: experiment-structure.png\n caption: |\n  A schematic representation of the structure of the 'Gaze cuing' experiment. The item types are in bold face, item names in regular face.\n--%\n\n</div>\n\n__Append a form_text_display item for the instruction display__\n\nAs the name suggests, a `form_text_display` is a form that displays text. We are going to use a `form_text_display` to give instructions to the participant at the beginning of the experiment.\n\nClick on *experiment* in the overview area to open its controls in the tab area. You will see an empty SEQUENCE. Drag a `form_text_display` from the item toolbar (under 'Form', see %FigInterface) onto the *experiment* SEQUENCE in the tab area. When you let go, a new `form_text_display` item will be inserted into the SEQUENCE. (We will get back to this in Step 12.)\n\n<div class='info-box' markdown='1'>\n\n__Background box__\n\n__Tip__ -- You can drag items into the overview area and into SEQUENCE tabs.\n\n__Tip__ -- If a drop action is ambiguous, a pop-up menu will ask you what you want to do.\n\n__Tip__ -- A `form_text_display` only shows text. If you require images etc., you can use a SKETCHPAD item. We will meet the SKETCHPAD in Step 5.\n\n</div>\n\n__Append a loop item, containing a new sequence item, for the practice phase__\n\nWe need to append a LOOP item to the *experiment* SEQUENCE. We will use this LOOP for the practice phase of the experiment. Click on the *experiment* SEQUENCE to open its controls in the tab area.\n\nDrag the LOOP item from the item toolbar into the SEQUENCE just the way you added the `form_text_display`. New items are inserted below the item that they are dropped on, so if you drop the new LOOP onto the previously created `form_text_display`, it will appear where you want it: after the `form_text_display`. But don't worry if you drop a new item in the wrong place, because you can always re-order things later.\n\nBy itself, a LOOP does not do anything. A LOOP always needs another item to run. Therefore, you have to fill the new LOOP item with another item. (If you view the loop item, you will also see a warning: 'No item selected'.) Drag a SEQUENCE item from the item toolbar onto the LOOP item. A pop-up menu will appear, asking you whether you want to insert the SEQUENCE after or into the LOOP item. Select 'Insert into new_loop'. (We will get back to this in Step 2.)\n\n<div class='info-box' markdown='1'>\n\n__Background box__\n\n__What is a LOOP item?__ -- A LOOP is an item that adds structure to your experiment. It repeatedly runs another item, typically a SEQUENCE. A LOOP is also the place where you will usually define your independent variables, that is, those variables that you manipulate in your experiment.\n\n__What is a SEQUENCE item?__ -- A SEQUENCE item also adds structure to your experiment. As the name suggests, a SEQUENCE runs multiple other items one after another.\n\n__The LOOP-SEQUENCE structure__ -- You often want to repeat a sequence of events. To do this, you will need a LOOP item that contains a SEQUENCE item. By itself, a SEQUENCE does not repeat. It simply starts with the first item and ends with the last item. By 'wrapping' a LOOP item around the SEQUENCE, you can repeat the SEQUENCE multiple times. For example, a single trial usually corresponds to a single SEQUENCE called *trial_sequence*. A LOOP (often called *block_loop*) around this *trial_sequence* would then constitute a single block of trials. Similarly, but at another level of the experiment, a SEQUENCE (often called *block_sequence*) may contain a single block of trials, followed by a FEEDBACK display. A *practice_phase* LOOP around this 'block' SEQUENCE would then constitute the practice phase of the experiment. This may seem a bit abstract right now, but as you follow this tutorial, you will become familiar with the use of LOOPs and SEQUENCEs.\n\n__Tip__ -- For more information about SEQUENCEs and LOOPs, see:\n\n- %link:loop%\n- %link:sequence%\n\n</div>\n\n__Append a new form_text_display item for the end-of-practice message__\n\nAfter the practice phase, we want to inform the participant that the real experiment will begin. For this we need another `form_text_display`. Go back to the *experiment* SEQUENCE, and drag a `form_text_display` from the item toolbar onto the LOOP item. The same pop-up menu will appear as before. This time, select 'Insert after new_loop'. (We will get back to this in Step 12.)\n\n<div class='info-box' markdown='1'>\n\n__Tip__ -- Don't worry if you have accidentally changed a LOOP's item to run. You can undo this easily by clicking the 'Undo' button in the toolbar (`Ctrl+Shift+Z`).\n\n</div>\n\n__Append a new loop item, containing the previously created sequence, for the experimental phase__\n\nWe need a LOOP item for the experimental phase, just like for the practice phase. Therefore, drag a LOOP from the item toolbar menu onto *_form_text_display*.\n\nThe newly created LOOP (called *new_loop_1*) is empty, and should be filled with a SEQUENCE, just like the LOOP we created before. However, because the trials of the practice and experimental phase are identical, they can use the same SEQUENCE. Therefore, instead of dragging a new SEQUENCE from the item toolbar, you can re-use the *existing* one (i.e. create a linked copy).\n\nTo do this, right-click on the previously created *new_sequence*, and select 'Copy (linked)'. Now, right-click on *new_loop_1* and select 'Paste'. In the pop-up menu that appears, select 'Insert into new_loop 1'.\n\n<div class='info-box' markdown='1'>\n\n__Background box__\n\n__Tip__ \u2014 There is an important distinction between *linked* and *unlinked* copies. If you create a linked copy of an item, you create another occurrence of the same item. Therefore, if you modify the original item, the linked copy will change as well. In contrast, if you create an unlinked copy of an item, the copy will be initially look identical (except for its name), but you can edit the original without affecting the unlinked copy, and vice versa.\n\n</div>\n\n__Append a new form_text_display item, for the goodbye message__\n\nWhen the experiment is finished, we should say goodbye to the participant. For this we need another `form_text_display` item. Go back to the *experiment* SEQUENCE, and drag a `form_text_display` from the item toolbar onto *new_loop_1*. In the pop-up menu that appears, select 'Insert after new_loop_1'. (We will get back to this in Step 12.)\n\n__Give the new items sensible names__\n\nBy default, new items have names like *new_sequence* and *new_form_text_display_2*. It is good practice to give items sensible names. This makes it much easier to understand the structure of the experiment. If you want, you can also add a description to each item. Item names must consist of alphanumeric characters and/or underscores.\n\n- Select *new_form_text_display* in the overview area, double-click on its label in the top of the tab area and rename the item to *instructions*. (Overview-area shortcut: `F2`)\n- Rename *new_loop* to *practice_loop*.\n- Rename *new_sequence* to *block_sequence*. Because you have re-used this item in *new_loop_1*, the name automatically changes there as well. (This illustrates why it is efficient to create linked copies whenever this is possible.)\n- Rename *new_form_text_display_1* to *end_of_practice*.\n- Rename *new_loop_1* to *experimental_loop*.\n- Rename *new_form_text_display_2* to *end_of_experiment*.\n\n__Give the whole experiment a sensible name__\n\nThe experiment in its entirety also has a title and a description. Click on 'New experiment' in the overview area. You can rename the experiment in the same way as you renamed its items. The title currently is 'New experiment'. Rename the experiment to 'Tutorial: Gaze cuing'. Unlike item names, the experiment title may contain spaces etc.\n\nThe overview area of your experiment now looks like %FigStep1. This would be a good time to save your experiment (shortcut: `Ctrl+S`).\n\n%--\nfigure:\n id: FigStep1\n source: step1.png\n caption: |\n  The overview area at the end of the step 1.\n--%\n\n\n## Step 2: Create the block sequence\n\nClick on *block_sequence* in the overview. At the moment this SEQUENCE is empty. We want *block sequence* to consist of a block of trials, followed by a  FEEDBACK display. For this we need to do the following:\n\n__Append a reset_feedback item to reset the feedback variables__\n\nWe don't want our feedback to be confounded by key presses that participants have made during the instruction phase or previous blocks of trials. Therefore, we start each block of trials by resetting the feedback variables. To do this we need a `reset_feedback` item. Grab `reset_feedback` from the item toolbar (under 'Response collection') and drag it onto *block_sequence*.\n\n__Append a new loop, containing a new sequence, for a block of trials__\n\nFor a single trial we need a SEQUENCE. For a block of trials, we need to repeat this SEQUENCE multiple times. Therefore, for a block of trials we need to wrap a LOOP around a SEQUENCE. Drag a LOOP from the item toolbar onto *new_reset_feedback*. Next, drag a SEQUENCE from the item toolbar onto the newly created LOOP, and select 'Insert into new_loop' in the pop-up menu that appears. (We will get back to this in Step 3.)\n\n__Append a feedback item__\n\nAfter every block of trials we want to give feedback to the participant, so that the participant knows how well he/ she is doing. For this we need a FEEDBACK item. Drag a FEEDBACK from the item toolbar onto *new_loop*, and select 'Insert after loop' in the pop-up menu that appears. (We will get back to this in Step 10.)\n\n__Give the new items sensible names__\n\nRename: (See Step 1 if you don't remember how to do this.)\n\n- *new_loop* to *block_loop*\n- *new_sequence* to *trial_sequence*\n- *new_reset_feedback* to *reset_feedback*\n- *new_feedback* to *feedback*\n\nThe overview of your experiment now looks like %FigStep2. Remember to save your experiment regularly.\n\n%--\nfigure:\n id: FigStep2\n source: step2.png\n caption: |\n  The overview area at the end of Step 2.\n--%\n", "url": "https://osdoc.cogsci.nl/4.0/tutorials/beginner", "title": "Beginner tutorial: gaze cuing"}
{"content": "# Beginner tutorial: gaze cuing\n\n## Step 3: Fill the block loop with independent variables\n\nAs the name suggests, *block_loop* corresponds to a single block of trials. In the previous step we created the *block_loop*, but we still need to define the independent variables that will be varied within the block. Our experiment has three independent variables:\n\n- __gaze_cue__ can be 'left' or 'right'.\n- __target_pos__ (the position of the target) can be '-300' or '300'. These values reflect the X-coordinate of the target in pixels (0 = center). Using the coordinates directly, rather than 'left' and 'right', will be convenient when we create the target displays (see Step 5).\n- __target_letter__ (the target letter) can be 'F' or 'H'.\n\nTherefore, our experiment has 2 x 2 x 2 = 8 levels. Although 8 levels is not that many (most experiments will have more), we don't need to enter all possible combinations by hand. Click on *block_loop* in the overview to open its tab. Now click on the 'Full-factorial design' button. In the variable wizard, you simply define all variables by typing the name in the first row and the levels in the rows below the name (see %FigVariableWizard). If you select 'Ok', you will see that *block_loop* has been filled with all 8 possible combinations.\n\n%--\nfigure:\n id: FigVariableWizard\n source: variable-wizard.png\n caption: |\n  The loop variable wizard in Step 3.\n--%\n\nIn the resulting loop table, each row corresponds to one run of *trial_sequence*. Because, in our case, one run of *trial_sequence* corresponds to one trial, each row in our loop table corresponds to one trial. Each column corresponds to one variable, which can have a different value on each trial.\n\nBut we are not done yet. We need to add three more variables: the location of the distractor, the correct response, and the congruency.\n\n- __dist_pos__ -- On the first row of the first empty column, enter 'dist_pos'. This automatically adds a new experimental variable named 'dist_pos'. In the rows below, enter '300' wherever 'target_pos' is -300, and '-300' wherever 'target_pos' is 300. In other words, the target and the distractor should be positioned opposite from each other.\n- __correct_response__ -- Create another variable, in another empty column, with the name 'correct_response'. Set 'correct_response' to 'z' where 'target_letter' is 'F', and to 'm' where 'target_letter' is 'H'. This means that the participant should press the 'z' key if she sees an 'F' and the 'm' key if she sees an 'H'. (Feel free to choose different keys if 'z' and 'm' are awkward on your keyboard layout; for example, 'w' and 'n' are better on AZERTY keyboards.)\n- __congruency__ -- Create another variable with the name 'congruency'. Set 'congruency' to 'congruent' where 'target_pos' is '-300' and 'gaze_cue' is 'left', and where 'target_pos' is '300' and 'gaze_cue' is 'right'. In other words, a trial is congruent if the face looks at the target. Set 'congruency' to 'incronguent' for the trials on which the face looks at the distractor. The 'congruency' variable is not necessary to run the experiment; however, it is useful for analyzing the data later on.\n\nWe need to do one last thing. 'Repeat' is currently set to '1.00'. This means that each cycle will be executed once. So the block now consists of 8 trials, which is a bit short. A reasonable length for a block of trials is 24, so set 'Repeat' to 3.00 (3 repeats x 8 cycles = 24 trials). You don't need to change 'Order', because 'random' is exactly what we want.\n\nThe *block_loop* now looks like %FigStep3. Remember to save your experiment regularly.\n\n%--\nfigure:\n id: FigStep3\n source: step3.png\n caption: \"The *block_loop* at the end of Step 3.\"\n--%\n\n<div class='info-box' markdown='1'>\n\n__Background box__\n\n__Tip__ -- You can prepare your loop table in your favorite spreadsheet program and copy-paste it into the LOOP variable table.\n\n__Tip__ -- You can specify your loop table in a separate file (in `.xlsx` or `.csv`) format, and use this file directly. To do so, select 'file' under 'Source'.\n\n__Tip__ -- You can set 'Repeat' to a non-integer number. For example, by setting 'Repeat' to '0.5', only half the trials (randomly selected) are executed.\n\n</div>\n\n## Step 4: Add images and sound files to the file pool\n\nFor our stimuli, we will use images from file. In addition, we will play a sound if the participant makes an error. For this we need a sound file.\n\nYou can download the required files here (in most webbrowsers you can right-click the links and choose 'Save Link As' or a similar option):\n\n- [gaze_neutral.png](/img/beginner-tutorial/gaze_neutral.png)\n- [gaze_left.png](/img/beginner-tutorial/gaze_left.png)\n- [gaze_right.png](/img/beginner-tutorial/gaze_right.png)\n- [incorrect.ogg](/img/beginner-tutorial/incorrect.ogg)\n\nAfter you have downloaded these files (to your desktop, for example), you can add them to the file pool. If the file pool is not already visible (by default on the right side of the window), click on the 'Show file pool' button in the main toolbar (shortcut: `Ctrl+P`). The easiest way to add the four files to the file pool is to drag them from the desktop (or wherever you have downloaded the files to) into the file pool. Alternatively, you can click on the '+' button in the file pool and add files using the file select dialog that appears. The file pool will be automatically saved with your experiment.\n\nYour file pool now looks like %FigStep4. Remember to save your experiment regularly.\n\n%--\nfigure:\n id: FigStep4\n source: step4.png\n caption: \"The file pool at the end of Step 4.\"\n--%\n\n## Step 5: Fill the trial sequence with items\n\nA trial in our experiment looks as follows:\n\n1. __Fixation dot__ -- 750 ms, SKETCHPAD item\n2. __Neutral gaze__ -- 750 ms, SKETCHPAD item\n3. __Gaze cue__ -- 500 ms, SKETCHPAD item\n4. __Target__  -- 0 ms, SKETCHPAD item\n5. __Response collection__ \t-- KEYBOARD_RESPONSE item\n6. __Play a sound if response was incorrect__ --  SAMPLER item\n7. __Log response to file__ -- LOGGER item\n\nClick on *trial_sequence* in the overview to open the *trial_sequence* tab. Pick up a SKETCHPAD from the item toolbar and drag it into the *trial_sequence*. Repeat this three more times, so that *trial_sequence* contains four SKETCHPADs. Next, select and append a KEYBOARD_RESPONSE item, a SAMPLER item, and a LOGGER item.\n\nAgain, we will rename the new items, to make sure that the *trial_sequence* is easy to understand. Rename:\n\n- *new_sketchpad* to *fixation_dot*\n- *new_sketchpad_1* to *neutral_gaze*\n- *new_sketchpad_2* to *gaze_cue*\n- *new_sketchpad_3* to *target*\n- *new_keyboard_response* to *keyboard_response*\n- *new_sampler* to *incorrect_sound*\n- *new_logger* to *logger*\n\nBy default, items are always executed, which is indicated by the run-if expression `True`. However, we want to change this for the *incorrect_sound* item, which should only be executed if an error was made. To do this, we need to change the 'Run if' expression to `correct == 0` in the *trial_sequence* tab. This works, because the *keyboard_response* item automatically creates a `correct` variable, which is set to `1` (correct), `0` (incorrect), or `undefined` (this relies on the `correct_response` variable that was defined in Step 3). The double equals sign is Python syntax and indicates that you want to compare whether the two things are equal to each other, in this case whether the variable `correct` is equal to 0. To change a run-if expression, double click on it (shortcut: `F3`).\n\nThe *trial_sequence* now looks like %FigStep5.\n\n%--\nfigure:\n id: FigStep5\n source: step5.png\n caption: \"The *trial_sequence* at the end of Step 5.\"\n--%\n\n<div class='info-box' markdown='1'>\n\n__Background box__\n\n__What is a SKETCHPAD item?__ -- A SKETCHPAD is used to present visual stimuli: text, geometric shapes, fixation dots, Gabor patches, etc. You can draw on the SKETCHPAD using the built-in drawing tools.\n\n__What is a KEYBOARD_RESPONSE item?__ -- A KEYBOARD_RESPONSE item collects a single participant's response from the keyboard.\n\n__What is a SAMPLER item?__ -- A SAMPLER item plays a sound from a sound file.\n\n__What is a LOGGER item?__ -- A LOGGER item writes data to the log file. This is very important: If you forget to include a LOGGER item, no data will be logged during the experiment!\n\n__Tip__ -- Variables and conditional \"if\" expressions are very powerful! To learn more about them, see:\n\n- %link:manual/variables%\n\n</div>\n\n## Step 6: Draw the sketchpad items\n\nThe SKETCHPAD items that we have created in Step 5 are still blank. It's time to do some drawing!\n\n__Set the background color to white__\n\nClick on *fixation_dot* in the overview area to open its tab. The SKETCHPAD is still dark gray, while the images that we have downloaded have a white background. Oops, we forgot to set the background color of the experiment to white (it is dark gray by default)! Click on 'Tutorial: Gaze cuing' in the overview area to open the 'General properties' tab. Change 'Foreground' to 'black' and 'Background' to 'white'.\n\n<div class='info-box' markdown='1'>\n\n__Background box__\n\n__Tip__ -- For more fine-grained control over colors, you can also use the hexadecimal RGB notation (e.g., `#FF000` for red), use various color spaces, or use the color-picker tool. See also:\n\n- %link:manual/python/canvas%\n\n</div>\n\n__Draw the fixation dot__\n\nGo back to the *fixation_dot* by clicking on *fixation_dot* in the overview. Now select the fixation-dot element by clicking on the button with the crosshair. If you move your cursor over the sketchpad, you can see the screen coordinates in the top-right. Set the (foreground) color to 'black'. Click on the center of the screen (0, 0) to draw a central fixation dot.\n\nFinally, change the 'Duration' field from 'keypress' to '745', because we want the fixation dot to be presented for 750 ms. Wait ... *why didn't we just specify a duration of 750 ms?* The reason for this is that the actual display-presentation duration is always rounded up to a value that is compatible with your monitor's refresh rate. This may sound complicated, but for most purposes the following rules of thumb are sufficient:\n\n1. Choose a duration that is possible given your monitor's refresh rate. For example, if your monitor's refresh rate is 60 Hz, it means that every frame lasts 16.7 ms (= 1000 ms/60 Hz). Therefore, on a 60 Hz monitor, you should always select a duration that is a multiple of 16.7 ms, such as 16.7, 33.3, 50, 100, etc.\n2. In the duration field of the SKETCHPAD specify a duration that is a few milliseconds less than what you're aiming for. So if you want to present a SKETCHPAD for 50 ms, choose a duration of 45. If you want to present a SKETCHPAD for 1000 ms, choose a duration of 995. Etcetera.\n\n<div class='info-box' markdown='1'>\n\n__Background box__\n\n__Tip__ -- For a detailed discussion of experimental timing, see:\n\n- %link:timing%\n\n__Tip__ -- The duration of a SKETCHPAD can be a value in milliseconds, but you can also enter 'keypress' or 'mouseclick' to collect a keyboard press or mouse click respectively. In this case a SKETCHPAD will work much the same as a KEYBOARD_RESPONSE item (but with fewer options).\n\n__Tip__ -- Make sure that the (foreground) color is set to black. Otherwise you will draw white on white and won't see anything!\n\n</div>\n\n__Draw the neutral gaze__\n\nOpen the *neutral_gaze* SKETCHPAD. Now select the image tool by clicking on the button with the mountain-landscape-like icon. Click on the center of the screen (0, 0). The 'Select file from pool' dialog will appear. Select the file `gaze_neutral.png` and click on the 'Select' button. The neutral gaze image will now stare at you from the center of the screen! Finally, like before, change the 'Duration' field from 'keypress' to '745'. (And note again that this means a duration of 750 ms on most monitors!)\n\n<div class='info-box' markdown='1'>\n\n__Background box__\n\n__Tip__ -- OpenSesame can handle a wide variety of image formats. However, some (non-standard) `.bmp` formats are known to cause trouble. If you find that a `.bmp` image is not shown, you can convert it to a different format, such as `.png`. You can convert images easily with free tools such as [GIMP].\n</div>\n\n__Draw the gaze cue__\n\nOpen the *gaze_cue* SKETCHPAD, and again select the image tool. Click on the center of the screen (0, 0) and select the file `gaze_left.png`.\n\nBut we are not done yet! Because the gaze cue should not always be 'left', but should depend on the variable `gaze_cue`, which we have defined in Step 3. However, by drawing the `gaze_left.png` image to the SKETCHPAD, we have generated a script that needs only a tiny modification to make sure that the proper image is shown. Click on the 'Select view' button at the top-right of the *gaze_cue* tab and select 'View script'. You will now see the script that corresponds to the sketchpad that we have just created:\n\n~~~ .python\nset duration keypress\nset description \"Displays stimuli\"\ndraw image center=1 file=\"gaze_left.png\" scale=1 show_if=True x=0 y=0 z_index=0\n~~~\n\nThe only thing that we need to do is replace `gaze_left.png` with `gaze_{gaze_cue}.png`. This means that OpenSesame uses the variable `gaze_cue` (which has the values `left` and `right`) to determine which image should be shown.\n\nWhile we are at it, we might as well change the duration to '495' (rounded up to 500!). The script now looks like this:\n\n~~~ .python\nset duration 495\nset description \"Displays stimuli\"\ndraw image center=1 file=\"gaze_{gaze_cue}.png\" scale=1 show_if=True x=0 y=0 z_index=0\n~~~\n\nClick the 'Apply' button at the top right to apply your changes to the script and return to the regular item controls. OpenSesame will warn you that the image cannot be shown, because it is defined using variables, and a placeholder image will be shown instead. Don't worry, the correct image will be shown during the experiment!\n\n<div class='info-box' markdown='1'>\n\n__Background box__\n\n__Tip__ -- The variable inspector (shortcut: `Ctrl+I`) is a powerful way to find out which variables have been defined in your experiment, and which values they have (see %FigVariableInspector). When your experiment is not running, most variables don't have a value yet. But when you run your experiment in a window, while having the variable inspector visible, you can see variables changing in real time. This is very useful for debugging your experiment.\n\n%--\nfigure:\n id: FigVariableInspector\n source: variable-inspector.png\n caption: \"The variable inspector is a convenient way to get an overview of the variables that exist in your experiment.\"\n--%\n\n</div>\n\n__Draw the target__\n\nWe want three objects to be part of the target display: the target letter, the distractor letter, and the gaze cue (see %FigGazeCuing). As before, we will start by creating a static display using the SKETCHPAD editor. After this, we will only need to make minor changes to the script so that the exact display depends on the variables.\n\nClick on *target* in the overview to open the target tab and like before, draw the `gaze_left.png` image at the center of the screen. Now select the draw text tool by clicking on the button with the 'A' icon. Change the foreground color to 'black' (if it isn't already). The default font size is 18 px, which is a bit small for our purpose, so change the font size to 32 px. Now click on (-320, 0) in the SKETCHPAD (the X-coordinate does not need to be exactly 320, since we will change this to a variable anyway). Enter \"{target_letter}\" in the dialog that appears, to draw the target letter (when drawing text, you can use variables directly). Similarly, click on (320, 0) and draw an 'X' (the distractor is always an 'X').\n\nNow open the script editor by clicking on the 'Select view' button at the top-right of the tab and selecting 'View script'. The script looks like this:\n\n~~~ .python\nset duration keypress\nset duration keypress\nset description \"Displays stimuli\"\ndraw image center=1 file=\"gaze_left.png\" scale=1 show_if=True x=0 y=0 z_index=0\ndraw textline center=1 color=black font_bold=no font_family=mono font_italic=no font_size=32 html=yes show_if=True text=\"{target_letter}\" x=-320 y=0 z_index=0\ndraw textline center=1 color=black font_bold=no font_family=mono font_italic=no font_size=32 html=yes show_if=True text=X x=320 y=0 z_index=0\n~~~\n\nLike before, change `gaze_left.png` to `gaze_{gaze_cue}.png`. We also need to make the position of the target and the distractor depend on the variables `target_pos` and `dist_pos` respectively. To do this, simply change `-320` to `{target_pos}` and `320` to `{dist_pos}`. Make sure that you leave the `0`, which is the Y-coordinate. The script now looks like this:\n\n~~~ .python\nset duration keypress\nset description \"Displays stimuli\"\ndraw image center=1 file=\"gaze_{gaze_cue}.png\" scale=1 show_if=True x=0 y=0 z_index=0\ndraw textline center=1 color=black font_bold=no font_family=mono font_italic=no font_size=32 html=yes show_if=True text=\"{target_letter}\" x={target_pos} y=0 z_index=0\ndraw textline center=1 color=black font_bold=no font_family=mono font_italic=no font_size=32 html=yes show_if=True text=X x={dist_pos} y=0 z_index=0\n~~~\n\nClick on the 'Apply' button to apply the script and go back to the regular item controls.\n\nFinally, set the 'Duration' field to '0'. This does not mean that the target is presented for only 0 ms, but that the experiment will advance to the next item (the *keyboard_response*) right away. Since the *keyboard_response* waits for a response, but doesn't change what's on the screen, the target will remain visible until a response has been given.\n\nRemember to save your experiment regularly.\n\n<div class='info-box' markdown='1'>\n\n__Background box__\n\n__Tip__ -- Each element of a SKETCHPAD has a 'Show if' option, which specifies when the element should be shown. You can use this to hide/ show elements from a SKETCHPAD depending on certain variables, similar to run-if statements in a SEQUENCE.\n\n__Tip__ -- Make sure that the (foreground) color is set to black. Otherwise you will draw white on white and won't see anything!\n\n</div>\n", "url": "https://osdoc.cogsci.nl/4.0/tutorials/beginner", "title": "Beginner tutorial: gaze cuing"}
{"content": "# Beginner tutorial: gaze cuing\n\n## Step 7: Configure the keyboard response item\n\nClick on *keyboard_response* in the overview to open its tab. You see three options: Correct response, Allowed responses, Timeout, and Event type.\n\nWe have already set the `correct_response` variable in Step 3. Unless we explicitly specify a correct response, OpenSesame automatically uses the `correct_response` variable if it is available. Therefore, we don't need to change the 'Correct response' field here.\n\nWe do need to set the allowed responses. Enter 'z;m' in the allowed-responses field (or other keys if you have chosen different response keys). The semicolon is used to separate responses. The KEYBOARD_RESPONSE now only accepts 'z' and 'm' keys. All other key presses are ignored, with the exception of 'escape', which pauses the experiment.\n\nWe also want to set a timeout, which is the maximum interval that the KEYBOARD_RESPONSE waits before deciding that the response is incorrect and setting the 'response' variable to 'None'. '2000' (ms) is a good value.\n\nWe don't need to change the Event type, because we want the participant to respond by pressing a key (keypress, the default) and not by releasing a key (keyrelease).\n\nThe KEYBOARD_RESPONSE now looks like %FigStep7.\n\n%--\nfigure:\n id: FigStep7\n source: step7.png\n caption: \"The KEYBOARD_RESPONSE at the end of Step 7.\"\n--%\n\n<div class='info-box' markdown='1'>\n\n__Background box__\n\n__Tip__ -- By default, the KEYBOARD_RESPONSE will use the `correct_response` variable to determine whether a response was correct. But you can use a different variable as well. To do this, enter a variable name between curly braces (`{my_variable}`) in the correct response field.\n\n__Tip__ -- If 'flush pending key presses' is enabled (it is by default), all pending key presses are discarded when the KEYBOARD_RESPONSE item is called. This prevents carry-over effects, which might otherwise occur if the participant accidentally presses a key during a non-response part of the trial.\n\n__Tip__ -- To use special keys, such as '/' or the up-arrow key, you can use key names (e.g., 'up' and 'space') or associated characters (e.g., '/' and ']'). The 'List available keys' button provides an overview of all valid key names.\n\n</div>\n\n## Step 8: Configure the incorrect (sampler) item\n\nThe *incorrect_sound* item doesn't need much work: We only need to select the sound that should be played. Click on *incorrect_sound* in the overview to open its tab. Click on the 'Browse' button and select `incorrect.ogg` from the file pool.\n\nThe sampler now looks like %FigStep8.\n\n%--\nfigure:\n id: FigStep8\n source: step8.png\n caption: \"The *incorrect_sound* item at the end of Step 8.\"\n--%\n\n<div class='info-box' markdown='1'>\n\n__Background box__\n\n__Tip__ -- You can use variables to specify which sound should be played by using a variable name between curly braces as (part of) the file name. For example: `{a_word}.ogg`\n\n__Tip__ -- The SAMPLER handles files in `.ogg`, `.mp3`, and `.wav` format. If you have sound files in a different format, [Audacity] is a great free tool to convert sound files (and much more).\n\n</div>\n\n## Step 9: Configure the variable logger\n\nActually, we don't need to configure the variable LOGGER, but let's take a look at it anyway. Click on *logger* in the overview to open its tab. You see that the option 'Automatically log all variables' is selected. This means that OpenSesame logs everything, which is fine.\n\n<div class='info-box' markdown='1'>\n\n__Background box__\n\n__Tip__ -- If you like your log-files clean, you can disable the 'Automatically log all variables' option and manually select variables, either by entering variable names manually ('Add custom variable'), or by dragging variables from the variable inspector into the LOGGER table. You can also leave the 'Automatically log all variables' option enabled and exclude variables that you are not interested in.\n\n__The one tip to rule them all__ -- Always triple-check whether all the necessary variables are logged in your experiment! The best way to check this is to run the experiment and investigate the resulting log files.\n\n</div>\n\n## Step 10: Draw the feedback item\n\nAfter every block of trials, we want to present feedback to the participant to let him/ her know how well he/ she is doing. Therefore, in Step 2, we added a FEEDBACK item, simply named *feedback* to the end of *block_sequence*.\n\nClick on *feedback* in the overview to open its tab, select the draw text tool, change the foreground color to 'black' (if it isn't already), and click at (0, 0). Now enter the following text:\n\n```text\nEnd of block\n\nYour average response time was {avg_rt} ms\nYour accuracy was {acc} %\n\nPress any key to continue\n```\n\nBecause we want the feedback item to remain visible as long as the participant wants (i.e. until he/ she presses a key), we leave 'Duration' field set to 'keypress'.\n\nThe feedback item now looks like %FigStep_10.\n\n%--\nfigure:\n id: FigStep_10\n source: step10.png\n caption: \"The feedback item at the end of Step 10.\"\n--%\n\n<div class='info-box' markdown='1'>\n\n__Background box__\n\n__What is a feedback item?__ -- A FEEDBACK item is almost identical to a SKETCHPAD item. The only difference is that a FEEDBACK item is not prepared in advance. This means that you can use it to present feedback, which requires up-to-date information about a participant's response. You should not use FEEDBACK items to present time-critical displays, because the fact that it is not prepared in advance means that its timing properties are not as good as that of the SKETCHPAD item. See also:\n\n- %link:visual%\n\n__Feedback and variables__ -- Response items automatically keep track of the accuracy and average response time of the participant in the variables 'acc' (synonym: 'accuracy') and 'avg_rt' (synonym: 'average_response_time') respectively. See also:\n\n- %link:manual/variables%\n\n__Tip__ -- Make sure that the (foreground) color is set to black. Otherwise you will draw white on white and won't see anything!\n\n</div>\n\n## Step 11: Set the length of the practice phase and experimental phase\n\nWe have previously created the *practice_loop* and *experiment_loop* items, which both call *block_sequence* (i.e., a block of trials). However, right now they call *block_sequence* only once, which means that both the practice and the experimental phase consist of only a single block of trials.\n\nClick on *practice_loop* to open its tab and set 'Repeat' to '2.00'. This means that the practice phase consists of two blocks.\n\nClick on *experimental_loop* to open its tab and set 'Repeat' to '8.00'. This means that the experimental phase consists of eight blocks.\n\n<div class='info-box' markdown='1'>\n\n__Background box__\n\n__Tip__ -- You can create a variable `practice` in both *practice_loop* and *experimental_loop* and set it to 'yes' and 'no' respectively. This is an easy way of keeping track of which trials were part of the practice phase.\n\n</div>\n\n## Step 12: Write the instruction, end_of_practice and end_of_experiment forms\n\nI think you can handle this step your own! Simply open the appropriate items and add some text to present instructions, an end-of-practice message, and an end-of-experiment message.\n\n<div class='info-box' markdown='1'>\n\n__Background box__\n\n__Tip__ -- You can use a subset of HTML tags to format your text. For example, *&lt;b&gt;this will be bold&lt;b&gt;* and *&lt;span color='red'&gt;this will be red&lt;span&gt;*. For more information, see:\n\n- %link:text%\n\n</div>\n\n## Step 13: Run the experiment!\n\nYou're done! Click on the 'Run in window' (shortcut: `Ctrl+W`) or 'Run fullscreen' (shortcut: `Ctrl+R`) buttons in the toolbar to run your experiment.\n\n<div class='info-box' markdown='1'>\n\n__Background box__\n\n__Tip__ -- A test run is executed even faster by clicking the orange 'Run in window' button (shortcut: `Ctrl+Shift+W`), which doesn't ask you how to save the logfile (and should therefore only be used for testing purposes).\n\n</div>\n\n\n## Understanding errors\n\nBeing able to understand error messages is a crucial skill when working with OpenSeame. After all, a newly built experiment rarely runs immediately without any errors!\n\nLet's say that we made a mistake during one of the steps above. When trying to run the experiment, we get the following error message (%FigErrorMessage):\n\n%--\nfigure:\n id: FigErrorMessage\n source: error-message.png\n caption: \"An error message in OpenSesame.\"\n--%\n\nThe error message starts with a name, in this case `FStringError`, which indicates the general type of error. This is followed by a short explanatory text, in this case 'Failed to evaluate f-string expression in the following text: gaze_{gaze_ceu}.png`. Even without understanding what an f-string is (it's a string that contains Python code between curly braces), it's clear that there is something wrong with the text '{gaze_ceu}.png'.\n\nThe error message also indicates that the error comes from the prepare phase of the *gaze_cue* item.\n\nFinally, the error message indicates what specifically went wrong when evaluating the text 'gaze_{gaze_ceu}.png': the name 'gaze_ceu' is not defined.\n\nWhile reading the error message carefully, the cause and solution probably already came to your mind: we made a simple spelling mistake in the *gaze_cue* item, writing '{gaze_ceu}' instead of '{gaze_cue}'! And this resulted in an error because there is no variable with the name `gaze_ceu`. This can be easily fixed by opening the script of the *gaze_cue* item and fixing the typo.\n\n\n## Finally: Some general considerations regarding timing and backend selection\n\nIn the 'General properties' tab of the experiment (the tab that you open by clicking on the experiment name), you can select a backend. The backend is the layer of software that controls the display, input devices, sound, etc. Most experiments work with all backends, but there are reasons to prefer one backend over the other, mostly related to timing. Currently there are four backends (depending on your system, not all three may be available):\n\n- __psycho__ -- a hardware-accelerated backend based on PsychoPy [(Peirce, 2007)][references]. This is the default.\n- __xpyriment__ -- a hardware-accelerated backend based on Expyriment [(Krause & Lindeman, 2013)][references]\n- __legacy__ -- a 'safe' backend, based on PyGame. It provides reliable performance on most platforms, but, due to a lack of hardware acceleration, its timing properties are not as good as those of the other backends.\n- __osweb__ -- runs experiments in a browser [(Math\u00f4t & March, 2022)][references].\n\nSee also:\n\n- %link:backends%\n- %link:timing%\n\n\n## References\n\n<div class='reference' markdown='1'>\n\nBrand, A., & Bradley, M. T. (2011). Assessing the effects of technical variance on the statistical outcomes of web experiments measuring response times. *Social Science Computer Review*. doi:10.1177/0894439311415604\n\nDamian, M. F. (2010). Does variability in human performance outweigh imprecision in response devices such as computer keyboards? *Behavior Research Methods*, *42*, 205-211. doi:10.3758/BRM.42.1.205\n\nFriesen, C. K., & Kingstone, A. (1998). The eyes have it! Reflexive orienting is triggered by nonpredictive gaze. *Psychonomic Bulletin & Review*, *5*, 490\u2013495. doi:10.3758/BF03208827\n\nKrause, F., & Lindemann, O. (2013). Expyriment: A Python library for cognitive and neuroscientific experiments. *Behavior Research Methods*. doi:10.3758/s13428-013-0390-6\n\nMath\u00f4t, S., Schreij, D., & Theeuwes, J. (2012). OpenSesame: An open-source, graphical experiment builder for the social sciences. *Behavior Research Methods*, *44*(2), 314-324. doi:10.3758/s13428-011-0168-7\n\nMath\u00f4t, S., & March, J. (2022). Conducting linguistic experiments online with OpenSesame and OSWeb. *Language Learning*. doi:10.1111/lang.12509\n\nPeirce, J. W. (2007). PsychoPy: Psychophysics software in Python. *Journal of Neuroscience Methods*, *162*(1-2), 8-13. doi:10.1016/j.jneumeth.2006.11.017\n\nUlrich, R., & Giray, M. (1989). Time resolution of clocks: Effects on reaction time measurement\u2014Good news for bad clocks. *British Journal of Mathematical and Statistical Psychology*, *42*(1), 1-12. doi:10.1111/j.2044-8317.1989.tb01111.x\n\n</div>\n\n[references]: #references\n[gpl]: http://www.gnu.org/licenses/gpl-3.0.en.html\n[gimp]: http://www.gimp.org/\n[audacity]: http://audacity.sourceforge.net/\n[python inline scripting]: /python/about", "url": "https://osdoc.cogsci.nl/4.0/tutorials/beginner", "title": "Beginner tutorial: gaze cuing"}
{"content": "# Intermediate tutorial (Python) visual search\n\ntitle: Intermediate tutorial (Python) visual search\n\n[TOC]\n\n## About OpenSesame\n\nOpenSesame is a user-friendly program for the development of behavioral experiments for psychology, neuroscience, and experimental economy. For beginners, OpenSesame has a comprehensive graphical, point-and-click interface.  For advanced users, OpenSesame supports Python (desktop only) and JavaScript (desktop and browser).\n\nOpenSesame is freely available under the [General Public License v3][gpl].\n\n## About this tutorial\n\nThis tutorial shows how to create a basic visual-search experiment using OpenSesame [(Math\u00f4t, Schreij, & Theeuwes, 2012)][references]. We will use both the graphical interface and Python scripting to develop an experiment that you can run on the desktop in a traditional lab-based setting. Some experience with OpenSesame and Python is recommended. This tutorial takes approximately one hour.\n\nA JavaScript-based version of this tutorial is also available. If you want to run your experiments online in a browser (with OSWeb), then the JavaScript tutorial is what you need:\n\n- %link:tutorials/intermediate-javascript%\n\n## Resources\n\n- __Download__ \u2014 This tutorial assumes that you are running OpenSesame version 4.0.0 or later. You can download the most recent version of OpenSesame from:\n\t- %link:download%\n- __Documentation__ \u2014 A dedicated documentation website can be found at:\n\t- <http://osdoc.cogsci.nl/>\n- __Forum__ \u2014 A support forum can be found at:\n\t- <http://forum.cogsci.nl/>\n\n## The experiment\n\nIn this tutorial, you will create a basic visual-search experiment. The experiment resembles the classic visual-search studies of [Treisman and Gelade (1980)][references], but it is not identical.\n\nIn this experiment, participants search for a target object, which can be a yellow square, a yellow circle, a blue square, or a blue circle; the identity of the target is varied between blocks of trials. Participants indicate whether the target is present or not by pressing the right (present) or left (absent) arrow key.\n\nIn addition to the target, zero or more distractor objects are shown. There are three conditions, and the condition determines what kind of distractors there are:\n\n- In the *Conjunction* condition, distractors can have any shape and color, with the only restriction that distractors cannot be identical to the target. So, for example, if the target is a yellow square, then distractors are yellow circles, blue circles, and blue squares.\n- In the *Shape Feature* condition, distractors have a different shape from the target, but can have any color. So, for example, if the target is a yellow square, then distractors are yellow circles and blue circles.\n- In the *Color Feature* condition, distractors can have any shape, but have a different color from the target. So, for example, if the target is a yellow square, then distractors are blue squares and blue circles.\n\nImmediate feedback is shown after each trial: a green dot after a correct response, and a red dot after an incorrect response. Detailed feedback on average response times and accuracy is shown after each block of trials.\n\n%--\nfigure:\n id: FigVisualSearch\n source: visual-search.svg\n caption: |\n  The visual-search experiment that you will implement in this tutorial.\n--%\n\nExperiments like this show two typical findings:\n\n- It takes more time to find the target in the Conjunction condition than in the two Feature conditions.\n- In the Conjunction condition, response times increase as the number of distractors increases. This suggests that people search for the target one item at a time; this is called *serial search*.\n- In the Feature conditions (both shape and color), response times do not, or hardly, increase as the the number of distractors increases. This suggests that people process the entire display at once; this is called *parallel search*.\n\nAccording to Treisman and Gelade's feature-integration theory, these results reflect that the Conjunction condition requires that you combine, or *bind*, the color and shape of each object. This binding requires attention, and you therefore need to shift your attention from one object to the next; this is slow, and explains why response times depend on how many objects there are. In contrast, in the Feature conditions, color and shape do not need to be bound, and therefore the whole display can be processed in a single sweep without attention being directed at each and every object.\n\n## Experimental design\n\nThis design:\n\n- Is *within-subject*, because all participants do all conditions\n- Is *fully crossed* (or full-factorial), because all combinations of conditions occur\n- Has three conditions (or factors):\n\t- Varied within blocks:\n\t\t- `set_size` with three levels (1, 5, 15), or SS<sub>3</sub>\n\t\t- `condition` with three levels (conjunction, feature_shape, feature_color), or CN<sub>3</sub>\n\t\t- `target_present` with two levels (present, absent), or TP<sub>2</sub>\n\t- Varied between blocks:\n\t\t- `target_shape` with two levels (square, circle), or TS<sub>2</sub>\n\t\t- `target_color` with two levels (yellow, blue), or TC<sub>2</sub>\n- Has N subjects, or <u>S</u><sub>N</sub>\n\nYou can write this design as <u>S</u><sub>N</sub>\u00d7SS<sub>3</sub>\u00d7CN<sub>3</sub>\u00d7TP<sub>2</sub>\u00d7TS<sub>2</sub>\u00d7TC<sub>2</sub>\n\nFor more information about this notation for experimental design, see:\n\n- %link:experimentaldesign%\n\n## Step 1: Create the basic structure of the experiment\n\nStart OpenSesame and, in the 'Get started!' tab, select the Extended template. This template provides the basic structure that is common to many cognitive-psychology experiments, such as the one that we will create here.\n\nThe Extended template contains a few items that we don't need. Delete the following items:\n\n- *about_this_template*\n- *practice_loop*\n- *end_of_practice*\n\nWhen you have deleted these items, they are still visible in the 'Unused items' bin. To permanently delete these items, click on the 'Unused items' bin, and then click on the 'Permanently delete unused items' button.\n\nFinally, give the experiment a good title, such as 'Visual search'. To do this, open the general-properties tab (by clicking on 'Extended template' in the overview area) and click on the experiment name to edit it.\n\nThe overview area should now look like %FigStep1:\n\n%--\nfigure:\n id: FigStep1\n source: step1.png\n caption: |\n  The overview area at the end of step 1.\n--%\n\n## Step 2: Define experimental variables that are varied between blocks\n\nAs described above, two variables are varied between blocks in our experiment: `target_shape` and `target_color`. We therefore need to define these variables in the *experimental_loop*. To understand why, consider the structure shown in %FigStep1, starting from the bottom (i.e. the most indented level).\n\n- *trial_sequence* corresponds to a single trial\n- *block_loop* corresponds to a block of a trials\n\t- Therefore, variables defined here vary for each run of *trial_sequence*; in other words, variables defined in *block_loop* are varied __within blocks__.\n- *block_sequence* corresponds to a block of trials, preceded by resetting of the feedback variables, and followed by participant feedback\n- *experimental_loop* corresponds to multiple blocks of trials\n\t- Therefore, variables defined here vary for each run of *block_sequence*; in other words, variables defined in *experimental_loop* are varied __between blocks__.\n- *experiment* corresponds to the entire experimental, which is an instruction screen, followed by multiple blocks of trials, followed by an end-of-experiment screen\n\nClick on experimental loop, and define:\n\n- `target_shape`, which can be 'square' or 'circle'; and\n- `target_color`, which can be 'yellow' or 'blue'.\n\nWe have a full-factorial design, which means that all 2 \u00d7 2 = 4 combinations must occur. The table of *experimental_loop* should now look like %FigStep2:\n\n%--\nfigure:\n id: FigStep2\n source: step2.png\n caption: |\n  The table of *experimental_loop* at the end of step 2.\n--%\n\n## Step 3: Give instructions at the start of each block\n\nRight now, the experiment starts with a single *instructions* screen. In our case, we want to give instructions before each block of trials, to tell the participant what target to look for (because the identity of the target varies between blocks).\n\n__Move the instructions into block_sequence__\n\nTherefore, pick up the *instructions* item and drag it onto *block_sequence*. A pop-up will appear, asking you if you want to:\n\n- Insert the item into *block_sequence*, in which case *instructions* would become the first item of *block_sequence*; or\n- Insert the item after *block_sequence*, in which case *instructions* would move to a position after *block_sequence*.\n\nSelect the first option ('Insert into'). Now *block_sequence* starts with an instructions screen, which is what we want.\n\n__Add instructional text__\n\nClick on *instructions* to open it, and add a good instructional text, such as:\n\n```text\nINSTRUCTIONS\n\nSearch for the {target_color} {target_shape}\n\nPress the right-arrow key if you find it\nPress the left-arrow key if you don't\n\nPress any key to begin\n```\n\nThe curly braces brackets around '{target_color}' and '{target_shape}' indicate that these are not literal text, but refer to the variables that we have defined in *experimental_loop*. When the experiment runs, the values of these variables will appear here, and the participant will see (for example), 'Search for the yellow circle'.\n\n__Give a visual preview of the target__\n\nIt also good to show the participant the actual stimulus that she needs to find. To do this:\n\n- Draw a filled circle at the center of the display (make sure it doesn't overlap with the text);\n- Change the color of the circle to '{target_color}'. This means that the color of the circle depends on the value of the variable `target_color`; and\n- Change the show-if expression to `target_shape == 'circle'`. This is a Python expression that checks if the variable `target_shape` has the value 'circle'.\n\nIn other words, we have drawn a circle of which the color is determined by `target_color`; furthermore, this circle is only shown when the variable `target_shape` has the value 'circle'. For more information about variables and show-if statements, see:\n\n- %link:manual/variables%\n\nWe use the same trick to draw a square:\n\n- Draw a filled square at the center of the display;\n- Change the color of the square to '{target_color}'; and\n- Change the show-if statement to `target_shape == 'square'`\n\nThe *instructions*  screen should now look like %FigStep3:\n\n%--\nfigure:\n id: FigStep3\n source: step3.png\n caption: |\n  The *instructions* screen at the end of step 3.\n--%\n\n## Step 4: Define experimental variables that are varied within blocks\n\nThree variables are varied within blocks in our experiment: `condition`, `set_size`, and `target_present`. As described under Step 2, we need to define these variables in the *block_loop* so that they vary for each run of *trial_sequence*.\n\nThe three variables make a total of 3 \u00d7 3 \u00d7 2 = 18 different combinations. We can type these into the table manually, but, because we have full-factorial design, we can also use the full-factorial-design wizard. To do this, first open *block_loop* and click on the 'Full-factorial design' button.\n\nIn the table that appears, put the variable names on the first row, and the values on the rows below, as shown in %FigFullFactorial.\n\n%--\nfigure:\n id: FigFullFactorial\n source: fullfactorial.png\n caption: |\n  The *instructions* screen at the end of step 3.\n--%\n\nNow click on 'Ok' to generate the full design. The table of *block_loop* should now look like %FigStep4.\n\n%--\nfigure:\n id: FigStep4\n source: step4.png\n caption: |\n  The table of *block_loop* at the end of step 4.\n--%\n\n## Step 5: Create the trial sequence\n\nWe want our trial sequence to look as follows:\n\n- A fixation dot, for which we will use a SKETCHPAD.\n- A search display, which we will create in Python with a custom INLINE_SCRIPT.\n- Response collection, for which we will use a KEYBOARD_RESPONSE.\n- Data logging, for which we will use a LOGGER.\n- (We also want immediate feedback after each trial, but we will get back to this later.)\n\nSo the only thing that is missing is an INLINE_SCRIPT.\n\n- Insert a new INLINE_SCRIPT after *sketchpad* and rename it to *search_display_script*.\n- Rename *sketchpad* to *fixation_dot*, so that its function is clear; and\n- Change the duration of *fixation_dot* to 500, so that the fixation dot is shown for 500 ms. (There should already be a fixation dot drawn; if not, draw one in the center of *fixation_dot*.)\n\nThe overview area should now look like %FigStep5.\n\n%--\nfigure:\n id: FigStep5\n source: step5.png\n caption: |\n  The overview area at the end of step 5.\n--%\n\n## Step 6: Generate the search display\n\n__Top-down and defensive programming__\n\nNow things will get interesting: We will start programming in Python. We will use two guiding principles: *top-down* and *defensive* programming.\n\n- *Top-down programming* means that we start with the most abstract logic, without bothering with how this logic is implemented. Once the most abstract logic is in place, we will move down to a slightly less abstract logic, and so on, until we arrive at the details of the implementation. This technique helps to keep the code structured.\n- *Defensive programming* means that we assume that we make mistakes. Therefore, to protect us from ourselves, we build sanity checks into the code.\n\n*Note:* The explanation below assumes that you're somewhat familiar with Python code. If concepts like `list`, `tuple`, and functions don't mean anything to you, then it's best to first walk through an introductory Python tutorial, such as this one:\n\n- <https://pythontutorials.eu/>\n\nThe logic of the code is shown in %FigHierarchy. The numbers indicate the order in which we will implement the functionality, starting at the abstract level.\n\n%--\nfigure:\n id: FigHierarchy\n source: hierarchy.svg\n caption: |\n  The logic of the code to draw a visual-search display.\n--%\n\n__The Prepare and Run phases__\n\nOpen *search_display_script* and switch to the Prepare tab. OpenSesame distinguishes two phases of execution:\n\n- During the Prepare phase, each item is given the opportunity to prepare itself; what this means depends on the item: For a SKETCHPAD, it means drawing a canvas (but not showing it); for a SAMPLER, it means loading a sound file (but not playing it); etc.\n- During the Run phase, each item is actually executed; again, what this means depends on the item: For a SKETCHPAD, it means showing the previously prepared canvas; for a SAMPLER, it means playing a previously loaded sound file.\n\nFor an INLINE_SCRIPT, you have to decide yourself what to put in the Prepare phase, and what to put in the Run phase. The distinction is usually quite clear: In our case, we put the code for drawing the canvas in the Prepare phase, and the code for showing the canvas (which is small) in the Run phase.\n\nSee also:\n\n- %link:prepare-run%\n\n__Implement the abstract level__\n\nWe start at the most abstract level: defining a function that draws a visual-search display. We don't specify *how* this is done; we simply assume that there is a function that does this, and we will worry about the details later\u2014that's top-down programming.\n\nIn the Prepare tab, enter the following code:\n\n~~~ .python\nc = draw_canvas()\n~~~\n\nWhat happens here? We \u2026\n\n- Call `draw_canvas()`, which returns a `Canvas` object that we store as `c`; in other words, `c` is a `Canvas` object that corresponds the search display. This assumes that there is a function `draw_canvas()`, even though we haven't defined it yet.\n\nA `Canvas` object is a single display; it is, in a sense, the Python counterpart of a SKETCHPAD. See also:\n\n- %link:manual/python/canvas%\n\nWe now go one step down by defining `draw_canvas()` (above the rest of the script so far):\n\n~~~ .python\ndef draw_canvas():\n    \"\"\"Draws the search canvas.\n\n    Returns\n    -------\n    Canvas\n    \"\"\"\n    c = Canvas()\n    xy_list = xy_random(n=set_size, width=500, height=500, min_dist=75)\n    if target_present == 'present':\n        x, y = xy_list.pop()\n        draw_target(c, x, y)\n    elif target_present != 'absent':\n        raise Exception(f'Invalid value for target_present: {target_present}')\n    for x, y in xy_list:\n        draw_distractor(c, x, y)\n    return c\n~~~\n\n\nWhat happens here? We \u2026\n\n- Create an empty canvas, `c`, using the factory function `Canvas()`.\n- Generate a list of random `x, y` coordinates, called `xy_list`, using another common function, `xy_random()`. This list determines where the stimuli are shown.\n- Check if the experimental variable `target_present` has the value 'present'; if so, `pop()` one `x, y` tuple from `xy_list`, and draw the target at this location. This assumes that there is a function `draw_target()`, even though we haven't defined it yet.\n- If `target_present` is neither 'present' nor 'absent', we raise an `Exception`; this is defensive programming, and protects us from typos (e.g. if we had accidentally entered 'presenr' instead of 'present').\n- Loop through all remaining `x, y` tuples and draw a distractor at each position. This assumes that there is a function `draw_distractor()`, even though we haven't defined it yet.\n- Return `c`, which now has the search display drawn onto it.\n\nThere are several common functions, such as `Canvas()` and `xy_random()`, which are always available. See:\n\n- %link:manual/python/common%\n\nExperimental variables are global variables. That's why you can refer to `set_size`, which is defined in *block_loop*, even though the variable `set_size` is never explicitly defined in the script. The same is true for `target_shape`, `target_color`, `condition`, etc. See:\n\n- %link:var%\n\n__Implement the intermediate level__\n\nWe now go one more step down by defining `draw_target` (above the rest of the script so far):\n\n~~~ .python\ndef draw_target(c, x, y):\n    \"\"\"Draws the target.\n\n    Parameters\n    ----------\n    c: Canvas\n    x: int\n    y: int\n    \"\"\"\n    draw_shape(c, x, y, color=target_color, shape=target_shape)\n~~~\n\nWhat happens here? We \u2026\n\n- Call another function, `draw_shape()`, and specify the color and shape that needs to be drawn. This assumes that there is a function `draw_shape()`, even though we haven't defined it yet.\n\nWe also define `draw_distractor` (above the rest of the script so far):\n\n~~~ .python\ndef draw_distractor(c, x, y):\n    \"\"\"Draws a single distractor.\n\n    Parameters\n    ----------\n    c: Canvas\n    x: int\n    y: int\n    \"\"\"\n    if condition == 'conjunction':\n        draw_conjunction_distractor(c, x, y)\n    elif condition == 'feature_shape':\n        draw_feature_shape_distractor(c, x, y)\n    elif condition == 'feature_color':\n        draw_feature_color_distractor(c, x, y)\n    else:\n        raise Exception(f'Invalid condition: {condition}')\n~~~\n\nWhat happens here? We \u2026\n\n- Call another function to draw a more specific distractor depending on the Condition.\n- Check whether `condition` has any of the expected values. If not, we raise an `Exception`. This is defensive programming! Without this check, if we made a typo somewhere, the distractor might simply not be shown without causing an error message.\n\nNow we define the function that draws distractors in the Conjunction condition (above the rest of the script so far):\n\n~~~ .python\nimport random\n\n\ndef draw_conjunction_distractor(c, x, y):\n    \"\"\"Draws a single distractor in the conjunction condition: an object that\n    can have any shape and color, but cannot be identical to the target.\n\n    Parameters\n    ----------\n    c: Canvas\n    x: int\n    y: int\n    \"\"\"\n    conjunctions = [('yellow', 'circle'),\n                    ('blue',   'circle'),\n                    ('yellow', 'square'),\n                    ('blue',   'square')]\n    conjunctions.remove((target_color, target_shape))\n    color, shape = random.choice(conjunctions)\n    draw_shape(c, x, y, color=color, shape=shape)\n~~~\n\nWhat happens here? We \u2026\n\n- Define a list, `conjunctions`, of all possible color and shape combinations.\n- Remove the target from this list; this is necessary, because the distractor cannot be identical to the target.\n- Randomly select one of the color and shape combinations from `conjunctions`.\n- Call another function, `draw_shape()`, and specify the color and shape of the to-be-drawn distractor. This assumes that there is a function `draw_shape()`, even though we haven't defined it yet.\n\nIn addition, we \u2026\n\n- Add the line `import random` to the top of the script. This is necessary so that we can use functions that are part of the `random` module, such as `random.choice()`.\n\nNow we define the function that draws distractors in the Shape Feature condition (right below the `import` statement):\n\n~~~ .python\ndef draw_feature_shape_distractor(c, x, y):\n    \"\"\"Draws a single distractor in the feature-shape condition: an object that\n    has a different shape from the target, but can have any color.\n\n    Parameters\n    ----------\n    c: Canvas\n    x: int\n    y: int\n    \"\"\"\n    colors = ['yellow', 'blue']\n    color = random.choice(colors)\n    if target_shape == 'circle':\n        shape = 'square'\n    elif target_shape == 'square':\n        shape = 'circle'\n    else:\n        raise Exception(f'Invalid target_shape: {target_shape}')\n    draw_shape(c, x, y, color=color, shape=shape)\n~~~\n\nWhat happens here? We \u2026\n\n- Randomly select a color.\n- Choose a square shape if the target is a circle, and a circle shape if the target is square.\n- If `target_shape` is neither 'circle' nor 'square', raise an `Exception`\u2014more defensive programming!\n- Call another function, `draw_shape()`, and specify the color and shape of the to-be-drawn distractor. This assumes that there is a function `draw_shape()`, even though we haven't defined it yet.\n\nNow we define the function that draws distractors in the Color Feature condition (right below the `import` statement):\n\n~~~ .python\ndef draw_feature_color_distractor(c, x, y):\n    \"\"\"Draws a single distractor in the feature-color condition: an object that\n    has a different color from the target, but can have any shape.\n\n    Parameters\n    ----------\n    c: Canvas\n    x: int\n    y: int\n    \"\"\"\n    shapes = ['circle', 'square']\n    shape = random.choice(shapes)\n    if target_color == 'yellow':\n        color = 'blue'\n    elif target_color == 'blue':\n        color = 'yellow'\n    else:\n        raise Exception(f'Invalid target_color: {target_color}')\n    draw_shape(c, x, y, color=color, shape=shape)\n~~~\n\nWhat happens here? We \u2026\n\n- Randomly select a shape.\n- Choose a blue color if the target is yellow, and a yellow color if the target is blue.\n- If `target_color` is neither 'yellow' nor 'blue', raise an `Exception`\u2014more defensive programming!\n- Call another function, `draw_shape()`, and specify the color and shape of the to-be-drawn distractor. This assumes that there is a function `draw_shape()`, even though we haven't defined it yet.\n\n__Implement the detailed level__\n\nNow we go all the way down to the details by defining the function that actually draws a shape to the canvas (right below the `import` statement):\n\n~~~ .python\ndef draw_shape(c, x, y, color, shape):\n    \"\"\"Draws a single shape.\n\n    Parameters\n    ----------\n    c: Canvas\n    x: int\n    y: int\n    color: str\n    shape: str\n    \"\"\"\n    if shape == 'square':\n        c += Rect(x=x-25, y=y-25, w=50, h=50, color=color, fill=True)\n    elif shape == 'circle':\n        c += Circle(x=x, y=y, r=25, color=color, fill=True)\n    else:\n        raise Exception(f'Invalid shape: {shape}')\n    if color not in ['yellow', 'blue']:\n        raise Exception(f'Invalid color: {color}')\n~~~\n\nWhat happens here? We \u2026\n\n- Check which shape should be drawn. For squares, we add a `Rect()` element to the canvas. For circles, we add a `Circle()` element.\n- Check if the the shape is either a square or a circle, and if not raise an `Exception`. This is another example of defensive programming! We're making sure that we haven't accidentally specified an invalid shape.\n- Check if the the color is neither yellow nor blue, and if not raise an `Exception`.\n\n__Implement the Run phase__\n\nBecause we have done all the hard work in the Prepare phase, the Run phase is just:\n\n~~~ .python\nc.show()\n~~~\n\nThat's it! Now you have drawn a full visual-search display. And, importantly, you have done so in a way that is easy to understand, because of top-down programming, and safe, because of defensive programming.\n\n", "url": "https://osdoc.cogsci.nl/4.0/tutorials/intermediate", "title": "Intermediate tutorial (Python) visual search"}
{"content": "# Intermediate tutorial (Python) visual search\n\n## Step 7: Define the correct response\n\nTo know if the participant responds correctly, we need to know the correct response. You can define this explicitly in the *block_loop* (as done in the beginner tutorial); but here we're going to use a simple Python script that checks whether the target is present or not, and defines the correct response accordingly.\n\nTo do this, insert a new INLINE_SCRIPT at the start of *trial_sequence*, and rename it to *correct_response_script*. In the Prepare phase (not the Run phase!), enter the following code:\n\n~~~ .python\nif target_present == 'present':\n    correct_response = 'right'\nelif target_present == 'absent':\n    correct_response = 'left'\nelse:\n    raise Exception(f'target_present should be absent or present, not {target}')\n~~~\n\nWhat happens here? We \u2026\n\n- Check whether the target is present or not. If the target is present, the correct response is 'right' (the right arrow key); if the target is absent, the correct response is 'left' (the left arrow key). The experimental (global) variable `correct_response` is automatically recognized by *keyboard_response*; therefore, we don't need to explicitly indicate that this variable contains the correct response.\n- Check if the target is either present or absent, and if not raise an `Exception`\u2014another example of defensive programming.\n\n## Step 8: Give per-trial feedback\n\nFeedback after every trial can motivate participants; however, per-trial feedback should not interfere with the flow of the experiment. A good way to give per-trial feedback is to briefly show a green fixation dot after a correct response, and a red fixation dot after an incorrect response.\n\nTo do this:\n\n- Insert two new SKETCHPADs into *trial_sequence*, just after *keyboard_response*.\n- Rename one SKETCHPAD to *green_dot*, draw a central green fixation dot onto it, and change its duration to 500.\n- Rename the other SKETCHPAD to *red_dot*, draw a central red fixation dot onto it, and change its duration to 500.\n\nOf course, only one of the two dots should be shown on each trial. To accomplish this, we will specify run-if expressions in *trial_sequence*:\n\n- Change the run-if expression for *green_dot* to 'correct == 1', indicating that it should only be shown after a correct response.\n- Change the run-if expression for *red_dot* to 'correct == 0', indicating that it should only be shown after an incorrect response.\n\nThe variable `correct` is automatically created if the variable `correct_response` is available; that's why we defined `correct_response` in step 7. For more information about variables and run-if statements, see:\n\n- %link:manual/variables%\n\nThe *trial_sequence* should now look like %FigStep8.\n\n%--\nfigure:\n id: FigStep8\n source: step8.png\n caption: |\n  The *trial_sequence* at the end of step 8.\n--%\n\n## Finished!\n\nCongratulations, the experiment is complete! You can give it a test run by pressing on the blue double-arrow button (shortcut: `Ctrl+W`).\n\nIf the experiment doesn't work on the first try: Don't worry, and calmly figure out where the mistake comes from. Crashes are part of the normal development process. But you can save yourself a lot of time and headache by working in a structured way, as we have done in this tutorial.\n\n## References\n\n<div class='reference' markdown='1'>\n\nMath\u00f4t, S., Schreij, D., & Theeuwes, J. (2012). OpenSesame: An open-source, graphical experiment builder for the social sciences. *Behavior Research Methods*, *44*(2), 314-324. doi:10.3758/s13428-011-0168-7\n\nTreisman, A. M., & Gelade, G. (1980). A feature-integration theory of attention. *Cognitive Psychology*, 12(1), 97\u2013136. doi:10.1016/0010-0285(80)90005-5\n\n</div>\n\n[references]: #references\n[gpl]: http://www.gnu.org/licenses/gpl-3.0.en.html", "url": "https://osdoc.cogsci.nl/4.0/tutorials/intermediate", "title": "Intermediate tutorial (Python) visual search"}
{"content": "# Touch response\n\ntitle: Touch response\n\nThe `touch_response` plug-in allows you to work with touch responses (or mouse clicks) in an easy way, by dividing the display into rows and columns. Each response is encoded by a single number, which corresponds to the position counting from left-to-right and top-down. For example, if you have specified 2 columns and 3 rows, the display is divided into the following response regions:\n\n```bash\n1\t2\n3\t4\n5\t6\n```\n\nSimilarly, if you have specified 4 columns and 1 row, the display is sliced horizontally into the following response regions:\n\n```bash\n1\t2\t3\t4\n```", "url": "https://osdoc.cogsci.nl/4.0/items/touch_response", "title": "Touch response"}
{"content": "# Advanced_delay\n\ntitle: Advanced_delay\n\nThe `advanced_delay` plug-in delays the experiment for a pre-specified average duration plus a random margin.\n\n- *Duration* is the average duration of the delay in milliseconds.\n- *Jitter* is the size of the variation in the delay in milliseconds.\n- *Jitter mode* is the how the jitter is calculated:\n\t- *Standard deviation* will draw the variation from a Gaussian distribution with Jitter as the standard deviation.\n\t- *Uniform* will draw the variation in duration from a uniform distribution.", "url": "https://osdoc.cogsci.nl/4.0/items/advanced_delay", "title": "Advanced_delay"}
{"content": "# Quest staircase next\n\ntitle: Quest staircase next\n\nProcesses a response and updates the Quest test value.", "url": "https://osdoc.cogsci.nl/4.0/items/quest_staircase_next", "title": "Quest staircase next"}
{"content": "# Repeat_cycle\n\ntitle: Repeat_cycle\n\nThis plug-in allows you to repeat cycles from a `loop`. Most commonly, this will be to repeat a trial when a participant made a mistake or was too slow.\n\nFor example, to repeat all trials on which a response was slower than 3000 ms, you can add a `repeat_cycle` item after (typically) the `keyboard_response` and add the following repeat-if expression:\n\n```bash\nresponse_time > 3000\n```\n\nYou can also force a cycle to be repeated by setting the variable `repeat_cycle` to 1 in an `inline_script`, like so:\n\n```python\nrepeat_cycle = 1\n```", "url": "https://osdoc.cogsci.nl/4.0/items/repeat_cycle", "title": "Repeat_cycle"}
{"content": "# Reset_feedback\n\ntitle: Reset_feedback\n\nThis plug-in has the same effect as presenting a FEEDBACK item with a duration of 0 ms\n{: .page-notification}\n\nIf you do not reset feedback variables, you may confound your feedback with responses that are not relevant to the task. For example, the key presses made during the instruction phase may affect the feedback during the first block of the experiment. Therefore, you will need to reset the feedback variables at appropriate moments.\n\nThis plug-in will reset the following variables to 0:\n\n- `total_response_time`\n- `total_response`\n- `acc`\n- `accuracy`\n- `avg_rt`\n- `average_response_time`", "url": "https://osdoc.cogsci.nl/4.0/items/reset_feedback", "title": "Reset_feedback"}
{"content": "# Quest staircase init\n\ntitle: Quest staircase init\n\nInitializes a new Quest staircase procedure.", "url": "https://osdoc.cogsci.nl/4.0/items/quest_staircase_init", "title": "Quest staircase init"}
{"content": "# Runners\n\ntitle: Runners\n\n\n[TOC]\n\n\n## About runners\n\nThere are several technically different ways in which you can execute your experiment. Each of these corresponds to a *runner*. You can select a runner under Menu \u2192 Tools \u2192 Preferences \u2192 Runner.\n\nUnless you have a reason not to, you should use the *multiprocess* runner. However, if OpenSesame sometimes crashes, you can try whether selecting a different runner resolves this.\n\n\n## Available runners\n\n### Multiprocess\n\nThe *multiprocess* runner executes your experiment in a different process. The benefit of this approach is that your experiment can crash without bringing the user interface down with it. Another advantage of the *multiprocess* runner is that it allows the variable inspector to show your experimental variables while the experiment is running.\n\n### Inprocess\n\nThe *inprocess* runner executes the experiment in the same process as the user interface. The benefit of this approach is its simplicity. The downside is that the user interface may crash if the experiment crashes, and vice versa.\n\n### External\n\nThe *external* runner executes the experiment by launching opensesamerun as a separate application. The benefit of this approach is that your experiment can crash without bringing the user interface down with it.", "url": "https://osdoc.cogsci.nl/4.0/manual/runners", "title": "Runners"}
{"content": "# OpenSesame script\n\ntitle: OpenSesame script\nreviewed: false\n\n[TOC]\n\n## About OpenSesame script\n\nOpenSesame script is a simple definitional language that defines an experiment. It is not a full fledged programming language, and does not include features such a `for` loops. The OpenSesame script is interpreted by an OpenSesame runtime environment.\n\nOpenSesame script is different from the Python scripts that are used in inline_script items. Python is a real programming language with all the flexibility and complexities that this entails. In contrast, OpenSesame script is used to define experiments in a simple, human-readable way.\n\n## General remarks\n\n### Keywords\n\nSome items, such as form_base and sketchpad accept keywords. Keywords are of the form `keyword=value`. Keywords are optional and should fall back to a default value.\n\n### Comments\n\nStrings preceded by a hash should be interpreted as comments.\n\n*Example*\n\n\t# This is a comment\n\n### Quotation\n\nQuotation is not necessary, except around strings that contain spaces or other forms of punctuation. So the following lines should be interpreted as identical:\n\n\tset my_var 'my_value'\n\tset my_var \"my_value\"\n\tset my_var my_value\n\nHowever, the following lines are not. In fact, the first line is not valid, because it has an unexpected third parameter.\n\n\tset my_var my value\n\tset my_var \"my value\"\n\n### Types\n\nThere are no types. No distinction is made between strings, integers, etc.\n\n### Item-specific syntax\n\nSome items have a specific syntax. This is indicated in the \u201cApplies to\u201d section for each of the keywords discussed below.\n\n### Resolving path names\n\nTODO\n\n## *define* statement\n\nStarts the definition of an item. After a define statement, all lines are indented by a single tab. The end of the item definition is the first string that is no longer indented. Nested define statements are not allowed.\n\n*Applies to*\n\nAll items\n\n*Format*\n\n\tdefine [item name] [item type]\n\t\t[item definition]\n\n*Parameters*\n\n|`item name`\t|the name of the item\t|\n|`item type`\t|the type of the item\t|\n\n*Example*\n\n\tdefine get_key keyboard_response\n\t\tset allowed_responses \"a;x\"\n\t\tset description \"Collects keyboard responses\"\n\t\tset timeout \"infinite\"\n\t\tset flush \"yes\"\n\n## *draw* statement\n\nDefines a visual element of a sketchpad or feedback item.\n\n*Applies to*\n\nsketchpad, feedback\n\n*Format*\n\nThe format depends on the element.\n\n\tdraw ellipse [left] [top] [width] [height] [keywords]\n\tdraw circle [x] [y] [radius] [keywords]\n\tdraw line [left] [right] [top] [bottom] [keywords]\n\tdraw arrow [left] [right] [top] [bottom] [keywords]\n\tdraw textline [x] [y] [text]\n\tdraw image [x] [y] [path]\n\tdraw gabor [x] [y]\n\tdraw noise [x] [y]\n\tdraw fixdot [x] [y]\n\n*Parameters*\n\n|`left` \t\t|the left-most x-coordinate\t\t|\n|`right`\t\t|the right-most x-coordinate\t|\n|`top`\t\t\t|the top y-coordinate\t\t\t|\n|`bottom`\t\t|the bottom y-coordinate\t\t|\n|`x` \t\t\t|the x-coordinate\t\t\t\t|\n|`y`\t\t\t|the y-coordinate\t\t\t\t|\n|`text` \t\t|text string\t\t\t\t\t|\n|`path` \t\t|the path to an image file\t\t|\n\n*Keywords*\n\nTODO\n\n*Example*\n\n\tdraw fixdot 0 0\n\n## *log* statement\n\nIndicates that a variable should be written to the log-file.\n\n*Applies to*\n\nlogger\n\n*Format*\n\n\tlog [variable name]\n\n*Parameters*\n\n|`variable name`\t\t|the name of a variable\t|\n\n*Example*\n\n\tlog response_time\n\n## *run* statement\n\nIndicates that an item should be run. In the case of the sequence, the order of the run statements determines the order in which items are called. In the case of the coroutines plugin all items are called at the same time.\n\n*Applies to*\n\nsequence\n\n*Format*\n\n\trun [item name] [optional: condition] [optional: disabled]\n\n*Parameters*\n\n|`item name`\t\t\t|the name of the item to run\t|\n|`condition` (optional)\t|the conditional statement, which determines the item is actually called. If no condition is provided, the item is always called.|\n\n*Example*\n\n\trun correct_feedback '[correct] = 1'\n\n## *set* statement\n\nDefines single-line variables.\n\n*Applies to*\n\nAll items\n\n*Format*\n\n\tset [variable name] [value]\n\n*Parameters*\n\n|`variable name`\t|the variable name\t|\n|`value`\t\t\t|the variable value\t|\n\n*Example*\n\n\tset timeout 1000\n\n*Notes*\n\nMulti-line variables are defined using the `__[variable name]__` notation. This is mostly useful for items that require large blocks of text. Within an item definition, each line is preceded by a single tab, which should not be interpreted as part of the text. `__end__` indicates the end of the variable.\n\n*For example:*\n\n\t__my_variable__\n\tThis is the first line.\n\tThis is the second line.\n\t__end__\n\n## *setcycle* statement\n\nSimilar to the regular \u201cset\u201d statement, but sets a variable only during a specific cycle of a loop. This is the script equivalent of the loop table.\n\n*Applies to*\n\nLoop\n\n*Format*\n\n\tsetcycle [cycle #] [variable name] [variable value]\n\n*Parameters*\n\n|`Cycle #`\t\t\t|the number of the cycle, where 0 is the first\t|\n|`variable name` \t|the variable name\t\t\t\t\t\t\t\t|\n|`value`\t\t\t|the variable value\t\t\t\t\t\t\t\t|\n\n*Example*\n\n\tsetcycle 0 cue valid\n\n## *widget* statement\n\nAdds a widget (buttons, labels, etc.) to a form. Valid keywords depend on the type of widget. The widget statement is not strictly part of the core OpenSesame syntax, but is used by the form_base plugin.\n\n*Applies to*\n\nform_base (plugin)\n\n*Format*\n\n\twidget [column] [row] [column span] [row span] [widget type] [keywords]\n\n*Parameters*\n\n|`column`\t\t|the widget's column position in the form, where 0 is left-most\t\t\t\t\t\t\t\t|\n|`row`\t\t\t|the widget's row position in the form, where 0 is top\t\t\t\t\t\t\t\t\t\t|\n|`column span`\t|the number of columns that the widget occupies\t\t\t\t\t\t\t\t\t\t\t\t|\n|`row span`\t\t|the number of rows that the widget occupies\t\t\t\t\t\t\t\t\t\t\t\t|\n|`widget type`\t|'button', 'checkbox', 'image', 'image_button', 'label', 'rating_scale', or 'text_input'\t|\n\n*Keywords*\n\nTODO\n\n*Example*\n\n\twidget 0 0 1 1 label text='This is a label'", "url": "https://osdoc.cogsci.nl/4.0/manual/opensesame-script", "title": "OpenSesame script"}
{"content": "# Counterbalancing\n\ntitle: Counterbalancing\n\nCounterbalancing is a way to remove confounding factors from an experiment by having slightly different tasks for different groups of participants. This sounds abstract, so let's consider two examples.\n\n[TOC]\n\n### Example 1: Counterbalancing response rule\n\nConsider a lexical-decision experiment in which participants classify words as verbs by pressing 'z' with their left hand, or as nouns by pressing 'm' with their right hand. This design has a problem: If you find that participants respond faster to nouns than to verbs, this could be because nouns are processed faster than verbs, or because participants respond faster with their right hand than with their left hand. You can fix this problem by counterbalancing the response rule.\n\nFor even participant numbers:\n\n- verb \u2192 z\n- noun \u2192 m\n\nFor uneven participant numbers:\n\n- verb \u2192 m\n- noun \u2192 z\n\n### Example 2: Rotating stimulus conditions\n\nConsider a masked-priming experiment in which participants read target words aloud. On each trial, the target word is preceded by one of three types of priming words:\n\n- An unrelated prime, e.g. priming with 'berry' for target 'house'.\n- An ortoghraphically related prime, e.g. priming with 'mouse' for target 'house'\n- A semantically related prime, e.g. priming with 'garden' for target 'house'\n\nTo avoid repetition effects, you only want to show target words only once per participant. Therefore, you create three different sets of target words, one for each prime type. This is a between-word design, which has less statistical power than a within-word design, in which each target word occurs in each condition. (For the same reason that between-subject designs are less powerful than within-subject designs.)\n\nYou can use counterbalancing to change this experiment into a within-word design by 'rotating' the condition in which each word occurs between participants. We have three conditions, and we therefore have three groups of participants:\n\n- Participants 1, 4, 7, etc.\n    - Word A in condition 1\n    - Word B in condition 2\n    - Word C in condition 3\n- Participants 2, 5, 8, etc.\n    - Word A in condition 2\n    - Word B in condition 3\n    - Word C in condition 1\n- Participants 3, 6, 9, etc.\n    - Word A in condition 3\n    - Word B in condition 1\n    - Word C in condition 2\n\n\n## Implementing counterbalancing\n\n\n### Using the subject number\n\nWhen you run an experiment in OpenSesame on the desktop, you are asked for a subject number. When you run an experiment online, a subject number is randomly selected from the list of possible subject numbers that you have specified in the [OSWeb extension](%url:osweb). (This means that for online experiments you cannot ensure that the number of participants is exactly equal for the different conditions that you want to counterbalance, at least not if you rely on the subject number.)\n\nThis subject number is available as the experimental variable `subject_nr`. In  addition, the experimental variable `subject_parity` has the value 'odd' or 'even', depending on whether the subject number is odd or even. Now say that you want to counterbalance the response rule as in Example 1, you could add the following INLINE_SCRIPT to the start of the experiment.\n\n```python\nif subject_parity == 'odd':\n    verb_response = 'z'\n    noun_response = 'm'\nelse:\n    verb_response = 'm'\n    noun_response = 'z'\n```\n\nOr, when creating an OSWeb experiment, add the following INLINE_JAVASCRIPT to the start of the experiment:\n\n```javascript\nif (subject_parity === 'odd') {\n    verb_response = 'z'\n    noun_response = 'm'\n} else {\n    verb_response = 'm'\n    noun_response = 'z'\n}\n```\n\nNow, in your *block_loop*, instead of setting `correct_response` to a fixed value, you set it to a variable: `{verb_response}` or `{noun_response}`. You can take a look at the *lexical-decision task* example to see how this works (Menu -> Tools -> Example experiments).\n\n\n### Using Batch Session Data (JATOS and OSWeb only)\n\nWhen running an OSWeb experiment that is hosted on JATOS, you can make use of [Batch Session Data](https://www.jatos.org/jatos.js-Reference.html#functions-to-access-the-batch-session). This is data that is shared between all experimental sessions that are part of the same worker batch. Therefore, you can use this data to define a list of conditions that should be distributed across participants. At the start of each experimental session, one condition is removed from this list and used for the current session. This is the most sophisticated way to implement counterbalancing for OSWeb experiments that are hosted on JATOS.\n\nYou can download a template experiment here:\n\n- %static:attachments/counterbalancing-osweb-jatos.osexp%\n\nWhen running from JATOS, the experiment retrieves a single condition from the Batch Session Data (see below) and registers this as the experimental variable `condition`. When doing a test run, `condition` is set to a default value specified at the end of *init_condition*.\n\nThe experiment itself should be implemented in the *experiment* SEQUENCE, which in the template contains only the *show_condition* SKETCHPAD (see %FigCounterbalancingOSWebJATOS).\n\n%--\nfigure:\n    source: counterbalancing-osweb-jatos.png\n    id: FigCounterbalancingOSWebJATOS\n    caption: |\n        The overview area of the template experiment for implementing counterbalancing with JATOS Batch Session Data.\n--%\n\nWhen importing the experiment into JATOS, all conditions should be specified in the Batch Session Data as the `pending` list (under Worker & Batch Manager; see %FigBatchSessionData). Each condition from `pending` corresponds to a single experimental session; therefore, if condition `a` should be used for two experimental sessions, then `a` needs to occur twice in the `pending` list. The conditions are used in the order in which they are defined.\n\n%--\nfigure:\n    source: batch-session-data.png\n    id: FigBatchSessionData\n    caption: |\n        The conditions should be specified in the Batch Session Data in JATOS.\n--%\n\nAt the start of an experimental session, a single condition is moved from `pending` to `started`. (When the `pending` list is empty, the participant is informed that he or she can no longer participate in the experiment.) At the end of the experimental session, the condition is appended to the `finished` list.\n\nTo make this more concrete, let's say that you've defined the Batch Session Data as shown in %FigBatchSessionData. Then, four experimental sessions are started, but the second experimental session, with condition `a`, never finishes, for example because the participant closes the browser halfway the experiment. The Batch Session Data will then look as in %FigBatchSessionAfter:\n\n%--\nfigure:\n    source: batch-session-data-after.png\n    id: FigBatchSessionAfter\n    caption: |\n        The Batch Session Data after all conditions have been consumed. One session, with condition `a`, never finished.\n--%\n\nYou can tell from the Batch Session Data that one experimental session started with condition `a` but never finished. To nevertheless collect an experimental session with this condition, you have to manually add a new `a` to the `pending` list and collect a new session.", "url": "https://osdoc.cogsci.nl/4.0/manual/counterbalancing", "title": "Counterbalancing"}
{"content": "# Variables\n\ntitle: Variables\n\n[TOC]\n\n## What is an experimental variable in OpenSesame?\n\nExperimental variables in OpenSesame are those variables that:\n\n- You can refer to in the user interface with the '{variable_name}' syntax.\n- Are available as global variables in a Python INLINE_SCRIPT.\n- Are available as global variables in a JavaScript INLINE_JAVASCRIPT.\n- Contain things like:\n\t- The variables that you have defined in a LOOP item.\n\t- The responses that you have collected.\n\t- Various properties of the experiment.\n\t- Etc.\n\n## The variable inspector\n\nThe variable inspector (`Ctrl+I`) provides an overview of available variables (%FigVariableInspector). When the experiment is not running, this overview is based on a best guess of which variables will become available during the experiment. However, when the experiment is running, the variable inspector shows a live overview of variables and their values. This is useful for debugging your experiment.\n\n%--\nfigure:\n id: FigVariableInspector\n source: variable-inspector.png\n caption: The variable inspector provides an overview of all variables that OpenSesame knows about.\n--%\n\n## Defining variables\n\nThe simplest way to define a variable is through the LOOP item. For example, %FigLoop shows how to define a variable named `gaze_cue`. In this example, *trial_sequence* item is called four times while `gaze_cue` is 'left' and another four times while 'gaze_cue' is 'right'.\n\n%--\nfigure:\n id: FigLoop\n source: defining-variables-in-a-loop.png\n caption: The most common way to define independent variables is using the LOOP table.\n--%\n\n## Built-in variables\n\nThe following variables are always available:\n\n### Experiment variables\n\n|Variable name\t\t\t|Description|\n|-----------------------|-----------|\n|`title`\t\t\t\t|The title of the experiment|\n|`description`\t\t\t|The description of the experiment|\n|`foreground`\t\t\t|The default foreground color. E.g., 'white' or '#FFFFFF'.|\n|`background`\t\t\t|The default background color. E.g., 'black' or '#000000'.|\n|`height`\t\t\t\t|The height-part of the display resolution. E.g., '768'|\n|`width`\t\t\t\t|The width-part of the display resolution. E.g., '1024'|\n|`subject_nr`\t\t\t|The subject number, which is asked when the experiment is started.|\n|`subject_parity`\t\t|Is 'odd' if `subject_nr` is odd and 'even' if `subject_nr` is even. Useful for counterbalancing.|\n|`experiment_path`\t\t|The folder of the current experiment, without the experiment filename itself. If the experiment is unsaved, it has the value `None`.|\n|`pool_folder`\t\t\t|The folder where the contents of the file pool have been extracted to. This is generally a temporary folder.|\n|`logfile`\t\t\t\t|The path to the logfile.|\n\n### Item variables\n\nThere are also variables that keep track of all the items in the experiment.\n\n|Variable name\t\t\t|Description|\n|-----------------------|-----------|\n|`time_[item_name]`\t\t|Contains a timestamp of when the item was last executed. For SKETCHPAD items, this can be used to verify the timing of display presentation.|\n|`count_[item_name]`\t|Is equal the number of times minus one (starting at 0, in other words) that an item has been called. This can, for example, be used as a trial or block counter.|\n\n### Response variables\n\nWhen you use the standard response items, such as the KEYBOARD_RESPONSE and MOUSE_RESPONSE, a number of variables are set based on the participant's response.\n\n|Variable name\t\t\t\t\t|Description|\n|-------------------------------|-----------|\n|`response`\t\t\t\t\t\t|Contains the last response that has been given.|\n|`response_[item_name]`\t\t\t|Contains the last response for a specific response item. This is useful in case there are multiple response items.|\n|`response_time`\t\t\t\t|Contains the interval in milliseconds between the start of the response interval and the last response.|\n|`response_time_[item_name]`\t|Contains the response time for a specific response item.|\n|`correct`\t\t\t\t\t\t|Is set to '1' if the last `response` matches the variable `correct_response`, '0' if not, and 'undefined' if the variable `correct_response` has not been set.|\n|`correct_[item_name]`\t\t\t|As `correct` but for a specifc response item.|\n\n### Feedback variables\n\nFeedback variables maintain a running average of accuracy and response times.\n\n|Variable name\t\t\t\t\t|Description|\n|-------------------------------|-----------|\n|`average_response_time`\t\t|The average response time. This is variable is useful for presenting feedback to the participant.|\n|`avg_rt`\t\t\t\t\t\t|Synonym for `average_response_time`|\n|`accuracy`\t\t\t\t\t\t|The average percentage of correct responses. This is variable is useful for presenting feedback to the participant.|\n|`acc`\t\t\t\t\t\t\t|Synonym for `accuracy`|\n\n\n## Using variables in the user interface\n\nWherever you see a value in the user interface, you can replace that value by a variable using the '{variable name}' notation. For example, if you have defined a variable `soa` in a LOOP item, you can use this variable for the duration of a sketchpad as shown in %FigSketchpad.\n\n%--\nfigure:\n id: FigSketchpad\n source: variable-duration.png\n caption: The duration '{soa}' indicates that the duration of the SKETCHPAD depends on the variable `soa`.\n--%\n\nThis works throughout the user interface. For example, if you have the defined a variable `my_freq`, you can use this variable as the frequency in a SYNTH item, as shown in %FigSynth.\n\n%--\nfigure:\n id: FigSynth\n source: variable-frequency.png\n caption: The frequency '{my_freq}' indicates that the frequency of the SYNTH depends on the variable `my_freq`.\n--%\n\nSometimes, the user interface doesn't let you type in arbitrary text. For example, the elements of a SKETCHPAD are shown visually, and you cannot directly change an X coordinate to a variable. However, you can click on the *Select view \u2192 View script* button on the top right, and edit the script directly.\n\nFor example, you can change the position of a fixation dot from the center:\n\n```text\ndraw fixdot x=0 y=0\n```\n\n\u2026 to a position defined by the variables `xpos` and `ypos`:\n\n```text\ndraw fixdot x={xpos} y={ypos}\n```\n\n\n## Using Python expressions in the user interface\n\nWhen referring to variables using the `{my_var}` notation, you are in fact using a so-called [f-string](https://peps.python.org/pep-0498/), which is a way to embed Python code in strings of text. You can also use f-strings to evaluate arbitrary Python code. For example, you can multiply the variables `width` and `height` and include the result in a SKETCHPAD, like so:\n\n%--\nfigure:\n id: FigFString\n source: fstrings.png\n caption: You can embed Python expressions using f-strings.\n--%\n\nf-strings are Python code, and are therefore only supported on the desktop, but see below for a JavaScript alternative for browser experiments.\n\n\n## Using JavaScript expressions in the user interface\n\nWhen using OSWeb, expressions included between curly braces are interpreted as [template literals](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Template_literals). This is very similar to f-strings in Python, with the important difference that it uses JavaScript.\n\nIn normal JavaScript, expressions inside template literals are prefixed with a `$`, like so: `${expression}`. This is allowed in OpenSesame but not necessary: the prefix is automatically added to improve compatibility between browser and desktop experiments. In most cases, as in the figure below, the exact same expression is valid as a Python f-string on the desktop and a JavaScript template literal in the browser.\n\n\n%--\nfigure:\n id: FigTempalteLiteral\n source: template-literals.png\n caption: You can embed JavaScript expressions using template literals.\n--%\n\n\n## Using variables in Python\n\nIn an INLINE_SCRIPT, experimental variables are available as global variables. For example, if you have defined `example_variable` in a LOOP, then the following will print the value `example_variable` to the debug window:\n\n~~~ .python\nprint(example_variable)\n~~~\n\nYou can set the experimental variable `example_variable` to the value 'some value' as follows:\n\n~~~ .python\nexample_variable = 'some value'\n~~~\n\n\n## Using variables in JavaScript\n\nIn an INLINE_JAVASCRIPT, experimental variables are available as global variables. For example, if you have defined `example_variable` in a LOOP, then the following will print the value `example_variable` to the browser console:\n\n```js\nconsole.log(example_variable)\n```\n\nYou can set the experimental variable `example_variable` to the value 'some value' as follows:\n\n```js\nexample_variable = 'some value'\n```\n\n\n## Using conditional (\"if\") statements\n\nConditional statements, or 'if statements', provide a way to indicate that something should happen only under specific circumstances, such when some variable has a specific value. Conditional statements are regular Python expressions.\n\nThe most commonly used if-statement in OpenSesame is the run-if statement of the SEQUENCE, which allows you to specify the conditions under which a particular element is executed. If you open a SEQUENCE item, you see that every item from the sequence has a 'Run if \u2026'' option. The default value is 'always', which means that the item is always run; but you can also enter a condition here. For example, if you want to show a green fixation dot after a correct response, and a red fixation dot after an incorrect response, you can create a SEQUENCE like the following (this makes use of the fact that a KEYBOARD_RESPONSE item automatically sets the `correct` variable, as discussed above) as shown in %FigRunIf.\n\n*Important:* Run-if statements only apply to the Run phase of items. The Prepare phase is always executed. See also [this page](%link:prepare-run%).\n\n%--\nfigure:\n id: FigRunIf\n source: run-if.png\n caption: |\n  'Run if' statements can be used to indicate that certain items from a SEQUENCE should only be executed under specific circumstances.\n--%\n\nYou can use more complex conditions as well. Let's take a look at a few examples:\n\n```python\ncorrect == 1 and response_time > 2000\ncorrect != 1 or response_time > max_response_time or response_time < min_response_time\n```\n\nThe same principle applies to 'Show if' fields in SKETCHPAD items. For example, if you want to draw a right-upwards-pointing arrow only if the variable `quadrant` has been set to 'upper right', simply type the proper condition in the 'Show if ...' field and draw the arrow, as in %FigShowIf. Make sure that you draw the arrow after you have set the condition.\n\n%--\nfigure:\n id: FigShowIf\n source: show-if.png\n caption: \"'Show if' statements can be used to indicate that certain elements from a SKETCHPAD or FEEDBACK item should only be shown under specific circumstances.\"\n--%\n\nImportant: The moment at which a conditional statement is evaluated may affect how your experiment works. This is related to the prepare-run strategy employed by OpenSesame, which is explained here:\n\n- %link:prepare-run%", "url": "https://osdoc.cogsci.nl/4.0/manual/variables", "title": "Variables"}
{"content": "# Examples\n\ntitle: Examples\n\nExample experiments are included with OpenSesame. A list of curated examples is available through Menu \u2192 Tools \u2192 Example experiments. You can also search for publicly available experiments on the OpenScienceFramework by using 'osexp' as search term.\n\n- <https://osf.io/search/?q=osexp>", "url": "https://osdoc.cogsci.nl/4.0/manual/examples", "title": "Examples"}
{"content": "# Mouse tracking\n\ntitle: Mouse tracking\n\nMousetrap is a third-party plugin, and is not maintained by the OpenSesame team.\n{: .alert .alert-info}\n\n## About\n\nPascal Kieslich and Felix Henninger have developed the [mousetrap plugins](https://github.com/PascalKieslich/mousetrap-os) for OpenSesame [(Kieslich & Henninger, 2017)](https://dx.doi.org/10.3758/s13428-017-0900-z). These plugins allow you to track the movement of the mouse cursor, which has been used to investigate the time course of cognitive processes in many psychological domains [(Freeman, Dale, & Farmer, 2011)](https://dx.doi.org/10.3389/fpsyg.2011.00059).\n\nMousetrap offers two plugins for mouse tracking in OpenSesame that can be included in the experiment via drag-and-drop.\nThe [mousetrap response plugin](https://github.com/PascalKieslich/mousetrap-os/blob/master/plugins/mousetrap_response/mousetrap_response.md) tracks mouse movements while another stimulus (e.g., a sketchpad) is shown, analogous to a keyboard or mouse response item.\nThe [mousetrap form plugin](https://github.com/PascalKieslich/mousetrap-os/blob/master/plugins/mousetrap_form/mousetrap_form.md) allows for tracking of mouse movements in [custom forms](%link:manual/forms/custom%).\nBesides, both plugins also provide Python classes, which can be used in Python inline scripts for maximum customizability.\n\nOnce data have been collected with the plugins, the data can be processed, analyzed and visualized using the [mousetrap R package](http://pascalkieslich.github.io/mousetrap/).\n\n## Installation\n\nInformation about how to install the mousetrap plugin can be found on its [GitHub page](https://github.com/PascalKieslich/mousetrap-os#installation). A number of example experiments that demonstrate the basic features are available in the [examples folder](https://github.com/PascalKieslich/mousetrap-os/tree/master/examples#example-experiments).\n\n\nSee also:\n\n- <https://rapunzel.cogsci.nl/manual/environment/>", "url": "https://osdoc.cogsci.nl/4.0/manual/mousetracking", "title": "Mouse tracking"}
{"content": "# Running experiments online\n\ntitle: Running experiments online\n\n\nThis page has been moved to:\n\n- %link:manual/osweb/workflow%", "url": "https://osdoc.cogsci.nl/4.0/manual/osweb", "title": "Running experiments online"}
{"content": "# Integration with the Open Science Framework\n\ntitle: Integration with the Open Science Framework\n\n[TOC]\n\n## About\n\nThe OpenScienceFramework extension connects OpenSesame to the [Open Science Framework](https://osf.io) (OSF), which is a web platform for sharing, connecting, and streamlining scientific workflows. To use this extension, [you need an OSF account](https://osf.io/login/?sign_up=True).\n\nWith the OpenScienceFramework extension, you can:\n\n- Automatically save your experiment to the OSF\n- Automatically upload data to the OSF\n- Open experiments from the OSF\n- Share your experiment and data with other researchers, by giving them access through the OSF\n\n## Logging in to the OSF\n\nTo log into the OSF:\n\n- Create an account on <https://osf.io>. (You cannot create an account from within OpenSesame.)\n- In OpenSesame, click on the log-in button in the main toolbar, and enter your credentials.\n- Once logged in, you can open the OSF Explorer by clicking on your name where the login button used to be, and selecting *Show explorer*. The explorer will show an overview of all your OSF projects, and all repositories/ cloud services that are linked to your projects.\n\n## Linking an experiment to the OSF\n\nIf you link an experiment to the OSF, each time that you save the experiment in OpenSesame, a new version is also uploaded to the OSF.\n\nTo link an experiment:\n\n- Save the experiment on your computer.\n- Open the OSF explorer and select a folder or repository where you would like your experiment to be stored on the OSF. Right-click on this folder and select *Sync experiment to this folder*. The OSF node to which the experiment is linked will be shown at the top of the explorer.\n- The experiment is then uploaded to the selected location.\n- If you check *Always upload experiment on save*, a new version is automatically saved to OSF on each save; if you don't enable this option, you will be asked every time whether or not you want to do this.\n\nTo unlink an experiment:\n\n- Open the OSF explorer, and click the *Unlink* button next to the *Experiment linked to* link.\n\n## Linking data to the OSF\n\nIf you link data to the OSF, each time that data has been collected (normally after every experimental session), this data is also uploaded to the OSF.\n\nTo link data to the OSF:\n\n- Save the experiment on your computer.\n- Open the OSF explorer, right-click on the folder that you want the data to be uploaded to, and select *Sync data to this folder*. The OSF node that the data is linked to will be shown at the top of the explorer.\n- If you check *Always upload collected data*, data files will be automatically saved to OSF after they have been collected; if you don't enable this option, you will be asked every time whether or not you want to do this.\n\nTo unlink data from the OSF:\n\n- Open the OSF explorer, and click the *Unlink* button next to the *Data stored to* link.\n\n## Opening an experiment stored on the OSF\n\nTo open an experiment from the OSF:\n\n- Open the OSF explorer, and find the experiment.\n- Right-click on the experiment and select *Open experiment*.\n- Save the experiment on your computer.\n\n## Handling non-matching versions\n\nIf you open an experiment on your computer that is linked to the OSF, but differs from the version on the OSF, you will be asked what you want to do:\n\n- Use the version from your computer; or\n- Use the version from the OSF. If you choose to use the version from the OSF, it will be downloaded and overwrite the experiment on your computer.\n\n## Installing the OpenScienceFramework extension\n\nThe OpenScienceFramework extension is installed by default in the Windows package of OpenSesame. If the extension is not installed, you can install it as follows:\n\nFrom PyPi:\n\n~~~\npip install opensesame-extension-osf\n~~~\n\nIn an Anaconda environment\n\n~~~\nconda install -c cogsci opensesame-extension-osf\n~~~\n\nThe source code of the extension is available on GitHub:\n\n- <https://github.com/dschreij/opensesame-extension-osf>\n\nAnd for the `python-qosf` module, which is used by the extension:\n\n- <https://github.com/dschreij/python-qosf>", "url": "https://osdoc.cogsci.nl/4.0/manual/osf", "title": "Integration with the Open Science Framework"}
{"content": "# Installing packages, plugins, and extensions\n\ntitle: Installing packages, plugins, and extensions\n\n\nThis page has moved to:\n\n- <https://rapunzel.cogsci.nl/manual/environment/>", "url": "https://osdoc.cogsci.nl/4.0/manual/environment", "title": "Installing packages, plugins, and extensions"}
{"content": "# Using the interface\n\ntitle: Using the interface\n\nOpenSesame has a powerful graphical interface that consists of several components (%FigInterface).\n\n%--\nfigure:\n id: FigInterface\n source: interface.png\n caption: The OpenSesame user interface.\n--%\n\n\n[TOC]\n\n## Toolbars and menubar\n\n### The menubar\n\nThe menubar (%FigMenubar) is shown at the top of the window, or, on some operating systems, is integrated into the border around the window. The menubar contains general functionality, such as saving and opening experiments, running experiments, etc.\n\n%--\nfigure:\n id: FigMenubar\n source: menubar.png\n caption: The menubar.\n--%\n\n### The main toolbar\n\nThe main toolbar (%FigMainToolbar) is (by default) shown at the top of the window, just below the menubar. The main toolbar contains a selection of the most relevant functionality from the menubar.\n\n%--\nfigure:\n id: FigMainToolbar\n source: main-toolbar.png\n caption: The main toolbar.\n--%\n\n### The item toolbar\n\nThe item toolbar (%FigItemToolbar) is (by default) shown at the left of the window. The item toolbar contains all items, that is, all building blocks of an experiment. You can add items to your experiment by dragging them from the item toolbar into the overview area.\n\n%--\nfigure:\n id: FigItemToolbar\n source: item-toolbar.png\n caption: The item toolbar.\n--%\n\n## The tab area\n\nThe tab area is the central part of the window (%FigTabArea). The tab area is where item controls, documentation, important messages, etc. are shown. The tab area can contain multiple tabs, and functions much like a tabbed web browser.\n\n%--\nfigure:\n id: FigTabArea\n source: tab-area.png\n caption: The tab area.\n--%\n\n## The overview area\n\nThe overview area (%FigOverviewArea) is (by default) shown at the left of the window, to the right of the item toolbar. The overview area shows the structure of your experiment as a tree. You can re-order the items in your experiment by dragging them from one position to another in the overview area.\n\n- Shortcut to hide/ show: `Ctrl+\\`\n\n%--\nfigure:\n id: FigOverviewArea\n source: overview-area.png\n caption: The overview area.\n--%\n\n## The file pool\n\nThe file pool (%FigFilePool) is (by default) shown at the right of the window. It provides an overview of all files that are bundled with the experiment.\n\n- Shortcut to hide/ show: `Ctrl+P`\n\n%--\nfigure:\n id: FigFilePool\n source: file-pool.png\n caption: The file pool.\n--%\n\n## The debug window\n\nThe debug window (%FigDebugWindow) is (by default) shown at the bottom of the window. It provides an [IPython interpreter](https://ipython.org/), and is used as the standard output while an experiment is running. That is, if you use the Python `print()` function, the result will be printed to the debug window.\n\n- Shortcut to hide/ show: `Ctrl+D`\n\n%--\nfigure:\n id: FigDebugWindow\n source: debug-window.png\n caption: The debug window.\n--%\n\n## The variable inspector\n\nThe variable inspector (%FigVariableInspector) is (by default) shown at the right of the window. It provides a list of all variables that are detected in your experiment. When you are running an experiment, the variable inspector also provides a real-time overview of variables and their values.\n\n- Shortcut to hide/ show: `Ctrl+I`\n\n%--\nfigure:\n id: FigVariableInspector\n source: variable-inspector.png\n caption: The variable inspector.\n--%\n\n## Keyboard shortcuts\n\nThe keyboard shortcuts listed below are default values. Many of them can be changed through *Menu \u2192 Tools \u2192 Preferences*.\n\n### General shortcuts\n\nThe following keyboard shortcuts are available everywhere:\n\n- Quick switcher: `Ctrl+Space`\n- Command palette: `Ctrl+Shift+P`\n- New experiment: `Ctrl+N`\n- Open experiment: `Ctrl+O`\n- Save experiment: `Ctrl+S`\n- Save experiment as: `Ctrl+Shift+S`\n- Undo: `Ctrl+Alt+Z`\n- Redo: `Ctrl+Alt+Shift+Z`\n- Run experiment fullscreen: `Ctrl+R`\n- Run experiment in window: `Ctrl+W`\n- Quick-run experiment: `Ctrl+Shift+W`\n- Test experiment in browser: `Alt+Ctrl+W`\n- Show/ hide overview area: `Ctrl+\\`\n- Show/ hide debug window: `Ctrl+D`\n- Show/ hide file pool: `Ctrl+P`\n- Show/ hide variable inspector: `Ctrl+I`\n- Focus overview area: `Ctrl+1`\n- Focus tab area: `Ctrl+2`\n- Focus debug window: `Ctrl+3`\n- Focus file pool: `Ctrl+4`\n- Focus variable inspector: `Ctrl+5`\n\n### Editor shortcuts\n\nThe following keyboard shortcuts are available in editor components, such as the INLINE_SCRIPT:\n\n- (Un)comment selected line(s): `Ctrl+/`\n- Find text: `Ctrl+F`\n- Replace text: `Ctrl+H`\n- Hide find/ replace dialog: `Escape`\n- Duplicate line: `Ctrl+Shift+D`\n- Undo: `Ctrl+Z`\n- Redo: `Ctrl+Shift+Z`\n- Copy: `Ctrl+C`\n- Cut: `Ctrl+X`\n- Paste: `Ctrl+V`\n\n### Tab-area shortcuts\n\nThe following keyboard shortcuts are available in the tab area:\n\n- Next tab: `Ctrl+Tab`\n- Previous tab: `Ctrl+Shift+Tab`\n- Close other tabs: `Ctrl+T`\n- Close all tabs: `Ctrl+Alt+T`\n- Close current tab: `Alt+T`\n\n### Overview-area and sequence shortcuts\n\nThe following keyboard shortcuts are available in the overview area and the SEQUENCE item:\n\n- Context menu: `+`\n- Copy item (unlinked): `Ctrl+C`\n- Copy item (linked): `Ctrl+Shift+C`\n- Paste item: `Ctrl+V`\n- Delete item: `Del`\n- Permanently delete item: `Shift+Del`\n- Rename: `F2`\n- Change run-if statement (if applicable): `F3`", "url": "https://osdoc.cogsci.nl/4.0/manual/interface", "title": "Using the interface"}
{"content": "# Runtime for Android\n\ntitle: Runtime for Android\n\n\n__Important note:__ The OpenSesame runtime for Android is based on software by others that is no longer developed. As a result, we are unable to make sure that the runtime works with recent versions of Android. Windows 10 tablets with Intel processors are a good alternative.\n{: .alert .alert-warning}\n\n\n[TOC]\n\n\n## OpenSesame runtime for Android\n\n### Download\n\nYou can download the OpenSesame runtime for Android through the Google Play Store:\n\n<a href=\"https://play.google.com/store/apps/details?id=nl.cogsci.opensesame\" style=\"border:none;\">\n  <img alt=\"Get it on Google Play\"\n       src=\"https://developer.android.com/images/brand/en_generic_rgb_wo_45.png\" />\n</a>\n\n### Usage\n\nWhen you start the OpenSesame runtime, you will be asked where your experiments are located. By default, OpenSesame assumes that they are in the `/sdcard/` folder, or (if it exists) in the `/sdcard/Experiments/` folder. If you have no experiments on your device, pressing `enter` will show the example experiments that are bundled with the `.apk`.\n\nThe `Back` button serves the same purpose as the `Escape` key on regular systems, and will exit OpenSesame.\n\n### Supported devices\n\nOpenSesame is developed with the Nexus 4 and 9 as reference devices. In general, any device that runs Android 2.2. 'Froyo' or later appears to work.\n\n### Disabling automatic updates\n\nIf you are using the OpenSesame runtime for Android in a production environment (e.g., while you are running an experiment), it is recommended to disable the Auto-update feature of the Google Play Store, at least for OpenSesame. This will prevent the app from being updated and potentially changing its behavior. In case you need to downgrade to a previous version of the Android runtime, you can find the `.apk` files for previous releases [here](https://github.com/smathot/OpenSesame/releases).\n\n### Automatically start an experiment\n\nIf you want to directly launch a specific experiment when the OpenSesame runtime for Android is started, you can create a file called `opensesame-autorun.yml` in the `/sdcard/` folder of your device. This is a YAML file with the following structure:\n\n~~~\nexperiment: /sdcard/experiments/my_experiment.opensesame\nsubject_nr: 3\nlogfile: /sdcard/data/subject03.csv\n~~~\n\n## Developing experiments for Android\n\n### backend\n\nThe OpenSesame runtime for Android requires the *droid* backend.\n\n### Design tips\n\nImplement most user interactions through the MOUSE_RESPONSE item or TOUCH_RESPONSE plugin. In general, screen touches are registered as mouse clicks. Using keyboard input will work as well, but it will show and hide the virtual keyboard after every key that is entered, which looks messy.\n\nThe resolution for the DROID backend is fixed at 1280x800 (landscape). On Android, your experiment will be automatically scaled up or down depending on the resolution of the device, but the resolution that you design with is always 1280x800.\n\n### Debugging\n\nDebug output is written to `/sdcard/opensesame-debug.txt`.\n\n### Limitations\n\n- The SYNTH item and `openexp.synth` module are not functional.\n- The SAMPLER item and `openexp.sampler` module will ignore panning and pitching.\n\n## Know issue: Frozen or misbehaving virtual keyboard\n\nOn some devices, the default virtual keyboard is unresponsive (i.e. it shows but doesn't respond to taps) or doesn't respond normally. This appears to happen on phones with recent versions of Android. To work around this issue, you can install a third-party keyboard. Keyboards that have been reported to work are:\n\n- [GO Keyboard](https://play.google.com/store/apps/details?id=com.jb.emoji.gokeyboard&hl=en)\n- [Smart Keyboard Trial](https://play.google.com/store/apps/details?id=net.cdeguet.smartkeyboardtrial&hl=en)\n\n## Available Python modules\n\nBelow is a list of Python modules that should be available in the OpenSesame runtime for android. (This list is copied from the pgs4a now-defunct website.)\n\n~~~\npygame\npygame.base\npygame.bufferproxy\npygame.colordict\npygame.color\npygame.compat\npygame.constants\npygame.cursors\npygame.display\npygame.draw\npygame.event\npygame.fastevent\npygame.font\npygame.gfxdraw\npygame.imageext\npygame.image\npygame.joystick\npygame.key\npygame.locals\npygame.mask\npygame.mouse\npygame.overlay\npygame.rect\npygame.rwobject\npygame.sprite\npygame.surface\npygame.surflock\npygame.sysfont\npygame.time\npygame.transform\npygame.version\n_abcoll\nabc\naliases\narray\nast\natexit\nbase64\nbisect\nbinascii\ncalendar\ncmath\ncodecs\ncollections\ncompileall\ncontextlib\ncopy\ncopy_reg\ncStringIO\ncPickle\ndatetime\ndifflib\ndis\ndummy_threading\ndummy_thread\nencodings\nencodings.raw_unicode_escape\nencodings.utf_8\nencodings.zlib_codec\nerrno\nfcntl\nfnmatch\nfunctools\n__future__\ngenericpath\ngetopt\nglob\ngzip\nhashlib\nheapq\nhttplib\ninspect\nitertools\nkeyword\nlinecache\nmath\nmd5\nmimetools\nopcode\noptparse\nos\noperator\nparser\npickle\nplatform\nposix\nposixpath\npprint\npy_compile\npwd\nQueue\nrandom\nrepr\nre\nrfc822\nselect\nsets\nshlex\nshutil\nsite\nsocket\nsre_compile\nsre_constants\nsre_parse\nssl\nstat\nStringIO\nstring\nstruct\nsubprocess\nsymbol\nsymtable\nstrop\ntarfile\ntempfile\ntextwrap\n_threading_local\nthreading\ntime\ntokenize\ntoken\ntraceback\ntypes\nurllib\nurllib2\nurlparse\nUserDict\nwarnings\nweakref\nwebbrowser\nzipfile\nzipimport\nzlib\n~~~\n\n[google-play]: https://play.google.com/store/apps/details?id=nl.cogsci.opensesame\n[forum]: http://forum.cogsci.nl/index.php?p=/discussion/333/a-video-of-opensesame-running-natively-on-android\n[droid]: /backends/droid\n[pgs4a]: http://pygame.renpy.org/", "url": "https://osdoc.cogsci.nl/4.0/manual/android", "title": "Runtime for Android"}
{"content": "# OpenSesameRun (no GUI)\n\ntitle: OpenSesameRun (no GUI)\n\n## About\n\n`opensesamerun` is a simple tool that allows you to execute OpenSesame experiments with a minimal GUI, or directly, by specifying all necessary options via the command line. A minimal GUI will automatically appear if not all command line options have been specified, notably the experiment file, the subject number, and the log file.\n\n~~~\nUsage: opensesamerun [experiment] [options]\n\nOptions:\n  --version             show program's version number and exit\n  -h, --help            show this help message and exit\n\n  Subject and log file options:\n    -s SUBJECT, --subject=SUBJECT\n                        Subject number\n    -l LOGFILE, --logfile=LOGFILE\n                        Logfile\n\n  Display options:\n    -f, --fullscreen    Run fullscreen\n    -c, --custom_resolution\n                        Do not use the display resolution specified in the\n                        experiment file\n    -w WIDTH, --width=WIDTH\n                        Display width\n    -e HEIGHT, --height=HEIGHT\n                        Display height\n\n  Miscellaneous options:\n    -d, --debug         Print lots of debugging messages to the standard\n                        output\n    --stack             Print stack information\n\n  Miscellaneous options:\n    --pylink            Load PyLink before PyGame (necessary for using the\n                        Eyelink plug-ins in non-dummy mode)\n~~~\n\n## Example\n\nLet's say that you want to run the gaze cuing example experiment, for subject #1, and save the log file in your Documents folder (this example assumes Linux, but it works analogously on other platforms):\n\n~~~\nopensesamerun /usr/share/opensesame/examples/gaze_cuing.opensesame.tar.gz -s 1 -l /home/sebastiaan/Documents/subject1.tsv -f \n~~~\n\n\n## Alternative `libopensesame`\n\nYou can also start experiments without using the GUI through the `libopensesame` Python module:\n\n- %link:manual/python/nogui%", "url": "https://osdoc.cogsci.nl/4.0/manual/opensesamerun", "title": "OpenSesameRun (no GUI)"}
{"content": "# Debugging\n\ntitle: Debugging\n\nWhile designing a new experiment, you will inevitably encounter bugs. Bugs can manifest as crashes accompanied by error messages, or as unexpected behaviors without any explicit error message.\n\nDebugging, the art and skill of diagnosing and rectifying these errors and unanticipated behaviors, is a critical part of the experimental design process.\n\n\n[TOC]\n\n\n## Debugging in the user interface\n\n### Using the variable inspector\n\nThe Variable Inspector in OpenSesame provides an overview of all variables that are currently active within your experiment. This includes:\n\n- Variables explicitly defined in the user interface, typically in a LOOP item.\n- Response variables, which are set by various response items such as a KEYBOARD_RESPONSE item.\n- Variables that are defined using Python INLINE_SCRIPT items.\n\nWhen an experiment is running, the Variable Inspector dynamically updates, providing a live overview of variables and their values. This feature allows you to monitor the behavior of your experiment in real-time, assisting you in identifying any potential issues or bugs.\n\nFor example, consider a situation where you have defined a variable `left_letter` to define which letter should appearing on the left side of a SKETCHPAD. However, during execution, you notice a mismatch in the Variable Inspector: `left_letter` is actually being shown on the right side of your display. This is indicates a bug such that you have misplaced the right and left letters on the SKETCHPAD.\n\n%--\nfigure:\n id: FigVariableInspector\n source: variable-inspector.png\n caption: You can use the variable inspector to check whether your experiment behaves as it should. In this example, there is a bug such that the letter that is defined through the variable `left_letter` actually appears on the right and vice versa.\n--%\n\nUsing the Variable Inspector regularly to monitor variables helps ensure that your experiment is behaving as expected and aids in identifying problems early on.\n\n\n### Printing debug messages to the IPython/ Jupyter console\n\nThe Python `print()` function is a simple-yet-powerful debugging tool when used inside INLINE_SCRIPT items, and serves a similar purpose to the Variable Inspector. For instance, you can print the values of the variables `left_letter` and `right_letter` during the Prepare phase of an INLINE_SCRIPT at the beginning of each trial.\n\nTo view these debug messages, open the Jupyter/ IPython console and monitor the output while running the experiment. By doing so, you can verify whether the output displayed in the console aligns with the experiment's actual behavior.\n\n%--\nfigure:\n id: FigPrintingOutput\n source: printing-output.png\n caption: The Python `print()` function can be used to output debug messages to the console.\n--%\n\nIn the above example, it becomes evident that the letter assigned to the `left_letter` variable (hence expected to appear on the left) is actually appearing on the right, and vice versa.\n\n\n### Interpreting user-interface error messages\n\nWhen a bug in your experiment causes a crash, OpenSesame displays an error message, also referred to as an 'Exception'. An error message typically consists of the following components:\n\n- **Error type:** Indicates the general class of error. In the example below this is an `FStringError`.\n- **Description:** Provides a more specific explanation of what triggered the error. In this case, 'Failed to evaluate \u2026'.\n- **Source:** Specifies the item that triggered the error and whether it occurred during the Run or Prepare phase.\n- **Traceback:** A detailed Python error message. This information is only shown if the error occurred while evaluating custom Python code, which includes INLINE_SCRIPT items, but also conditional expressions (e.g. run-if expressions), and text with embedded variable references.\n- **Learn more about this error:** An interactive button you can click to get more detailed information about the error message.\n\nLet's look at an example to better understand these components and learn how to fix a common error:\n\n%--\nfigure:\n id: FigFStringError\n source: fstring-error.png\n caption: An `FStringError` indicates an issue when trying to evaluate a text string containing a Python expression.\n--%\n\nThis is an `FStringError`, which means there was an issue while interpreting a text string that includes a Python expression. In this example, the problematic text is `{right_leter}`. Anything enclosed within curly braces is interpreted as a Python expression, and therefore in this case the Python expression is `right_leter`\u2014which is simply a variable name. Trying to evaluate the Python expression `right_leter` triggered a `NameError` because `right_leter` is not defined.\n\nThat's pretty technical, but what exactly went wrong here in simple terms? The issue arises from referring to a non-existent variable: `right_leter`. Looking at the variable name, it seems likely that there's a typo: the intended variable is likely `right_letter`, with a double 't'.\n\nWhere should we correct this mistake? The error message indicates that the source of the error is an item called *target*, which is a SKETCHPAD. To resolve the error, we need to open *target* and change the text from '{right_leter}' to '{right_letter}'. \n\n\n### Interpreting Python error messages\n\nIn Python, errors fall into two categories: syntax errors and exceptions (or runtime errors).\n\n\n#### Python syntax errors\n\nA syntax error occurs when the Python interpreter cannot parse code because it violates Python's syntax rules. This could be due to mismatched parentheses, missing commas, incorrect indentation, and so on. In OpenSesame, this results in a `PythonSyntaxError`.\n\n%--\nfigure:\n id: FigPythonSyntaxError\n source: python-syntax-error.png\n caption: A `PythonSyntaxError` is triggered when the code violates Python's syntax rules and cannot be parsed.\n--%\n\nThe error message above indicates that a syntax error has occurred on line 16 of the Prepare phase of an item named *constants*. Here's the problematic line:\n\n```python\ntarget_orientations = [('z', 0), ('/', 90]\n```\n\nThe message also hints at mismatched parentheses as the potential source of the error. Taking that into consideration, we can fix the issue by adding a missing parenthesis `)` before the closing bracket `]`:\n\n```python\ntarget_orientations = [('z', 0), ('/', 90)]\n```\n\n\n#### Python Exceptions\n\nWhen Python code is syntactically correct but encounters a problem during execution, an exception is raised. In OpenSesame, such exceptions result in a `PythonError`.\n\n%--\nfigure:\n id: FigPythonError\n source: python-error.png\n caption: A `PythonError` is triggered when an exception is raised during the execution of syntactically correct Python code.\n--%\n\nThe error message above indicates that a `NameError` was raised on line 2 of the Run phase of an item named *trial_script*. Specifically, the identifier 'clock_sleep' is not recognized. Looking at the error-causing line, it's apparent that we've used an underscore (`_`) instead of a dot (`.`), incorrectly implying that `clock_sleep()` is a function.\n\n```python\nclock_sleep(495)\n```\n\nTo rectify this, we should correctly reference the `sleep()` function as part of the `clock` object:\n\n```python\nclock.sleep(495)\n```\n\n## Debugging in a web browser (OSWeb)\n\n\n### Printing output to the browser console\n\nThe JavaScript `console.log()` function is a simple-yet-powerful debugging tool when used inside INLINE_JAVASCRIPT items. It serves a similar purpose to the Python `print()` function and the Variable Inspector, neither of which are available in OSWeb. For instance, you can print the values of the variables `left_letter` and `right_letter` during the Prepare phase of an INLINE_SCRIPT at the beginning of each trial.\n\nTo view these debug messages, you need to open the browser console. Here's how to do it in Chrome, Firefox, and Edge:\n\n- **Google Chrome:** Press Ctrl + Shift + J (Windows / Linux) or Cmd + Option + J (Mac).\n- **Mozilla Firefox:** Press Ctrl + Shift + K (Windows / Linux) or Cmd + Option + K (Mac).\n- **Microsoft Edge:** Press F12 to open the developer tools, then select the \"Console\" tab.\n\nOnce the console is open, you can monitor the output while running the experiment, allowing you to check whether the output displayed in the console aligns with the experiment's actual behavior.\n\n%--\nfigure:\n id: FigPrintingOutputOSWeb\n source: printing-output-osweb.png\n caption: The JavaScript `console.log()` function can be used to output debug messages to the browser console.\n--%\n\nIn the above example, it becomes evident that the letter assigned to the `left_letter` variable (which should appear on the left) is actually appearing on the right, and vice versa.\n\n\n### Understanding error messages\n\nWhen your browser-based experiment crashes, OSWeb will show an error message in the browser. An error message typically consists of the following components:\n\n- **Error type:** Indicates the general class of error. In this example below this is a `ReferenceError`.\n- **Description:** Provides a more specific explanation of what triggered the error. In this case, 'right_leter is not defined'.\n- **Source:** Specifies the item that triggered the error and whether it occurred during the Run or Prepare phase.\n- **Source script:** The JavaScript code that caused the error. This information is only shown if the error occurred while evaluating custom JavaScript, which includes INLINE_JAVASCRIPT items, but also conditional expressions (e.g. run-if expressions), and text with embedded variable references.\n\nLet's look at an example to better understand these components and learn how to fix a common error:\n\n%--\nfigure:\n id: FigOSWebError\n source: osweb-error.png\n caption: A `ReferenceError` indicates a reference to a non-existent variable or other non-existent object.\n--%\n\nThis is a `ReferenceError`, which indicates that the experiment refers to a non-existent variable or other non-existent object. In this example, the error arose from the text `${right_leter}`. Anything enclosed within curly braces and prefixed by a `$` is interpreted as JavaScript expression, and in this case, the JavaScript expression is `right_leter`\u2014which is simply a variable name. Trying to evaluate the JavaScript expression `right_leter` triggered a `ReferenceError` because `right_leter` is not defined.\n\nThat's pretty technical, but what exactly went wrong here in simple terms? The issue arises from referring to a non-existent variable: `right_leter`. Looking at the variable name, it seems likely that there's a typographical error: the intended variable is likely `right_letter`, with a double 't'.\n\nWhere should we correct this mistake? The error message indicates that the source of the error is an item called *target*, which is a SKETCHPAD. To resolve the error, we need to open *target* and change the text from '{right_leter}' to '{right_letter}'. \n\n\n### Using the `debugger` statement in INLINE_JAVASCRIPT items\n\nThe JavaScript `debugger` statement is a powerful tool for debugging `INLINE_JAVASCRIPT` items in OpenSesame/OSWeb experiments. It allows you to insert breakpoints in your code, causing the browser's JavaScript execution to pause at that point. This allows you to inspect the current state of the JavaScript workspace.\n\nUsing the `debugger` statement is straightforward. Simply insert the statement `debugger` on the line where you want to pause execution. For example:\n\n```javascript\nconsole.log(`left_letter = ${left_letter}`)\nconsole.log(`right_letter = ${right_letter}`)\ndebugger // Execution will pause here\n```\n\nOnce you've inserted the `debugger` statement into your code, you need to open the browser console as explained above. After you open the browser console, run your experiment. When the JavaScript interpreter reaches the `debugger` statement, it will pause execution, and the developer tools will switch to the \"Sources\" (Chrome/Edge) or \"Debugger\" (Firefox) tab, highlighting the breakpoint line.\n\n%--\nfigure:\n id: FigJavaScriptDebugger\n source: javascript-debugger.png\n caption: When the JavaScript interpreter reaches the `debugger` statement, it will pause execution and allow you to inspect the JavaScript workspace. The `debugger` statement only works when the browser console is open.\n--%\n\nWhile execution is paused, you can inspect variable values, step through the code line by line, and investigate the call stack to better understand the state of your program at the breakpoint.\n\nRemember to remove or comment out the `debugger` statements when you're finished debugging, as leaving them in can interfere with the normal operation of your experiment.\n\n\n## Handling ExperimentProcessDied errors\n\nOccasionally, you might encounter an `ExperimentProcessDied` error during an experiment.\n\n%--\nfigure:\n id: FigExperimentProcessDied\n source: experiment-process-died.png\n caption: The `ExperimentProcessDied` error generally indicates an issue with the underlying Python process or associated libraries, not your experiment's code.\n--%\n\nThis error implies that the Python process in which the experiment was running terminated unexpectedly. It typically doesn't indicate a bug in your experiment, but rather suggests a problem in one of the low-level libraries used by OpenSesame, or even a bug in Python itself.\n\nDetermining the exact cause of this error can be challenging, and fixing it may be even more so. However, there are a few workarounds you can try to mitigate the issue:\n\n- **Change the backend:** Select a different backend under 'Run Experiment' in the experiment properties. This might resolve the issue as different backends use different sets of low-level libraries.\n- **Update OpenSesame and relevant packages:** Regularly updating OpenSesame and all associated packages can potentially resolve this issue, as bugs are routinely fixed in new versions.", "url": "https://osdoc.cogsci.nl/4.0/manual/debugging", "title": "Debugging"}
{"content": "# Logging and reading data files\n\ntitle: Logging and reading data files\n\nAlways triple check whether your data has been logged correctly before running your experiment!\n{: .page-notification}\n\n[TOC]\n\n\n## Using the logger item\n\nOpenSesame will not log your data automatically. Instead, you need to insert a LOGGER item, typically at the end of your trial sequence.\n\n%--\nfigure:\n id: FigLogger\n source: logger.png\n caption: |\n  The LOGGER item.\n--%\n\nThe simplest way to use the LOGGER is by leaving the option 'Automatically log all variables' enabled. That way, all variables that OpenSesame knows about are written the log file, except for those that are explicitly excluded (see below).\n\nYou can explicitly *include* which variables you want to log. The main reason for doing so is when you find that some variables are missing (because OpenSesame did not automatically detect them), or if you have disabled the option 'Automatically log all variables', \n\nYou can also explicitly exclude certain variables from the log file. The main reason for doing so is to keep the log files clean by excluding variables that are generally not useful.\n\nIn general, you should create only one logger item, and reuse that LOGGER at different locations in your experiment if necessary (i.e. use linked copies of the same LOGGER item). If you create multiple LOGGERs (rather than using a single LOGGER multiple times), they will all write to the same log file, and the result will be a mess!\n\n## Using Python inline script\n\nYou can write to the log file using the `log` object:\n\n~~~ .python\nlog.write('This will be written to the log file!')\n~~~\n\nFor more information, see:\n\n- %link:log%\n\nYou should generally not write to the log file directly and use a LOGGER item at the same time; doing so will result in messy log files.\n\n## Format of the data files\n\nIf you have used the standard LOGGER item, data files are in the following format format (simply standard csv):\n\n- plain-text\n- comma-separated\n- double-quoted (literal double-quotes are escaped with backward slashes)\n- unix-style line endings\n- UTF-8 encoded\n- column names on the first row\n\n## Which variables are logged?\n\nBy default, variables that are defined in the user interface, such as columns in a `loop` table or response variables are always logged.\n\nBy default, variables that are defined in an `inline_script` or `inline_javascript` are logged if they are numbers (`int` and `float`), strings (`str` and `bytes`), and `None` values. This is to avoid log files from becoming unreasonably large due to logging of long lists and other large values. (As of OpenSesame 4.0, there is no longer a need to use the `var` (Python) or `vars` (JavaScript) object.)\n\nIf you want to explicitly log a variable that is not logged by default, you can use the 'Include' field in the LOGGER item.\n\n\n## Reading and processing data files\n\n### In Python with pandas or DataMatrix\n\nIn Python, you can use [pandas](http://pandas.pydata.org/) to read csv files.\n\n```python\nimport pandas\ndf = pandas.read_csv('subject-1.csv')\nprint(df)\n```\n\nOr [DataMatrix](https://datamatrix.cogsci.nl/):\n\n```python\nfrom datamatrix import io\ndm = io.readtxt('subject-1.csv')\nprint(dm)\n```\n\n### In R\n\nIn R, you can simply use the `read.csv()` function to read a single data file.\n\n~~~ .R\ndf = read.csv('subject-1.csv', encoding = 'UTF-8')\nhead(df)\n~~~\n\nIn addition, you can use the `read_opensesame()` function from the [readbulk](https://github.com/pascalkieslich/readbulk) package to easily read and merge multiple data files into one large data frame. The package is available on CRAN and can be installed via `install.packages('readbulk')`.\n\n~~~ .R\n# Read and merge all data files stored in the folder 'raw_data'\nlibrary(readbulk)\ndf = read_opensesame('raw_data')\n~~~\n\n### In JASP\n\n[JASP](http://jasp-stats.org/), an open-source statistics package, opens csv files straight away.\n\n### In LibreOffice Calc\n\nIf you open a csv file in LibreOffice Calc, you have to indicate the exact data format, as indicated in %FigLibreOffice. (The default settings are often correct.)\n\n%--\nfigure:\n source: libreoffice.png\n id: FigLibreOffice\n--%\n\n### In Microsoft Excel\n\nIn Microsoft Excel, you need to use the Text Import Wizard.\n\n### Merging multiple data files into one large file\n\nFor some purposes, such as using pivot tables, it may be convenient to merge all data files into one large file. With Python DataMatrix, you can do this with the following script:\n\n```python\nimport os\nfrom datamatrix import DataMatrix, io, operations as ops\n\n# Change this to the folder that contains the .csv files\nSRC_FOLDER = 'student_data'\n# Change this to a list of column names that you want to keep\nCOLUMNS_TO_KEEP = [\n    'RT_search',\n    'load',\n    'memory_resp'\n]\n\n\ndm = DataMatrix()\nfor basename in os.listdir(SRC_FOLDER):\n    path = os.path.join(SRC_FOLDER, basename)\n    print('Reading {}'.format(path))\n    dm <<= ops.keep_only(io.readtxt(path), *COLUMNS_TO_KEEP)\nio.writetxt(dm, 'merged-data.csv')\n```\n\n\n## Logging in OSWeb\n\nWhen you run an experiment in a browser with OSWeb, logging works differently from when you run an experiment on the desktop.\n\nSpecifically, when you launch an OSWeb experiment directly from within OpenSesame, the log file is downloaded at the end of the experiment. This log file is in `.json` format. When you launch an OSWeb experiment from JATOS, there is no log file as such, but rather all data is sent to JATOS from where it can be downloaded.\n\nSee also:\n\n- %link:manual/osweb/workflow%\n\n\n\n[libreoffice]: http://www.libreoffice.org/\n[openoffice]: http://www.openoffice.org/\n[gnumeric]: http://projects.gnome.org/gnumeric/\n[log-func]: /python/inline-script/#inline_script.log\n[codecs]: http://docs.python.org/2/library/codecs.html\n[ppa]: https://launchpad.net/~smathot/+archive/cogscinl/", "url": "https://osdoc.cogsci.nl/4.0/manual/logging", "title": "Logging and reading data files"}
{"content": "# Timing\n\ntitle: Timing\nreviewed: false\n\nThis page describes various issues related to timing, and provides benchmark results and tips for testing your own system. If you experience problems with timing, please take the time to read this page. Many issues are resolved by taking into account things such as stimulus preparation and the properties of your monitor.\n\n[TOC]\n\n## Is OpenSesame capable of millisecond precision timing?\n\nThe short answer is: yes. The long answer is the rest of this page.\n\n\n## Important considerations for time-critical experiments\n\n### Check your timing!\n\nOpenSesame allows you to control your experimental timing very accurately. But this does not guarantee accurate timing in every specific experiment! For any number of reasons, many of which are described on this page, you may experience issues with timing. Therefore, in time-critical experiments you should always check whether the timing in your experiment is as intended. The easiest way to do this is by checking the display timestamps reported by OpenSesame.\n\nEvery SKETCHPAD item has a variable called `time_[sketchpad name]` that contains the timestamp of the last time that the SKETCHPAD was shown. Therefore, if you want the SKETCHPAD *target* to be shown for 100 ms, followed by the SKETCHPAD *mask*, you should verify that `time_mask` - `time_target` is indeed 100. When using Python inline code, you can make use of the fact that `canvas.show()` returns the display timestamp.\n\n\n### Understanding your monitor\n\nComputer monitors refresh periodically. For example, if the refresh rate of your monitor is 100 Hz, the display is refreshed every 10 ms (1000 ms / 100 Hz). This means that a visual stimulus is always presented for a duration that is a multiple of 10 ms, and you will not be able to present a stimulus for, say, 5 or 37 ms. The most common refresh rate is 60 Hz (= 16.67 ms refresh cycle), although monitors with much higher refresh rates are sometimes used for experimental systems.\n\nIn %VidRefresh you can see what a monitor refresh looks like in slow motion. On CRT monitors (i.e. non-flatscreen, center) the refresh is a single pixel that traces across the monitor from left to right and top to bottom. Therefore, only one pixel is lighted at a time, which is why CRT monitors flicker slightly. On LCD or TFT monitors (flatscreen, left and right) the refresh is a 'flood fill' from top to bottom. Therefore, LCD and TFT monitors do not flicker. (Unless you present a flickering stimulus, of course.)\n\n%--\nvideo:\n id: VidRefresh\n source: vimeo\n videoid: 24216910\n width: 640\n height: 240\n caption: A slow-motion video of the refresh cycle on CRT (center) and LCD/ TFT monitors. Video courtesy of Jarik den Hartog and the VU University Amsterdam technical support staff.\n--%\n\nIf a new stimulus display is presented while the refresh cycle is halfway, you will observe 'tearing'. That is, the upper half of the monitor will show the old display, while the lower part will show the new display. This is generally considered undesirable, and therefore a new display should be presented at the exact moment that the refresh cycle starts from the top. This is called 'synchronization to the vertical refresh' or simply 'v-sync'. When v-sync is enabled, tearing is no longer visible, because the tear coincides with the upper edge of the monitor. However, v-sync does not change anything about the fact that a monitor does not refresh instantaneously and will therefore always, for some time, show both the old and the new display.\n\nAnother important concept is that of 'blocking on the vertical retrace' or the 'blocking flip'. Usually, when you send a command to show a new display, the computer will accept this command right away and put the to-be-shown display in a queue. However, the display may not actually appear on the monitor until some time later, typically until the start of the next refresh cycle (assuming that v-sync is enabled). Therefore, you don't know exactly when the display has appeared, because your timestamp reflects the moment that the display was queued, rather than the moment that it was presented. To get around this issue, you can use a so-called 'blocking flip'. This basically means that when you send a command to show a new display, the computer will freeze until the display actually appears. This allows you to get very accurate display timestamps, at the cost of a significant performance hit due to the computer being frozen for much of the time while it is waiting for a display to be shown. But for the purpose of experiments, a blocking flip is generally considered the optimal strategy.\n\nFinally, LCD monitors may suffer from 'input lag'. This means that there is an additional and sometimes variable delay between the moment that the computer 'thinks' that a display appears, and the moment that the display actually appears. This delay results from various forms of digital processing that are performed by the monitor, such as color correction or image smoothing. As far as I know, input lag is not something that can be resolved programmatically, and you should avoid monitors with significant input lag for time-critical experiments. \n\nFor a related discussion, see:\n\n- <http://docs.expyriment.org/Timing.html#visual>\n\n\n### Making the refresh deadline\n\nImagine that you arrive at a train station at 10:30. Your train leaves at 11:00, which gives you exactly 30 minutes to get a cup of coffee. However, if you have coffee for exactly 30 minutes, then you will arrive back at the platform just in time to see your train depart, and you will have to wait for the next train. Therefore, if you have 30 minutes waiting time, you should have a coffee for slightly less than 30 minutes, such as 25 minutes.\n\nThe situation is analogous when specifying intervals for visual-stimulus presentation. Let's say that you have a 100 Hz monitor (so 1 refresh every 10 ms) and want to present a target stimulus for 100 ms, followed by a mask. Your first inclination might be to specify an interval of 100 ms between the target and the mask, because that's after all what you want. However, specifying an interval of exactly 100 ms will likely cause the mask to 'miss the refresh deadline', and the mask will be presented only on the next refresh cycle, which is 10 ms later (assuming that v-sync is enabled). So if you specify an interval of 100 ms, you will in most cases end up with an interval of 110 ms!\n\nThe solution is simple: You should specify an interval that is slightly shorter than what you are aiming for, such as 95 ms. Don't worry about the interval being too short, because on a 100 Hz monitor the interval between two stimulus displays is necessarily a multiple of 10 ms. Therefore, 95 ms will become 100 ms (10 frames), 1 ms will become 10 ms (1 frame), etc. Phrased differently, intervals will be rounded up (and never rounded down!) to the nearest interval that is consistent with your monitor's refresh rate.\n\n\n### Disabling desktop effects\n\nMany modern operating systems make use of graphical desktop effects. These provide, for example, the transparency effects and the smooth window minimization and maximization effects that you see on most modern operating systems. Although the software that underlies these effects differs from system to system, they generally form an additional layer between your application and the display. This additional layer may prevent OpenSesame from synchronizing to the vertical refresh and/ or from implementing a blocking flip.\n\nAlthough desktop effects *may* cause problems, they usually don't. This appears to vary from system to system and from video card to video card. Nevertheless, when the operating systems allows it, it's best to disable desktop effects on systems that are used for experimental testing.\n\nSome tips regarding desktop effects for the various operating systems:\n\n- Under *Windows XP* there are no desktop effects at all.\n- Under *Windows 7* desktop effects can be disabled by selecting any of the themes listed under 'Basic and High Contrast Themes' in the 'Personalization' section.\n- Under *Windows 10* there is no way to completely disable desktop effects.\n- Under *Ubuntu and other Linux distributions using Gnome 3* there is no way to completely disable desktop effects.\n- Under *Linux distributions using KDE* you can disable desktop effects in the 'Desktop Effects' section of the System Settings.\n- Under *Mac OS* there is apparently no way to completely disable desktop effects.\n\n\n### Taking into account stimulus-preparation time/ the prepare-run structure\n\nIf you care about accurate timing during visual-stimulus presentation, you should prepare your stimuli in advance. That way, you will not get any unpredictable delays due to stimulus preparation during the time-critical parts of your experiment.\n\nLet's first consider a script (you can paste this into an INLINE_SCRIPT item) that includes stimulus-preparation time in the interval between `canvas1` and `canvas2` (%LstStimPrepBad). The interval that is specified is 95 ms, so--taking into account the 'rounding up' rule described in [Making the refresh deadline]--you would expect an interval of 100 ms on my 60 Hz monitor. However, on my test system the script below results in an interval of 150 ms, which corresponds to 9 frames on a 60 Hz monitor. This is an unexpected delay of 50 ms, or 3 frames, due to the preparation of `canvas2`.\n\n%--\ncode:\n id: LstStimPrepBad\n syntax: python\n source: stimulus-preparation-bad.py\n caption: \"In this script, the duration between `canvas1` and `canvas2` is confounded by stimulus-preparation time.\"\n--%\n\nNow let's consider a simple variation of the script above (%LstStimPrepGood). This time, we first prepare both `canvas1` and `canvas2` and only afterwards present them. On my test system, this results in a consistent 100 ms interval, just as it should!\n\n%--\ncode:\n id: LstStimPrepGood\n syntax: python\n source: stimulus-preparation-good.py\n caption: \"In this script, the duration between `canvas1` and `canvas2` is not confounded by stimulus-preparation time.\"\n--%\n\nWhen using the graphical interface, the same considerations apply, but OpenSesame helps you by automatically handling most of the stimulus preparation in advance. However, you have to take into account that this preparation occurs at the level of SEQUENCE items, and not at the level of LOOP items. Practically speaking, this means that the timing *within* a SEQUENCE is not confounded by stimulus-preparation time. But the timing *between* SEQUENCEs is.\n\nTo make this more concrete, let's consider the structure shown below (%FigStimPrepBad). Suppose that the duration of the SKETCHPAD item is set to 95 ms, thus aiming for a 100 ms duration, or 6 frames on a 60 Hz monitor. On my test system the actual duration is 133 ms, or 8 frames, because the timing is confounded by preparation of the SKETCHPAD item, which occurs each time that that the sequence is executed. So this is an example of how you should *not* implement time-critical parts of your experiment.\n\n%--\nfigure:\n id: FigStimPrepBad\n source: stimulus-preparation-incorrect.png\n caption: \"An example of an experimental structure in which the timing between successive presentations of SKETCHPAD is confounded by stimulus-preparation time. The sequence of events in this case is as follows: prepare SKETCHPAD (2 frames), show SKETCHPAD (6 frames), prepare SKETCHPAD (2 frames), show SKETCHPAD (6 frames), etc.\"\n--%\n\nNow let's consider the structure shown below (%FigStimPrepGood). Suppose that the duration of `sketchpad1` is set to 95 ms, thus aiming for a 100 ms interval between `sketchpad1` and `sketchpad2`. In this case, both items are shown as part of the same SEQUENCE and the timing will not be confounded by stimulus-preparation time. On my test system the actual interval between `sketchpad1` and `sketchpad2` is therefore indeed 100 ms, or 6 frames on a 60 Hz monitor.\n\nNote that this only applies to the interval between `sketchpad1` and `sketchpad2`, because they are executed in that order as part of the same sequence. The interval between `sketchpad2` on run *i* and `sketchpad1` on run *i+1* is again confounded by stimulus-preparation time.\n\n%--\nfigure:\n id: FigStimPrepGood\n source: stimulus-preparation-correct.png\n caption: \"An example of an experimental structure in which the timing between the presentation of `sketchpad1` and `sketchpad2` is not confounded by stimulus-preparation time. The sequence of events in this case is as follows: prepare `sketchpad1` (2 frames), prepare `sketchpad2` (2 frames), show `sketchpad1` (6 frames), show `sketchpad2` (6 frames), prepare `sketchpad1` (2 frames), prepare `sketchpad2` (2 frames), show `sketchpad1` (6 frames), show `sketchpad2` (6 frames), etc.\"\n--%\n\nFor more information, see:\n\n- [usage/prepare-run]\n\n### Differences between backends\n\nOpenSesame is not tied to one specific way of controlling the display, system timer, etc. Therefore, OpenSesame *per se* does not have specific timing properties, because these depend on the backend that is used. The performance characteristics of the various backends are not perfectly correlated: It is possible that on some system the [psycho] backend works best, whereas on another system the [xpyriment] backend works best. Therefore, one of the great things about OpenSesame is that you can choose which backend works best for you!\n\nIn general, the [xpyriment] and [psycho] backends are preferable for time-critical experiments, because they use a blocking flip. On the other hand, the [legacy] backend is slightly more stable and also considerably faster when using [forms].\n\nUnder normal circumstances the three current OpenSesame backends have the properties shown in %TblBackendInfo.\n\n%--\ntable:\n id: TblBackendInfo\n source: backend-info.csv\n caption: backend properties.\n--%\n\nSee also:\n\n- [backends]\n\n## Benchmark results and tips for testing your own system\n\n### Checking whether v-sync is enabled\n\nAs described in [Understanding your monitor], the presentation of a new display should ideally coincide with the start of a new refresh cycle (i.e. 'v-sync'). You can test whether this is the case by presenting displays of different colors in rapid alternation. If v-sync is not enabled you will clearly observe horizontal lines running across the monitor (i.e. 'tearing'). To perform this test, run an experiment with the following script in an INLINE_SCRIPT item (%LstVSync):\n\n%--\ncode:\n id: LstVSync\n syntax: python\n source: v-sync-check.py\n caption: A script that presents yellow and blue displays in rapid alternation. A lack of synchronization with the vertical refresh can be observed as horizontal lines running through the monitor.\n--%\n\n### Testing precision and accuracy of timing\n\nTiming is precise or consistent when you can present visual stimuli over and over again with the same timing. Timestamps are accurate when they accurately reflect when visual stimuli appear on the monitor. The script below shows how you can check precision and accuracy of timing. This test can be performed both with and without an external photodiode, although the use of a photodiode provides extra verification.\n\nTo keep things simple, let's assume that your monitor is running at 100 Hz, which means that a single frame takes 10 ms. The script then presents a white canvas for 1 frame (10 ms). Next, the script presents a black canvas for 9 frames (90 ms). Note that we have specified a duration of 85, which is rounded up as explained under [Making the refresh deadline]. Therefore, we expect that the interval between the onsets of two consecutive white displays will be 10 frames or 100 ms (= 10 ms + 90 ms).\n\nWe can use two ways to verify whether the interval between two white displays is indeed 100 ms:\n\n1. Using the timestamps reported by OpenSesame. This is the easiest way and is generally accurate when the backend uses a blocking flip.\n2. Using a photodiode that responds to the onsets of the white displays and logs the timestamps of these onsets to an external computer. This is the best way to verify the timing, because it does not rely on introspection of the software. Certain issues, such as TFT input lag, discussed above, will come out only using external photodiode measurement.\n\n%--\ncode:\n id: LstIntervalBenchmark\n syntax: python\n source: interval-benchmark.py\n caption: A Python script to test the timing consistency and accuracy of display timestamps. You can paste this code into an INLINE_SCRIPT item.\n--%\n\nI ran %LstIntervalBenchmark on Windows XP, using all three backends. I also recorded the onsets of the white displays using a photodiode connected to a second computer. The results are summarized in %TblBenchmarkResults.\n\n%--\ntable:\n id: TblBenchmarkResults\n source: benchmark-results.csv\n caption: Benchmark results for %LstIntervalBenchmark. Tested with Windows XP, HP Compaq dc7900, Intel Core 2 Quad Q9400 @ 2.66Ghz, 3GB, 21\" ViewSonic P227f CRT. Each test was conducted twice (i.e. two sessions). The column `Session` corresponds to different test runs. The column `Source` indicates whether the measurements are from an external photiodiode, or based on OpenSesame's internal timestamps.\n--%\n\nAs you can see, the [xpyriment] and [psycho] backends consistently show a 100 ms interval. This is good and just as we would expect. However, the [legacy] backend shows a 90 ms interval. This discrepancy is due to the fact that the [legacy] backend does not use a blocking flip (see [Understanding your monitor]), which leads to some unpredictability in display timing. Note also that there is close agreement between the timestamps as recorded by the external photodiode and the timestamps reported by OpenSesame. This agreement demonstrates that OpenSesame's timestamps are reliable, although, again, they are slightly less reliable for the [legacy] backend due to the lack of a blocking-flip.\n\n", "url": "https://osdoc.cogsci.nl/4.0/manual/timing", "title": "Timing"}
{"content": "# Timing\n\n## Expyriment benchmarks and test suite\n\nA very nice set of benchmarks is available on the Expyriment website. This information is applicable to OpenSesame experiments using the [xpyriment] backend.\n\n- <http://docs.expyriment.org/Timing.html>\n\nExpyriment includes a very useful test suite. You can launch this test suite by running the `test_suite.opensesame` example experiment, or by adding a simple INLINE_SCRIPT to your experiment with the following lines of code (%LstExpyrimentTestSuite):\n\n%--\ncode:\n id: LstExpyrimentTestSuite\n syntax: python\n source: expyriment-test-suite.py\n caption: A script to start the Expyriment test suite.\n--%\n\nFor more information, please visit:\n\n- <http://docs.expyriment.org/Testsuite.html>\n\n## PsychoPy benchmarks and timing-related information\n\nSome information about timing is available on the PsychoPy documentation site. This information is applicable to OpenSesame experiments using the [psycho] backend.\n\n- <http://www.psychopy.org/general/timing/timing.html>\n\n[psycho]: /backends/xpyriment/\n[xpyriment]: /backends/xpyriment/\n[legacy]: /backends/legacy/\n[miscellaneous/clock-drift]: /miscellaneous/clock-drift\n[usage/prepare-run]: /usage/prepare-run\n[backends]: /backends\n[forms]: /forms", "url": "https://osdoc.cogsci.nl/4.0/manual/timing", "title": "Timing"}
{"content": "# Backends\n\ntitle: Backends\n\nThe *backend* is the software layer that deals with input (keyboard input, mouse input, etc.) and output (display presentation, sound playback, etc.). There are many libraries that offer this type of functionality and OpenSesame could, in principle, use any one of them. For this reason, OpenSesame is backend-independent, in the sense that you can choose which backend should be used. Currently there are four backends: *legacy*, *psycho*, *xpyriment*, and *osweb*.\n\n[TOC]\n\n## Differences and some tips\n\nUsually, you won't notice which backend is used. The differences between backends are largely technical, and, as long as you use the graphical user interface, all backends work more ore less the same way. However, there are a few reasons to prefer one backend over another:\n\n- If you want to run the experiment in a browser, you need to select the *osweb* backend.\n- Backend differs in [temporal precision](%link:timing%).\n\t- Tip: If you care about millisecond temporal precision, use *xpyriment* or *psycho*.\n- Backends differ in how long stimulus preparation takes.\n\t- Tip: If [forms](%link:manual/forms/about%) are slow, use *legacy*.\n\t- Tip: If the intertrial interval is long (due to stimulus preparation), use *legacy*.\n- You can use backend-specific functionality when writing Python code.\n\t- Tip: If you want to use PsychoPy functionality, use *psycho*.\n\t- Tip: If you want to use Expyriment functionality, use *xpyriment*.\n\t- Tip: If you want to use PyGame functionality, use *legacy*.\n- Some backends are not available on all platforms.\n\n## Selecting a backend\n\nYou can select a backend in the general properties of the experiment (%FigSelect).\n\n%--\nfigure:\n id: FigSelect\n source: fig-select.png\n caption: \"Selecting a backend\"\n--%\n\nIf you view the general script (select \"Show script editor\"), you will see that there are actually six distinct backends: canvas, keyboard, mouse, sampler, color, and clock. The combobox-method automatically selects an appropriate, predefined combination of backends, but you could, in theory, mix and match.\n\nFor example, if you select the *xpyriment* backend, the following code will be generated:\n\n\tset sampler_backend legacy\n\tset mouse_backend xpyriment\n\tset keyboard_backend legacy\n\tset color_backend legacy\n\tset clock_backend legacy\n\tset canvas_backend xpyriment\n\n## xpyriment\n\nThe *xpyriment* backend is built on top of [Expyriment][], a library designed for creating psychology experiments. It is a light-weight hardware-accelerated backend with excellent timing properties. If you care about temporal precision, but do not plan on generating complex stimuli (i.e. Gabor patches, random-dot gratings, etc.) *xpyriment* is a good choice.\n\n### Using Expyriment directly\n\nYou can find extensive documentation on Expyriment at <http://www.expyriment.org/doc>. The following code snippet shows a line of text:\n\n~~~ .python\nfrom expyriment import stimuli\ntext = stimuli.TextLine('This is expyriment!')\ntext.present()\n~~~\n\n### Citation\n\nAlthough Expyriment is bundled with the binary distributions of OpenSesame, it is a separate project. When appropriate, please provide the following citation in addition to citing OpenSesame:\n\nKrause, F., & Lindemann, O. (in press). Expyriment: A Python library for cognitive and neuroscientific experiments. *Behavior Research Methods*.\n{: .reference}\n\n## psycho\n\nThe psycho backend is built on top of [PsychoPy][], a library designed for creating psychology experiments. It is hardware accelerated and provides high-level routines for creating complex visual stimuli (drifting gratings, etc.). If you care about timing and plan on creating complex stimuli, Psycho is a good choice.\n\n### Using PsychoPy directly\n\nYou can find extensive documentation on PsychoPy at <http://www.psychopy.org/>. When using PsychoPy in OpenSesame, it is important to know that the main window can be accessed as `self.experiment.window` or simply `win`. So the following code snippet draws a Gabor patch:\n\n~~~ .python\nfrom psychopy import visual\ngabor = visual.PatchStim(win, tex=\"sin\", size=256, mask=\"gauss\", sf=0.05, ori=45)\ngabor.draw()\nwin.flip()\n~~~\n\n### Tutorials\n\nA tutorial specifically for using PsychoPy from within OpenSesame:\n\n- <http://www.cogsci.nl/blog/tutorials/211-a-bit-about-patches-textures-and-masks-in-psychopy>\n\nAnd a more general PsychoPy tutorial:\n\n- <http://gestaltrevision.be/wiki/coding>\n\n### Citation\n\nAlthough PsychoPy is bundled with the binary distributions of OpenSesame, it is a separate project. When appropriate, please cite the following papers in addition to citing OpenSesame:\n\nPeirce, J. W. (2007). PsychoPy: Psychophysics software in Python. *Journal of Neuroscience Methods*, *162*(1-2), 8-13. doi:10.1016/j.jneumeth.2006.11.017\n{: .reference}\n\nPeirce, J. W. (2009). Generating stimuli for neuroscience using PsychoPy. *Frontiers in Neuroinformatics*, *2*(10). doi:10.3389/neuro.11.010.2008\n{: .reference}\n\n## legacy\n\nThe legacy backend is built on top of [PyGame][] in non-OpenGL mode. The downside of this is that there is no hardware acceleration, and the timing properties are not as good as that of the psycho or xpyriment backends. The upside is that PyGame is very easy to use, very reliable, and well supported on a wide range of platforms.\n\n### Mouse-cursor visibility\n\nOn some systems, the mouse cursor is not visible when using the *legacy* backend in fullscreen mode. You can work around this is the following ways:\n\n1. Open the *legacy* backend settings and set \"Double buffering\" to \"no\".\n\t- *Note:* This may disable v-sync, which can be important for time critical experiments, as discussed [here](%link:timing%).\n2. Open the *legacy* backend settings and set \"Custom cursor\" to \"yes\".\n3. Switch to another backend.\n\n### Using PyGame directly\n\nPyGame is well documented and you can find everything you need to know about using PyGame on <http://www.pygame.org/docs/>. Specific to OpenSesame is the fact that the display surface is stored as `self.experiment.window` or simply `win`. So the following code snippet, which you could paste into an INLINE_SCRIPT item, draws a red rectangle to the display:\n\n~~~ .python\nimport pygame # Import the PyGame module\npygame.draw.rect(self.experiment.window, pygame.Color(\"red\"),\n\t[20, 20, 100, 100]) # Draw a red rectangle. Not shown yet...\npygame.display.flip() # Update the display to show the red rectangle.\n~~~\n\n\n## osweb\n\nThe *osweb* backend is built on top of OSWeb and allows you run experiments in a browser. For more information, see:\n\n- %link:manual/osweb/workflow%", "url": "https://osdoc.cogsci.nl/4.0/manual/backends", "title": "Backends"}
{"content": "# The prepare-run strategy\n\ntitle: The prepare-run strategy\n\n[TOC]\n\n## About\n\nExperiments typically consist of short intervals ('trials') during which participants perceive stimuli and perform a task. Timing should be controlled during a trial, but some unpredictable variation in the duration of the interval between trials is acceptable. Therefore, a good strategy is to perform time-consuming tasks before a trial, and to keep the operations that are performed during a trial to a minimum.\n\nOpenSesame does this by calling each element from a SEQUENCE item twice. This is the *prepare-run strategy*:\n\n- During the Prepare phase, items are given the opportunity to prepare. For example, a SYNTH generates a sound (but doesn't play it); and a SKETCHPAD draws a canvas (but doesn't show it).\n- During the Run phase, items do as a little as possible. For example, a SYNTH plays back a previously prepared sound; and a SKETCHPAD shows a previously prepared canvas.\n\nThis reduces the risk of timing glitches. The prepare-run strategy is implemented at the level of SEQUENCE items, which typically contains the time-critical parts of an experiment. This means that before a SEQUENCE is started, there is some unpredictable temporal jitter.\n\n## Item-specific notes\n\n### loop items\n\nA LOOP item is not prepared in advance. It is important to take this into account when using a LOOP to implement time-critical parts. For example, you may be tempted to implement an RSVP stream using a LOOP item as follows:\n\n~~~text\nrsvp_loop item (4 cycles)\n- stimulus_item\n~~~\n\nIn this construction, *stimulus_item* will be prepared and run four times in alternation, like so:\n\n~~~text\nprepare stimulus_item\nrun stimulus_item\nprepare stimulus_item\nrun stimulus_item\nprepare stimulus_item\nrun stimulus_item\nprepare stimulus_item\nrun stimulus_item\n~~~\n\nTherefore, you need to verify that the preparation of *stimulus_item* does not cause any timing glitches.\n\n### sequence items\n\nAll items that are part of a SEQUENCE are prepared in advance. Therefore, the following construction ...\n\n~~~text\ntrial_sequence\n- fixation_sketchpad\n- target_sketchpad\n- keyboard_response\n- logger\n~~~\n\n... will be executed as follows ...\n\n~~~text\nprepare fixation_sketchpad\nprepare target_sketchpad\nprepare keyboard_response\nprepare logger\nrun fixation_sketchpad\nrun target_sketchpad\nrun keyboard_response\nrun logger\n~~~\n\n### sketchpad and feedback items\n\nSKETCHPAD and FEEDBACK items differ in when they are prepared. For SKETCHPADs preparation occurs during the Prepare phase; for FEEDBACK items, preparation occurs only during the Run phase.\n\nFor more information, see:\n\n- %link:manual/stimuli/visual%\n\n### synth and sampler items\n\nFor SYNTH and SAMPLER items, the sound is generated and preloaded during the Prepare phase.\n\n### inline_script items\n\nIn an INLINE_SCRIPT item, you can choose how you want to implement the run and prepare strategy. In general, it is good practice to adhere to the following guidelines:\n\n- Time-consuming, preparatory functionality goes in the Prepare phase. For example, creating canvas objects, and generating sounds.\n- A minimum amount of code is put in the run phase. For example, only showing a previously prepared canvas.\n\n### Other items and plugins\n\nIn general, items should follow the principle of performing as much as possible time-consuming preparation during the Prepare phase, and minimizing the Run phase. However, every plugin is implemented differently. If you are unsure about a specific case, please post a query on the forum.\n\n## Conditional expressions (run if, show if, break if, etc)\n\nIn SEQUENCE items, the 'Run if' condition is evaluated at the last moment, during the run phase. Therefore, you can use a condition like `correct == 0` which depends on the results of a KEYBOARD_RESPONSE item which has been called just before. It is important to take into account that the 'Run if' expression applies *only* to the run phase of an item\u2014The prepare phase is *always* executed.\n\nIn COROUTINES items, the 'Run if' condition is evaluated during the Prepare phase. Therefore, the conditions cannot depend on events that occur during the execution of the COROUTINES.\n\nIn SKETCHPAD items, the 'Show if' condition is evaluated during the Prepare phase, when the canvas is constructed. In FEEDBACK items, the 'Show if' condition is evaluated during the Run phase (because the canvas is only constructed in the Run phase).", "url": "https://osdoc.cogsci.nl/4.0/manual/prepare-run", "title": "The prepare-run strategy"}
{"content": "# Oculus rift (virtual reality)\n\n---\nlayout: osdoc\ntitle: Oculus rift (virtual reality)\ngroup: Devices\npermalink: /oculus-rift/\n---\n\n<iframe src=\"http://wl.figshare.com/articles/1394986/embed?show_title=1\" width=\"640\" height=\"861\" frameborder=\"0\"></iframe>\n\nHern\u00e1ndez-Sande, A., Lorca, J. A. (2015): OpenSesame: An example of stimulus presentation in Virtual Reality headsets (Oculus Rift DK1). *Figshare*. doi:10.6084/m9.figshare.1394986", "url": "https://osdoc.cogsci.nl/4.0/manual/devices/oculusrift", "title": "Oculus rift (virtual reality)"}
{"content": "# Ambulatory Monitoring System (VU-AMS)\n\ntitle: Ambulatory Monitoring System (VU-AMS)\n\nVU-AMS is a third-party plugin, and is not maintained by the OpenSesame team.\n{: .alert .alert-info}\n\n\nThe VU University Ambulatory Monitoring System (VU-AMS) is a device that can be used to measure a variety of factors related to heart rate, respiration, and body movement. The developers offer an OpenSesame template on their website.\n\nFor more information, see:\n\n- <http://www.vu-ams.nl> (product website)\n- <http://www.vu-ams.nl/support/downloads/extras/> (OpenSesame template)", "url": "https://osdoc.cogsci.nl/4.0/manual/devices/vuams", "title": "Ambulatory Monitoring System (VU-AMS)"}
{"content": "# StimSync\n\ntitle: StimSync\n\nStimSync is an open-source open-hardware device for handling input (e.g., button presses) and output (e.g., triggers) in psychological and neuroscientific experiments. StimSync offers examples for use with OpenSesame.\n\nFor more information, see:\n\n- <http://www.mccauslandcenter.sc.edu/crnl/stimsync-0>", "url": "https://osdoc.cogsci.nl/4.0/manual/devices/stimsync", "title": "StimSync"}
{"content": "# Serial port\n\ntitle: Serial port\n\nPySerial is an easy to use Python library for serial port communications, which is bundled with all OpenSesame packages. For more information, see:\n\n- <http://pyserial.sourceforge.net/>", "url": "https://osdoc.cogsci.nl/4.0/manual/devices/serial", "title": "Serial port"}
{"content": "# Parallel port (EEG triggers)\n\ntitle: Parallel port (EEG triggers)\nreviewed: false\n\nIn EEG/ ERP studies it is common to send triggers to mark the timestamp for significant events (e.g., the onset of a trial, presentation of a particular stimulus, etc.). Triggers are typically bytes that are sent via the parallel port to the EEG apparatus.\n\n[TOC]\n\n\n## Using the `parallel_port_trigger` plugin\n\nParallel_port_trigger is a third-party plugin and not maintained by the OpenSesame team.\n{: .page-notification}\n\nAn OpenSesame plug-in for sending stimulus synchronization triggers through the parallel port to data acquisition systems.\n\n- <https://github.com/dev-jam/opensesame-plugin-parallel_port_trigger/>\n\nYou can install the `parallel_port_trigger` plugin from PyPi:\n\n```\npip install pip install opensesame-plugin-parallel-port-trigger\n```\n\n\n## Using `dportio.dll` in a Python inline Script (Windows only)\n\nInstead of using the `parallel_port_trigger` plugin, it is also possible to send triggers with `dlportio.dll` through a Python inline script. This approach is Windows only. To do so, first add an INLINE_SCRIPT to the start of the experiment with the following code in the prepare phase:\n\n~~~ .python\ntry:\n\tfrom ctypes import windll\n\tglobal io\n\tio = windll.dlportio # requires dlportio.dll !!!\nexcept:\n\tprint('The parallel port couldn\\'t be opened')\n~~~\n\nThis will load `dlportio.dll` as a global object called `io`. Please note that failure will not crash the experiment, so make sure to check the debug window for error messages!\n\nNow use the following code in an INLINE_SCRIPT anywhere in the experiment to send a trigger:\n\n~~~ .python\nglobal io\ntrigger = 1\nport = 0x378\ntry:\n\tio.DlPortWritePortUchar(port, trigger)\nexcept:\n\tprint('Failed to send trigger!')\n~~~\n\nNote that this sends trigger 1 to port 0x378 (=888). Change these values according to your set-up.\n\n## Getting access to the parallel port\n\n### Linux\n\nIn Linux we use the `parport_pc` module (tested in Debian Wheezy) and we need to provide ourselves with permissions to do so. We can accomplish this by executing the following commands:\n\n\tsudo rmmod lp\n\tsudo rmmod parport_pc\n\tsudo modprobe parport_pc\n\tsudo adduser [user] lp\n\nHere, `[user]` should be replaced by your username. Next, logout and login, and you are ready to go!\n\n### Windows XP and Windows Vista (32 bit)\n\n1. Download the 32-bit DLPortIO driver from [here][win32-dll] and uncompress the zip archive.\n2. Go to `DriverLINX/drivers` folder and copy `dlportio.dll` and `dlportio.sys` to the `install` folder. This is the folder  where `install.exe` is located. Then run `install.exe`\n3. You need to copy `dlportio.dll` to the OpenSesame folder (that is, the same folder that contains `opensesame.exe`).\n\n### Windows 7 (32 and 64 bit)\n\n1. Download the 32-bit or 64bit DLPortIO driver [here][win7-dll] and uncompress the zip archive.\n2. As Windows 7 has a strengthened security system (at least compared to XP) one cannot simply install the DLPortIO driver. This won't work as Windows 7 will block all attempts of installing a not-officially-signed (by Microsoft) driver. Good for the security of an average user -- bad for us. To bypass this restriction one has to use a little helper program called \"Digital Signature Enforcement Overrider\" (DSEO) which can be downloaded [here][dseo] (of course there are other possible ways to do this but this program is mentioned in the DLPortIO `readme.txt` and one does not have to dive deeper into MS Windows 7 architecture specialities).\n3. Start DSEO with administrator privileges (right click on `dseo13b.exe`, select \"run as administrator\"). Now the DSEO window pops up. It just presents a list of options which operation to run next.\n4. Choose the option \"sign driver/sys-file\" and press ok. Now another window appears where you have to type in the absolute path to the `DLPortIO.sys` file (only this one, not the dll!). Remember to escape spaces in the path if you have any (don't ask how long that took me) otherwise your files will not be found. Pressing ok will sign the sys-file.\n5. Back in the DSEO list choose \"enable test mode\" and press ok. Then choose \"exit\" and restart your PC. Windows 7 wrongly complains that DSEO might not be installed correctly -- just click on \"yes, the software is installed correctly\".\n6. After boot-up is completed you'll see that something like \"Windows 7 test mode built #number#\" is written on the desktop just above the clock in the starter-bar. That's necessary. You have to be in test mode to run this unofficially signed driver.\n7. Now run `DLPortIO_install.bat` with administrator privileges (in Windows Explorer, right click the file, ...). Answer \"yes\" if Windows warns you about registry changes.\n8. Reboot.\n9. Copy `DLPortIO.dll` to the Opensesame folder, that is, the same folder that contains `opensesame.exe`.\n\nSource: [Forum post by Absurd][post-3]\n\n## Recommendations\n\n- Start your experiment with a 'zero' trigger to make sure all the pins are set to zero.\n- It's recommended to use the [psycho] or [xpyriment] backends instead of the [legacy] backend (using PyGame) for time-critical experiments. This is because [psycho] and [xpyriment] takes the refresh rate of the monitor into account when returning timestamps, whereas [legacy] does not. For more information, see [miscellaneous/timing].\n- Send the trigger code right after (instead of just before) the presentation of your stimulus (assuming that it's the stimulus onset you want to mark). By doing so you'll make sure that the time stamp is as accurately as possible and will not suffer from a small random jitter due to your monitor's refresh rate. [Source: lvanderlinden][post-2]\n\n## Troubleshooting\n\nThere are a number of relevant forum topics in which trigger-related problems are discussed (and, for the most, solved!).\n\n- A post about ghost triggers, i.e. unwanted triggers that are mysteriously registered by the EEG apparatus: [link][post-2]\n- A post with elaborate installation instructions for DLPortIO on Windows 7 ([Source: absurd][post-3]).\n\nPlease don't hesitate to post questions on the forum, or to let us know of your experiences (good or bad).\n\n[win32-dll]: http://files.cogsci.nl/misc/dlportio.zip\n[win7-dll]: http://real.kiev.ua/avreal/download/#DLPORTIO_TABLE\n[dseo]: http://www.ngohq.com/home.php?page=dseo\n[post-2]: http://forum.cogsci.nl/index.php?p=/discussion/comment/780#Comment_780\n[post-3]: http://forum.cogsci.nl/index.php?p=/discussion/comment/745#Comment_745\n[miscellaneous/timing]: /miscellaneous/timing\n[legacy]: /backends/legacy\n[xpyriment]: /backends/xpyriment\n[psycho]: /backends/psycho", "url": "https://osdoc.cogsci.nl/4.0/manual/devices/parallel", "title": "Parallel port (EEG triggers)"}
{"content": "# Emotiv EEG\n\n---\nlayout: osdoc\ntitle: Emotiv EEG\ngroup: Devices\npermalink: /emotiv/\n---\n\n[Emotiv](https://emotiv.com/) is a low-cost EEG headset. Dimitrios Adamos (Neuroinformatics.GRoup of the Aristotle University of Thessaloniki) has written a tutorial for using the Emotiv with OpenSesame:\n\n- <http://neuroinformatics.gr/node/37>\n\n%--\nfigure:\n source: emotiv.png\n id: FigEmotiv\n caption: Emotiv is a low-cost EEG headset.\n--%", "url": "https://osdoc.cogsci.nl/4.0/manual/devices/emotiv", "title": "Emotiv EEG"}
{"content": "# Using the form plugins\n\ntitle: Using the form plugins\n\nA number of commonly used forms are available as ready-made plugins. These allow you to use common forms, without any need for scripting.\n\n- FORM_CONSENT is a simple digital consent form (disclaimer: some journals may require *written* consent)\n- FORM_MULTIPLE_CHOICE allows you to present multiple choice questions\n- FORM_TEXT_DISPLAY is a simple text display that you can use to show instructions etc.\n- FORM_TEXT_INPUT is a simple text input display that allows you to ask a question and collect a multi-character response from the participant\n\nThe FORM_BASE plugin is special. It allows you to define custom forms using OpenSesame script, as described here:\n\n- %link:manual/forms/custom%\n\n%--\nfigure:\n id: FigFormPlugins\n source: form-plugins.png\n caption: The FORM plugins in the item toolbar.\n--%", "url": "https://osdoc.cogsci.nl/4.0/manual/forms/readymade", "title": "Using the form plugins"}
{"content": "# Form variables\n\ntitle: Form variables\n\n[TOC]\n\n## About form variables\n\nWhen you present a form with multiple `checkbox`es, you generally want to know which `checkbox` the user has checked. Similarly, when you present a form with two `button`s, you want to know which `button` the user has clicked. This information is available through variables that are automatically set when the user interacts with a form. You can specify yourself which response variables should be used. How this is done depends on how you have created your form.\n\n### In ready-made form plugins\n\nWhen you use one of the ready-made form plugins, such as FORM_TEXT_INPUT, you can specify the name of the response variable directly in the plugin controls.\n\n### In custom forms\n\nYou can use the `var` keyword to indicate which variable should be used. For example, the following OpenSesame script, which you can enter into a FORM_BASE plugin, indicates that the response from a `text_input` widget should be stored in a variable called `my_response_var`:\n\n```python\nwidget 0 0 1 1 text_input var=my_response_var\n```\n\nThe equivalent Python code is:\n\n~~~ .python\nmy_widget = TextInput(var='my_response_var')\n~~~\n\nSee also:\n\n- %link:manual/forms/widgets%\n\n## Widget-specific information\n\nEach widget uses its response variable in a slightly different way.\n\n### button\n\nThe `button` widget sets the response variable to 'yes' if it has been clicked and to 'no' if it has not.\n\n### checkbox\n\nThe `checkbox` widget sets the response variable to a semicolon-separated list of the text on all checkboxes that have been checked (for that variable), or 'no' if no `checkbox` has been checked (for that variable). This sounds a bit complicated, so let's see a few examples.\n\n```python\nwidget 0 0 1 1 checkbox group=\"1\" text=\"A\" var=\"my_response_var\"\nwidget 1 0 1 1 checkbox group=\"1\" text=\"B\" var=\"my_response_var\"\nwidget 1 1 1 1 button text=\"Next\"\n```\n\nHere there are two `checkbox`es with the text 'A' and 'B'. Both part of the same group, called '1'. Both have the same response variable, called `my_response_var`. If 'A' is checked, `my_response_var` will be 'A'. If 'B' is checked, `my_response_var` will be 'B'. If neither is checked, `my_response_var` will be 'no'. Note that only one `checkbox` in the same group can be checked, so `my_response_var` will *never* be 'A;B' in this example.\n\nNow let's consider the same script, with the sole difference that the two `checkbox`es are not part of a group:\n\n```python\nwidget 0 0 1 1 checkbox text=\"A\" var=\"my_response_var\"\nwidget 1 0 1 1 checkbox text=\"B\" var=\"my_response_var\"\nwidget 1 1 1 1 button text=\"Next\"\n```\n\nIn this case, the situation is much like described above, with the exception that both `checkbox`es can be checked at the same time, in which case `my_response_var` will be set to 'A;B'.\n\nYou cannot use the same response variable for `checkbox`es in different groups.\n\n### image\n\nVariables are not applicable to the `image` widget.\n\n### image_button\n\nThe `image_button` widget sets the response variable to 'yes' if it has been clicked and to 'no' if it has not.\n\n### label\n\nVariables are not applicable to the `label` widget.\n\n### rating_scale\n\nThe `rating_scale` widget sets the response variable to the number of the option that has been clicked, where '0' is the first option (zero-based indexing). If no option has been selected, the response variable is set to 'None'.\n\n### text_input\n\nThe `text_input` widget sets the response variable to the entered text.", "url": "https://osdoc.cogsci.nl/4.0/manual/forms/variables", "title": "Form variables"}
{"content": "# About forms\n\ntitle: About forms\n\nForms are simple interactive displays that can be used to implement questionnaires, instructions, text input displays, etc. You can use forms in four ways.\n\n- Use the form plugins, such as FORM_TEXT_INPUT, which offer ready-made forms. This is the easiest, but least flexible way of using forms. This works both on the desktop and in a browser.\n\t- %link:manual/forms/readymade%\n- Define custom forms using OpenSesame script and the form_base plugin. This offers considerable flexibility, and does not require any real programming skills. This only works on the desktop.\n\t- %link:manual/forms/custom%\n- Create custom forms using Python inline script. This offers the most flexibility, but requires some knowledge of Python programming. This only works on the desktop.\n\t- %link:manual/forms/custom%\n- Create custom forms using HTML code. This only works when running experiments in a browser with OSWeb.\n\t- %link:manual/forms/html%\n\n%--\nfigure:\n id: FigAbout\n source: about.png\n caption: An example form.\n--%", "url": "https://osdoc.cogsci.nl/4.0/manual/forms/about", "title": "About forms"}
{"content": "# Custom HTML forms\n\ntitle: Custom HTML forms\n\n\nThe INLINE_HTML item allows you to implement forms using custom HTML.\n\n- The `name` attribute of `input` tags corresponds to an experimental variable. Therefore, the text that is entered into the text input of Example 1 will be stored as the experimental variable `text_response`.\n- For `checkbox` and `radio` elements, you can use the `id` attribute to assign a specific value to the associated experimental variable.\n- You can use the `required` attribute to indicate that a form cannot be submitted before a field has been filled out.\n- The form is closed when the participant clicks on an input of type submit.\n- To include images from the file pool in a custom HTML form, first retrieve the URL to the file, assign it to an experimental variable, and then use this variable as the source for the `<img>` tag (see Example 3).\n\n\nExample 1:\n\nA very basic text input form:\n\n```html\n<input type='text' name='text_response'>\n<input type='submit' value='click here to continue'>\n```\n\nExample 2:\n\nA form with multiple radio buttons:\n\n```html\n<p>Please select your age:</p>\n<input type=\"radio\" id=\"age1\" name=\"age\" value=\"30\" required>\n<label for=\"age1\">0 - 30</label><br>\n<input type=\"radio\" id=\"age2\" name=\"age\" value=\"60\">\n<label for=\"age2\">31 - 60</label><br>  \n<input type=\"radio\" id=\"age3\" name=\"age\" value=\"100\">\n<label for=\"age3\">61 - 100</label><br><br>\n<input type=\"submit\" value=\"Submit\">\n```\n\nExample 3:\n\nYou can include variable references (except within `<script>` tags, where curly braces are simply interpreted as part of JavaScript code):\n\n```html\n<p>You age group is {age}</p>\n<input type='submit' value='ok'>\n```\n\nExample 4:\n\nYou can JavaScript through `<script>` tags. For example, you can get an image from the file pool and assign to an initially empty `<img>` tag like this:\n\n```html\n<img id='capybara'>\n<input type='submit' value='ok'>\n\n<script>\ndocument.getElementById('capybara').src = pool['capybara.png'].data.src\n</script>\n```", "url": "https://osdoc.cogsci.nl/4.0/manual/forms/html", "title": "Custom HTML forms"}
{"content": "# Form widgets and keywords\n\ntitle: Form widgets and keywords\n\n\n[TOC]\n\n\n## Screenshot\n\n%--\nfigure:\n id: FigWidgets\n source: widgets.png\n caption: A list of available FORM widgets.\n--%\n\n\n## Widgets and keywords\n\nAll keywords are optional, instead otherwise indicated.\n\n### Form\n\nThe `cols` and `rows` keywords can either be single `int` values, in which case they specify the number of equally sized columns and rows, or lists of `int`, in which case they specify the relative sizes of each column and row. For more information about form geometry, see:\n\n- %link:manual/forms/custom%\n\nThe `validator` keyword can be used to validate form input. For more information, see:\n\n- %link:manual/forms/validation%\n\n(In OpenSesame script, you do not need to explicitly create a form.)\n\nPython script:\n\n~~~ .python\nform = Form(\n    cols=2, rows=2, spacing=10, margins=(100, 100, 100, 100), theme='gray',\n    timeout=None, clicks=False, validator=None\n)\nbutton = Button(text='Ok!')\nform.set_widget(button, (0, 0))\nform._exec()\n~~~\n\n\n### button / Button\n\nOpenSesame script:\n\n~~~python\nwidget 0 0 1 1 button text=\"Click me!\" center=yes frame=yes var=response\n~~~\n\nPython script:\n\n~~~ .python\nform = Form()\nbutton = Button(text='Click me!', frame=True, center=True, var='response')\nform.set_widget(button, (0, 0))\nform._exec()\n~~~\n\n\n### checkbox / Checkbox\n\nIf a group is specified, checking one checkbox from that group will uncheck all other checkboxes from that group. Checkboxes that are part of a group cannot be unchecked, except by clicking on another checkbox in that group.\n\nThe `group` keyword also affects how variables are stored, as described here:\n\n- %link:manual/forms/variables%\n\nOpenSesame script:\n\n~~~python\nwidget 0 0 1 1 checkbox group=group text=\"Option 1\"\nwidget 0 1 1 1 checkbox group=group text=\"Option 2\"\n~~~\n\nPython script:\n\n~~~ .python\nform = Form()\ncheckbox1 = Checkbox(text='Option 1', group='group')\ncheckbox2 = Checkbox(text='Option 2', group='group')\nform.set_widget(checkbox1, (0, 0))\nform.set_widget(checkbox2, (0, 1))\nform._exec()\n~~~\n\n\n### image / ImageWidget\n\nThe Python object is called `ImageWidget` to distinguish it from the `Image` canvas element.\n\nOpenSesame script:\n\n~~~python\n# Only path is a required keyword\nwidget 0 0 1 1 image path=\"my_image.png\" adjust=yes frame=no\n~~~\n\nPython script:\n\n~~~ .python\n# Only path is a required keyword\nform = Form()\nimage = ImageWidget(path=pool['my_image.png'], adjust=True, frame=False)\nform.set_widget(image, (0, 0))\nform._exec()\n~~~\n\n\n### image_button / ImageButton\n\nThe `image_id` keyword is used to identify the image button when it is clicked. If no `image_id` is provided, the path to the image is used as id.\n\nOpenSesame script:\n\n~~~python\n# Only path is a required keyword\nwidget 0 0 1 1 image_button path=\"my_image.png\" adjust=yes frame=no image_id=my_image var=response\n~~~\n\nPython script:\n\n~~~ .python\n# Only path is a required keyword\nform = Form()\nimage_button = ImageButton(\n    path=pool['my_image.png'], adjust=True, frame=False,\n    image_id='my_image', var='response'\n)\nform.set_widget(image_button, (0, 0))\nform._exec()\n~~~\n\n\n### label / Label\n\nOpenSesame script:\n\n~~~python\nwidget 0 0 1 1 label text=\"My text\" frame=no center=yes\n~~~\n\nPython script:\n\n~~~ .python\nform = Form()\nlabel = Label(text='My text', frame=False, center=True)\nform.set_widget(label, (0,0))\nform._exec()\n~~~\n\n\n### rating_scale / RatingScale\n\nThe `nodes` keyword can be an `int` or a semicolon-separated list of labels. If `nodes` is an `int`, it specified the number of (unlabeled) nodes.\n\nThe `default` keyword indicates which node number is selected by default, where the first node is 0.\n\nOpenSesame script:\n\n~~~python\nwidget 0 1 1 1 rating_scale var=response nodes=\"Agree;Don't know;Disagree\" click_accepts=no orientation=horizontal var=response default=0\n~~~\n\nPython script:\n\n~~~ .python\nform = Form()\nrating_scale = RatingScale(\n    nodes=['Agree', u\"Don't know\", 'Disagree'], click_accepts=False,\n    orientation='horizontal', var='response', default=0\n)\nform.set_widget(rating_scale, (0, 0))\nform._exec()\n~~~\n\n\n### text_input / TextInput\n\nThe `stub` keyword indicates placeholder text that is shown when no text has been entered. The `key_filter` keyword, available only in Python, specifies a function to filter key presses. This is described in more detail under:\n\n- %link:manual/forms/validation%\n\nOpenSesame script:\n\n~~~python\nwidget 0 0 1 1 text_input text=\"Initial text\" frame=yes center=no stub=\"Type here \u2026\" return_accepts=yes var=response\n~~~\n\nPython script:\n\n~~~ .python\nform = Form()\ntext_input = TextInput(\n    text='Initial text', frame=True, center=False, stub='Type here \u2026',\n    return_accepts=True, var='response', key_filter=my_filter_function\n)\nform.set_widget(text_input, (0, 0))\nform._exec()\n~~~", "url": "https://osdoc.cogsci.nl/4.0/manual/forms/widgets", "title": "Form widgets and keywords"}
{"content": "# Creating custom forms\n\ntitle: Creating custom forms\n\n\n[TOC]\n\n\n## About forms, geometries, and widgets\n\nA form is a set of widgets (buttons, labels, text-input fields, etc.) arranged into a grid with a particular geometry. In the image below you see an example of a 2 (columns) \u00d7 3 (rows) form. A form geometry is simple, and consists of the following properties:\n\n- *margins* ensure that the widgets do not touch the edge of the display. You can have different margins for the top, right, bottom, and left.\n- *spacing* ensure that the widgets do not touch each other. The horizontal and vertical spacing is the same.\n- There are one or more *rows*, possibly of different sizes.\n- There are one or more *columns*, possibly of different sizes.\n\n%--\nfigure:\n id: FigGeometry\n source: geometry.png\n caption: A schematic of FORM geometries.\n--%\n\nOf course, an empty form is no fun. So let's add the following widgets to create a simple question form:\n\n- A `label` that spans the two columns of the top row. We use this label to give a title to the form.\n- Another `label` that spans the two columns of the middle row. This label contains the actual question.\n- A `button` in the bottom right widget area. This button allows the user to give the $0.05 response.\n- Another `button` in the bottom left widget area. This button allows the user to give the $0.10 response.\n\n%--\nfigure:\n id: FigSchematicExample1\n source: schematic-example1.png\n caption: A schematic example FORM.\n--%\n\nThe images above are schematic examples. How this form actually looks in OpenSesame depends on your settings (notably your font and colors), but it may look something like this:\n\n%--\nfigure:\n id: FigExample1\n source: example1.png\n caption: A example FORM.\n--%\n\n## Creating custom forms\n\nThere are two ways to create custom forms. You can:\n\n- Use the FORM_BASE item, and specify your form using OpenSesame script.\n- Using Python in an INLINE_SCRIPT item. The Python way is slightly more flexible, but for most purposes both ways can be used.\n\n### Creating forms using OpenSesame script\n\nWe will create the form described above using OpenSesame script. First, drag the FORM_BASE plugin into your experiment. Click on the newly created item to open its tab. Next, click on the 'Edit script' button (with the terminal icon), in the top-right of the tab area. This will open the script editor. Enter the following script to generate the form described above (see the comments for explanations).\n\n~~~\n# Margins are defined as \"top;right;bottom;left\". Each value corresponds to a\n# margin in pixels.\nset margins \"50;100;50;100\"\n# The spacing is simply a value in pixels.\nset spacing \"25\"\n# The sizes of the rows are relative. \"1;2;1\" means that there are three rows,\n# where the middle one is twice as large as the bottom and top ones. So \"1;2;1\"\n# means exactly the same thing as \"3;6;3\". Please note that \"3\" does not mean\n# that there are three equally-sized rows (but \"1;1;1\" does).\nset rows \"1;2;1\"\n# Columns are defined in the same way. \"1;1\" simply means that there\n# are two columns of the same size.\nset cols \"1;1\"\n# Widgets are defined as follows:\n# widget [column] [row] [column span] [row span] [widget type] [keywords]\n#\n# The columns and rows start counting at 0. If you do not want to have your widget\n# span multiple columns and rows, you simply set the column and row span to 1.\nwidget 0 0 2 1 label text=\"Question\"\nwidget 0 1 2 1 label center=\"no\" text=\"A bat and a baseball together cost $1.10. The bat costs one dollar more than the ball. How much does the ball cost?\"\nwidget 0 2 1 1 button text=\"$0.10\"\nwidget 1 2 1 1 button text=\"$0.05\"\n~~~\n\nIf you want a specific widget to receive the focus when the form is executed, you can apply the `focus=yes` keyword to one of the widgets:\n\n```\nwidget 0 0 1 1 text_input text=\"Initial text\" frame=yes center=no stub=\"Type here \u2026\" return_accepts=yes var=response focus=yes\n```\n\n\n### Creating forms using Python inline script\n\nThe exact same form can be created using an INLINE_SCRIPT and a bit of Python code. You will notice that the Python code somewhat resembles the OpenSesame script shown above. This is no wonder: The FORM_BASE plugin essentially translates the OpenSesame script into Python code.\n\nFirst, drag an INLINE_SCRIPT into your experiment. Select the newly created item to open its tab, and add the following script into the Run phase of the INLINE_SCRIPT item (see the comments for explanations).\n\n~~~ .python\n# Create a form\nform = Form(\n    cols=[1,1], rows=[1,2,1],\n    margins=(50,100,50,100), spacing=25\n)\n# Create four widgets\nlabelTitle = Label(text='Question')\nlabelQuestion = Label(\n    text='A bat and a baseball together cost $1.10. The bat costs one dollar more than the ball. How much does the ball cost?',\n    center=False\n)\nbutton5cts = Button(text='$0.05')\nbutton10cts = Button(text='$0.10')\n# Add the widgets to the form. The position in the form is indicated as a\n# (column, row) tuple.\nform.set_widget(labelTitle, (0,0), colspan=2)\nform.set_widget(labelQuestion, (0,1), colspan=2)\nform.set_widget(button5cts, (0,2))\nform.set_widget(button10cts, (1,2))\n# Execute the form! In this case, the form will return the text of the button that\n# was clicked. This is one way to get a return value out of the form. Another way\n# is to use the 'var' keyword, supported some of the widgets.\nbutton_clicked = form._exec()\n~~~\n\nIf you want a specific widget to receive the focus when the form is executed, you can use the `focus_wiget` keyword:\n\n~~~ .python\nbutton_clicked = form._exec(focus_widget=button5cts)\n~~~\n\n### Non-interactive forms\n\nUsually, a form will have an input field, a button, or some other interactive element. However, you can also use forms without having any interactive element. To do this in OpenSesame script, you set `only_render` to \"yes\":\n\n```python\nset only_render yes\n```\n\nTo this in a Python INLINE_SCRIPT, you call `form.render()`, instead of `form._exec()`.\n\n### Themes\n\nForms support theming. Currently, two themes are available: 'gray' and 'plain'. The 'gray' theme is the default. Although the 'gray' theme is already quite plain, the 'plain' theme is even more basic. You can choose a theme like this in OpenSesame script:\n\n```python\nset theme plain\n```\n\nAnd by using the `theme` keyword in Python inline script:\n\n~~~ .python\nform = Form(theme='plain')\n~~~\n\n### Available widgets and keywords\n\nFor a list of available widgets and keywords, see:\n\n- %link:manual/forms/widgets%\n\n### Validating input\n\nTo see how you can validate form input, see:\n\n- %link:manual/forms/validation%\n\n## Another example\n\nThe following OpenSesame script (in a FORM_BASE plugin) will produce a questionnaire of three rating scales plus a next button:\n\n```python\nset rows \"1;1;1;1;1\"\nset cols \"1;1\"\nwidget 0 0 2 1 label text=\"Indicate how much you agree with the following statements\"\nwidget 0 1 1 1 label center=\"no\" text=\"Forms are easy\"\nwidget 1 1 1 1 rating_scale var=\"question1\" nodes=\"Agree;Don't know;Disagree\"\nwidget 0 2 1 1 label center=\"no\" text=\"I like data\"\nwidget 1 2 1 1 rating_scale var=\"question2\" nodes=\"Agree;Don't know;Disagree\"\nwidget 0 3 1 1 label center=\"no\" text=\"I like questionnaires\"\nwidget 1 3 1 1 rating_scale var=\"question3\" nodes=\"Agree;Don't know;Disagree\"\nwidget 0 4 2 1 button text=\"Next\"\n```\n\nThe following Python inline_script will produce the same questionnaire.\n\n~~~ .python\nform = Form(cols=[1,1], rows=[1,1,1,1,1])\ntitle = Label(\n    text='Indicate how much you agree with the following statement'\n)\nquestion1 = Label(text='Forms are easy', center=False)\nquestion2 = Label(text='I like data', center=False)\nquestion3 = Label(text='I like questionnaires', center=False)\nratingScale1 = RatingScale(\n    var='question1',\n    nodes=['Agree', u\"Don't know\", 'Disagree']\n)\nratingScale2 = RatingScale(\n    var='question2',\n    nodes=['Agree', u\"Don't know\", 'Disagree']\n)\nratingScale3 = RatingScale(var='question3',\n    nodes=['Agree', u\"Don't know\", 'Disagree'])\nnextButton = Button(text='Next')\nform.set_widget(title, (0, 0), colspan=2)\nform.set_widget(question1, (0, 1))\nform.set_widget(question2, (0, 2))\nform.set_widget(question3, (0, 3))\nform.set_widget(ratingScale1, (1, 1))\nform.set_widget(ratingScale2, (1, 2))\nform.set_widget(ratingScale3, (1, 3))\nform.set_widget(nextButton, (0, 4), colspan=2)\nform._exec()\n~~~\n\nThe resulting form looks something like this. (The exact appearance depends on your font, colors, etc.)\n\n%--\nfigure:\n id: FigExample2\n source: example2.png\n caption: Another example FORM.\n--%", "url": "https://osdoc.cogsci.nl/4.0/manual/forms/custom", "title": "Creating custom forms"}
{"content": "# Validating form input\n\ntitle: Validating form input\n\n\nTo validate a form, pass a function with the `validator` keyword to `Form()`. In the example below, `my_form_validator()` is used in this way. A validator function should not expect any arguments, and should return a `bool` to indicate whether or not the form validates. If the form does not validate, no error message is shown, but the form simply stays open.\n\nIn addition, you can validate (or filter) input to a `TextInput` widget to exclude certain characters as input. To do so, pass a function with the `key_filter` keyword to `TextInput()`. In the example below, `filter_digits()` is used in this way. A key-filter function should accept a single argument, which corresponds to a single key press, and should return a `bool` to indicate whether or not the key is accepted as input.\n\n~~~ .python\ndef my_form_validator():\n    \"\"\"Checks whether both the gender and age fields have been filled out\"\"\"\n    return gender != 'no' and age != ''\n\n\ndef filter_digits(ch):\n    \"\"\"Allows only digit characters as input\"\"\"\n    return ch in '0123456789'\n\n\n# Define all widgets\nbutton_ok = Button(text='Ok')\nlabel_gender= Label('Your gender')\ncheckbox_male = Checkbox(text='Male', group='gender', var='gender')\ncheckbox_female = Checkbox(text='Female', group='gender', var='gender')\nlabel_age = Label('Your age')\n# Specify a key filter so that only digits are accepted as text input\ninput_age = TextInput(stub='Age here \u2026', var='age', key_filter=filter_digits)\n# Build the form. Specify a validator function to make sure that the form is\n# completed.\nmy_form = Form(validator=my_form_validator, rows=[1,1,1], cols=[1,1,1])\nmy_form.set_widget(label_gender, (0, 0))\nmy_form.set_widget(checkbox_male, (1, 0))\nmy_form.set_widget(checkbox_female, (2, 0))\nmy_form.set_widget(label_age, (0, 1))\nmy_form.set_widget(input_age, (1, 1), colspan=2)\nmy_form.set_widget(button_ok, (1, 2))\nmy_form._exec()\n~~~", "url": "https://osdoc.cogsci.nl/4.0/manual/forms/validation", "title": "Validating form input"}
{"content": "# CSV functions (csv-parse)\n\ntitle: CSV functions (csv-parse)\n\nThe synchronous `parse()` function from the `csv-parse` library is available. This allows you to parse CSV-formatted text, for example from a CSV file in the file pool, into an Object.\n\n__Example:__\n\n```js\nconst conditions = csvParse(\n    pool['attentional-capture-jobs.csv'].data,\n    {columns: true}\n)\nfor (const trial of conditions) {\n    console.log(trial.distractor)\n}\n```\n\nFor an overview, see:\n\n- <https://csv.js.org/parse/api/sync/#sync-api>", "url": "https://osdoc.cogsci.nl/4.0/manual/javascript/csv", "title": "CSV functions (csv-parse)"}
{"content": "# Python-like iterators (pythonic)\n\ntitle: Python-like iterators (pythonic)\n\nThe `pythonic` library provides Python-like functions for iterating over arrays. Available functions are: `range()`, `enumerate()`, `items()`, `zip()`, and `zipLongest()`.\n\n__Example:__\n\nDraw a five by five grid of incrementing numbers:\n\n```js\nlet positions = xy_grid(5, 50)\nconst cnv = Canvas()\nfor (const [i, [x, y]] of enumerate(positions)) {\n    cnv.text({text: i, x: x, y: y})\n}\ncnv.show()\n```\n\nFor an overview, see:\n\n- <https://www.npmjs.com/package/pythonic>", "url": "https://osdoc.cogsci.nl/4.0/manual/javascript/pythonic", "title": "Python-like iterators (pythonic)"}
{"content": "# About JavaScript\n\ntitle: About JavaScript\n\nIn OpenSesame you can create complex experiments using only the graphical user interface (GUI). But you will sometimes encounter situations in which the functionality provided by the GUI is insufficient. In these cases you can add JavaScript code to your experiment.\n\nJavaScript is for experiments that run in a browser with OSWeb. If you need to run your experiment on the desktop, you need to use [Python](%url:manual/python/about%) instead of JavaScript.\n\n__Version note:__ Desktop support for JavaScript was removed in OpeSesame 4.0. This is because JavaScript support on the desktop was incomplete and was perceived by users as confusing without adding much benefit.\n{: .page-notification}\n\n[TOC]\n\n\n## Learning JavaScript\n\nThere are many JavaScript tutorials available online. One good resource is Code Academy:\n\n- <https://www.codecademy.com/learn/introduction-to-javascript>\n\n\n## JavaScript in the OpenSesame GUI\n\n\n### Inline_javascript items\n\nIn order to use JavaScript code you need to add an INLINE_JAVASCRIPT item to your experiment. After you have done this you will see something like %FigInlineJavaScript.\n\n%--\nfigure:\n id: FigInlineJavaScript\n source: inline-javascript.png\n caption: The INLINE_JAVASCRIPT item.\n--%\n\nAs you can see, the INLINE_JAVASCRIPT item consists of two tabs: one for the Prepare phase and one for the Run phase. The Prepare phase is executed first, to allow items to prepare for the time-critical run phase. It is good practice to construct `Canvas` objects during the Prepare phase, so that they can be presented without delay during the Run phase. But this is only convention; you can execute arbitrary JavaScript code during both phases.\n\nFor more information about the prepare-run strategy, see:\n\n- %link:prepare-run%\n\n\n### Printing output to the console\n\nYou can print to the console with the `console.log()` command:\n\n```js\nconsole.log('This will appear in the console!')\n```\n\nWhen running on the desktop, the output will appear in the OpenSesame console (or: debug window). When running in a browser, the output will appear in the browser console.\n\n\n## Things to know\n\n### Common functions\n\nMany common functions are directly available in an INLINE_JAVASCRIPT item. For example:\n\n```js\n// `Canvas()` is a factory function that returns a `Canvas` object\nlet fixdotCanvas = Canvas()\nif (sometimes()) {  // Sometimes the fixdot is green\n    fixdotCanvas.fixdot({color: 'green'})\n} else {  // Sometimes it is red\n    fixdotCanvas.fixdot({color: 'red'})\n}\nfixdotCanvas.show()\n```\n\nFor a list of common functions, see:\n\n- %link:manual/javascript/common%\n\n\n### Declaring variables (let and var)\n\nINLINE_JAVASCRIPT items are executed in non-strict (or: sloppy) mode. This means that you can assign a value to a variable that was not explicitly declared. When you do this, the variable is implicitly declared using `var` if it wasn't already declared.\n\n```js\nmy_variable = 'my value'  // implicitly declared using var\n```\n\nVariables that are declared implicitly or explicitly using `var` are global, which primarily means that they may be logged by a LOGGER. Variables that are declared using `let` are not global, which primarily means that they are not logged by a LOGGER.\n\n```js\nthis_is_a_global_variable = 'my value'\nvar this_is_also_a_global_variable = 'my value'\nlet this_is_not_a_global_variable = 'my value'\n```\n\n\n### The `persistent` object: preserving objects across scripts\n\n__Version note__ As of OSWeb 2.0, all JavaScript code is executed in the same workspace and objects are therefore preserved across scripts. This means that you no longer need the `persistent` object.\n{:.page-notification}\n\nEach INLINE_JAVASCRIPT item is executed in its own workspace. This means\u2014and this is different from Python INLINE_SCRIPT items!\u2014that you cannot use variables or functions that you've declared in one script in another script. As a workaround, you can attach variables or functions as properties to the `persistent` object, which serves as a container of things that you want to preserve across scripts.\n\nThis way you can construct a `Canvas` in one INLINE_JAVASCRIPT ...\n\n```js\npersistent.myCanvas = Canvas()\npersistent.myCanvas.fixdot()\n```\n\n.. and show it in another INLINE_JAVASCRIPT:\n\n```js\npersistent.myCanvas.show()\n```\n\n\n### The `vars` object: Access to experimental variables\n\n__Version note__ As of OSWeb 2.0, all experimental variables are available as globals. This means that you no longer need the `vars` object.\n{:.page-notification}\n\nYou can access experimental variables through the `vars` object:\n\n```js\n// OSWeb <= 1.4 (with vars object)\n// Get an experimental variable\nconsole.log('my_variable is: ' + vars.my_variable)\n// Set an experimental variable\nvars.my_variable = 'my_value'\n\n// OSWeb >= 2.0 (without vars object)\n// Get an experimental variable\nconsole.log('my_variable is: ' + my_variable)\n// Set an experimental variable\nmy_variable = 'my_value'\n```\n\n\n### The `pool` object: Access to the file pool\n\nYou access 'files' from the file pool through the `pool` object. The most obvious use of this is to parse CSV files, for example with experimental conditions, from the file pool using the `csv-parse` library (described in more detail below).\n\n```js\nconst conditions = csvParse(\n    pool['attentional-capture-jobs.csv'].data,\n    {columns: true}\n)\nfor (const trial of conditions) {\n    console.log(trial.distractor)\n}\n```\n\nYou can also play sound files from the file pool directly. Assuming that there is a file called `bark.ogg` in the file pool, you can play it like so:\n\n```js\npool['bark.ogg'].data.play()\n```\n\n\n### The `Canvas` class: Presenting visual stimuli\n\nThe `Canvas` class is used to present visual stimuli. For example, you can show a fixation dot as follows:\n\n```js\nlet myCanvas = Canvas()\nmyCanvas.fixdot()\nmyCanvas.show()\n```\n\nA full overview of the `Canvas` class can be found here:\n\n- %link:manual/javascript/canvas%\n\n## Available JavaScript libraries\n\nThe following JavaScript libraries are included by default:\n\n- [random functions (`random-ext`)](%url:manual/javascript/random%)\n- [Color-conversion functions (`color-convert`)](%url:manual/javascript/color-convert%)\n- [CSV functions (`csv-parse`)](%url:manual/javascript/csv%)\n- [Python-like iterators (`pythonic`)](%url:manual/javascript/pythonic%)\n\nYou can include additional JavaScript libraries by URLs to the libraries in the 'External JavaScript' libraries field of the OSWeb control panel.\n\n\n## Debugging\n\nSee:\n\n- %link:debugging%", "url": "https://osdoc.cogsci.nl/4.0/manual/javascript/about", "title": "About JavaScript"}
{"content": "# Common functions\n\nThe provided API is a JavaScript API designed for use with OpenSesame, a software platform widely used for creating and conducting psychology experiments. This API consists of a suite of functions that can be employed within OpenSesame to add interactivity, collect data, and manipulate the experiment environment programmatically.\n\nThis API is particularly relevant for users who wish to enhance their psychology experiments with custom scripts and functionalities. It is designed to be used in conjunction with `Canvas` functions, which are part of OpenSesame's feature set for drawing stimuli and interfacing with the participant's visual input.\n\nUnfortunately, the actual list of functions and their parameters is not provided in the snippet above. The snippet indicates that there is a markdown document (likely containing the API documentation) included within the text, but the contents of this document are not directly visible. Normally, one would expect to see a bulleted list of functions here, each with a brief description of its purpose and the parameters it accepts.\n\nTo summarize, the API provides:\n\n- A set of JavaScript functions tailored for use in OpenSesame.\n- Capabilities that complement `Canvas` functions for visual stimuli presentation.\n- Tools to enhance the interactivity and data collection capabilities of psychology experiments.\n\nTo fully understand the API's capabilities, access to the included markdown document (javascript_workspace_api.md) would be necessary. That document would contain the specific details about each function, including their names, parameters, and descriptions of what they do.", "url": "https://osdoc.cogsci.nl/4.0/manual/javascript/common", "title": "Common functions"}
{"content": "# Common functions\n\ntitle: Common functions\n\n<summary_prompt>\nWrite a summary for the API below:\n\n- Describe the API's overall functionality\n- Explain that this is a JavaScript API for OpenSesame, software for implementing psychology experiments\n- Explain that these functions are commonly used in combination with `Canvas` functions\n- Provide a bulleted list of all available functions and their parameters. Don't just name the functions, but create one bullet per function.\n\nYour response should be a comprehensive summary.\n\n```markdown\n{content}\n```\n</summary_prompt>\n\n[TOC]\n\n\nThe following functions are available in INLINE_JAVASCRIPT items:\n\n<div class=\"cogsci-jsdoc\" markdown=\"1\">\n\n%-- include: include/javascript-api/javascript_workspace_api.md --%\n\n</div>", "url": "https://osdoc.cogsci.nl/4.0/manual/javascript/common", "title": "Common functions"}
{"content": "# random functions (random-ext)\n\ntitle: random functions (random-ext)\n\n\nThe `random-ext` library is available as `random`. This library provides many convenient, higher-level functions for randomization.\n\n__Example:__\n\nDraw eight circle with a random color and a location that is randomly sampled from a five by five grid:\n\n```js\nlet positions = xy_grid(5, 50)\npositions = random.subArray(positions, 8)\nconst cnv = Canvas()\ncnv.fixdot()\nfor (const [x, y] of positions) {\n    cnv.circle({x: x, y: y, r: 20, fill: true, color: random.color()})\n}\ncnv.show()\n```\n\nFor an overview, see:\n\n- <https://www.npmjs.com/package/random-ext>", "url": "https://osdoc.cogsci.nl/4.0/manual/javascript/random", "title": "random functions (random-ext)"}
{"content": "# Canvas functions\n\nThe API described is a JavaScript-based Application Programming Interface (API) designed specifically for OpenSesame, which is a software platform used for conducting psychological experiments. The overall functionality of this API centers around providing a means for experiment designers to create, manipulate, and display visual content on a digital canvas as part of their experimental setups.\n\nTo utilize this API for visual experiments, one must first initialize a `Canvas` object. Initializing a `Canvas` typically involves specifying its dimensions and optionally, the initial content that should be displayed. The canvas acts as a drawing surface where visual elements can be added or modified.\n\nThe `styleArgs` parameter is used to define the styling of the canvas and its elements. This could include details such as color, font, line thickness, and more. By setting `styleArgs`, users can customize the appearance of text, shapes, and other graphical elements to match their experimental design.\n\nIn terms of coordinates, the API uses a coordinate system where x=0 and y=0 represent the center of the display. This central origin allows for a more intuitive placement of elements on the canvas, especially in psychology experiments where stimuli often need to be positioned relative to a participant's focal point.\n\nThe available functions in the API cover a range of operations related to the `Canvas` object, including but not limited to:\n\n- **Creation of a new Canvas**: This function would initialize a new canvas with specified dimensions.\n- **Drawing shapes**: Parameters would include shape type (e.g., rectangle, circle), position, size, and style arguments.\n- **Adding text**: Parameters would include the text string, position, font specifications, and styling options.\n- **Clearing the canvas**: This function would remove all elements from the canvas, possibly with parameters to specify a certain area to clear.\n- **Updating elements**: Parameters would include the identifier of the element to update and the new values for its properties, such as position or style.\n- **Saving the canvas state**: This would allow the current state of the canvas to be saved for later restoration.\n- **Restoring a saved state**: This function would revert the canvas to a previously saved state.\n- **Exporting the canvas content**: Parameters could include the file format and options for what part of the canvas to export.\n\nPlease note that the exact names and parameters of the functions cannot be provided, as the actual API documentation content is not included in the provided text snippet. The bullet points listed are generic descriptions of common functions that one might expect to find in a canvas-manipulation API for psychological experiments.", "url": "https://osdoc.cogsci.nl/4.0/manual/javascript/canvas", "title": "Canvas functions"}
{"content": "# Canvas functions\n\ntitle: Canvas functions\n\n<summary_prompt>\nWrite a summary for the API below:\n\n- Describe the API's overall functionality\n- Explain that this is a JavaScript API for OpenSesame, software for implementing psychology experiments\n- Explain the process to initialize a `Canvas`\n- Define the usage of `styleArgs`\n- Explain coordinates: x=0, y=0 is the display center\n- Provide a bulleted list of all available functions and their parameters. Important: Don't just name the functions, but create one bullet per function.\n\nYour response should be a comprehensive summary.\n\n```markdown\n{content}\n```\n</summary_prompt>\n\n<div class=\"cogsci-jsdoc\" markdown=\"1\">\n\n%-- include: include/javascript-api/canvas.md --%\n\n</div>", "url": "https://osdoc.cogsci.nl/4.0/manual/javascript/canvas", "title": "Canvas functions"}
{"content": "# Color conversion functions (color-convert)\n\ntitle: Color conversion functions (color-convert)\n\n\nThe `color-convert` library is available as `convert`. It provides convenient high level functions for converting from one color specification to another.\n\n__Example:__\n\n```js\nconsole.log('The RGB values for blue are ' + convert.keyword.rgb('blue'))\n```\n\nFor an overview, see:\n\n- <https://www.npmjs.com/package/color-convert>", "url": "https://osdoc.cogsci.nl/4.0/manual/javascript/color-convert", "title": "Color conversion functions (color-convert)"}
{"content": "# Downloading and converting data\n\ntitle: Downloading and converting data\n\nAfter collecting data with OSWeb through JATOS, you can download and process this data for analysis. To download, navigate to your study within JATOS, click on 'Results', select all Result entries, and then choose 'Export Results \u2192 JATOS Results Archive' (see %FigJatosExportResults).\n\n%--\nfigure:\n id: FigJatosExportResults\n source: jatos-export-results.png\n caption: Procedure for exporting results collected with OSWeb through JATOS.\n--%\n\nThe downloaded file, typically named in the format `jatos_results_<timestamp>.jzip`, contains various folders and files corresponding to metadata and participant data. This format can be difficult to work with directly for data analysis.\n\nTo simplify data analysis, you can convert this file to a more accessible format like `.csv` or `.xlsx`. This conversion can be easily achieved by using the 'Convert OSWeb results to csv/xlsx' option found in the OSWeb extension.", "url": "https://osdoc.cogsci.nl/4.0/manual/osweb/data", "title": "Downloading and converting data"}
{"content": "# Running experiments online with OSWeb\n\ntitle: Running experiments online with OSWeb\n\n\n[TOC]\n\n\n## The workflow\n\nFor an introduction to the workflow, see also:\n\nMath\u00f4t, S., & March, J. (2022). Conducting linguistic experiments online with OpenSesame and OSWeb. *Language Learning*. doi:10.1111/lang.12509\n<br /><small>[Related preprint (not identical to published manuscript)](https://doi.org/10.31234/osf.io/wnryc)</small>\n\n\n### Developing your experiment\n\nFirst, you develop your experiment as you ordinarily would, using the OpenSesame desktop application. Not all functionality is available in online experiments. Notably, you cannot use Python INLINE_SCRIPT items, but have to use JavaScript INLINE_JAVASCRIPT items instead. During the development of your experiment, it is therefore important to check that your experiment is compatible with OSWeb.\n\n- %link:manual/osweb/osweb%\n- %link:manual/javascript/about%\n\n\n### Uploading your experiment to JATOS\n\nOnce you have developed your experiment, you publish it to JATOS. JATOS is a web server that manages experiments: it allows you to generate links that you can distribute participants, and it stores data that has been collected.\n\nThere is not a single JATOS server. Rather, many institutions maintain their own JATOS server. In addition, <https://mindprobe.eu> is a free JATOS server, sponsored by ESCoP and OpenSesame.\n\n- %link:jatos%\n\n\n### Collecting data\n\nOne you have published your experiment to JATOS, you can start collecting data. You can do this by manually sending links to participants, for example through email. Or you can use a platform for participant recruitment, such as Prolific, Mechanical Turk, or Sona Systems.\n\n- %link:prolific%\n- %link:mturk%\n- %link:sonasystems%\n\n\n### Analyzing data\n\nOnce data collection is finished, you can download the data from JATOS and convert it to `.xlsx` or `.csv` format for further analysis:\n\n- %link:manual/osweb/data%\n\n\n## Tutorials\n\n- %link:tutorials/intermediate-javascript%\n- %link:wcst%", "url": "https://osdoc.cogsci.nl/4.0/manual/osweb/workflow", "title": "Running experiments online with OSWeb"}
{"content": "# JATOS\n\ntitle: JATOS\n\n\n[TOC]\n\n\n## Introduction to JATOS\n\n[JATOS](https://www.jatos.org/) is a system for managing online experiments. It allows you to create accounts for experimenters, upload experiments, and generate links that you can distribute to participants. OpenSesame integrates closely with JATOS.\n\nTo access a JATOS server, you have three main options:\n\n- Request a free account on [MindProbe](https://mindprobe.eu/), a public JATOS server sponsored by ESCoP and OpenSesame.\n- se a JATOS server provided by your institution.\n- Download JATOS and install it on your own server.\n\n## Linking OpenSesame with JATOS/MindProbe\n\nOpenSesame requires an API token to access your account on a JATOS server such as MindProbe. Follow these steps to generate an API token:\n\n1. **Log into JATOS.**\n2. **Open your user profile** by clicking on your name located in the top right corner of the page.\n3. **Create an API token** by clicking on 'API tokens' to view all your current tokens, and then click 'New Token'.\n4. **Assign a name to your token**. This name serves as a descriptor indicating its intended use, such as 'OpenSesame integration'.\n5. **Set an expiration for your token**. Tokens default to expire after 30 days, requiring you to generate a new token each month. You can select 'No Expiration' for convenience, but be aware that it is less secure. If someone gains access to a non-expiring token, they can use it indefinitely, or until you revoke the token.\n\n%--\nfigure:\n id: FigAPIToken\n source: api-token.png\n caption: API tokens can be generated within your JATOS user profile.\n--%\n\nNote: An API token always begins with `jap_`, followed by a series of characters and numbers. Keep your token secure!\n\nOnce you have your API token, open the OSWeb and JATOS control panel in OpenSesame. Enter your API token into the corresponding field and also adjust the JATOS server URL, if necessary.\n\n%--\nfigure:\n id: FigJATOSControlPanel\n source: jatos-control-panel.png\n caption: Specify the JATOS server and your API token in the OSWeb and JATOS control panel.\n--%\n\n\n## Publishing experiments to, and downloading from, JATOS/MindProbe\n\nAfter successfully connecting OpenSesame to JATOS, as explained above, you can publish your experiment to JATOS. To do this, select the 'Publish to JATOS/MindProbe' option from the File menu. Upon initial publication, your experiment will be assigned a unique identifier (UUID) that links it to a study on JATOS.\n\nYou can then visit your JATOS server and observe that the newly published experiment has been added to your list of studies.\n\nFrom that point forward, each time you publish the experiment, the existing JATOS study will be updated with the new version. If you wish to publish the experiment as a completely new study on JATOS, you will need to reset the JATOS UUID via the OSWeb and JATOS control panel.\n\nTo download an experiment from JATOS, select the 'Open from JATOS/MindProbe' option from the File menu. Please note, this function is only applicable if the corresponding JATOS study is compatible with OSWeb 2.", "url": "https://osdoc.cogsci.nl/4.0/manual/osweb/jatos", "title": "JATOS"}
{"content": "# Inline JavaScript\n\ntitle: Inline JavaScript\n\nThis page has moved to:\n\n- %link:manual/javascript/about%", "url": "https://osdoc.cogsci.nl/4.0/manual/osweb/javascript", "title": "Inline JavaScript"}
{"content": "# Sona Systems\n\ntitle: Sona Systems\n\n\n[TOC]\n\n\n## About Sona Systems\n\nSona Systems is an online tool that many universities use for recruiting participants, granting course credit to student participants, etc.\n\nSee also:\n\n- <https://www.sona-systems.com/help/integration_test.aspx>\n\n\n## Create a study on JATOS\n\nFirst, import your experiment into JATOS, as described above. Next, go the Worker & Batch Manager, activate the General Multiple Worker, get a URL by clicking on Get Link, and copy it.\n\n\n## Create a study on Sona Systems\n\nNext, create a study on Sona Systems. Insert the JATOS study URL in the field labeled \"Study URL\". This will tell Sona Systems how to start the experiment. Importantly, add the following to the end of the URL (this will pass the participant's Sona ID to your experiment):\n\n```bash\n?SONA_ID=%SURVEY_CODE%  \n```\n\nSona Systems does not use a Redirect URL. This means that Sona Systems will not automatically know whether or not the participant finished the study.\n\n\n## Register the Sona ID in your experiment\n\nEvery participant from Sona is identified by a unique ID. It's important to log this ID in your experiment, because this allows you to tell which participant from Sona corresponds to which entry in the JATOS results. You can do this by adding the script below in the Prepare phase of an `inline_javascript` item at the very start of your experiment.\n\nWhen running the experiment through Sona, this will make the Sona ID available as the experimental variable `sona_participant_id`. When the running the experiment in any other way (e.g. during testing), the variable `sona_participant_id` will be set to -1. \n\n\n```javascript\nif (window.jatos && jatos.urlQueryParameters.SONA_ID) {\n    console.log('Sona information is available')\n    var sona_participant_id = jatos.urlQueryParameters.SONA_ID\n} else {\n    console.log('Sona information is not available (setting value to -1)')\n    var sona_participant_id = -1\n}\nconsole.log('sona_participant_id = ' + sona_participant_id)\n```\n\n\n## Automatically grant credits on study completion\n\nSona Systems provides a completion URL (client-side), which should be called when a study is succesfully completed, so that Sona Systems can grant credit to the participant (see %FigCompletionURL).\n\n%--\nfigure:\n id: FigCompletionURL\n source: completion-url.png\n caption: The completion URL in the Sona Systems study information.\n--%\n\nThe completion URL (client side) has three arguments in it:\n\n- `experiment_id` which identifies the study and is the same for all participants\n- `credit_token` which (apparently) changes when you change the study information, but is otherwise the same for all participants\n- `survey_code` which corresponds to the Sona Participant ID, and is therefore different for each participant\n\nCopy the completion URL, and replace the `XXX` by `[SONA_ID]`. Go to Study Properties on JATOS, and insert the resulting URL into the End Redirect URL field.\n\n%--\nfigure:\n id: FigEndRedirectURL\n source: end-redirect-url.png\n caption: The end-redirect URL in the JATOS study properties.\n--%", "url": "https://osdoc.cogsci.nl/4.0/manual/osweb/sonasystems", "title": "Sona Systems"}
{"content": "# OSWeb\n\ntitle: OSWeb\n\n\n[TOC]\n\n\n## About OSWeb\n\nOSWeb is an online runtime for OpenSesame experiments. It is a JavaScript library that executes OpenSesame experiments in a browser. To use OSWeb, you need the `opensesame-extension-osweb` package, which comes pre-installed with the Windows and macOS distributions of OpenSesame.\n\n\n## Executing an experiment in a web browser\n\nTo run an experiment in a web browser using OSWeb, follow these steps:\n\n1. Open the Experiment Properties and select 'In a browser with OSWeb (osweb)' in the 'Run experiment' section.\n2. Click any of the 'Run' buttons to start the experiment.\n3. If the experiment is not compatible with OSWeb, an error message will appear that details the compatibility issues. (Refer to the 'supported functionality' section for more details.)\n4. If there are no compatibility issues, the experiment will open in a new browser window. Note that even though the experiment is running in a web browser, it is still executing locally on your own computer. To host the experiment online, you need to publish it to [JATOS](%url:jatos%).\n5. When the experiment is finished, the data will be downloaded in `.json` format. This data file can then be [converted to `.xlsx` or `.csv` format](%url:manual/osweb/data%) for further analysis.\n\n\n%--\nfigure:\n id: FigTestRun\n source: testrun.png\n caption: Open the Experiment Properties and select 'In a browser with OSWeb (osweb)' under 'Run experiment'.\n--%\n\n\n## OSWeb control panel\n\nFor more control over OSWeb experiments, you can access the OSWeb and JATOS control panel from the Tools menu. This panel offers a range of configuration options:\n\n- **Possible subject numbers:** When running an experiment from within JATOS, a subject number is randomly selected from this list. You can specify individual numbers using commas (e.g., '1,2,3') or number ranges (e.g., '1-10'). When running an experiment from within OpenSesame, this option does not apply, as the subject number is specified when the experiment starts.\n- **Make browser fullscreen:** This option determines whether the browser should switch to fullscreen mode when an experiment starts within JATOS. If you're running an experiment directly from OpenSesame, this option is ignored; instead, you can run the experiment fullscreen by using the regular Run button, while the Quick Run button does not enable fullscreen.\n- **Show OSWeb Welcome Screen:** This toggle controls whether participants will see a welcome screen before the experiment starts. The welcome screen can convey crucial information to participants. Additionally, it serves a technical purpose\u2014due to browser-security policies, media playback and certain functionality is only available if the experiment is initiated by a user action. Therefore, it is generally recommended to leave this option enabled.\n- **Bypass Compatibility Check:** Enabling this option allows you to run the experiment even when the OSWeb compatibility check fails. Note that doing so will not automagically resolve compatibility issues!\n- **Welcome Text:** This field allows you to customize the welcome message displayed to participants on the welcome screen.\n- **External Libraries:** This field lets you specify any external libraries that should be loaded with your experiment. The use of external libraries is explained in more detail in the section below.\n\n\n%--\nfigure:\n id: FigOSWebControlPanel\n source: osweb-control-panel.png\n caption: The OSWeb and JATOS control panel offers a range of configuration options for your OSWeb experiments.\n--%\n\n\n## Supported functionality\n\nWhen you run the experiment from within OpenSesame, a compatibility check is automatically performed. However, this check is fairly superficial. A more complete overview of supported functionality can be found below.\n\n\n- `advanced_delay`\n- `feedback`\n    - See `sketchpad`\n- `form_consent` (supported >= v1.4)\n- `form_text_display` (supported >= 1.4)\n- `form_text_input` (supported >= 1.4)\n    - Unsupported: fullscreen mode\n- `form_multiple_choice` (supported >= 1.4)\n- `inline_html` (supported >= 1.4)\n- `inline_javascript`\n- `keyboard`\n    - Unsupported: key release\n    - Unsupported: HSV, HSL, and CIELab color spaces\n- `logger`\n- `loop`\n    - Unsupported: resume after break\n    - Unsupported: Disabling of evaluate on first cycle\n    - Unsupported: constraints (pseudorandomization)\n    - Supported >= 1.4: file source\n- `mouse`\n    - Unsupported: mouse release\n    - Unsupported: linked sketchpad\n- `notepad`\n- `repeat_cycle`\n- `reset_feedback`\n- `sampler`\n    - Supported >= 1.4.12: panning, pitch, and fade in\n    - Supported >= 1.4.12: Sound playback on Safari on Mac OS or any browser on iOS\n    - Unsupported: stop after\n- `sequence`\n- `sketchpad`\n    - Unsupported: named elements\n    - Supported >= 1.4: image rotation\n    - Unsupported: HSV, HSL, and CIELab color spaces\n- `touch_response`\n\n\nThe compatibility check may also indicate errors of the following type:\n\n> The prepare phase for item new_logger is called multiple times in a row\n\nThis error results from how the experiment is structured, and specifically the use of linked copies. It's not always easy to understand where this error comes from, but you can read more about the prepare-run strategy in [this article](%url:prepare-run%). As a workaround, you can put the problematic items in a dummy LOOP, that is, a LOOP that simply calls the item once.\n\n\n## Including external JavaScript packages\n\nYou can include external JavaScript packages by entering URLs to these packages (one URL per line) in the input field labeled 'External JavaScript libraries'. These packages are then included with `<script>` tags in the head of the HTML.\n\nFor example, you can include [WebGazer](%url:webgazer%) for in-browser by entering the following link:\n\n```\nhttps://webgazer.cs.brown.edu/webgazer.js\n```\n\n\n## Debugging\n\nSee:\n\n- %link:debugging%", "url": "https://osdoc.cogsci.nl/4.0/manual/osweb/osweb", "title": "OSWeb"}
{"content": "# Questionnaires in OSWeb\n\ntitle: Questionnaires in OSWeb\n\n\n## Forms and custom HTML\n\nForms and custom HTML are supported as of OSWeb 1.4\n{:.page-notification}\n\nYou can use the form plugins as described here:\n\n- %link:manual/forms/about%\n\nThe FORM_BASE plugin is *not* supported in OSWeb. Instead, you can use the INLINE_HTML item to implement custom HTML forms, as described here:\n\n- %link:manual/forms/html%\n\n\n## Linking to a different platform\n\nAs an alternative, you can implement a questionnaire using another platform, such as [LimeSurvey](https://www.limesurvey.org/), and then link to this questionnaire from your OSWeb experiment. The video below shows how to do this in such a way that you can tell afterwards which questionnaire data belongs to which OSWeb data.\n\n%--\nvideo:\n source: youtube\n id: BeginnerTutorial\n videoid: 1WvTUQr0JL0\n width: 640\n height: 360\n caption: |\n  Combining OSWeb and LimeSurvey.\n--%", "url": "https://osdoc.cogsci.nl/4.0/manual/osweb/questionnaires", "title": "Questionnaires in OSWeb"}
{"content": "# Mechanical Turk\n\ntitle: Mechanical Turk\n\n\nThere is currently no information that is specific to running OSWeb experiments on Mechanical Turk. For general information about connecting JATOS to Mechanical Turk, see:\n\n- <http://www.jatos.org/Connect-to-Mechanical-Turk.html>", "url": "https://osdoc.cogsci.nl/4.0/manual/osweb/mturk", "title": "Mechanical Turk"}
{"content": "# Prolific\n\ntitle: Prolific\n\n\n[TOC]\n\n\n## About Prolific\n\n[Prolific](https://prolific.co/) is a commercial tool for recruiting participants for research. To run OSWeb experiments on Prolific, you need to follow the steps explained below.\n\nSee also:\n\n- <http://www.jatos.org/Use-Prolific.html>\n\n\n## Create a study on JATOS\n\nFirst, import your experiment into JATOS, as described above. Next, go the Worker & Batch Manager, activate the General Multiple Worker, get a URL by clicking on Get Link, and copy it (%FigJatosURL).\n\n\n%--\nfigure:\n id: FigJatosURL\n source: jatos-url.png\n caption: Get a study URL from JATOS.\n--%\n\n\n\n## Create a study on Prolific\n\nNext, create a study on Prolific. Under Study Details (%FigProlific), insert the JATOS study URL in the field labeled \"What is the URL of your study?\". This will tell Prolific how to start the experiment. Importantly, add the following to the end of the URL (this will pass important information from Prolific to your experiment):\n\n{% raw %}\n```bash\n&PROLIFIC_PID={{%PROLIFIC_PID%}}&STUDY_ID={{%STUDY_ID%}}&SESSION_ID={{%SESSION_ID%}}\n```\n{% endraw %}\n\nWhen the experiment is finished, Prolific needs to know about it. For this purpose, Prolific uses an End Redirect URL, which is listed in the field labeled \"To prove that participants have completed your study \u2026\". Copy this End Redirect URL. Also check the box labeled \"I've set up my study to redirect to this url at the end\".\n\n%--\nfigure:\n id: FigProlific\n source: prolific.png\n caption: Study details on Prolific.\n--%\n\n\n\n## Set an End Redirect URL in JATOS\n\nNow go back to JATOS, and open the Properties of your study (%FigJatosProperties). There, paste the End Redirect URL that you have copied from Prolific in the field labeled \"End Redirect URL\". This will tell JATOS that the participant should be redirected back to Prolific when the experiment is finished, so that Prolific knows that the participant completed the experiment.\n\n\n%--\nfigure:\n id: FigJatosProperties\n source: jatos-properties.png\n caption: Set the End Redirect URL in JATOS.\n--%\n\n\n## Register Prolific information in your experiment\n\nEvery participant from Prolific is identified by a unique ID. It's important to log this ID in your experiment, because this allows you to tell which participant from Prolific corresponds to which entry in the JATOS results. You can do this by adding the script below in the Prepare phase of an `inline_javascript` item at the very start of your experiment.\n\nWhen running the experiment through Prolific, this will make the Prolific ID available as the experimental variable `prolific_participant_id`. When the running the experiment in any other way (e.g. during testing), the variable `prolific_participant_id` will be set to -1. The same logic applied to the Prolific Study ID (`prolific_study_id`) and the Prolific Session ID (`prolific_session_id`).\n\n\n```javascript\nif (window.jatos && jatos.urlQueryParameters.PROLIFIC_PID) {\n    console.log('Prolific information is available')\n    var prolific_participant_id = jatos.urlQueryParameters.PROLIFIC_PID\n    var prolific_study_id = jatos.urlQueryParameters.STUDY_ID\n    var prolific_session_id = jatos.urlQueryParameters.SESSION_ID\n} else {\n    console.log('Prolific information is not available (setting values to -1)')\n    var prolific_participant_id = -1\n    var prolific_study_id = -1\n    var prolific_session_id = -1\n}\nconsole.log('prolific_participant_id = ' + prolific_participant_id)\nconsole.log('prolific_study_id = ' + prolific_study_id)\nconsole.log('prolific_session_id = ' + prolific_session_id)\n```\n\n\n## Test the study\n\nGo back to the Study Details page on Prolific. At the bottom of the page, there is a Preview button. This allows you to test the experiment by acting as a participant yourself. Don't forget to check the JATOS results to make sure that the experiment has successfully finished, and that all the necessary information (including the Prolific information) has been logged!", "url": "https://osdoc.cogsci.nl/4.0/manual/osweb/prolific", "title": "Prolific"}
{"content": "# Looping and independent variables\n\ntitle: Looping and independent variables\n\nThe LOOP item has two important functions:\n\n- It runs another item multiple times.\n- It is where you usually define your independent variables; that is, the variables that you manipulate in your experiment.\n\n[TOC]\n\n## The item to run\n\nA LOOP is always connected to a single other item: the item to run. You select the item to run in the box labeled \"Run\". In most cases, the item to run is a SEQUENCE, which runs multiple items sequentially.\n\nTwo common SEQUENCE-LOOP structures are:\n\n- If a SEQUENCE corresponds to a single trial (by convention called *trial_sequence*), then a LOOP that is connected to this sequence corresponds to multiple trials, or a block (by convention called *block_loop*).\n- If a SEQUENCE corresponds to a block of trials followed by a feedback display (by convention called *block_sequence*), then a loop that is connected to this sequence corresponds to multiple blocks, or a complete experimental session (by convention called *experimental_loop*).\n\n## Defining independent variables\n\nThe loop table is a powerful-yet-simple way to define independent variables. Every column in the table corresponds to a variable; every row corresponds to a cycle, that is, a level of the variable. For example, a simple loop with one variable (`animal`) that has two cycles (\"cat\" and \"dog\") looks like this:\n\nanimal |\n------ |\ncat    |\ndog    |\n\nThe loop has a few important options:\n\n*Repeat* indicates how often each cycle should be executed. In the example above, repeat is set to 2, which means that *trial_sequence* is called twice while the variable `animal` has the value \"cat\", and twice while `animal` has the value \"dog\" (so four times in total).\n\n*Order* indicates whether cycles should be executed sequentially or in random order. Randomization is complete, in the sense that the complete list of number-of-cycles \u00d7 repeat trials is randomized.\n\n## Reading independent variables from file\n\nIf you want to read independent variables from file, rather than entering them into the loop table, you can do so as follows:\n\n- Set *Source* to *file*.\n- Select an Excel (`.xlsx`) or CSV (`.csv`) file in the *File* entry.\n\nThe source file follows the same conventions as the loop table; that is, each column corresponds to a variable, and each row corresponds to a cycle.\n\nCSV files are expected to be in the following format:\n\n- plain-text\n- comma-separated\n- double-quoted (literal double-quotes are escaped with backward slashes)\n- UTF-8 encoded\n\n## Breaking the loop\n\nIf you want to break the loop before all cycles have been executed, you can specify a break-if expression. This break-if expression follows the same syntax as other conditional expressions, as described on:\n\n- %link:manual/variables%\n\nFor example, the following break-if statement would break the loop as soon as a correct response is given:\n\n```python\ncorrect == 1\n```\n\nThe *Evaluate on first cycle* option indicates whether the break-if statement should be evaluated before the first cycle, in which case no cycles may be executed at all, or only before the second cycle, in which case at least one cycle is always executed. In some cases, the break-if statement will refer to a variable that is only defined after the first cycle, in which case you should disable the 'Evaluate on first cycle' option to avoid a 'Variable does not exist' error.\n\n## Generating a full-factorial design\n\nBy clicking on the *Full-factorial design* you open a wizard that allows you to easily generate a full-factorial design, that is, a design in which each combination of factors occurs.\n\n## Pseudorandomization\n\nYou can add constraints for pseudorandomization to the script of the loop item. This shuffles the rows, even if Order is set to sequential. (Currently, this is not possible through the GUI.)\n\nExample: Make sure that repetitions of the same word (given by the `word` variable) are separated by at least 4 cycles:\n\n```python\nconstrain word mindist=4\n```\n\nExample: Make sure that the same word is not repeated:\n\n```python\nconstrain word maxrep=1\n```\n\n`constrain` commands must come *after* `setcycle` commands.\n\n## Advanced loop operations\n\nCommands for advanced loop operations must come *after* `constrain` and `setcycle` commands.\n\n### fullfactorial\n\nThe `fullfactorial` instruction treats the loop table as the input for a full-factorial design. For example, the following loop table:\n\ncue   | duration\n----- | --------\nleft  | 0\nright | 100\n      | 200\n\nWould result in:\n\ncue   | duration\n----- | --------\nleft  | 0\nleft  | 100\nleft  | 200\nright | 0\nright | 100\nright | 200\n\n### shuffle\n\n`shuffle` without argument randomizes the entire table. When a column name is specified (`shuffle cue`), only that column is randomized.\n\n### shuffle_horiz\n\n`shuffle_horiz` shuffles all columns horizontally. When multiple columns are specified, only those columns are shuffled horizontally.\n\nFor example, when `shuffle_horiz word1 word2` is applied to the following table:\n\nword1 | word2 | word3\n----- | ----- | -----\ncat   | dog   | bunny\ncat   | dog   | bunny\ncat   | dog   | bunny\n\nThe result could be (i.e. values are randomly swapped between `word1` and `word2`, but not `word3`):\n\nword1 | word2 | word3\n----- | ----- | -----\ndog   | cat   | bunny\ndog   | cat   | bunny\ncat   | dog   | bunny\n\n### slice\n\n`slice [from] [to]` selects a slice from the loop. It requires a start and an end index, where 0 is the first row, and negative values are counted from the end backwards. (Just like list slicing in Python, in other words.)\n\nFor example, when `slice 1 -1` is applied to the following table:\n\nword  |\n----- |\ncat   |\ndog   |\nbunny |\nhorse |\n\nThe result would be:\n\nword  |\n----- |\ndog   |\nbunny |\n\n### sort\n\n`sort [column]` sorts a single column, without changing any of the other columns.\n\n### sortby\n\n`sortby [column]` sorts the entire table by a single column.\n\n### reverse\n\n`reverse` reverses the order of the entire table. If a column name is specified (e.g. `reverse word`), only that column is reversed, without changing any of the other columns.\n\n### roll\n\n`roll [value]` rolls the entire table forward (for positive values) or backward (for negative values). If a column name is specified (e.g. `roll 1 word`), only that column is rolled, without changing any of the other columns.\n\nFor example, if `roll 1` is applied to the following table:\n\nword  |\n----- |\ncat   |\ndog   |\nbunny |\nhorse |\n\nThe result would be:\n\nword  |\n----- |\nhorse |\ncat   |\ndog   |\nbunny |\n\n### weight\n\n`weight [column]` repeats each row by a weighting value specified in a column.\n\nFor example, if `weight w` is applied to the following table:\n\nword  | w\n----- | -\ncat   | 0\ndog   | 0\nbunny | 2\nhorse | 1\n\nThe result would be:\n\nword  | w\n----- | -\nbunny | 2\nbunny | 2\nhorse | 1\n\n## Previewing the loop\n\nIf you have specified constraints, or have used advanced loop operations, then it is a good idea to check that the result is as expected. To do so, you can generate a preview of the loop table as it will be (or could be, in case of randomization) when you run the experiment.\n\nTo generate a preview, click on the *Preview* button.\n\n\n## Accessing the loop table in Python inline script\n\nThe original LOOP table, as you see it in the OpenSesame user interface, is a [`DataMatrix`](http://datamatrix.cogsci.nl/) object called `dm`, and is a property of the LOOP item.\n\nThis original LOOP table is usually transformed in various ways; for example, the order of the rows can be randomized, and rows can be repeated multiple times. The transformed LOOP is also a `DataMatrix` object, and is called `live_dm`. `live_dm` is created just before the loop is executed and is set to `None` when the loop is finished; that is, `live_dm` is only available during the *run* phase of the LOOP.\n\nFinally, the index of the current row is stored as the experimental variable `live_row`. That is, `live_row` indicates the currently active row of `live_dm`.\n\nSo let's say that we have a LOOP called *block_loop*. We could then access the LOOP table in a Python inline script as follows:\n\n~~~ .python\nprint('The original loop table:')\nprint(items['block_loop'].dm)\n\nprint('The transformed loop table:')\nprint(items['block_loop'].live_dm)\n\nprint('The current row:')\nprint(items['block_loop'].live_dm[var.live_row])\n~~~\n\nYou can even programatically define the LOOP table. You have to do this in the Prepare phase of an INLINE_SCRIPT that precedes the LOOP.\n\n```python\nfrom datamatrix import DataMatrix\n\nitems['block_loop'].dm = DataMatrix(length=4)\nitems['block_loop'].dm.cue_side = 'left', 'right', 'left', 'right'\nitems['block_loop'].dm.cue_validity = 'valid', 'valid', 'invalid', 'invalid'\n```\n\n`DataMatrix` objects are powerful structures for working with tabular data. For more information, see:\n\n- <https://pydatamatrix.eu/>", "url": "https://osdoc.cogsci.nl/4.0/manual/structure/loop", "title": "Looping and independent variables"}
{"content": "# Doing things in parallel\n\ntitle: Doing things in parallel\n\n\nCoroutines run multiple items in parallel\u2014or, to be more exact, they run items in rapid alternation in a way that looks parallel. Not all items support coroutines.\n\n\n[TOC]\n\n\n## Using coroutines\n\nYou can use coroutines through the COROUTINES plugin (see %FigCoroutinesInterface).\n\n\n%--\nfigure:\n source: FigCoroutinesInterface.png\n caption: The interface of the coroutines plugin.\n id: FigCoroutinesInterface\n--%\n\n\nAs you can see, the COROUTINES plugin looks similar to the SEQUENCE item, but has a few extra options:\n\n- *Duration* indicates the total duration of the coroutines.\n- *End after item (optional)* indicates that the coroutines should end when a specific item has ended. This allows you, for example, to indicate that the coroutines should end when a key press has been collected, by selecting a KEYBOARD_RESPONSE item here.\n- Each item has a *Start time*. Most items also have an *End time*. The end time does not apply to one-shot items; for example, SKETCHPADs show a display and terminate immediately, so they have no end time.\n\nSpecifically, the example from %FigCoroutinesInterface (from the stop-signal-task example) does the following:\n\n- It shows a target display immediately.\n- If the `stop_after` variable is not empty, it shows the stop_signal display after an interval specified by the `stop_after` variable.\n- During the entire (2000 ms) interval, a keyboard response is collected.\n\nThe temporal flow is controlled by the COROUTINES plugin. Therefore, the timeout and duration values specified in the items are not used. For example, in %FigCoroutinesInterface, the KEYBOARD_RESPONSE will run for 2000 ms, regardless of the timeout that is specified in the item.\n\n\n## Supported items\n\nCurrently, the following items are supported (this list may not be exhaustive):\n\n- FEEDBACK\n- INLINE_SCRIPT\n- KEYBOARD_RESPONSE\n- LOGGER\n- MOUSE_RESPONSE\n- SAMPLER\n- SYNTH\n- SKETCHPAD\n\n\n## Using inline_script items in coroutines\n\nWhen you use an INLINE_SCRIPT item in a COROUTINES, the Run phase works a little differently from what you might be used to. Specifically, the Run phase is executed on every iteration of the COROUTINES. In addition, the Run phase should only contain code that takes very little time to execute; this is because time-consuming operations will block the COROUTINES, thus interfering with the timing of other items in the COROUTINES as well. To end the COROUTINES, you can raise an `AbortCoroutines()` exception.\n\nFor example, say that you have a COROUTINES with two KEYBOARD_RESPONSE items, *kb1* and *kb2*, and you want to run the COROUTINES until two key presses have been collected, with a timeout of 5000 ms. You could then create the following COROUTINES structure:\n\n\n%--\nfigure:\n source: FigCoroutinesTwoResponses.png\n caption: A coroutines that collects two keypress responses\n id: FigCoroutinesTwoResponses\n--%\n\nThe *check_responses* INLINE_SCRIPT would then first set both responses variables to an empty string in the Prepare phase:\n\n```python\n# This is executed at the start of the coroutines\nresponse_kb1 = ''\nresponse_kb2 = ''\n```\n\nAnd then, in the Run phase, check if both variables have been set, and abort the coroutines if this is the case:\n\n```python\n# Values that are not an empty string are True for Python\n# This code will be executed many times!\nif response_kb1 and response_kb2:\n    raise AbortCoroutines()\n```\n\n## Run-if expressions\n\nThe behavior of run-if expressions in COROUTINES is a bit different from that in SEQUENCE items. Specifically, run-if expressions in COROUTINES are evaluated during the prepare phase. See also:\n\n- %link:prepare-run%", "url": "https://osdoc.cogsci.nl/4.0/manual/structure/coroutines", "title": "Doing things in parallel"}
{"content": "# Doing things in sequence\n\ntitle: Doing things in sequence\n\nThe SEQUENCE item has two important functions:\n\n- It runs multiple other items one after another.\n- It determines which items should, and which shouldn't, be run.\n\nSEQUENCEs are run from top to bottom; that is, the item at the top is run first. The order of a SEQUENCE is always sequential.\n\n## Run-if expressions\n\nYou can use run-if expressions to determine whether or not a particular item should be run. For example, if you want a display to be presented only if a participant has made an incorrect response, you can set the run-if expressions for that item to:\n\n```python\ncorrect == 0\n```\n\nIf you leave the run-if expressions empty or enter `True`, the item will always be run. Run-if expressions use the same syntax as other conditional expressions. For more information, see:\n\n- %link:manual/variables%\n\nRun-if expressions only affect which items are run, not which items are prepared. Phrased differently, the Prepare phase of all items in a SEQUENCE is always executed, regardless of the run-if expressions. See also:\n\n- %link:prepare-run%\n\n\n## Disabling items\n\nTo completely disable an item in a SEQUENCE, right-click on it and select 'Disable'. This is mostly useful during development of your experiment, for example to temporarily bypass the instructions.", "url": "https://osdoc.cogsci.nl/4.0/manual/structure/sequence", "title": "Doing things in sequence"}
{"content": "# GazePoint / OpenGaze\n\ntitle: GazePoint / OpenGaze\n\nPyGaze offers *experimental* support for GazePoint eye trackers through the OpenGaze API as of OpenSesame 3.3.11. For more information, see:\n\n- %link:pygaze%\n- <https://www.gazept.com/>", "url": "https://osdoc.cogsci.nl/4.0/manual/eyetracking/gazepoint", "title": "GazePoint / OpenGaze"}
{"content": "# WebGazer.js\n\ntitle: WebGazer.js\n\nRequires OSWeb v1.4.6.1\n{:.page-notification}\n\n[TOC]\n\n\n## About WebGazer\n\nWebGazer.js is an eye-tracking library written in JavaScript. You can include it with OSWeb to perform eye tracking in online experiments.\n\n- <https://webgazer.cs.brown.edu/>\n\n\n## Including WebGazer.js in the experiment\n\nWebGazer.js is not bundled with OSWeb by default. However, you can include it as an external library by entering a link to `webgazer.js` under External JavaScript libraries. Currently, a functional link is:\n\n```\nhttps://webgazer.cs.brown.edu/webgazer.js\n```\n\nSee also:\n\n- %link:manual/osweb/osweb%\n\n\n## Example experiment\n\nBelow you can download an example experiment that uses WebGazer.js. Participants are first asked to click on and look at a set of dots; this will cause WebGazer.js to automatically perform something akin to a calibration procedure. Next, the experiment shows a simple screen to test the accuracy of gaze-position recording. In general, fine-grained eye tracking is not feasible, but you can tell which quadrant of the screen a participant is looking at. To run this experiment, you need include WebGazer.js in the experiment, as described above. \n\n- %static:attachments/webgazer.osexp%\n\nYou can also launch the experiment directly in the browser:\n\n- <https://jatos.mindprobe.eu/publix/BowSAFY2VWl>", "url": "https://osdoc.cogsci.nl/4.0/manual/eyetracking/webgazer", "title": "WebGazer.js"}
{"content": "# Tobii\n\ntitle: Tobii\n\nPyGaze offers *experimental* support for Tobii eye trackers.\n\n`tobii-research` is the Python library for Tobii support. As of July 2023, `tobii-research` requires Python 3.10, whereas OpenSesame by default uses Python 3.11. Therefore, until `tobii-research` is updated for Python 3.11, the easiest way to install OpenSesame with Tobii support is by building a Python 3.10 environment through Anaconda.\n\nThis sounds complicated, but it is really not. To do so, first read the general procedure for installing OpenSesame through Anaconda as described on the Downloads page:\n\n- %link:download%\n\nNext, once you understand the general procedure, start by creating a Python 3.10 environment, continue with the instructions from the Downloads page, and then install `tobii-research`:\n\n```\n# Start by creating a Python 3.10 environment\nconda create -n opensesame-py3 python=3.10\nconda activate opensesame-py3\n# Now follow the instructions from the downloads page\n# ...\n# Then install Tobii support\npip install tobii-research\n# And now launch OpenSesame!\nopensesame\n```\n\nFor more information, see:\n\n- %link:pygaze%\n- <https://rapunzel.cogsci.nl/manual/environment/>\n- <http://www.tobii.com/en/eye-tracking-research/global/>", "url": "https://osdoc.cogsci.nl/4.0/manual/eyetracking/tobii", "title": "Tobii"}
{"content": "# EyeTribe\n\ntitle: EyeTribe\n\nThe EyeTribe is supported through PyGaze. For more information, see:\n\n- %link:pygaze%", "url": "https://osdoc.cogsci.nl/4.0/manual/eyetracking/eyetribe", "title": "EyeTribe"}
{"content": "# Eyelink\n\ntitle: Eyelink\n\n[TOC]\n\n## About EyeLink\n\nThe Eyelink series of eye trackers, produced by SR Research, are one of the most commonly used eye trackers in psychological research. SR Research provides Python bindings for the Eyelink (called PyLink), which are used by PyGaze. The license of PyLink is incompatible with the license used by OpenSesame. For that reason, PyLink is not included in the default distribution of OpenSesame, and needs to be installed separately.\n\n\n## Windows\n\n### Installing the EyeLink Developers Kit\n\nThe Eyelink Developers Kit (sometimes called Display Software) provides the libraries that are required to communicate with the Eyelink PC. You can find it here (free registration required):\n\n- <https://www.sr-research.com/support/thread-13.html>\n\nIf you extract the `.zip`, and then run the `.exe` installer, the EyeLink display will be installed in one of the following folders (depending on your version of Windows:\n\n```\nC:\\Program Files\\SR Research\\EyeLink\\\nC:\\Program Files (x86)\\SR Research\\EyeLink\n```\n\nIn this folder, there is a `libs` subfolder, which you need to add to the system Path (this may have been added to the path automatically, but check to make sure). You can do this by opening \"My Computer\", clicking on \"View system information\", opening the \"Advanced\" tab, clicking on \"Environment Variables\" and appending `;C:\\Program Files\\SR Research\\EyeLink\\libs` or (depending on your system) `;C:\\Program Files (x86)\\SR Research\\EyeLink\\libs` to the Path variable (under System variables).\n\n\n### Installing OpenSesame with PyLink\n\nPyLink is the Python library for EyeLink support. PyLink can be installed from the SR Research PyPi repository through `pip install`:\n\n```\npip install --index-url=https://pypi.sr-research.com sr-research-pylink\n```\n\nYou can find more information about PyLink on the SR Research forum (free registration required):\n\n- <https://www.sr-research.com/support/thread-8291.html>\n\n\n## Ubuntu\n\nThe EyeLink display software can be installed directly from a repository. This also installs PyLink and various convenient tools, such ast the `edf2asc` converter.\n\n```bash\nsudo add-apt-repository 'deb [arch=amd64] https://apt.sr-research.com SRResearch main'\nsudo apt-key adv --fetch-keys https://apt.sr-research.com/SRResearch_key\nsudo apt-get update\nsudo apt-get install eyelink-display-software\n```\n\nFor more information, please visit:\n\n- <https://www.sr-support.com/thread-13.html>\n\n\n## PyGaze\n\nAfter you have install the EyeLink display software and PyLink per the instructions above, you can use the EyeLink with PyGaze! See:\n\n- %link:pygaze%", "url": "https://osdoc.cogsci.nl/4.0/manual/eyetracking/eyelink", "title": "Eyelink"}
{"content": "# PyGaze (eye tracking)\n\ntitle: PyGaze (eye tracking)\n\n[TOC]\n\n## About\n\nPyGaze is a Python library for eye tracking. A set of plugins allow you to use PyGaze from within OpenSesame. For more information on PyGaze, visit:\n\n- <http://www.pygaze.org/>\n\nPlease cite PyGaze as:\n\nDalmaijer, E., Math\u00f4t, S., & Van der Stigchel, S. (2014). PyGaze: An open-source, cross-platform toolbox for minimal-effort programming of eyetracking experiments. *Behavior Research Methods*. doi:10.3758/s13428-013-0422-2\n{: .reference}\n\n## Supported eye trackers\n\nPyGaze supports the following eye trackers:\n\n- [EyeLink](%link:eyelink%)\n- [EyeTribe](%link:eyetribe%)\n\nFor the following eye trackers, there is experimental support:\n\n- [EyeLogic](%link:eyelogic%)\n- [GazePoint / OpenGaze](%link:gazepoint%)\n- [SMI](%link:smi%)\n- [Tobii](%link:tobii%)\n\nYou can also perform basic eye tracking in online experiments with WebGazer.js:\n\n- [WebGazer.js](%link:webgazer%)\n\nPyGaze also includes two dummy eye trackers for testing purposes:\n\n- __Simple dummy__ \u2014 Does nothing.\n- __Advanced dummy__ \u2014 Mouse simulation of eye movements.\n\n## Installing PyGaze\n\n### Windows\n\nIf you use the official Windows package of OpenSesame, PyGaze is already installed.\n\n### Ubuntu\n\nIf you use Ubuntu, you can get PyGaze from the Cogsci.nl PPA:\n\n```\nsudo add-apt-repository ppa:smathot/cogscinl\nsudo apt-get update\nsudo apt-get install python-pygaze\n```\n\nOr, if you are using Python 3, change the last comment to:\n\n```\nsudo apt-get install python3-pygaze\n```\n\n## pip install (all platforms)\n\nYou can install PyGaze with `pip`:\n\n```\npip install python-pygaze\n```\n\n### Anaconda (all platforms)\n\n```\nconda install python-pygaze -c cogsci\n```\n\n## PyGaze OpenSesame plugins\n\nThe following PyGaze plugins are available:\n\n- PYGAZE_INIT \u2014 Initializes PyGaze. This plugin is generally inserted at the start of the experiment.\n- PYGAZE_DRIFT_CORRECT \u2014 Implements a drift correction procedure.\n- PYGAZE_START_RECORDING \u2014 Puts PyGaze in recording mode.\n- PYGAZE_STOP_RECORDING \u2014 Puts PyGaze out of recording mode.\n- PYGAZE_WAIT \u2014 Pauses until an event occurs, such as a saccade start.\n- PYGAZE_LOG \u2014 Logs experimental variables and arbitrary text.\n\n## Example\n\nFor an example of how to use the PyGaze plugins, see the PyGaze template that is included with OpenSesame.\n\nBelow is an example of how to use PyGaze in a Python INLINE_SCRIPT:\n\n~~~ .python\n# Create a keyboard and a canvas object\nmy_keyboard = Keyboard(timeout=0)\nmy_canvas = Canvas()\nmy_canvas['dot'] = Circle(x=0, y=0, r=10, fill=True)\n# Loop ...\nwhile True:\n\t# ... until space is pressed\n\tkey, timestamp = my_keyboard.get_key()\n\tif key == 'space':\n\t\tbreak\n\t# Get gaze position from pygaze ...\n\tx, y = eyetracker.sample()\n\t# ... and draw a gaze-contingent fixation dot!\n\tmy_canvas['dot'].x = x + my_canvas.left\n\tmy_canvas['dot'].y = y + my_canvas.top\n\tmy_canvas.show()\n~~~\n\n## Function overview\n\nTo initialize PyGaze in OpenSesame, insert the PYGAZE_INIT plugin into your experiment. Once you have done this, an `eyetracker` object will be available, which offers the following functions:\n\n%-- include: include/api/eyetracker.md --%", "url": "https://osdoc.cogsci.nl/4.0/manual/eyetracking/pygaze", "title": "PyGaze (eye tracking)"}
{"content": "# SMI\n\ntitle: SMI\n\nPyGaze offers *experimental* support for SMI eye trackers. (SMI no longer exists as a company, but its eye trackers are still used in some labs.) For more information, see:\n\n- %link:pygaze%", "url": "https://osdoc.cogsci.nl/4.0/manual/eyetracking/smi", "title": "SMI"}
{"content": "# EyeLogic\n\ntitle: EyeLogic\n\nPyGaze offers *experimental support* for EyeLogic eye trackers as of OpenSesame 3.3.11. For more information, see:\n\n- %link:pygaze%\n- <https://www.eyelogicsolutions.com/>", "url": "https://osdoc.cogsci.nl/4.0/manual/eyetracking/eyelogic", "title": "EyeLogic"}
{"content": "# Button box\n\ntitle: Button box\n\nThere are many different types of button boxes, and they all work in different ways. Therefore, there is no single OpenSesame item that works with all button boxes. (This is different from keyboards, which are standard devices that all work with the KEYBOARD_RESPONSE item.)\n\nCommon types of button boxes:\n\n- Some button boxes *emulate keypresses*. This is easy, because you can use the normal KEYBOARD_RESPONSE item.\n\t- %link:manual/response/keyboard%\n- Some button boxes *emulate a joystick*. This is also easy, because you can use the JOYSTICK plugin.\n\t- %link:joystick%\n- Some button boxes are compatible with the *Serial Response Box* that is developed by Psychology Software Tools. These button boxes are supported by the SRBOX plugin.\n\t- %link:srbox%\n- Some button boxes have their own Python libaries. In this case, you should be able to find example scripts of how to use the button box in Python, that is, in an OpenSesame INLINE_SCRIPT item.", "url": "https://osdoc.cogsci.nl/4.0/manual/response/buttonbox", "title": "Button box"}
{"content": "# Mouse responses\n\ntitle: Mouse responses\n\nMouse responses are collected with the MOUSE_RESPONSE item. The MOUSE_RESPONSE is primarily intended to collect individual mouse clicks. If you want to collect mouse-cursor trajectories, take a look at the MOUSETRAP plugins:\n\n- %link:mousetracking%\n\n[TOC]\n\n\n## Response variables\n\nThe MOUSE_RESPONSE sets the standard response variables as described here:\n\n- %link:manual/variables%\n\n\n## Mouse-button names\n\nMouse buttons have a number (`1`, etc.) as well as a name (`left_button`, etc.). Both can be used to specify correct and allowed responses, but the `response` variable will be set to a number.\n\n- `left_button` corresponds to `1`\n- `middle_button` corresponds to `2`\n- `right_button` corresponds to `3`\n- `scroll_up` corresponds to `4`\n- `scroll_down` corresponds to `5`\n\n\n## Correct response\n\nThe *Correct response* field indicates which response is considered correct. After a correct response, the `correct` variable is automatically set to 1; after an incorrect response or a timeout (i.e. everything else), `correct` is set to 0; if no correct response is specified, `correct` is set to 'undefined'.\n\nYou can indicate the correct response in three main ways:\n\n- *Leave the field empty.* If you leave the *Correct response* field empty, OpenSesame will automatically check if a variable called `correct_response` has been defined, and, if so, use this variable for the correct response.\n- *Enter a literal value.* You can explicitly enter a response, such as 1. This is only useful if the correct response is fixed.\n- *Enter a variable name.* You can enter a variable, such as '{cr}'. In this case, this variable will be used for the correct response.\n\nNote that the correct response refers to which mouse button was clicked, not to which region of interest was clicked (ROI); see the section below for more information about ROIs.\n\n## Allowed responses\n\nThe *Allowed responses* field indicates a list of allowed responses. All other responses will be ignored, except for 'Escape', which will pause the experiment. The allowed responses should be a semicolon-separated list of responses, such as '1;3' to allow the left and right mouse buttons. To accept all responses, leave the *Allowed responses* field empty.\n\nNote that the allowed responses refer to which mouse button can be clicked, not to which region of interest can be clicked (ROI); see the section below for more information about ROIs.\n\n\n%--include: include/timeout.md--%\n\n## Coordinates and regions of interest (ROIs)\n\nThe `cursor_x` and `cursor_y` variables hold the location of the mouse click.\n\nIf you indicate a linked SKETCHPAD, the variable `cursor_roi` will hold a comma-separated list of names of elements that contain the clicked coordinate. In other words, elements on the SKETCHPAD automatically serve as regions of interest for the mouse click.\n\nIf the correctness of a response depends on which ROI was clicked, you cannot use the `correct_response` variable for this, because this currently refers only to which mouse button was clicked. Instead you need to use a simple script.\n\nIn a Python INLINE_SCRIPT you can do this as follows:\n\n```python\nclicked_rois = cursor_roi.split(';')\ncorrect_roi = 'my_roi'\nif correct_roi in clicked_rois:\n    print('correct!')\n    correct = 1\nelse:\n    print('incorrect!')\n    correct = 0\n```\n\nWith OSWeb using a INLINE_JAVASCRIPT you can do this as follows:\n\n```js\nclicked_rois = cursor_roi.split(';')\ncorrect_roi = 'my_roi'\nif (clicked_rois.includes(correct_roi)) {\n    console.log('correct!')\n    correct = 1\n} else {\n    console.log('incorrect!')\n    correct = 0\n}\n```\n\n\n%--\nvideo:\n source: youtube\n id: VidMouseROI\n videoid: 21cgX_zHDiA\n width: 640\n height: 360\n caption: |\n  Collecting mouse clicks and using regions of interest.\n--%\n\n## Collecting mouse responses in Python\n\nYou can use the `mouse` object to collect mouse responses in Python:\n\n- %link:manual/python/mouse%", "url": "https://osdoc.cogsci.nl/4.0/manual/response/mouse", "title": "Mouse responses"}
{"content": "# Keyboard responses\n\ntitle: Keyboard responses\n\nKeyboard responses are collected with the KEYBOARD_RESPONSE item.\n\n[TOC]\n\n\n## Response variables\n\nThe KEYBOARD_RESPONSE sets the standard response variables as described here:\n\n- %link:manual/variables%\n\n## Key names\n\nKeys are generally identified by their character and/ or their description (depending on which is applicable). For example:\n\n- The `/` key is named 'slash' and '/'. You can use either of the two names.\n- The `a` is named 'a'.\n- The left-arrow key is named 'left'.\n\nIf you don't know what a particular key is named, you can:\n\n- Click on the 'List available keys' button; or\n- Create a simple experiment in which a KEYBOARD_RESPONSE is immediately followed by a FEEDBACK item with the text '{response}' on it. This will show the name of the previously collected response.\n\n\n## Correct response\n\nThe *Correct response* field indicates which response is considered correct. After a correct response, the `correct` variable is automatically set to 1; after an incorrect response (i.e. everything else), `correct` is set to 0; if no correct response is specified, `correct` is set to 'undefined'.\n\nYou can indicate the correct response in three main ways:\n\n- *Leave the field empty.* If you leave the *Correct response* field empty, OpenSesame will automatically check if a variable called `correct_response` has been defined, and, if so, use this variable for the correct response.\n- *Enter a literal value.* You can explicitly enter a response, such as 'left' in the case of a KEYBOARD_RESPONSE item. This is only useful if the correct response is fixed.\n- *Enter a variable name.* You can enter a variable, such as '{cr}'. In this case, this variable will be used for the correct response.\n\n\n## Allowed responses\n\nThe *Allowed responses* field indicates a list of allowed responses. All other responses will be ignored, except for 'Escape', which will pause the experiment. The allowed responses should be a semicolon-separated list of responses, such as 'a;left;/' for a KEYBOARD_RESPONSE. To accept all responses, leave the *Allowed responses* field empty.\n\n\n%--include: include/timeout.md--%\n\n## Collecting keyboard responses in Python\n\nYou can use the `keyboard` object to collect keyboard responses in Python:\n\n- %link:manual/python/keyboard%", "url": "https://osdoc.cogsci.nl/4.0/manual/response/keyboard", "title": "Keyboard responses"}
{"content": "# Sound recording\n\ntitle: Sound recording\n\n[TOC]\n\n\n## Audio Low Latency plugins\n\nThe Audio Low Latency plugins, developed by Bob Rosbag, are the recommended way to record sound input. The main goal of this set of plugins is to play and record audio with minimal and predictable latencies to achieve a high accuracy and precision. The `PyAlsaAudio` package which uses the Linux ALSA audio system provided the best results within Python. `PortAudio` and `sounddevice` are cross-platform and work on both Windows as Linux.\n\nThe plugins are not installed by default, but can be installed through pip:\n\n```bash\npip install opensesame-plugin-audio-low-latency\n```\n\nSee also:\n\n- <https://pypi.org/project/opensesame-plugin-audio-low-latency/>\n\n\n## Sound recorder plugins\n\nThe sound recorder plugins, developed by Daniel Schreij, are no longer under active development and are therefore no longer recommended. More information about this set of plugins can be found on previous version of this page:\n\n- <https://osdoc.cogsci.nl/3.2/manual/response/soundrecording/>", "url": "https://osdoc.cogsci.nl/4.0/manual/response/soundrecording", "title": "Sound recording"}
{"content": "# Joystick and gamepad\n\ntitle: Joystick and gamepad\n\nJoysticks and gamepads are supported through the JOYSTICK plugin.\n\n[TOC]\n\n%-- include: include/api/joystick.md --%", "url": "https://osdoc.cogsci.nl/4.0/manual/response/joystick", "title": "Joystick and gamepad"}
{"content": "# SR Box\n\ntitle: SR Box\n\n[TOC]\n\n## About the srbox plugin\n\nThe serial response (SR) box is a button box, specifically designed for response collection in psychological experiments. The original version, developed by Psychology Software Tools, has 5 buttons, 5 lights, and is connected to the PC trough the serial port. There are also SR Box compatible devices by other manufacturers, which may differ in the number of buttons and lights and often use a USB connection, which emulates a serial port.\n\nThe SRBOX plugin for OpenSesame allows you to use the SR Box or compatible device in your OpenSesame experiments.\n\n## Screenshot\n\n%--\nfigure:\n  source: srbox.png\n  id: FigSrbox\n  caption: The srbox plugin in OpenSesame.\n--%\n\n## Setting the device name\n\nBy default, the plugin tries to autodetect your SR Box. If this works, you don't have to change it. If your experiment freezes, OpenSesame has chosen the wrong serial port and you must enter the device name manually. Under Windows, the device is probably called something like\n\n```text\nCOM4\n```\n\nUnder Linux the device is probably called something like\n\n```text\n/dev/tty0\n```\n\n## Requirements\n\nAn SR Box or compatible button box. Not all button boxes are compatible, see:\n\n- %link:buttonbox%\n\n## Using the SR Box from Python inline code\n\nThe `srbox` object does *not* exist when the plug-in is in dummy mode.\n\n%-- include: include/api/srbox.md --%", "url": "https://osdoc.cogsci.nl/4.0/manual/response/srbox", "title": "SR Box"}
{"content": "# Access the file pool\n\ndummy", "url": "https://osdoc.cogsci.nl/4.0/manual/python/pool", "title": "Access the file pool"}
{"content": "# Access the file pool\n\ntitle: Access the file pool\n\n<summary_prompt>\nWrite a summary for the API below:\n\n- Describe the API's overall functionality\n- Explain that this is a Python API for OpenSesame, software for implementing psychology experiments\n- Explain that the `pool` object does not need to be imported\n- Give examples of how to:\n    - Check whether a file is in the file pool\n    - Retrieve the path to a file in the file pool\n- Provide a bulleted list of all available functions and their parameters. Important: Don't just name the functions, but create one bullet per function.\n\nYour response should be a comprehensive summary.\n\n```markdown\n{content}\n```\n</summary_prompt>\n\n%-- include: include/api/pool.md --%", "url": "https://osdoc.cogsci.nl/4.0/manual/python/pool", "title": "Access the file pool"}
{"content": "# Sampler functions\n\ndummy", "url": "https://osdoc.cogsci.nl/4.0/manual/python/sampler", "title": "Sampler functions"}
{"content": "# Sampler functions\n\ntitle: Sampler functions\n\n<summary_prompt>\nWrite a summary for the API below:\n\n- Describe the API's overall functionality\n- Explain that this is a Python API for OpenSesame, software for implementing psychology experiments\n- Explain that the `Sampler` class does not need to be imported\n- Explain the process to initialize a Sampler\n- Define the usage of `**playback_args`\n- Explain supported file formats\n- Provide a bulleted list of all available functions and their parameters. Important: Don't just name the functions, but create one bullet per function.\n\nYour response should be a comprehensive summary.\n\n```markdown\n{content}\n```\n</summary_prompt>\n\n%-- include: include/api/sampler.md --%", "url": "https://osdoc.cogsci.nl/4.0/manual/python/sampler", "title": "Sampler functions"}
{"content": "# Clock functions\n\ndummy", "url": "https://osdoc.cogsci.nl/4.0/manual/python/clock", "title": "Clock functions"}
{"content": "# Clock functions\n\ntitle: Clock functions\n\n<summary_prompt>\nWrite a summary for the API below:\n\n- Describe the API's overall functionality\n- Explain that this is a Python API for OpenSesame, software for implementing psychology experiments\n- Explain that the `clock` object does not need to be imported\n- Provide a bulleted list of all available functions and their parameters. Important: Don't just name the functions, but create one bullet per function.\n\nYour response should be a comprehensive summary.\n\n```markdown\n{content}\n```\n</summary_prompt>\n\n%-- include: include/api/clock.md --%", "url": "https://osdoc.cogsci.nl/4.0/manual/python/clock", "title": "Clock functions"}
{"content": "# Access response history\n\ndummy", "url": "https://osdoc.cogsci.nl/4.0/manual/python/responses", "title": "Access response history"}
{"content": "# Access response history\n\ntitle: Access response history\n\n<summary_prompt>\nWrite a summary for the API below:\n\n- Describe the API's overall functionality\n- Explain that this is a Python API for OpenSesame, software for implementing psychology experiments\n- Explain that the `responses` object does not need to be imported\n- Provide a bulleted list of all available functions and their parameters. Important: Don't just name the functions, but create one bullet per function.\n\nYour response should be a comprehensive summary.\n\n```markdown\n{content}\n```\n</summary_prompt>\n\n%-- include: include/api/responses.md --%", "url": "https://osdoc.cogsci.nl/4.0/manual/python/responses", "title": "Access response history"}
{"content": "# Mouse functions\n\ndummy", "url": "https://osdoc.cogsci.nl/4.0/manual/python/mouse", "title": "Mouse functions"}
{"content": "# Mouse functions\n\ntitle: Mouse functions\n\n<summary_prompt>\nWrite a summary for the API below:\n\n- Describe the API's overall functionality\n- Explain that this is a Python API for OpenSesame, software for implementing psychology experiments\n- Explain that the `Mouse` class does not need to be imported\n- Explain the process to initialize a Mouse\n- Define the usage of `**resp_args`\n- Explain how to specify button names/ numbers\n- Explain coordinates: x=0, y=0 is the display center\n- Provide a bulleted list of all available functions and their parameters. Important: Don't just name the functions, but create one bullet per function.\n\nYour response should be a comprehensive summary.\n\n```markdown\n{content}\n```\n</summary_prompt>\n\n%-- include: include/api/mouse.md --%", "url": "https://osdoc.cogsci.nl/4.0/manual/python/mouse", "title": "Mouse functions"}
{"content": "# Log functions\n\ndummy", "url": "https://osdoc.cogsci.nl/4.0/manual/python/log", "title": "Log functions"}
{"content": "# Log functions\n\ntitle: Log functions\n\n<summary_prompt>\nWrite a summary for the API below:\n\n- Describe the API's overall functionality\n- Explain that this is a Python API for OpenSesame, software for implementing psychology experiments\n- Explain that the `log` object does not need to be imported\n- Provide a bulleted list of all available functions and their parameters. Important: Don't just name the functions, but create one bullet per function.\n\nYour response should be a comprehensive summary.\n\n```markdown\n{content}\n```\n</summary_prompt>\n\n%-- include: include/api/log.md --%", "url": "https://osdoc.cogsci.nl/4.0/manual/python/log", "title": "Log functions"}
{"content": "# About Python\n\ntitle: About Python\n\nIn OpenSesame you can create complex experiments using only the graphical user interface (GUI). But you will sometimes encounter situations in which the functionality provided by the GUI is insufficient. In these cases you can add Python code to your experiment.\n\nPython is not supported in online experiments with OSWeb. If you need to run your experiment online, you have to use [JavaScript](%url:manual/javascript/about%) instead.\n\n[TOC]\n\n## Learning Python\n\nYou can find a set of basic tutorials and exercises to get you started with Python at <https://pythontutorials.eu/>.\n\n\n## Python in the OpenSesame GUI\n\n### A single Python workspace\n\nAll Python code is executed in a single Python workspace. This means that variables that have been defined in one INLINE_SCRIPT are accessible in all other INLINE_SCRIPTs, as well as in Python statements that are embedded in run-if statements and text strings. The same principle applies to modules: once `import`ed, they are available everywhere.\n\nFor example, you can simply construct the `Canvas` in one INLINE_SCRIPT ...\n\n~~~ .python\nmy_canvas = Canvas()\nmy_canvas.fixdot()\n~~~\n\n... and show it in another INLINE_SCRIPT ...\n\n~~~ .python\nmy_canvas.show()\n~~~\n\n### Inline_script items\n\nIn order to use Python code you need to add an INLINE_SCRIPT item to your experiment. You can do this by dragging the Python icon (the blue/yellow icon) from the item toolbar into the experiment sequence. After you have done this you will see something like %FigInlineScript.\n\n%--\nfigure:\n id: FigInlineScript\n source: inline-script.png\n caption: The INLINE_SCRIPT item.\n--%\n\nAs you can see, the INLINE_SCRIPT item consists of two tabs: one for the Prepare phase and one for the Run phase. The Prepare phase is executed first, to allow items to prepare for the time-critical run phase. It is good practice to construct `Canvas` objects, `Sampler` objects, etc. during the Prepare phase, so that they can be presented without delay during the Run phase. But this is only convention; you can execute arbitrary Python code during both phases.\n\nFor more information about the prepare-run strategy, see:\n\n- %link:prepare-run%\n\n\n### Conditional (\"if\") expressions\n\nYou can use single-line Python expressions in conditional expressions. For example, you can use the following Python script as a run-if expression (see also %FigRunIf):\n\n~~~ .python\ncorrect == 1 and response_time < 1000\n~~~\n\n%--\nfigure:\n id: FigRunIf\n source: run-if.png\n caption: Using Python script in the run-if statement of a SEQUENCE item.\n--%\n\nFor more information about conditional (\"if\") expressions, see:\n\n- %link:manual/variables%\n\n\n### Python in text strings\n\nYou can embed Python statements in text strings using the `{...} syntax. This works for simple variable references, but also for single-line expressions. For example, you could the following text to a SKETCHPAD:\n\n```text\nThe resolution is {width} x {height} px, which is a total of {width * height} pixels\n```\n\nDepending on your experiment's resolution, this might evaluate to:\n\n```text\nThe resolution is 1024 x 768 px, which is a total of 786432 pixels\n```\n\nFor more information about variables and text, see:\n\n- %link:manual/variables%\n- %link:manual/stimuli/text%\n\n\n### The Jupyter console (debug window)\n\nOpenSesame reroutes the standard output to the console (or: debug window), which you can activate using Control + D or through the menu (Menu -> View -> Show debug window; see %FigDebugNormal). You can print to the console using `print()`.\n\n~~~ .python\nprint('This will appear in the debug window!')\n~~~\n\nThe console is also an interactive Python interpreter powered by [project Jupyter](https://jupyter.org).\n\n\n## Things to know\n\n### Common functions\n\nMany common functions are directly available in an INLINE_SCRIPT item, without the need to import anything. For example:\n\n~~~ .python\n# `Canvas()` is a factory function that returns a `Canvas` object\nfixdot_canvas = Canvas()\nif sometimes(): # Sometimes the fixdot is green\n    fixdot_canvas.fixdot(color='green')\nelse: # Sometimes it is red\n    fixdot_canvas.fixdot(color='red')\nfixdot_canvas.show()\n~~~\n\nFor a list of common functions, see:\n\n- %link:manual/python/common%\n\n\n### The `var` object: Access to experimental variables\n\n__Version note__ As of OpenSesame 4.0, all experimental variables are available as globals. This means that you no longer need the `var` object.\n{:.page-notification}\n\nYou can access experimental variables through the `var` object:\n\n~~~ .python\n# OpenSesame <= 3.3 (with var object)\n# Get an experimental variable\nprint('my_variable is: %s' % var.my_variable)\n# Set an experimental variable\nvar.my_variable = 'my_value'\n\n# OpenSesame >= 4.0 (without var object)\n# Get an experimental variable\nprint('my_variable is: %s' % my_variable)\n# Set an experimental variable\nmy_variable = 'my_value'\n~~~\n\nA full overview of the `var` object can be found here:\n\n- %link:manual/python/var%\n\n\n### The `clock` object: Time functions\n\nBasic time functions are available through the `clock` object:\n\n~~~ .python\n# Get the current timestamp\nt = clock.time()\n# Wait for 1 s\nclock.sleep(1000)\n~~~\n\nA full overview of the `clock` object can be found here:\n\n- %link:manual/python/clock%\n\n\n### The `log` object: Data logging\n\nData logging is available through the `log` object:\n\n~~~ .python\n# Write one line of text\nlog.write('My custom log message')\n# Write all variables\nlog.write_vars()\n~~~\n\nA full overview of the `log` object can be found here:\n\n- %link:manual/python/log%\n\n\n### The `pool` object: Access to the file pool\n\nYou get the full path to a file in the file pool through the `pool` object:\n\n~~~ .python\n# Show an image from the file pool\npath = pool['img.png']\nmy_canvas = Canvas()\nmy_canvas.image(path)\nmy_canvas.show()\n~~~\n\nA full overview of the `pool` object can be found here:\n\n- %link:manual/python/pool%\n\n\n### The `responses` object: Access to participant responses\n\nThe `responses` object keeps track of all participant responses that have been collected during the experiment. For example, to list the correctness of all responses so far:\n\n~~~ .python\nfor response in responses:\n\tprint(response.correct)\n~~~\n\nA full overview of the `responses` object can be found here:\n\n- %link:manual/python/responses%\n\n\n### The `Canvas` class: Presenting visual stimuli\n\nThe `Canvas` class is used to present visual stimuli. For example, you can show a fixation dot as follows:\n\n~~~ .python\nmy_canvas = Canvas()\nmy_canvas.fixdot()\nmy_canvas.show()\n~~~\n\nA full overview of the `Canvas` class can be found here:\n\n- %link:manual/python/canvas%\n\n\n### The `Keyboard` class: Collecting key presses\n\nThe `Keyboard` class is used to collect key presses. For example, to collect a key press with a timeout of 1000 ms:\n\n~~~ .python\nmy_keyboard = Keyboard(timeout=1000)\nkey, time = my_keyboard.get_key()\n~~~\n\nA full overview of the `Keyboard` class can be found here:\n\n- %link:manual/python/keyboard%\n\n\n### The `Mouse` class: Collecting mouse clicks and screen touches\n\nThe `Mouse` class is used to collect mouse clicks and screen touches. (OpenSesame makes no distinction between the two.) For example, to collect a mouse click with a timeout of 1000 ms:\n\n~~~ .python\nmy_mouse = Mouse(timeout=1000)\nbutton, position, time = my_mouse.get_click()\n~~~\n\nA full overview of the `Mouse` class can be found here:\n\n- %link:manual/python/mouse%\n\n\n### The `Sampler` class: Sound playback\n\nThe `Sampler` class is used to play back sound samples. For example, to play back a simple beep:\n\n~~~ .python\nmy_sampler = Sampler()\nmy_sampler.play()\n~~~\n\nA full overview of the `Sampler` class can be found here:\n\n- %link:manual/python/sampler%\n\n\n## Alternative modules for display presentation, response collection, etc.\n\n\n### `psychopy`\n\nIf you are using the *psycho* backend, you can directly use the various [PsychoPy] modules. For more information, see:\n\n- %link:backends%\n\n\n### `expyriment`\n\nIf you are using the *xpyriment* backend, you can directly use the various [Expyriment] modules. For more information, see:\n\n- %link:backends%\n\n### `pygame`\n\nIf you are using the *legacy*, *droid*, or *xpyriment* (only with \"Use OpenGL\" set to \"no\") backend, you can directly use the various [PyGame] modules. For more information, see:\n\n- %link:backends%\n\n\n[python]: http://www.python.org/\n[backends]: /backends/about-backends\n[ipython]: http://ipython.org/\n[swaroop]: http://www.swaroopch.com/notes/Python\n[swaroop-direct]: http://www.ibiblio.org/swaroopch/byteofpython/files/120/byteofpython_120.pdf\n[downey]: http://www.greenteapress.com/thinkpython/\n[downey-direct]: http://www.greenteapress.com/thinkpython/thinkpython.pdf\n[opensesamerun]: /usage/opensesamerun/\n[psychopy]: http://www.psychopy.org/\n[expyriment]: http://www.expyriment.org/\n[pygame]: http://www.pygame.org/", "url": "https://osdoc.cogsci.nl/4.0/manual/python/about", "title": "About Python"}
{"content": "# Common functions\n\ndummy", "url": "https://osdoc.cogsci.nl/4.0/manual/python/common", "title": "Common functions"}
{"content": "# Common functions\n\ntitle: Common functions\n\n<summary_prompt>\nWrite a summary for the API below:\n\n- Describe the API's overall functionality\n- Explain that this is a Python API for OpenSesame, software for implementing psychology experiments\n- Explain that these functions are commonly used in combination with Canvas functions\n- Explain that none of the listed functions need to be imported\n- Provide a bulleted list of all available functions and their parameters. Important: Don't just name the functions, but create one bullet per function.\n\nYour response should be a comprehensive summary.\n\n```markdown\n{content}\n```\n</summary_prompt>\n\nThe following functions are available in INLINE_SCRIPT items:\n\n[TOC]\n\n%-- include: include/api/python_workspace_api.md --%", "url": "https://osdoc.cogsci.nl/4.0/manual/python/common", "title": "Common functions"}
{"content": "# Canvas functions\n\ndummy", "url": "https://osdoc.cogsci.nl/4.0/manual/python/canvas", "title": "Canvas functions"}
{"content": "# Canvas functions\n\ntitle: Canvas functions\n\n<summary_prompt>\nWrite a summary for the API below:\n\n- Describe the API's overall functionality\n- Explain that this is a Python API for OpenSesame, software for implementing psychology experiments\n- Explain that `Canvas` and Element classes do not need to be imported\n- Explain the process to initialize a `Canvas`\n- Discuss three methods of drawing elements:\n    - Naming an Element interface (`my_canvas['name'] = FixDot()`)\n    - Adding an Element interface (`my_canvas += FixDot()`)\n    - Not preferred: function interface (`my_canvas.fixdot()`)\n- Illustrate how to modify named elements with an example\n- Define the usage of `**style_args`\n- Explain how to specify colors\n- Explain coordinates: x=0, y=0 is the display center\n- Provide a bulleted list of all available functions and their parameters. Important: Don't just name the functions, but create one bullet per function.\n\nYour response should be a comprehensive summary.\n\n```markdown\n{content}\n```\n</summary_prompt>\n\n%-- include: include/api/canvas.md --%", "url": "https://osdoc.cogsci.nl/4.0/manual/python/canvas", "title": "Canvas functions"}
{"content": "# Access items\n\ndummy", "url": "https://osdoc.cogsci.nl/4.0/manual/python/items", "title": "Access items"}
{"content": "# Access items\n\ntitle: Access items\n\n<summary_prompt>\nWrite a summary for the API below:\n\n- Describe the API's overall functionality\n- Explain that this is a Python API for OpenSesame, software for implementing psychology experiments\n- Explain that the `items` object does not need to be imported\n- Provide a bulleted list of all available functions and their parameters. Important: Don't just name the functions, but create one bullet per function.\n\nYour response should be a comprehensive summary.\n\n```markdown\n{content}\n```\n</summary_prompt>\n\n%-- include: include/api/items.md --%", "url": "https://osdoc.cogsci.nl/4.0/manual/python/items", "title": "Access items"}
{"content": "# Keyboard functions\n\ndummy", "url": "https://osdoc.cogsci.nl/4.0/manual/python/keyboard", "title": "Keyboard functions"}
{"content": "# Keyboard functions\n\ntitle: Keyboard functions\n\n<summary_prompt>\nWrite a summary for the API below:\n\n- Describe the API's overall functionality\n- Explain that this is a Python API for OpenSesame, software for implementing psychology experiments\n- Explain that the `Keyboard` class does not need to be imported\n- Explain the process to initialize a Keyboard\n- Define the usage of `**resp_args`\n- Explain how to specify key names\n- Provide a bulleted list of all available functions and their parameters. Important: Don't just name the functions, but create one bullet per function.\n\nYour response should be a comprehensive summary.\n\n```markdown\n{content}\n```\n</summary_prompt>\n\n%-- include: include/api/keyboard.md --%", "url": "https://osdoc.cogsci.nl/4.0/manual/python/keyboard", "title": "Keyboard functions"}
{"content": "# Access experimental variables\n\ndummy", "url": "https://osdoc.cogsci.nl/4.0/manual/python/var", "title": "Access experimental variables"}
{"content": "# Access experimental variables\n\ntitle: Access experimental variables\n\n<summary_prompt>\nWrite a summary for the API below:\n\n- Describe the API's overall functionality\n- Explain that this is a Python API for OpenSesame, software for implementing psychology experiments\n- Explain that the `var` object does not need to be imported\n- Explain that there are two ways to refer to experimental variables:\n    - Preferred: as global variables: (`my_var = 10`)\n    - Non-preferred: as properties of the `var` object (`var.my_var = 10`)\n- Provide a bulleted list of all available functions and their parameters. Important: Don't just name the functions, but create one bullet per function.\n\nYour response should be a comprehensive summary.\n\n```markdown\n{content}\n```\n</summary_prompt>\n\n%-- include: include/api/var.md --%", "url": "https://osdoc.cogsci.nl/4.0/manual/python/var", "title": "Access experimental variables"}
{"content": "# OpenSesame as a Python library (no GUI)\n\ntitle: OpenSesame as a Python library (no GUI)\n\nYou can also write experiments fully programmatically by using OpenSesame as a Python module. This is mainly suited for people who prefer coding over using a graphical user interface.\n\nUsing OpenSesame as a Python module works much the same way as using Python `inline_script` items in the user interface, with two notable exceptions:\n\n- Functions and classes need to be explicitly imported from `libopensesame.python_workspace_api`. All functions and classes described under [Common functions](%url:manual/python/common%) are available.\n- An `experiment` object needs to be explicitly created using the `Experiment()` factory function.\n\nA simple Hello World experiment looks like this:\n\n```python\nfrom libopensesame.python_workspace_api import \\\n  Experiment, Canvas, Keyboard, Text\n\n# Initialize the experiment window using the legacy backend\nexp, win, clock, log = Experiment(canvas_backend='legacy')\n# Prepare a stimulus canvas and a keyboard\ncnv = Canvas()\ncnv += Text('Hello world')\nkb = Keyboard()\n# Show the canvas, wait for a key press, and then end the experiment\ncnv.show()\nkb.get_key()\nexp.end()\n```\n\nYou can also programmatically open a `.osexp` experiment file and execute it:\n\n```python\nfrom libopensesame.python_workspace_api import Experiment\nexp, win, clock, log = Experiment(osexp_path='my_experiment.osexp',\n                                  subject_nr=2)\nexp.run()\n```", "url": "https://osdoc.cogsci.nl/4.0/manual/python/nogui", "title": "OpenSesame as a Python library (no GUI)"}
{"content": "# Sound\n\ntitle: Sound\n\nThe most common way to play sound is using the SAMPLER item, for playback of audio files, or the SYNTH item, for playback of simple beeps, etc.\n\n[TOC]\n\n## The sampler\n\nThe SAMPLER plays back a single sound file, typically from the file pool.\n\nSound files are always played back at the sampling rate that is used by the OpenSesame sampler backend. If your sample appears to be sped up (high pitch) or slowed down (low pitch), you can adjust the sampling rate of your sound file in a sound editor, or change the sampling rate used by the OpenSesame sampler backend (under 'Show backend settings and info' in the General tab).\n\nThe SAMPLER has a few options:\n\n- *Sound file* indicates the file to be played.\n- *Volume* between 0 (silent) and 1 (normal volume).\n- *Pan* turns the right (negative values) or left (positive values) channel down. For full panning, enter 'left' or 'right',\n- *Pitch* indicates the playback speed, where 1 corresponds to the original speed.\n- *Stop after* indicates for how long the sound file should be played. For example, a value of 100 ms means that playback will be stopped after 100 ms, regardless of how long the sound file is. A value of 0 ms means that the sound file will be played back completely.\n- *Fade in* indicates the fade-in time for the sound file. For example, a value of 100 ms means that the sound file will start silent, and build up to maximum value in 100 ms.\n- *Duration* indicates the duration of the sampler item, before the next item is presented. This doesn't need to match the length of the sound file. For example, if the duration of the sampler is set to 0 ms, OpenSesame will advance directly to the item that follows the SAMPLER (e.g., a sketchpad), *while the sound file continues playing in the background*. In addition to a numeric value, you can set duration to:\n\t- 'keypress' to wait for a key press\n\t- 'mouseclick' to wait for a mouse click\n\t- 'sound' to wait until the sampler has finished playing.\n\n## The synth\n\nThe SYNTH is a basic sound synthesizer.\n\nYou can specify a\nnumber of options:\n\n- *Waveform* can be set to sine, sawtooth, square, or white noise\n- *Attack* is the time it takes for the sound the reach maximum volume (i.e. fade in).\n- *Decay* is the time it takes for the sound to die out (i.e. fade out). Note that the decay occurs within the length of the sound.\n- *Volume* between 0 and 100%\n- *Pan* turns the right (negative values) or left (positive values) channel down. Setting pan to -20 or 20 completely mutes the right or left channel, respectively.\n- *Length* indicates the length of the sound (in milliseconds).\n- *Duration* indicates the duration of the SYNTH item, before the next item is presented. This doesn't need to match the length of the sound. For example, the duration of the SYNTH may be set to 0ms, in order to advance directly to the next item (e.g., a SKETCHPAD), while the sound continues playing in the background. In addition to a numeric value, you can set the duration to 'keypress', to wait for a keyboard press, 'mouseclick', to wait for a mouse click, or 'sound', to wait until the SYNTH has finished playing.\n\n## Sound playback in Python\n\nYou can use the SAMPLER object and the SYNTH function to present visual stimuli in Python:\n\n- %link:sampler%\n- %link:manual/python/common%\n\n\n## Audio Low Latency plugins\n\nThe main goal of the Audio Low Latency plugins, developed by Bob Rosbag, is to play and record audio with minimal and predictable latencies to achieve a high accuracy and precision. The `PyAlsaAudio` package which uses the Linux ALSA audio system provided the best results within Python. `PortAudio` and `sounddevice` are cross-platform and work on both Windows as Linux.\n\nThe plugins are not installed by default, but can be installed through pip:\n\n```bash\npip install opensesame-plugin-audio-low-latency\n```\n\nSee also:\n\n- <https://pypi.org/project/opensesame-plugin-audio-low-latency/>", "url": "https://osdoc.cogsci.nl/4.0/manual/stimuli/sound", "title": "Sound"}
{"content": "# Text\n\ntitle: Text\n\n[TOC]\n\n## How can I present text?\n\nThe most common way to show text is using a SKETCHPAD or FEEDBACK item. These allow you to enter text and other visual stimuli. For a questionnaire-like way to show text, you can use [forms](%link:manual/forms/about%).\n\n\n## HTML formatting\n\nYou can use a HTML tags, which you can simply insert into your text. You can use these tags everywhere: In SKETCHPAD items, in INLINE_SCRIPTs (provided you use the `Canvas` class), in forms, etc.\n\nExample:\n\n~~~ .html\nOpenSesame supports a sub-set of HTML tags:\n- <b>Bold face</b>\n- <i>Italic</i>\n- <u>Underline</u>\n\nIn addition, you can pass 'color', 'size', and 'style' as keywords to a 'span' tag:\n- <span style='color:red;'>Color</span>\n- <span style='font-size:32px;'>Font size</span>\n- <span style='font-family:serif;'>Font style</span>\n\nFinally, you can force newlines with the 'br' tag:\nLine 1<br>Line 2\n~~~\n\n\n## Variables and inline Python\n\nYou can embed variables in text using the `{...}` syntax. For example, the following:\n\n~~~ .python\nThe subject number is {subject_nr}\n~~~\n\n... might evaluate to (for subject 1):\n\n~~~ .python\nThe subject number is 1\n~~~\n\nYou can also embed Python expression. For example, the following:\n\n~~~ .python\nThe subject number modulo five is {subject_nr % 5}\n~~~\n\n... might evaluate to (for subject 7)\n\n~~~ .python\nThe subject number modulo five is 2\n~~~\n\n\n## Fonts\n\n### Default fonts\n\nYou can select one of the default fonts from the font-selection dialogs (%FigFontSelect). These fonts are included with OpenSesame and your experiment will therefore be fully portable when you use them.\n\n%--\nfigure:\n id: FigFontSelect\n source: font-selection-dialog.png\n caption: \"A number of default fonts, which are bundled with OpenSesame, can be selected through the font-selection dialogs.\"\n--%\n\nThe fonts have been renamed for clarity, but correspond to the following open-source fonts:\n\n|__Name in OpenSesame__\t\t|__Actual font__\t\t|\n|---------------------------|-----------------------|\n|`sans`\t\t\t\t\t\t|Droid Sans\t\t\t\t|\n|`serif`\t\t\t\t\t|Droid Serif\t\t\t|\n|`mono`\t\t\t\t\t\t|Droid Sans Mono\t\t|\n|`chinese-japanese-korean`\t|WenQuanYi Micro Hei\t|\n|`arabic`\t\t\t\t\t|Droid Arabic Naskh\t\t|\n|`hebrew`\t\t\t\t\t|Droid Sans Hebrew\t\t|\n|`hindi`\t\t\t\t\t|Lohit Hindi\t\t\t|\n\n### Selecting a custom font through the font-selection dialog\n\nIf you select 'other ...' in the font selection dialog, you can select any font that is available on your operating system. If you do this, your experiment is no longer fully portable, and will require that the selected font is installed on the system that you run your experiment on.\n\n### Placing a custom font in the file pool\n\nAnother way to use a custom font is to put a font file in the file pool. For example, if you place the font file `inconsolata.ttf` in the file pool, you can use this font in a SKETCHPAD item, like so:\n\n\tdraw textline 0.0 0.0 \"This will be inconsolata\" font_family=\"inconsolata\"\n\nNote that the font file must be a truetype `.ttf` file.", "url": "https://osdoc.cogsci.nl/4.0/manual/stimuli/text", "title": "Text"}
{"content": "# Video playback\n\ntitle: Video playback\n\n[TOC]\n\n\n## media_player_mpy plugin\n\nThe MEDIA_PLAYER_MPY plugin is based on MoviePy. It is included by default with the Windows and Mac OS packages of OpenSesame. If it is not installed, you can get it by installing the `opensesame-plugin-media-player-mpy` package, as described here:\n\n- <https://rapunzel.cogsci.nl/manual/environment/>\n\nThe source code is hosted at:\n\n- <https://github.com/dschreij/opensesame-plugin-mediaplayer>\n\n\n## OpenCV\n\nOpenCV is a powerful computer vision library, which contains (among many other things) routines for reading video files.\n\n- <http://docs.opencv.org/3.0-beta/doc/py_tutorials/py_tutorials.html>\n\nThe following example shows how to play back a video file, while drawing a red square on top of the video. This example assumes that you're using the legacy backend.\n\n~~~ .python\nimport cv2\nimport numpy\nimport pygame\n# Full path to the video file in file pool\npath = pool['myvideo.avi']\n# Open the video\nvideo = cv2.VideoCapture(path)\n# A loop to play the video file. This can also be a while loop until a key\n# is pressed. etc.\nfor i in range(100):\n    # Get a frame\n    retval, frame = video.read()\n    # Rotate it, because for some reason it otherwise appears flipped.\n    frame = numpy.rot90(frame)\n    # The video uses BGR colors and PyGame needs RGB\n    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n    # Create a PyGame surface\n    surf = pygame.surfarray.make_surface(frame)\n    # Now you can draw whatever you want onto the PyGame surface!\n    pygame.draw.rect(surf, (255,0,0), (100, 100, 200, 200))\n    # Show the PyGame surface!\n    exp.surface.blit(surf, (0, 0))\n    pygame.display.flip()\n~~~", "url": "https://osdoc.cogsci.nl/4.0/manual/stimuli/video", "title": "Video playback"}
{"content": "# Visual stimuli\n\ntitle: Visual stimuli\n\nThe most common way to present visual stimuli is using the SKETCHPAD item, or, for non-time-critical stimuli, the FEEDBACK item.\n\n\n[TOC]\n\n\n## Using the sketchpad and feedback items\n\nThe SKETCHPAD and FEEDBACK item offer basic what-you-see-is-what-you get drawing tools (%FigSketchpad).\n\n%--\nfigure:\n id: FigSketchpad\n source: sketchpad.png\n caption: The SKETCHPAD provides built-in drawing tools.\n--%\n\n\n## Using show-if expressions\n\nYou can use show-if expressions to determine whether or not a particular element should be shown. For example, if you have an image of a happy face that should be shown only when the variable `valence` has the value 'positive', then you can set the show-if expression for the corresponding image element to:\n\n```python\nvalence == 'positive'\n```\n\nIf you leave a show-if expression empty or enter `True`, element will always be shown. Show-if expressions use the same syntax as other conditional expressions. For more information, see:\n\n- %link:manual/variables%\n\nShow-if expressions are evaluated at the moment that the display is prepared. This means that for SKETCHPAD items, they are evaluated during the prepare phase, whereas for FEEDBACK items, they are evaluated during the run phase (see also the section below).\n\n\n## The difference between sketchpad and feedback items\n\nThe SKETCHPAD and FEEDBACK items are identical in most ways, except for two important differences.\n\n\n### Sketchpad items are prepared in advance, feedback items are not\n\nThe contents of a SKETCHPAD are prepared during the prepare phase of the SEQUENCE that it is part of. This is necessary to ensure accurate timing: It allows the SKETCHPAD to be shown right away during the run phase, without any delays due to stimulus preparation. However, the downside of this is that the contents of a SKETCHPAD cannot depend on what happens during the SEQUENCE that it is part of. For example, you cannot use a SKETCHPAD to provide immediate feedback on the response time collected by a KEYBOARD_RESPONSE item (assuming that the SKETCHPAD and KEYBOARD_RESPONSE are part of the same sequence.)\n\nIn contrast, the contents of a FEEDBACK item are only prepared when they are actually shown, that is, during the run phase of the SEQUENCE that it is part of. This makes it possible to provide feedback on things that just happened--hence the name. However, the FEEDBACK item should not be used to present time-critical stimuli, because it suffers from delays due to stimulus preparation.\n\nFor more information about the prepare-run strategy, see:\n\n- %link:prepare-run%\n\n\n### Feedback variables are (by default) reset by feedback items\n\nThe FEEDBACK item has an option 'Reset feedback variables'. When this option is enabled (it is by default), feedback variables are reset when the FEEDBACK item is shown.\n\nFor more information about feedback variables, see:\n\n- %link:manual/variables%\n\n\n## Presenting visual stimuli in Python inline script\n\n### Accessing a SKETCHPAD in Python\n\nYou can access the `Canvas` object for a SKETCHPAD as the items `canvas` property. For example, say that your SKETCHPAD is called *my_sketchpad*, and contains an image elements with the name 'my_image'. You could then have this image rotate with the following script:\n\n~~~ .python\nmy_canvas = items['my_sketchpad'].canvas\nfor angle in range(360):\n\tmy_canvas['my_image'].rotation = angle\n\tmy_canvas.show()\n~~~\n\n\n### Creating a Canvas in Python\n\nYou can use the `Canvas` object to present visual stimuli in Python:\n\n- %link:manual/python/canvas%", "url": "https://osdoc.cogsci.nl/4.0/manual/stimuli/visual", "title": "Visual stimuli"}
{"content": "# Intermediate tutorial (JavaScript): visual search\n\ntitle: Intermediate tutorial (JavaScript): visual search\n\n[TOC]\n\n## About OpenSesame\n\nOpenSesame is a user-friendly program for the development of behavioral experiments for psychology, neuroscience, and experimental economy. For beginners, OpenSesame has a comprehensive graphical, point-and-click interface. For advanced users, OpenSesame supports Python (desktop only) and JavaScript (desktop and browser).\n\nOpenSesame is freely available under the [General Public License v3][gpl].\n\n## About this tutorial\n\nThis tutorial shows how to create a basic visual-search experiment using OpenSesame [(Math\u00f4t, Schreij, & Theeuwes, 2012)][references]. We will use both the graphical interface and JavaScript to develop an experiment that you can run online in a browser. Some experience with OpenSesame and JavaScript is recommended. This tutorial takes approximately one hour.\n\nA Python-based version of this tutorial is also available. If you don't need to run your experiments online, then the Python tutorial is likely what you need:\n\n- %link:tutorials/intermediate%\n\n\n## Resources\n\n- __Download__ \u2014 This tutorial assumes that you are running OpenSesame version 4.0.0 or later and OSWeb 2.0 or later. You can download the most recent version of OpenSesame from:\n\t- %link:download%\n- __Documentation__ \u2014 A dedicated documentation website can be found at:\n\t- <http://osdoc.cogsci.nl/>\n- __Forum__ \u2014 A support forum can be found at:\n\t- <http://forum.cogsci.nl/>\n\n\n## The experiment\n\nIn this tutorial, you will create a basic visual-search experiment. The experiment resembles the classic visual-search studies of [Treisman and Gelade (1980)][references], but it is not identical.\n\nBefore starting to *build* the experiment for yourself, you can already *participate* in it. This will give you a good idea of what you're working towards in this tutorial.\n\n<a role=\"button\" class=\"btn btn-success btn-align-left\" href=\"https://jatos.mindprobe.eu/publix/1938/start?batchId=2191&generalMultiple\">Participate in the experiment!</a>\n\nIn this experiment, participants search for a target object, which can be a yellow square, a yellow circle, a blue square, or a blue circle; the identity of the target is varied between blocks of trials. Participants indicate whether the target is present or not by pressing the right (present) or left (absent) arrow key.\n\nIn addition to the target, zero or more distractor objects are shown. There are three conditions, and the condition determines what kind of distractors there are:\n\n- In the *Conjunction* condition, distractors can have any shape and color, with the only restriction that distractors cannot be identical to the target. So, for example, if the target is a yellow square, then distractors are yellow circles, blue circles, and blue squares.\n- In the *Shape Feature* condition, distractors have a different shape from the target, but can have any color. So, for example, if the target is a yellow square, then distractors are yellow circles and blue circles.\n- In the *Color Feature* condition, distractors can have any shape, but have a different color from the target. So, for example, if the target is a yellow square, then distractors are blue squares and blue circles.\n\nImmediate feedback is shown after each trial: a green dot after a correct response, and a red dot after an incorrect response. Detailed feedback on average response times and accuracy is shown after each block of trials.\n\n%--\nfigure:\n id: FigVisualSearch\n source: visual-search.svg\n caption: |\n  The visual-search experiment that you will implement in this tutorial.\n--%\n\nExperiments like this show two typical findings:\n\n- It takes more time to find the target in the Conjunction condition than in the two Feature conditions.\n- In the Conjunction condition, response times increase as the number of distractors increases. This suggests that people search for the target one item at a time; this is called *serial search*.\n- In the Feature conditions (both shape and color), response times do not, or hardly, increase as the the number of distractors increases. This suggests that people process the entire display at once; this is called *parallel search*.\n\nAccording to Treisman and Gelade's feature-integration theory, these results reflect that the Conjunction condition requires that you combine, or *bind*, the color and shape of each object. This binding requires attention, and you therefore need to shift your attention from one object to the next; this is slow, and explains why response times depend on how many objects there are. In contrast, in the Feature conditions, color and shape do not need to be bound, and therefore the whole display can be processed in a single sweep without attention being directed at each and every object.\n\n## Experimental design\n\nThis design:\n\n- Is *within-subject*, because all participants do all conditions\n- Is *fully-crossed* (or full factorial), because all combinations of conditions occur\n- Has three conditions (or factors):\n\t- Varied within blocks:\n\t\t- `set_size` with three levels (1, 5, 15), or SS<sub>3</sub>\n\t\t- `condition` with three levels (conjunction, feature_shape, feature_color), or CN<sub>3</sub>\n\t\t- `target_present` with two levels (present, absent), or TP<sub>2</sub>\n\t- Varied between blocks:\n\t\t- `target_shape` with two levels (square, circle), or TS<sub>2</sub>\n\t\t- `target_color` with two levels (yellow, blue), or TC<sub>2</sub>\n- Has N subjects, or <u>S</u><sub>N</sub>\n\nYou can write this design as <u>S</u><sub>N</sub>\u00d7SS<sub>3</sub>\u00d7CN<sub>3</sub>\u00d7TP<sub>2</sub>\u00d7TS<sub>2</sub>\u00d7TC<sub>2</sub>\n\nFor more information about this notation for experimental design, see:\n\n- %link:experimentaldesign%\n\n## Step 1: Create the basic structure of the experiment\n\nStart OpenSesame and, in the 'Get started!' tab, select the Extended template. This template provides the basic structure that is common to many cognitive-psychology experiments, such as the one that we will create here.\n\nThe Extended template contains a few items that we don't need. Delete the following items:\n\n- *about_this_template*\n- *practice_loop*\n- *end_of_practice*\n\nWhen you have deleted these items, they are still visible in the 'Unused items' bin. To permanently delete these items, click on the 'Unused items' bin, and then click on the 'Permanently delete unused items' button.\n\nFinally, give the experiment a good title, such as 'Visual search'. To do this, open the general-properties tab (by clicking on 'Extended template' in the overview area) and click on the experiment name to edit it.\n\nAlso configure OpenSesame to run the experiment in a browser, rather than on the desktop.\n\nThe overview area should now look like %FigStep1:\n\n%--\nfigure:\n id: FigStep1\n source: step1.png\n caption: |\n  The overview area at the end of step 1.\n--%\n\n\n## Step 2: Define experimental variables that are varied between blocks\n\nAs described above, two variables are varied between blocks in our experiment: `target_shape` and `target_color`. We therefore need to define these variables in the *experimental_loop*. To understand why, consider the structure shown in %FigStep1, starting from the bottom (i.e. the most indented level).\n\n- *trial_sequence* corresponds to a single trial\n- *block_loop* corresponds to a block of a trials\n\t- Therefore, variables defined here vary for each run of *trial_sequence*; in other words, variables defined in *block_loop* are varied __within blocks__.\n- *block_sequence* corresponds to a block of trials, preceded by resetting of the feedback variables, and followed by participant feedback\n- *experimental_loop* corresponds to multiple blocks of trials\n\t- Therefore, variables defined here vary for each run of *block_sequence*; in other words, variables defined in *experimental_loop* are varied __between blocks__.\n- *experiment* corresponds to the entire experimental, which is an instruction screen, followed by multiple blocks of trials, followed by an end-of-experiment screen\n\nClick on experimental loop, and define:\n\n- `target_shape`, which can be 'square' or 'circle'; and\n- `target_color`, which can be 'yellow' or 'blue'.\n\nWe have a full-factorial design, which means that all 2 \u00d7 2 = 4 combinations must occur. The table of *experimental_loop* should now look like %FigStep2:\n\n%--\nfigure:\n id: FigStep2\n source: step2.png\n caption: |\n  The table of *experimental_loop* at the end of step 2.\n--%\n\n## Step 3: Give instructions at the start of each block\n\nRight now, the experiment starts with a single *instructions* screen. In our case, we want to give instructions before each block of trials, to tell the participant what target to look for (because the identity of the target varies between blocks).\n\n__Move the instructions into block_sequence__\n\nTherefore, pick up the *instructions* item and drag it onto *block_sequence*. A pop-up will appear, asking you if you want to:\n\n- Insert the item into *block_sequence*, in which case *instructions* would become the first item of *block_sequence*; or\n- Insert the item after *block_sequence*, in which case *instructions* would move to a position after *block_sequence*.\n\nSelect the first option ('Insert into'). Now *block_sequence* starts with an instructions screen, which is what we want.\n\n__Add instructional text__\n\nClick on *instructions* to open it, and add a good instructional text, such as:\n\n```text\nINSTRUCTIONS\n\nSearch for the {target_color} {target_shape}\n\nPress the right-arrow key if you find it\nPress the left-arrow key if you don't\n\nPress any key to begin\n```\n\nThe curly braces brackets around '{target_color}' and '{target_shape}' indicate that these are not literal text, but refer to the variables that we have defined in *experimental_loop*. When the experiment runs, the values of these variables will appear here, and the participant will see (for example), 'Search for the yellow circle'.\n\n__Give a visual preview of the target__\n\nIt also good to show the participant the actual stimulus that she needs to find. To do this:\n\n- Draw a filled circle at the center of the display (make sure it doesn't overlap with the text);\n- Change the color of the circle to '{target_color}'. This means that the color of the circle depends on the value of the variable `target_color`; and\n- Change the show-if expression to `target_shape == 'circle'`. This is a Python expression that checks if the variable `target_shape` has the value 'circle'. Note that even though you *cannot* use full-fledged Python `inline_script` items when running experiments in a browser, you *can* use Python for these simple conditional expressions.\n\nIn other words, we have drawn a circle of which the color is determined by `target_color`; furthermore, this circle is only shown when the variable `target_shape` has the value 'circle'. For more information about variables and show-if statements, see:\n\n- %link:manual/variables%\n\nWe use the same trick to draw a square:\n\n- Draw a filled square at the center of the display;\n- Change the color of the square to '{target_color}'; and\n- Change the show-if statement to `target_shape == 'square'`\n\nThe *instructions*  screen should now look like %FigStep3:\n\n%--\nfigure:\n id: FigStep3\n source: step3.png\n caption: |\n  The *instructions* screen at the end of step 3.\n--%\n\n\n## Step 4: Define experimental variables that are varied within blocks\n\nThree variables are varied within blocks in our experiment: `condition`, `set_size`, and `target_present`. As described under Step 2, we need to define these variables in the *block_loop* so that they vary for each run of *trial_sequence*.\n\nThe three variables make a total of 3 \u00d7 3 \u00d7 2 = 18 different combinations. We can type these into the table manually, but, because we have full-factorial design, we can also use the full-factorial-design wizard. To do this, first open *block_loop* and click on the 'Full-factorial design' button.\n\nIn the table that appears, put the variable names on the first row, and the values on the rows below, as shown in %FigFullFactorial.\n\n%--\nfigure:\n id: FigFullFactorial\n source: fullfactorial.png\n caption: |\n  The *instructions* screen at the end of step 3.\n--%\n\nNow click on 'Ok' to generate the full design. The table of *block_loop* should now look like %FigStep4.\n\n%--\nfigure:\n id: FigStep4\n source: step4.png\n caption: |\n  The table of *block_loop* at the end of step 4.\n--%\n\n## Step 5: Create the trial sequence and add an initialization script\n\nWe want our trial sequence to look as follows:\n\n- A fixation dot, for which we will use a SKETCHPAD.\n- A search display, which we will create in JavaScript with a custom INLINE_JAVASCRIPT.\n- Response collection, for which we will use a KEYBOARD_RESPONSE.\n- Data logging, for which we will use a LOGGER.\n- (We also want immediate feedback after each trial, but we will get back to this later.)\n\nSo the only thing that is missing from *trial_sequence* is an INLINE_JAVASCRIPT.\n\n- Insert a new INLINE_JAVASCRIPT after *sketchpad* and rename it to *search_display_script*.\n- Rename *sketchpad* to *fixation_dot*, so that its function is clear; and\n- Change the duration of *fixation_dot* to 500, so that the fixation dot is shown for 500 ms. (There should already be a fixation dot drawn; if not, draw one in the center of *fixation_dot*.)\n\nWe also need to add a initialization script to start of the experiment. We will use this only to define (`let`) a variable that will hold the `Canvas` object on which we will draw. In JavaScript, you have to define a variable exactly once, which is why we cannot do that in the *trial_sequence*.\n\n- Insert a new INLINE_JAVASCRIPT at the top of the *experiment* sequence and rename it to *init*.\n\nThe overview area should now look like %FigStep5.\n\n%--\nfigure:\n id: FigStep5\n source: step5.png\n caption: |\n  The overview area at the end of step 5.\n--%\n\n## Step 6: Generate the search display\n\n__Top-down and defensive programming__\n\nNow things will get interesting: We will start programming in JavaScript. We will use two guiding principles: *top-down* and *defensive* programming.\n\n- *Top-down programming* means that we start with the most abstract logic, without bothering with how this logic is implemented. Once the most abstract logic is in place, we will move down to a slightly less abstract logic, and so on, until we arrive at the details of the implementation. This technique helps to keep the code structured.\n- *Defensive programming* means that we assume that we make mistakes. Therefore, to protect us from ourselves, we build sanity checks into the code.\n\n*Note:* The explanation below assumes that you're somewhat familiar with JavaScript. If concepts like `Array`, `for` loop, and functions don't mean anything to you, then it's best to first walk through an introductory JavaScript tutorial. You can find links to JavaScript tutorials here:\n\n- %link:manual/javascript/about%\n\nThe logic of the code is shown in %FigHierarchy. The numbers indicate the order in which we will implement the functionality, starting at the abstract level.\n\n%--\nfigure:\n id: FigHierarchy\n source: hierarchy.svg\n caption: |\n  The logic of the code to draw a visual-search display.\n--%\n\n__Declaring variables with let, var, and const__\n\nIn JavaScript, you have to 'declare' a variable before you can use it. (In Python, this is not necessary.) In our case, we will use a variable called `c`, which we therefore need to declare. To do so, open the Prepare tab of the *init* script and use the `let` keyword to declare the variable `c`:\n\n```js\nlet c\n```\n\nThere are three different ways to declare variables:\n\n- Using `let`, as we've done here. In OpenSesame, this makes the variable available in JavaScript but not as an experimental variable in the user interface.\n- Using `var`. In OpenSesame, this makes the variable also available as an experimental variable in the user interface. (We will do that later for the variable `correct_response`.)\n- Using `const`. This is like `var` with the important difference that the variable cannot be re-assigned later.\n\n\n__The Prepare and Run phases__\n\nOpen *search_display_script* and switch to the Prepare tab. OpenSesame distinguishes two phases of execution:\n\n- During the Prepare phase, each item is given the opportunity to prepare itself; what this means depends on the item: For a SKETCHPAD, it means drawing a canvas (but not showing it); for a SAMPLER, it means loading a sound file (but not playing it); etc.\n- During the Run phase, each item is actually executed; again, what this means depends on the item: For a SKETCHPAD, it means showing the previously prepared canvas; for a SAMPLER, it means playing a previously loaded sound file.\n\nFor an INLINE_JAVASCRIPT, you have to decide yourself what to put in the Prepare phase, and what to put in the Run phase. The distinction is usually quite clear: In our case, we put the code for drawing the canvas in the Prepare phase, and the code for showing the canvas (which is small) in the Run phase.\n\nSee also:\n\n- %link:prepare-run%\n\n\n__Implement the abstract level__\n\nWe start at the most abstract level: defining a function that draws a visual-search display. We don't specify *how* this is done; we simply assume that there is a function that does this, and we will worry about the details later\u2014that's top-down programming.\n\nIn the Prepare tab, enter the following code:\n\n```js\nc = draw_canvas()\n```\n\nWhat happens here? We \u2026\n\n- Call `draw_canvas()`, which returns a `Canvas` object that we store as `c`; in other words, `c` is a `Canvas` object that corresponds the search display. This assumes that there is a function `draw_canvas()`, even though we haven't defined it yet.\n\nA `Canvas` object is a single display; it is, in a sense, the JavaScript counterpart of a SKETCHPAD. See also:\n\n- %link:manual/javascript/canvas%\n\nWe now go one step down by defining `draw_canvas()` (above the rest of the script so far):\n\n```js\n/**\n * Draws the search canvas.\n * @return A Canvas\n **/\nfunction draw_canvas() {\n    let c = Canvas()\n    let xy_list = xy_random(set_size, 500, 500, 75)\n    if (target_present === 'present') {\n        let [x, y] = xy_list.pop()\n        draw_target(c, x, y)\n    } else if (target_present !== 'absent') {\n        throw 'Invalid value for target_present ' + target_present\n    }\n    for (let [x, y] of xy_list) {\n        draw_distractor(c, x, y)\n    }\n    return c\n}\n```\n\n\nWhat happens here? We \u2026\n\n- Create an empty canvas, `c`, using the factory function `Canvas()`.\n- Generate an array of random `x, y` coordinates, called `xy_list`, using another common function, `xy_random()`. This array determines where the stimuli are shown. Locations are sampled from a 500 \u00d7 500 px area with a minimum spacing of 75 px.\n- Check if the experimental variable `target_present` has the value 'present'; if so, `pop()` one `x, y` tuple from `xy_list`, and draw the target at this location. This assumes that there is a function `draw_target()`, even though we haven't defined it yet.\n- If `target_present` is neither 'present' nor 'absent', we `throw` an error; this is defensive programming, and protects us from typos (e.g. if we had accidentally entered 'presenr' instead of 'present').\n- Loop through all remaining `x, y` values and draw a distractor at each position. This assumes that there is a function `draw_distractor()`, even though we haven't defined it yet.\n- Return `c`, which now has the search display drawn onto it.\n\nThere are several common functions, such as `Canvas()` and `xy_random()`, which are always available in an INLINE_JAVASCRIPT item. See:\n\n- %link:manual/javascript/common%\n\nExperimental variables are global variables. That's why you can refer to `set_size`, which is defined in *block_loop*, even though the variable `set_size` is never explicitly defined in the script. The same is true for `target_shape`, `target_color`, `condition`, etc. See:\n\n- %link:var%\n\n\n__Implement the intermediate level__\n\nWe now go one more step down by defining `draw_target` (above the rest of the script so far):\n\n```js\n/**\n * Draws the target.\n * @param c A Canvas\n * @param x An x coordinate\n * @param y A y coordinate\n **/\nfunction draw_target(c, x, y) {\n    draw_shape(c, x, y, target_color, target_shape)\n}\n```\n\nWhat happens here? We \u2026\n\n- Call another function, `draw_shape()`, and specify the color and shape that needs to be drawn. This assumes that there is a function `draw_shape()`, even though we haven't defined it yet.\n\nWe also define `draw_distractor` (above the rest of the script so far):\n\n```js\n/**\n * Draws a single distractor.\n * @param c A Canvas\n * @param x An x coordinate\n * @param y A y coordinate\n **/\nfunction draw_distractor(c, x, y) {\n    if (condition === 'conjunction') {\n        draw_conjunction_distractor(c, x, y)\n    } else if (condition === 'feature_shape') {\n        draw_feature_shape_distractor(c, x, y)\n    } else if (condition === 'feature_color') {\n        draw_feature_color_distractor(c, x, y)\n    } else {\n        throw 'Invalid condition: ' + condition\n    }\n}\n```\n\nWhat happens here? We \u2026\n\n- Call another function to draw a more specific distractor depending on the Condition.\n- Check whether `condition` has any of the expected values. If not, we `throw` an error. This is defensive programming! Without this check, if we made a typo somewhere, the distractor might simply not be shown without causing an error message.\n\nNow we define the function that draws distractors in the Conjunction condition (above the rest of the script so far):\n\n```js\n/**\n * Draws a single distractor in the conjunction condition: an object that\n * can have any shape and color, but cannot be identical to the target.\n * @param c A Canvas.\n * @param x An x coordinate.\n * @param y A y coordinate.\n **/\nfunction draw_conjunction_distractor(c, x, y) {\n    let conjunctions = [\n        ['yellow', 'circle'],\n        ['blue', 'circle'],\n        ['yellow', 'square'],\n        ['blue', 'square']\n    ]\n    let [color, shape] = random.pick(conjunctions)\n    while (color === target_color && shape === target_shape) {\n        [color, shape] = random.pick(conjunctions)\n    }\n    draw_shape(c, x, y, color, shape)\n}\n```\n\nWhat happens here? We \u2026\n\n- Define a list, `conjunctions`, of all possible color and shape combinations.\n- Randomly select one of the color and shape combinations from `conjunctions`.\n- Check if the selected color and shape are both equal to the color and shape of the target. If so, keep selecting a new color and shape until this is no longer the case. After all, the distractor cannot be identical to the target!\n- Call another function, `draw_shape()`, and specify the color and shape of the to-be-drawn distractor. This assumes that there is a function `draw_shape()`, even though we haven't defined it yet.\n\nIn addition, we \u2026\n\n- Use the `random` library, which is corresponds to the `random-ext` package. This library contains useful randomization functions (such as `random.pick()`) and is one of the non-standard JavaScript libraries that is included with OSWeb.\n\nNow we define the function that draws distractors in the Shape Feature condition (above the rest of the script so far):\n\n```js\n/**\n * Draws a single distractor in the feature-shape condition: an object that\n * has a different shape from the target, but can have any color.\n * @param c A Canvas.\n * @param x An x coordinate.\n * @param y A y coordinate.\n **/\nfunction draw_feature_shape_distractor(c, x, y) {\n    let colors = ['yellow', 'blue']\n    let color = random.pick(colors)\n    let shape\n    if (target_shape === 'circle') {\n        shape = 'square'\n    } else if (target_shape === 'square') {\n        shape = 'circle'\n    } else {\n        throw 'Invalid target_shape: ' + target_shape\n    }\n    draw_shape(c, x, y, color, shape)\n}\n```\n\nWhat happens here? We \u2026\n\n- Randomly select a color.\n- Choose a square shape if the target is a circle, and a circle shape if the target is square.\n- If `target_shape` is neither 'circle' nor 'square', `throw` an error\u2014more defensive programming!\n- Call another function, `draw_shape()`, and specify the color and shape of the to-be-drawn distractor. This assumes that there is a function `draw_shape()`, even though we haven't defined it yet.\n\nNow we define the function that draws distractors in the Color Feature condition (above the rest of the script so far):\n\n```js\n/**\n * Draws a single distractor in the feature-color condition: an object that\n * has a different color from the target, but can have any shape.\n * @param c A Canvas.\n * @param x An x coordinate.\n * @param y A y coordinate.\n **/\nfunction draw_feature_color_distractor(c, x, y) {\n    let shapes = ['circle', 'square']\n    let shape = random.pick(shapes)\n    let color\n    if (target_color === 'yellow') {\n        color = 'blue'\n    } else if (target_color === 'blue') {\n        color = 'yellow'\n    } else {\n        throw 'Invalid target_color: ' + target_color\n    }\n    draw_shape(c, x, y, color, shape)\n}\n```\n\nWhat happens here? We \u2026\n\n- Randomly select a shape.\n- Choose a blue color if the target is yellow, and a yellow color if the target is blue.\n- If `target_color` is neither 'yellow' nor 'blue', `throw` and error\u2014more defensive programming!\n- Call another function, `draw_shape()`, and specify the color and shape of the to-be-drawn distractor. This assumes that there is a function `draw_shape()`, even though we haven't defined it yet.\n\n__Implement the detailed level__\n\nNow we go all the way down to the details by defining the function that actually draws a shape to the canvas (above the rest of the script so far):\n\n```js\n/**\n * Draws a single shape.\n * @param c A Canvas.\n * @param x An x coordinate.\n * @param y A y coordinate.\n * @param color A color (yellow or blue)\n * @param shape A shape (square or circle)\n **/\nfunction draw_shape(c, x, y, color, shape) {\n    if (shape === 'square') {\n        // Parameters are passed as an Object!\n        c.rect({x:x-25, y:y-25, w:50, h:50, color:color, fill:true})\n    } else if (shape === 'circle') {\n        // Parameters are passed as an Object!\n        c.circle({x:x, y:y, r:25, color:color, fill:true})\n    } else {\n        throw 'Invalid shape: ' + shape\n    }\n    if (color !== 'yellow' && color !== 'blue') {\n        throw 'Invalid color: ' + color\n    }\n}\n```\n\nWhat happens here? We \u2026\n\n- Check which shape should be drawn. For squares, we add a `rect()` element to the canvas. For circles, we add a `circle()` element.\n- Check if the the shape is either a square or a circle, and if not `throw` and error. This is another example of defensive programming! We're making sure that we haven't accidentally specified an invalid shape.\n- Check if the the color is neither yellow nor blue, and if not `throw` and error.\n\nImportantly, `Canvas` functions accept a single object (`{}`) that specifies all parameters by name, like so:\n\n```js\n// Correct: pass a single object that contains all parameters by name\nc.rect({x:x-25, y:y-25, w:50, h:50, color:color, fill:true})\n// Incorrect: do not pass parameters by order\n// c.rect(x-25, y-25, 50, 50, color, true)\n// Incorrect: named parameters are not supported in JavaScript\n// c.rect(x=x-25, y=y-25, w=50, h=50, color=color, fill=true)\n```\n\n__Implement the Run phase__\n\nBecause we have done all the hard work in the Prepare phase, the Run phase is just:\n\n```js\nc.show()\n```\n\nThat's it! Now you have drawn a full visual-search display. And, importantly, you have done so in a way that is easy to understand, because of top-down programming, and safe, because of defensive programming.\n\n", "url": "https://osdoc.cogsci.nl/4.0/tutorials/intermediate-javascript", "title": "Intermediate tutorial (JavaScript): visual search"}
{"content": "# Intermediate tutorial (JavaScript): visual search\n\n## Step 7: Define the correct response\n\nTo know if the participant responds correctly, we need to know the correct response. You can define this explicitly in the *block_loop* (as done in the beginner tutorial); but here we're going to use some simple JavaScript that checks whether the target is present or not, and defines the correct response accordingly.\n\nTo do this, we first need to declare the variable in the Prepare tab of the *init* script, just below `let c`. This time, we use the `var` keyword to declare `correct_response`, because this makes the variable available in the user interface (whereas `let` does not do this):\n\n```js\nvar correct_response\n```\n\nNext, insert a new INLINE_JAVASCRIPT at the start of *trial_sequence*, and rename it to *correct_response_script*. In the Prepare phase, enter the following code:\n\n```js\nif (target_present === 'present') {\n    correct_response = 'right'\n} else if (vars.target_present === 'absent') {\n    correct_response = 'left'\n} else {\n    throw 'target_present should be absent or present, not ' + target\n}\n```\n\nWhat happens here? We \u2026\n\n- Check whether the target is present or not. If the target is present, the correct response is 'right' (the right arrow key); if the target is absent, the correct response is 'left' (the left arrow key). The experimental variable `correct_response` is automatically used by OpenSesame; therefore, we don't need to explicitly indicate that this variable contains the correct response.\n- Check if the target is either present or absent, and if not `throw` an error\u2014another example of defensive programming.\n\n## Step 8: Give per-trial feedback\n\nFeedback after every trial can motivate participants; however, per-trial feedback should not interfere with the flow of the experiment. A good way to give per-trial feedback is to briefly show a green fixation dot after a correct response, and a red fixation dot after an incorrect response.\n\nTo do this:\n\n- Insert two new SKETCHPADs into *trial_sequence*, just after *keyboard_response*.\n- Rename one SKETCHPAD to *green_dot*, draw a central green fixation dot onto it, and change its duration to 500.\n- Rename the other SKETCHPAD to *red_dot*, draw a central red fixation dot onto it, and change its duration to 500.\n\nOf course, only one of the two dots should be shown on each trial. To accomplish this, we will specify run-if statements in *trial_sequence*:\n\n- Change the run-if statement for *green_dot* to 'correct == 1', indicating that it should only be shown after a correct response.\n- Change the run-if statement for *red_dot* to 'correct == 0', indicating that it should only be shown after an incorrect response.\n\nThe variable `correct` is automatically created if the variable `correct_response` is available; that's why we defined `correct_response` in step 7. For more information about variables and run-if statements, see:\n\n- %link:manual/variables%\n\nThe *trial_sequence* should now look like %FigStep8.\n\n%--\nfigure:\n id: FigStep8\n source: step8.png\n caption: |\n  The *trial_sequence* at the end of step 8.\n--%\n\n\n## Finished!\n\nCongratulations, the experiment is complete! You can give it a test run by pressing on the toolbar button that shows a green circle with a gray play button inside (shortcut: `Alt+Ctrl+W`).\n\nIf the experiment doesn't work on the first try: Don't worry, and calmly figure out where the mistake comes from. Crashes are part of the normal development process. But you can save yourself a lot of time and headache by working in a structured way, as we have done in this tutorial.\n\n## References\n\n<div class='reference' markdown='1'>\n\nMath\u00f4t, S., Schreij, D., & Theeuwes, J. (2012). OpenSesame: An open-source, graphical experiment builder for the social sciences. *Behavior Research Methods*, *44*(2), 314-324. doi:10.3758/s13428-011-0168-7\n\nTreisman, A. M., & Gelade, G. (1980). A feature-integration theory of attention. *Cognitive Psychology*, 12(1), 97\u2013136. doi:10.1016/0010-0285(80)90005-5\n\n</div>\n\n[references]: #references\n[gpl]: http://www.gnu.org/licenses/gpl-3.0.en.html", "url": "https://osdoc.cogsci.nl/4.0/tutorials/intermediate-javascript", "title": "Intermediate tutorial (JavaScript): visual search"}
{"content": "# Beginner tutorial: gaze cuing\n\ntitle: Beginner tutorial: gaze cuing\n\n[TOC]\n\n## About OpenSesame\n\nOpenSesame is a program for easy of development of behavioral experiments for psychology, neuroscience, and experimental economy. For beginners, OpenSesame has a comprehensive graphical, point-and-click interface. For advanced users, OpenSesame supports Python scripting (not covered in this tutorial).\n\nOpenSesame is freely available under the [General Public License v3][gpl].\n\n## About this tutorial\n\nThis tutorial shows how to create a simple but complete psychological experiment using OpenSesame [(Math\u00f4t, Schreij, & Theeuwes, 2012; Math\u00f4t & March, 2022)][references]. You will use mainly the graphical user interface of OpenSesame (i.e., no Python inline coding), although you will make small modifications to the OpenSesame script. This tutorial takes approximately one hour.\n\n## Resources\n\n- __Download__ -- This tutorial assumes that you are running OpenSesame version 4.0.0 or later. To check which version you are running, see the bottom right of the 'Get started' tab (see %FigGetStarted). You can download the most recent version of OpenSesame from:\n\t- %link:download%\n- __Documentation__ -- A dedicated documentation website can be found at:\n\t- <http://osdoc.cogsci.nl/>\n- __Forum__ -- A support forum can be found at:\n\t- <http://forum.cogsci.nl/>\n\n## The experiment\n\nIn this tutorial, you will create a gaze-cuing experiment as introduced by [Friesen and Kingstone (1998)][references]. In this experiment, a face is presented in the center of the screen (%FigGazeCuing). This face looks either to the right or to the left. A target letter (an 'F' or an 'H') is presented to the left or right of the face. A distractor stimulus (the letter 'X') is presented on the other side of the face. The task is to indicate as quickly as possible whether the target letter is an 'F' or an 'H'. In the congruent condition, the face looks at the target. In the incongruent condition, the face looks at the distractor. As you may have guessed, the typical finding is that participant respond faster in the congruent condition than in the incongruent condition, even though the direction of gaze is not predictive of the target location. This shows that our attention is automatically guided by other people's gaze, even in situations where this doesn't serve any purpose. (And even when the face is just a smiley!)\n\n%--\nfigure:\n id: FigGazeCuing\n source: gaze-cuing.png\n caption: |\n  The gaze-cuing paradigm [(Friesen and Kingstone, 1998)][references] that you will implement in this tutorial. This example depicts a trial in the incongruent condition, because the smiley looks at the distractor ('X') and not at the target ('F').\n--%\n\nThe experiment consists of a practice and an experimental phase. Visual feedback will be presented after every block of trials. A sound will be played after every incorrect response.\n\n## Experimental design\n\nThis design:\n\n- is *within-subject*, because all participants do all conditions\n- is *fully crossed* (or full-factorial), because all combinations of conditions occur\n- has three factors (or factors):\n    - *gaze side* with two levels (left, right)\n    - *target side* with two levels (left, right)\n    - *target letter* with two levels (F, H)\n- has N subjects\n\n\nSee also %DesignScreencast for an explanation of the logic and design of the experiment:\n\n\n%--\nvideo:\n source: youtube\n id: DesignScreencast\n videoid: aWvibRH6D4E\n width: 640\n height: 360\n caption: |\n  An explanation of the experimental logic and design.\n--%\n\n\n## Step 1: Create the main sequence\n\nWhen you start OpenSesame, you see the 'Get started!' tab (%FigGetStarted). A list of templates is shown below 'Start a new experiment'. These templates provide convenient starting points for new experiments. After you saved an experiment the first time, recently opened experiments are shown under 'Continue with a recent experiment'. At the bottom of the page there are links to the documentation (which includes this tutorial), the community forum, and a page with professional (paid) support options. And of course a link where you can buy us a cup of coffee to help us stay awake while we are working on providing the best free software!\n\n%--\nfigure:\n id: FigGetStarted\n source: get-started.png\n caption: |\n  The 'Get started' dialog on OpenSesame start-up.\n--%\n\nClick on 'Default template' to start with a minimal experimental template.\n\nBy default there is a main SEQUENCE, which is simply called *experiment*. Click on *experiment* in the overview area (by default on the left side, see %FigInterface) to open its controls in the tab area. The *experiment* SEQUENCE consists of two items: a `notepad` called *getting started* and a SKETCHPAD called *welcome*.\n\nWe don't need these two items. Remove *getting_started* by right-clicking on it in the overview area and selecting 'Delete' (shortcut: `Del`). Remove *welcome* in the same way. The *experiment* SEQUENCE is now empty.\n\n%--\nfigure:\n id: FigInterface\n source: interface.png\n caption: \"The default layout of the OpenSesame interface.\"\n--%\n\n<div class='info-box' markdown='1'>\n\n__Background box__\n\n__Names vs types__ -- Items in OpenSesame have a name and a type. The name and type can be the same, but they are usually not. For example, a SKETCHPAD item can have the name *my_target_sketchpad*. To make this distinction clear, we will use `monospace` to indicate item types, and *italics* to indicate names.\n\n__Tip__ -- The 'Extended template' is a good starting point for many experiments. It already contains the basic structure of a trial-based experiment.\n\n__Tip__ -- You can click on the Help icons in the top right of an item's tab to get context-sensitive help.\n\n__Tip__ -- Save (shortcut: `Ctrl+S`) your experiment often! In the unfortunate (and unlikely) event of data loss, you will often be able to recover your work from the back-ups that are created automatically, by default, every 10 minutes (Menu \u2192 Tools \u2192 Open backup folder).\n\n__Tip__ -- Unless you have used 'Permanently delete' (shortcut: `Shift+Del`), deleted items are still available in the 'Unused items' bin, until you select 'Permanently delete unused items' in the 'Unused items' tab. You can re-add deleted items to a SEQUENCE by dragging them out of the 'Unused items' bin to somewhere in your experiment.\n\n__Tip__ -- %FigExperimentStructure schematically shows the structure of the experiment that you will create. If you get confused during the tutorial, you can refer to %FigExperimentStructure to see where you are.\n\n%--\nfigure:\n id: FigExperimentStructure\n source: experiment-structure.png\n caption: |\n  A schematic representation of the structure of the 'Gaze cuing' experiment. The item types are in bold face, item names in regular face.\n--%\n\n</div>\n\n__Append a form_text_display item for the instruction display__\n\nAs the name suggests, a `form_text_display` is a form that displays text. We are going to use a `form_text_display` to give instructions to the participant at the beginning of the experiment.\n\nClick on *experiment* in the overview area to open its controls in the tab area. You will see an empty SEQUENCE. Drag a `form_text_display` from the item toolbar (under 'Form', see %FigInterface) onto the *experiment* SEQUENCE in the tab area. When you let go, a new `form_text_display` item will be inserted into the SEQUENCE. (We will get back to this in Step 12.)\n\n<div class='info-box' markdown='1'>\n\n__Background box__\n\n__Tip__ -- You can drag items into the overview area and into SEQUENCE tabs.\n\n__Tip__ -- If a drop action is ambiguous, a pop-up menu will ask you what you want to do.\n\n__Tip__ -- A `form_text_display` only shows text. If you require images etc., you can use a SKETCHPAD item. We will meet the SKETCHPAD in Step 5.\n\n</div>\n\n__Append a loop item, containing a new sequence item, for the practice phase__\n\nWe need to append a LOOP item to the *experiment* SEQUENCE. We will use this LOOP for the practice phase of the experiment. Click on the *experiment* SEQUENCE to open its controls in the tab area.\n\nDrag the LOOP item from the item toolbar into the SEQUENCE just the way you added the `form_text_display`. New items are inserted below the item that they are dropped on, so if you drop the new LOOP onto the previously created `form_text_display`, it will appear where you want it: after the `form_text_display`. But don't worry if you drop a new item in the wrong place, because you can always re-order things later.\n\nBy itself, a LOOP does not do anything. A LOOP always needs another item to run. Therefore, you have to fill the new LOOP item with another item. (If you view the loop item, you will also see a warning: 'No item selected'.) Drag a SEQUENCE item from the item toolbar onto the LOOP item. A pop-up menu will appear, asking you whether you want to insert the SEQUENCE after or into the LOOP item. Select 'Insert into new_loop'. (We will get back to this in Step 2.)\n\n<div class='info-box' markdown='1'>\n\n__Background box__\n\n__What is a LOOP item?__ -- A LOOP is an item that adds structure to your experiment. It repeatedly runs another item, typically a SEQUENCE. A LOOP is also the place where you will usually define your independent variables, that is, those variables that you manipulate in your experiment.\n\n__What is a SEQUENCE item?__ -- A SEQUENCE item also adds structure to your experiment. As the name suggests, a SEQUENCE runs multiple other items one after another.\n\n__The LOOP-SEQUENCE structure__ -- You often want to repeat a sequence of events. To do this, you will need a LOOP item that contains a SEQUENCE item. By itself, a SEQUENCE does not repeat. It simply starts with the first item and ends with the last item. By 'wrapping' a LOOP item around the SEQUENCE, you can repeat the SEQUENCE multiple times. For example, a single trial usually corresponds to a single SEQUENCE called *trial_sequence*. A LOOP (often called *block_loop*) around this *trial_sequence* would then constitute a single block of trials. Similarly, but at another level of the experiment, a SEQUENCE (often called *block_sequence*) may contain a single block of trials, followed by a FEEDBACK display. A *practice_phase* LOOP around this 'block' SEQUENCE would then constitute the practice phase of the experiment. This may seem a bit abstract right now, but as you follow this tutorial, you will become familiar with the use of LOOPs and SEQUENCEs.\n\n__Tip__ -- For more information about SEQUENCEs and LOOPs, see:\n\n- %link:loop%\n- %link:sequence%\n\n</div>\n\n__Append a new form_text_display item for the end-of-practice message__\n\nAfter the practice phase, we want to inform the participant that the real experiment will begin. For this we need another `form_text_display`. Go back to the *experiment* SEQUENCE, and drag a `form_text_display` from the item toolbar onto the LOOP item. The same pop-up menu will appear as before. This time, select 'Insert after new_loop'. (We will get back to this in Step 12.)\n\n<div class='info-box' markdown='1'>\n\n__Tip__ -- Don't worry if you have accidentally changed a LOOP's item to run. You can undo this easily by clicking the 'Undo' button in the toolbar (`Ctrl+Shift+Z`).\n\n</div>\n\n__Append a new loop item, containing the previously created sequence, for the experimental phase__\n\nWe need a LOOP item for the experimental phase, just like for the practice phase. Therefore, drag a LOOP from the item toolbar menu onto *_form_text_display*.\n\nThe newly created LOOP (called *new_loop_1*) is empty, and should be filled with a SEQUENCE, just like the LOOP we created before. However, because the trials of the practice and experimental phase are identical, they can use the same SEQUENCE. Therefore, instead of dragging a new SEQUENCE from the item toolbar, you can re-use the *existing* one (i.e. create a linked copy).\n\nTo do this, right-click on the previously created *new_sequence*, and select 'Copy (linked)'. Now, right-click on *new_loop_1* and select 'Paste'. In the pop-up menu that appears, select 'Insert into new_loop 1'.\n\n<div class='info-box' markdown='1'>\n\n__Background box__\n\n__Tip__ \u2014 There is an important distinction between *linked* and *unlinked* copies. If you create a linked copy of an item, you create another occurrence of the same item. Therefore, if you modify the original item, the linked copy will change as well. In contrast, if you create an unlinked copy of an item, the copy will be initially look identical (except for its name), but you can edit the original without affecting the unlinked copy, and vice versa.\n\n</div>\n\n__Append a new form_text_display item, for the goodbye message__\n\nWhen the experiment is finished, we should say goodbye to the participant. For this we need another `form_text_display` item. Go back to the *experiment* SEQUENCE, and drag a `form_text_display` from the item toolbar onto *new_loop_1*. In the pop-up menu that appears, select 'Insert after new_loop_1'. (We will get back to this in Step 12.)\n\n__Give the new items sensible names__\n\nBy default, new items have names like *new_sequence* and *new_form_text_display_2*. It is good practice to give items sensible names. This makes it much easier to understand the structure of the experiment. If you want, you can also add a description to each item. Item names must consist of alphanumeric characters and/or underscores.\n\n- Select *new_form_text_display* in the overview area, double-click on its label in the top of the tab area and rename the item to *instructions*. (Overview-area shortcut: `F2`)\n- Rename *new_loop* to *practice_loop*.\n- Rename *new_sequence* to *block_sequence*. Because you have re-used this item in *new_loop_1*, the name automatically changes there as well. (This illustrates why it is efficient to create linked copies whenever this is possible.)\n- Rename *new_form_text_display_1* to *end_of_practice*.\n- Rename *new_loop_1* to *experimental_loop*.\n- Rename *new_form_text_display_2* to *end_of_experiment*.\n\n__Give the whole experiment a sensible name__\n\nThe experiment in its entirety also has a title and a description. Click on 'New experiment' in the overview area. You can rename the experiment in the same way as you renamed its items. The title currently is 'New experiment'. Rename the experiment to 'Tutorial: Gaze cuing'. Unlike item names, the experiment title may contain spaces etc.\n\nThe overview area of your experiment now looks like %FigStep1. This would be a good time to save your experiment (shortcut: `Ctrl+S`).\n\n%--\nfigure:\n id: FigStep1\n source: step1.png\n caption: |\n  The overview area at the end of the step 1.\n--%\n\n\n## Step 2: Create the block sequence\n\nClick on *block_sequence* in the overview. At the moment this SEQUENCE is empty. We want *block sequence* to consist of a block of trials, followed by a  FEEDBACK display. For this we need to do the following:\n\n__Append a reset_feedback item to reset the feedback variables__\n\nWe don't want our feedback to be confounded by key presses that participants have made during the instruction phase or previous blocks of trials. Therefore, we start each block of trials by resetting the feedback variables. To do this we need a `reset_feedback` item. Grab `reset_feedback` from the item toolbar (under 'Response collection') and drag it onto *block_sequence*.\n\n__Append a new loop, containing a new sequence, for a block of trials__\n\nFor a single trial we need a SEQUENCE. For a block of trials, we need to repeat this SEQUENCE multiple times. Therefore, for a block of trials we need to wrap a LOOP around a SEQUENCE. Drag a LOOP from the item toolbar onto *new_reset_feedback*. Next, drag a SEQUENCE from the item toolbar onto the newly created LOOP, and select 'Insert into new_loop' in the pop-up menu that appears. (We will get back to this in Step 3.)\n\n__Append a feedback item__\n\nAfter every block of trials we want to give feedback to the participant, so that the participant knows how well he/ she is doing. For this we need a FEEDBACK item. Drag a FEEDBACK from the item toolbar onto *new_loop*, and select 'Insert after loop' in the pop-up menu that appears. (We will get back to this in Step 10.)\n\n__Give the new items sensible names__\n\nRename: (See Step 1 if you don't remember how to do this.)\n\n- *new_loop* to *block_loop*\n- *new_sequence* to *trial_sequence*\n- *new_reset_feedback* to *reset_feedback*\n- *new_feedback* to *feedback*\n\nThe overview of your experiment now looks like %FigStep2. Remember to save your experiment regularly.\n\n%--\nfigure:\n id: FigStep2\n source: step2.png\n caption: |\n  The overview area at the end of Step 2.\n--%\n", "url": "https://osdoc.cogsci.nl/4.0/tutorials/beginner", "title": "Beginner tutorial: gaze cuing"}
{"content": "# Beginner tutorial: gaze cuing\n\n## Step 3: Fill the block loop with independent variables\n\nAs the name suggests, *block_loop* corresponds to a single block of trials. In the previous step we created the *block_loop*, but we still need to define the independent variables that will be varied within the block. Our experiment has three independent variables:\n\n- __gaze_cue__ can be 'left' or 'right'.\n- __target_pos__ (the position of the target) can be '-300' or '300'. These values reflect the X-coordinate of the target in pixels (0 = center). Using the coordinates directly, rather than 'left' and 'right', will be convenient when we create the target displays (see Step 5).\n- __target_letter__ (the target letter) can be 'F' or 'H'.\n\nTherefore, our experiment has 2 x 2 x 2 = 8 levels. Although 8 levels is not that many (most experiments will have more), we don't need to enter all possible combinations by hand. Click on *block_loop* in the overview to open its tab. Now click on the 'Full-factorial design' button. In the variable wizard, you simply define all variables by typing the name in the first row and the levels in the rows below the name (see %FigVariableWizard). If you select 'Ok', you will see that *block_loop* has been filled with all 8 possible combinations.\n\n%--\nfigure:\n id: FigVariableWizard\n source: variable-wizard.png\n caption: |\n  The loop variable wizard in Step 3.\n--%\n\nIn the resulting loop table, each row corresponds to one run of *trial_sequence*. Because, in our case, one run of *trial_sequence* corresponds to one trial, each row in our loop table corresponds to one trial. Each column corresponds to one variable, which can have a different value on each trial.\n\nBut we are not done yet. We need to add three more variables: the location of the distractor, the correct response, and the congruency.\n\n- __dist_pos__ -- On the first row of the first empty column, enter 'dist_pos'. This automatically adds a new experimental variable named 'dist_pos'. In the rows below, enter '300' wherever 'target_pos' is -300, and '-300' wherever 'target_pos' is 300. In other words, the target and the distractor should be positioned opposite from each other.\n- __correct_response__ -- Create another variable, in another empty column, with the name 'correct_response'. Set 'correct_response' to 'z' where 'target_letter' is 'F', and to 'm' where 'target_letter' is 'H'. This means that the participant should press the 'z' key if she sees an 'F' and the 'm' key if she sees an 'H'. (Feel free to choose different keys if 'z' and 'm' are awkward on your keyboard layout; for example, 'w' and 'n' are better on AZERTY keyboards.)\n- __congruency__ -- Create another variable with the name 'congruency'. Set 'congruency' to 'congruent' where 'target_pos' is '-300' and 'gaze_cue' is 'left', and where 'target_pos' is '300' and 'gaze_cue' is 'right'. In other words, a trial is congruent if the face looks at the target. Set 'congruency' to 'incronguent' for the trials on which the face looks at the distractor. The 'congruency' variable is not necessary to run the experiment; however, it is useful for analyzing the data later on.\n\nWe need to do one last thing. 'Repeat' is currently set to '1.00'. This means that each cycle will be executed once. So the block now consists of 8 trials, which is a bit short. A reasonable length for a block of trials is 24, so set 'Repeat' to 3.00 (3 repeats x 8 cycles = 24 trials). You don't need to change 'Order', because 'random' is exactly what we want.\n\nThe *block_loop* now looks like %FigStep3. Remember to save your experiment regularly.\n\n%--\nfigure:\n id: FigStep3\n source: step3.png\n caption: \"The *block_loop* at the end of Step 3.\"\n--%\n\n<div class='info-box' markdown='1'>\n\n__Background box__\n\n__Tip__ -- You can prepare your loop table in your favorite spreadsheet program and copy-paste it into the LOOP variable table.\n\n__Tip__ -- You can specify your loop table in a separate file (in `.xlsx` or `.csv`) format, and use this file directly. To do so, select 'file' under 'Source'.\n\n__Tip__ -- You can set 'Repeat' to a non-integer number. For example, by setting 'Repeat' to '0.5', only half the trials (randomly selected) are executed.\n\n</div>\n\n## Step 4: Add images and sound files to the file pool\n\nFor our stimuli, we will use images from file. In addition, we will play a sound if the participant makes an error. For this we need a sound file.\n\nYou can download the required files here (in most webbrowsers you can right-click the links and choose 'Save Link As' or a similar option):\n\n- [gaze_neutral.png](/img/beginner-tutorial/gaze_neutral.png)\n- [gaze_left.png](/img/beginner-tutorial/gaze_left.png)\n- [gaze_right.png](/img/beginner-tutorial/gaze_right.png)\n- [incorrect.ogg](/img/beginner-tutorial/incorrect.ogg)\n\nAfter you have downloaded these files (to your desktop, for example), you can add them to the file pool. If the file pool is not already visible (by default on the right side of the window), click on the 'Show file pool' button in the main toolbar (shortcut: `Ctrl+P`). The easiest way to add the four files to the file pool is to drag them from the desktop (or wherever you have downloaded the files to) into the file pool. Alternatively, you can click on the '+' button in the file pool and add files using the file select dialog that appears. The file pool will be automatically saved with your experiment.\n\nYour file pool now looks like %FigStep4. Remember to save your experiment regularly.\n\n%--\nfigure:\n id: FigStep4\n source: step4.png\n caption: \"The file pool at the end of Step 4.\"\n--%\n\n## Step 5: Fill the trial sequence with items\n\nA trial in our experiment looks as follows:\n\n1. __Fixation dot__ -- 750 ms, SKETCHPAD item\n2. __Neutral gaze__ -- 750 ms, SKETCHPAD item\n3. __Gaze cue__ -- 500 ms, SKETCHPAD item\n4. __Target__  -- 0 ms, SKETCHPAD item\n5. __Response collection__ \t-- KEYBOARD_RESPONSE item\n6. __Play a sound if response was incorrect__ --  SAMPLER item\n7. __Log response to file__ -- LOGGER item\n\nClick on *trial_sequence* in the overview to open the *trial_sequence* tab. Pick up a SKETCHPAD from the item toolbar and drag it into the *trial_sequence*. Repeat this three more times, so that *trial_sequence* contains four SKETCHPADs. Next, select and append a KEYBOARD_RESPONSE item, a SAMPLER item, and a LOGGER item.\n\nAgain, we will rename the new items, to make sure that the *trial_sequence* is easy to understand. Rename:\n\n- *new_sketchpad* to *fixation_dot*\n- *new_sketchpad_1* to *neutral_gaze*\n- *new_sketchpad_2* to *gaze_cue*\n- *new_sketchpad_3* to *target*\n- *new_keyboard_response* to *keyboard_response*\n- *new_sampler* to *incorrect_sound*\n- *new_logger* to *logger*\n\nBy default, items are always executed, which is indicated by the run-if expression `True`. However, we want to change this for the *incorrect_sound* item, which should only be executed if an error was made. To do this, we need to change the 'Run if' expression to `correct == 0` in the *trial_sequence* tab. This works, because the *keyboard_response* item automatically creates a `correct` variable, which is set to `1` (correct), `0` (incorrect), or `undefined` (this relies on the `correct_response` variable that was defined in Step 3). The double equals sign is Python syntax and indicates that you want to compare whether the two things are equal to each other, in this case whether the variable `correct` is equal to 0. To change a run-if expression, double click on it (shortcut: `F3`).\n\nThe *trial_sequence* now looks like %FigStep5.\n\n%--\nfigure:\n id: FigStep5\n source: step5.png\n caption: \"The *trial_sequence* at the end of Step 5.\"\n--%\n\n<div class='info-box' markdown='1'>\n\n__Background box__\n\n__What is a SKETCHPAD item?__ -- A SKETCHPAD is used to present visual stimuli: text, geometric shapes, fixation dots, Gabor patches, etc. You can draw on the SKETCHPAD using the built-in drawing tools.\n\n__What is a KEYBOARD_RESPONSE item?__ -- A KEYBOARD_RESPONSE item collects a single participant's response from the keyboard.\n\n__What is a SAMPLER item?__ -- A SAMPLER item plays a sound from a sound file.\n\n__What is a LOGGER item?__ -- A LOGGER item writes data to the log file. This is very important: If you forget to include a LOGGER item, no data will be logged during the experiment!\n\n__Tip__ -- Variables and conditional \"if\" expressions are very powerful! To learn more about them, see:\n\n- %link:manual/variables%\n\n</div>\n\n## Step 6: Draw the sketchpad items\n\nThe SKETCHPAD items that we have created in Step 5 are still blank. It's time to do some drawing!\n\n__Set the background color to white__\n\nClick on *fixation_dot* in the overview area to open its tab. The SKETCHPAD is still dark gray, while the images that we have downloaded have a white background. Oops, we forgot to set the background color of the experiment to white (it is dark gray by default)! Click on 'Tutorial: Gaze cuing' in the overview area to open the 'General properties' tab. Change 'Foreground' to 'black' and 'Background' to 'white'.\n\n<div class='info-box' markdown='1'>\n\n__Background box__\n\n__Tip__ -- For more fine-grained control over colors, you can also use the hexadecimal RGB notation (e.g., `#FF000` for red), use various color spaces, or use the color-picker tool. See also:\n\n- %link:manual/python/canvas%\n\n</div>\n\n__Draw the fixation dot__\n\nGo back to the *fixation_dot* by clicking on *fixation_dot* in the overview. Now select the fixation-dot element by clicking on the button with the crosshair. If you move your cursor over the sketchpad, you can see the screen coordinates in the top-right. Set the (foreground) color to 'black'. Click on the center of the screen (0, 0) to draw a central fixation dot.\n\nFinally, change the 'Duration' field from 'keypress' to '745', because we want the fixation dot to be presented for 750 ms. Wait ... *why didn't we just specify a duration of 750 ms?* The reason for this is that the actual display-presentation duration is always rounded up to a value that is compatible with your monitor's refresh rate. This may sound complicated, but for most purposes the following rules of thumb are sufficient:\n\n1. Choose a duration that is possible given your monitor's refresh rate. For example, if your monitor's refresh rate is 60 Hz, it means that every frame lasts 16.7 ms (= 1000 ms/60 Hz). Therefore, on a 60 Hz monitor, you should always select a duration that is a multiple of 16.7 ms, such as 16.7, 33.3, 50, 100, etc.\n2. In the duration field of the SKETCHPAD specify a duration that is a few milliseconds less than what you're aiming for. So if you want to present a SKETCHPAD for 50 ms, choose a duration of 45. If you want to present a SKETCHPAD for 1000 ms, choose a duration of 995. Etcetera.\n\n<div class='info-box' markdown='1'>\n\n__Background box__\n\n__Tip__ -- For a detailed discussion of experimental timing, see:\n\n- %link:timing%\n\n__Tip__ -- The duration of a SKETCHPAD can be a value in milliseconds, but you can also enter 'keypress' or 'mouseclick' to collect a keyboard press or mouse click respectively. In this case a SKETCHPAD will work much the same as a KEYBOARD_RESPONSE item (but with fewer options).\n\n__Tip__ -- Make sure that the (foreground) color is set to black. Otherwise you will draw white on white and won't see anything!\n\n</div>\n\n__Draw the neutral gaze__\n\nOpen the *neutral_gaze* SKETCHPAD. Now select the image tool by clicking on the button with the mountain-landscape-like icon. Click on the center of the screen (0, 0). The 'Select file from pool' dialog will appear. Select the file `gaze_neutral.png` and click on the 'Select' button. The neutral gaze image will now stare at you from the center of the screen! Finally, like before, change the 'Duration' field from 'keypress' to '745'. (And note again that this means a duration of 750 ms on most monitors!)\n\n<div class='info-box' markdown='1'>\n\n__Background box__\n\n__Tip__ -- OpenSesame can handle a wide variety of image formats. However, some (non-standard) `.bmp` formats are known to cause trouble. If you find that a `.bmp` image is not shown, you can convert it to a different format, such as `.png`. You can convert images easily with free tools such as [GIMP].\n</div>\n\n__Draw the gaze cue__\n\nOpen the *gaze_cue* SKETCHPAD, and again select the image tool. Click on the center of the screen (0, 0) and select the file `gaze_left.png`.\n\nBut we are not done yet! Because the gaze cue should not always be 'left', but should depend on the variable `gaze_cue`, which we have defined in Step 3. However, by drawing the `gaze_left.png` image to the SKETCHPAD, we have generated a script that needs only a tiny modification to make sure that the proper image is shown. Click on the 'Select view' button at the top-right of the *gaze_cue* tab and select 'View script'. You will now see the script that corresponds to the sketchpad that we have just created:\n\n~~~ .python\nset duration keypress\nset description \"Displays stimuli\"\ndraw image center=1 file=\"gaze_left.png\" scale=1 show_if=True x=0 y=0 z_index=0\n~~~\n\nThe only thing that we need to do is replace `gaze_left.png` with `gaze_{gaze_cue}.png`. This means that OpenSesame uses the variable `gaze_cue` (which has the values `left` and `right`) to determine which image should be shown.\n\nWhile we are at it, we might as well change the duration to '495' (rounded up to 500!). The script now looks like this:\n\n~~~ .python\nset duration 495\nset description \"Displays stimuli\"\ndraw image center=1 file=\"gaze_{gaze_cue}.png\" scale=1 show_if=True x=0 y=0 z_index=0\n~~~\n\nClick the 'Apply' button at the top right to apply your changes to the script and return to the regular item controls. OpenSesame will warn you that the image cannot be shown, because it is defined using variables, and a placeholder image will be shown instead. Don't worry, the correct image will be shown during the experiment!\n\n<div class='info-box' markdown='1'>\n\n__Background box__\n\n__Tip__ -- The variable inspector (shortcut: `Ctrl+I`) is a powerful way to find out which variables have been defined in your experiment, and which values they have (see %FigVariableInspector). When your experiment is not running, most variables don't have a value yet. But when you run your experiment in a window, while having the variable inspector visible, you can see variables changing in real time. This is very useful for debugging your experiment.\n\n%--\nfigure:\n id: FigVariableInspector\n source: variable-inspector.png\n caption: \"The variable inspector is a convenient way to get an overview of the variables that exist in your experiment.\"\n--%\n\n</div>\n\n__Draw the target__\n\nWe want three objects to be part of the target display: the target letter, the distractor letter, and the gaze cue (see %FigGazeCuing). As before, we will start by creating a static display using the SKETCHPAD editor. After this, we will only need to make minor changes to the script so that the exact display depends on the variables.\n\nClick on *target* in the overview to open the target tab and like before, draw the `gaze_left.png` image at the center of the screen. Now select the draw text tool by clicking on the button with the 'A' icon. Change the foreground color to 'black' (if it isn't already). The default font size is 18 px, which is a bit small for our purpose, so change the font size to 32 px. Now click on (-320, 0) in the SKETCHPAD (the X-coordinate does not need to be exactly 320, since we will change this to a variable anyway). Enter \"{target_letter}\" in the dialog that appears, to draw the target letter (when drawing text, you can use variables directly). Similarly, click on (320, 0) and draw an 'X' (the distractor is always an 'X').\n\nNow open the script editor by clicking on the 'Select view' button at the top-right of the tab and selecting 'View script'. The script looks like this:\n\n~~~ .python\nset duration keypress\nset duration keypress\nset description \"Displays stimuli\"\ndraw image center=1 file=\"gaze_left.png\" scale=1 show_if=True x=0 y=0 z_index=0\ndraw textline center=1 color=black font_bold=no font_family=mono font_italic=no font_size=32 html=yes show_if=True text=\"{target_letter}\" x=-320 y=0 z_index=0\ndraw textline center=1 color=black font_bold=no font_family=mono font_italic=no font_size=32 html=yes show_if=True text=X x=320 y=0 z_index=0\n~~~\n\nLike before, change `gaze_left.png` to `gaze_{gaze_cue}.png`. We also need to make the position of the target and the distractor depend on the variables `target_pos` and `dist_pos` respectively. To do this, simply change `-320` to `{target_pos}` and `320` to `{dist_pos}`. Make sure that you leave the `0`, which is the Y-coordinate. The script now looks like this:\n\n~~~ .python\nset duration keypress\nset description \"Displays stimuli\"\ndraw image center=1 file=\"gaze_{gaze_cue}.png\" scale=1 show_if=True x=0 y=0 z_index=0\ndraw textline center=1 color=black font_bold=no font_family=mono font_italic=no font_size=32 html=yes show_if=True text=\"{target_letter}\" x={target_pos} y=0 z_index=0\ndraw textline center=1 color=black font_bold=no font_family=mono font_italic=no font_size=32 html=yes show_if=True text=X x={dist_pos} y=0 z_index=0\n~~~\n\nClick on the 'Apply' button to apply the script and go back to the regular item controls.\n\nFinally, set the 'Duration' field to '0'. This does not mean that the target is presented for only 0 ms, but that the experiment will advance to the next item (the *keyboard_response*) right away. Since the *keyboard_response* waits for a response, but doesn't change what's on the screen, the target will remain visible until a response has been given.\n\nRemember to save your experiment regularly.\n\n<div class='info-box' markdown='1'>\n\n__Background box__\n\n__Tip__ -- Each element of a SKETCHPAD has a 'Show if' option, which specifies when the element should be shown. You can use this to hide/ show elements from a SKETCHPAD depending on certain variables, similar to run-if statements in a SEQUENCE.\n\n__Tip__ -- Make sure that the (foreground) color is set to black. Otherwise you will draw white on white and won't see anything!\n\n</div>\n", "url": "https://osdoc.cogsci.nl/4.0/tutorials/beginner", "title": "Beginner tutorial: gaze cuing"}
{"content": "# Beginner tutorial: gaze cuing\n\n## Step 7: Configure the keyboard response item\n\nClick on *keyboard_response* in the overview to open its tab. You see three options: Correct response, Allowed responses, Timeout, and Event type.\n\nWe have already set the `correct_response` variable in Step 3. Unless we explicitly specify a correct response, OpenSesame automatically uses the `correct_response` variable if it is available. Therefore, we don't need to change the 'Correct response' field here.\n\nWe do need to set the allowed responses. Enter 'z;m' in the allowed-responses field (or other keys if you have chosen different response keys). The semicolon is used to separate responses. The KEYBOARD_RESPONSE now only accepts 'z' and 'm' keys. All other key presses are ignored, with the exception of 'escape', which pauses the experiment.\n\nWe also want to set a timeout, which is the maximum interval that the KEYBOARD_RESPONSE waits before deciding that the response is incorrect and setting the 'response' variable to 'None'. '2000' (ms) is a good value.\n\nWe don't need to change the Event type, because we want the participant to respond by pressing a key (keypress, the default) and not by releasing a key (keyrelease).\n\nThe KEYBOARD_RESPONSE now looks like %FigStep7.\n\n%--\nfigure:\n id: FigStep7\n source: step7.png\n caption: \"The KEYBOARD_RESPONSE at the end of Step 7.\"\n--%\n\n<div class='info-box' markdown='1'>\n\n__Background box__\n\n__Tip__ -- By default, the KEYBOARD_RESPONSE will use the `correct_response` variable to determine whether a response was correct. But you can use a different variable as well. To do this, enter a variable name between curly braces (`{my_variable}`) in the correct response field.\n\n__Tip__ -- If 'flush pending key presses' is enabled (it is by default), all pending key presses are discarded when the KEYBOARD_RESPONSE item is called. This prevents carry-over effects, which might otherwise occur if the participant accidentally presses a key during a non-response part of the trial.\n\n__Tip__ -- To use special keys, such as '/' or the up-arrow key, you can use key names (e.g., 'up' and 'space') or associated characters (e.g., '/' and ']'). The 'List available keys' button provides an overview of all valid key names.\n\n</div>\n\n## Step 8: Configure the incorrect (sampler) item\n\nThe *incorrect_sound* item doesn't need much work: We only need to select the sound that should be played. Click on *incorrect_sound* in the overview to open its tab. Click on the 'Browse' button and select `incorrect.ogg` from the file pool.\n\nThe sampler now looks like %FigStep8.\n\n%--\nfigure:\n id: FigStep8\n source: step8.png\n caption: \"The *incorrect_sound* item at the end of Step 8.\"\n--%\n\n<div class='info-box' markdown='1'>\n\n__Background box__\n\n__Tip__ -- You can use variables to specify which sound should be played by using a variable name between curly braces as (part of) the file name. For example: `{a_word}.ogg`\n\n__Tip__ -- The SAMPLER handles files in `.ogg`, `.mp3`, and `.wav` format. If you have sound files in a different format, [Audacity] is a great free tool to convert sound files (and much more).\n\n</div>\n\n## Step 9: Configure the variable logger\n\nActually, we don't need to configure the variable LOGGER, but let's take a look at it anyway. Click on *logger* in the overview to open its tab. You see that the option 'Automatically log all variables' is selected. This means that OpenSesame logs everything, which is fine.\n\n<div class='info-box' markdown='1'>\n\n__Background box__\n\n__Tip__ -- If you like your log-files clean, you can disable the 'Automatically log all variables' option and manually select variables, either by entering variable names manually ('Add custom variable'), or by dragging variables from the variable inspector into the LOGGER table. You can also leave the 'Automatically log all variables' option enabled and exclude variables that you are not interested in.\n\n__The one tip to rule them all__ -- Always triple-check whether all the necessary variables are logged in your experiment! The best way to check this is to run the experiment and investigate the resulting log files.\n\n</div>\n\n## Step 10: Draw the feedback item\n\nAfter every block of trials, we want to present feedback to the participant to let him/ her know how well he/ she is doing. Therefore, in Step 2, we added a FEEDBACK item, simply named *feedback* to the end of *block_sequence*.\n\nClick on *feedback* in the overview to open its tab, select the draw text tool, change the foreground color to 'black' (if it isn't already), and click at (0, 0). Now enter the following text:\n\n```text\nEnd of block\n\nYour average response time was {avg_rt} ms\nYour accuracy was {acc} %\n\nPress any key to continue\n```\n\nBecause we want the feedback item to remain visible as long as the participant wants (i.e. until he/ she presses a key), we leave 'Duration' field set to 'keypress'.\n\nThe feedback item now looks like %FigStep_10.\n\n%--\nfigure:\n id: FigStep_10\n source: step10.png\n caption: \"The feedback item at the end of Step 10.\"\n--%\n\n<div class='info-box' markdown='1'>\n\n__Background box__\n\n__What is a feedback item?__ -- A FEEDBACK item is almost identical to a SKETCHPAD item. The only difference is that a FEEDBACK item is not prepared in advance. This means that you can use it to present feedback, which requires up-to-date information about a participant's response. You should not use FEEDBACK items to present time-critical displays, because the fact that it is not prepared in advance means that its timing properties are not as good as that of the SKETCHPAD item. See also:\n\n- %link:visual%\n\n__Feedback and variables__ -- Response items automatically keep track of the accuracy and average response time of the participant in the variables 'acc' (synonym: 'accuracy') and 'avg_rt' (synonym: 'average_response_time') respectively. See also:\n\n- %link:manual/variables%\n\n__Tip__ -- Make sure that the (foreground) color is set to black. Otherwise you will draw white on white and won't see anything!\n\n</div>\n\n## Step 11: Set the length of the practice phase and experimental phase\n\nWe have previously created the *practice_loop* and *experiment_loop* items, which both call *block_sequence* (i.e., a block of trials). However, right now they call *block_sequence* only once, which means that both the practice and the experimental phase consist of only a single block of trials.\n\nClick on *practice_loop* to open its tab and set 'Repeat' to '2.00'. This means that the practice phase consists of two blocks.\n\nClick on *experimental_loop* to open its tab and set 'Repeat' to '8.00'. This means that the experimental phase consists of eight blocks.\n\n<div class='info-box' markdown='1'>\n\n__Background box__\n\n__Tip__ -- You can create a variable `practice` in both *practice_loop* and *experimental_loop* and set it to 'yes' and 'no' respectively. This is an easy way of keeping track of which trials were part of the practice phase.\n\n</div>\n\n## Step 12: Write the instruction, end_of_practice and end_of_experiment forms\n\nI think you can handle this step your own! Simply open the appropriate items and add some text to present instructions, an end-of-practice message, and an end-of-experiment message.\n\n<div class='info-box' markdown='1'>\n\n__Background box__\n\n__Tip__ -- You can use a subset of HTML tags to format your text. For example, *&lt;b&gt;this will be bold&lt;b&gt;* and *&lt;span color='red'&gt;this will be red&lt;span&gt;*. For more information, see:\n\n- %link:text%\n\n</div>\n\n## Step 13: Run the experiment!\n\nYou're done! Click on the 'Run in window' (shortcut: `Ctrl+W`) or 'Run fullscreen' (shortcut: `Ctrl+R`) buttons in the toolbar to run your experiment.\n\n<div class='info-box' markdown='1'>\n\n__Background box__\n\n__Tip__ -- A test run is executed even faster by clicking the orange 'Run in window' button (shortcut: `Ctrl+Shift+W`), which doesn't ask you how to save the logfile (and should therefore only be used for testing purposes).\n\n</div>\n\n\n## Understanding errors\n\nBeing able to understand error messages is a crucial skill when working with OpenSeame. After all, a newly built experiment rarely runs immediately without any errors!\n\nLet's say that we made a mistake during one of the steps above. When trying to run the experiment, we get the following error message (%FigErrorMessage):\n\n%--\nfigure:\n id: FigErrorMessage\n source: error-message.png\n caption: \"An error message in OpenSesame.\"\n--%\n\nThe error message starts with a name, in this case `FStringError`, which indicates the general type of error. This is followed by a short explanatory text, in this case 'Failed to evaluate f-string expression in the following text: gaze_{gaze_ceu}.png`. Even without understanding what an f-string is (it's a string that contains Python code between curly braces), it's clear that there is something wrong with the text '{gaze_ceu}.png'.\n\nThe error message also indicates that the error comes from the prepare phase of the *gaze_cue* item.\n\nFinally, the error message indicates what specifically went wrong when evaluating the text 'gaze_{gaze_ceu}.png': the name 'gaze_ceu' is not defined.\n\nWhile reading the error message carefully, the cause and solution probably already came to your mind: we made a simple spelling mistake in the *gaze_cue* item, writing '{gaze_ceu}' instead of '{gaze_cue}'! And this resulted in an error because there is no variable with the name `gaze_ceu`. This can be easily fixed by opening the script of the *gaze_cue* item and fixing the typo.\n\n\n## Finally: Some general considerations regarding timing and backend selection\n\nIn the 'General properties' tab of the experiment (the tab that you open by clicking on the experiment name), you can select a backend. The backend is the layer of software that controls the display, input devices, sound, etc. Most experiments work with all backends, but there are reasons to prefer one backend over the other, mostly related to timing. Currently there are four backends (depending on your system, not all three may be available):\n\n- __psycho__ -- a hardware-accelerated backend based on PsychoPy [(Peirce, 2007)][references]. This is the default.\n- __xpyriment__ -- a hardware-accelerated backend based on Expyriment [(Krause & Lindeman, 2013)][references]\n- __legacy__ -- a 'safe' backend, based on PyGame. It provides reliable performance on most platforms, but, due to a lack of hardware acceleration, its timing properties are not as good as those of the other backends.\n- __osweb__ -- runs experiments in a browser [(Math\u00f4t & March, 2022)][references].\n\nSee also:\n\n- %link:backends%\n- %link:timing%\n\n\n## References\n\n<div class='reference' markdown='1'>\n\nBrand, A., & Bradley, M. T. (2011). Assessing the effects of technical variance on the statistical outcomes of web experiments measuring response times. *Social Science Computer Review*. doi:10.1177/0894439311415604\n\nDamian, M. F. (2010). Does variability in human performance outweigh imprecision in response devices such as computer keyboards? *Behavior Research Methods*, *42*, 205-211. doi:10.3758/BRM.42.1.205\n\nFriesen, C. K., & Kingstone, A. (1998). The eyes have it! Reflexive orienting is triggered by nonpredictive gaze. *Psychonomic Bulletin & Review*, *5*, 490\u2013495. doi:10.3758/BF03208827\n\nKrause, F., & Lindemann, O. (2013). Expyriment: A Python library for cognitive and neuroscientific experiments. *Behavior Research Methods*. doi:10.3758/s13428-013-0390-6\n\nMath\u00f4t, S., Schreij, D., & Theeuwes, J. (2012). OpenSesame: An open-source, graphical experiment builder for the social sciences. *Behavior Research Methods*, *44*(2), 314-324. doi:10.3758/s13428-011-0168-7\n\nMath\u00f4t, S., & March, J. (2022). Conducting linguistic experiments online with OpenSesame and OSWeb. *Language Learning*. doi:10.1111/lang.12509\n\nPeirce, J. W. (2007). PsychoPy: Psychophysics software in Python. *Journal of Neuroscience Methods*, *162*(1-2), 8-13. doi:10.1016/j.jneumeth.2006.11.017\n\nUlrich, R., & Giray, M. (1989). Time resolution of clocks: Effects on reaction time measurement\u2014Good news for bad clocks. *British Journal of Mathematical and Statistical Psychology*, *42*(1), 1-12. doi:10.1111/j.2044-8317.1989.tb01111.x\n\n</div>\n\n[references]: #references\n[gpl]: http://www.gnu.org/licenses/gpl-3.0.en.html\n[gimp]: http://www.gimp.org/\n[audacity]: http://audacity.sourceforge.net/\n[python inline scripting]: /python/about", "url": "https://osdoc.cogsci.nl/4.0/tutorials/beginner", "title": "Beginner tutorial: gaze cuing"}
{"content": "# Intermediate tutorial (Python) visual search\n\ntitle: Intermediate tutorial (Python) visual search\n\n[TOC]\n\n## About OpenSesame\n\nOpenSesame is a user-friendly program for the development of behavioral experiments for psychology, neuroscience, and experimental economy. For beginners, OpenSesame has a comprehensive graphical, point-and-click interface.  For advanced users, OpenSesame supports Python (desktop only) and JavaScript (desktop and browser).\n\nOpenSesame is freely available under the [General Public License v3][gpl].\n\n## About this tutorial\n\nThis tutorial shows how to create a basic visual-search experiment using OpenSesame [(Math\u00f4t, Schreij, & Theeuwes, 2012)][references]. We will use both the graphical interface and Python scripting to develop an experiment that you can run on the desktop in a traditional lab-based setting. Some experience with OpenSesame and Python is recommended. This tutorial takes approximately one hour.\n\nA JavaScript-based version of this tutorial is also available. If you want to run your experiments online in a browser (with OSWeb), then the JavaScript tutorial is what you need:\n\n- %link:tutorials/intermediate-javascript%\n\n## Resources\n\n- __Download__ \u2014 This tutorial assumes that you are running OpenSesame version 4.0.0 or later. You can download the most recent version of OpenSesame from:\n\t- %link:download%\n- __Documentation__ \u2014 A dedicated documentation website can be found at:\n\t- <http://osdoc.cogsci.nl/>\n- __Forum__ \u2014 A support forum can be found at:\n\t- <http://forum.cogsci.nl/>\n\n## The experiment\n\nIn this tutorial, you will create a basic visual-search experiment. The experiment resembles the classic visual-search studies of [Treisman and Gelade (1980)][references], but it is not identical.\n\nIn this experiment, participants search for a target object, which can be a yellow square, a yellow circle, a blue square, or a blue circle; the identity of the target is varied between blocks of trials. Participants indicate whether the target is present or not by pressing the right (present) or left (absent) arrow key.\n\nIn addition to the target, zero or more distractor objects are shown. There are three conditions, and the condition determines what kind of distractors there are:\n\n- In the *Conjunction* condition, distractors can have any shape and color, with the only restriction that distractors cannot be identical to the target. So, for example, if the target is a yellow square, then distractors are yellow circles, blue circles, and blue squares.\n- In the *Shape Feature* condition, distractors have a different shape from the target, but can have any color. So, for example, if the target is a yellow square, then distractors are yellow circles and blue circles.\n- In the *Color Feature* condition, distractors can have any shape, but have a different color from the target. So, for example, if the target is a yellow square, then distractors are blue squares and blue circles.\n\nImmediate feedback is shown after each trial: a green dot after a correct response, and a red dot after an incorrect response. Detailed feedback on average response times and accuracy is shown after each block of trials.\n\n%--\nfigure:\n id: FigVisualSearch\n source: visual-search.svg\n caption: |\n  The visual-search experiment that you will implement in this tutorial.\n--%\n\nExperiments like this show two typical findings:\n\n- It takes more time to find the target in the Conjunction condition than in the two Feature conditions.\n- In the Conjunction condition, response times increase as the number of distractors increases. This suggests that people search for the target one item at a time; this is called *serial search*.\n- In the Feature conditions (both shape and color), response times do not, or hardly, increase as the the number of distractors increases. This suggests that people process the entire display at once; this is called *parallel search*.\n\nAccording to Treisman and Gelade's feature-integration theory, these results reflect that the Conjunction condition requires that you combine, or *bind*, the color and shape of each object. This binding requires attention, and you therefore need to shift your attention from one object to the next; this is slow, and explains why response times depend on how many objects there are. In contrast, in the Feature conditions, color and shape do not need to be bound, and therefore the whole display can be processed in a single sweep without attention being directed at each and every object.\n\n## Experimental design\n\nThis design:\n\n- Is *within-subject*, because all participants do all conditions\n- Is *fully crossed* (or full-factorial), because all combinations of conditions occur\n- Has three conditions (or factors):\n\t- Varied within blocks:\n\t\t- `set_size` with three levels (1, 5, 15), or SS<sub>3</sub>\n\t\t- `condition` with three levels (conjunction, feature_shape, feature_color), or CN<sub>3</sub>\n\t\t- `target_present` with two levels (present, absent), or TP<sub>2</sub>\n\t- Varied between blocks:\n\t\t- `target_shape` with two levels (square, circle), or TS<sub>2</sub>\n\t\t- `target_color` with two levels (yellow, blue), or TC<sub>2</sub>\n- Has N subjects, or <u>S</u><sub>N</sub>\n\nYou can write this design as <u>S</u><sub>N</sub>\u00d7SS<sub>3</sub>\u00d7CN<sub>3</sub>\u00d7TP<sub>2</sub>\u00d7TS<sub>2</sub>\u00d7TC<sub>2</sub>\n\nFor more information about this notation for experimental design, see:\n\n- %link:experimentaldesign%\n\n## Step 1: Create the basic structure of the experiment\n\nStart OpenSesame and, in the 'Get started!' tab, select the Extended template. This template provides the basic structure that is common to many cognitive-psychology experiments, such as the one that we will create here.\n\nThe Extended template contains a few items that we don't need. Delete the following items:\n\n- *about_this_template*\n- *practice_loop*\n- *end_of_practice*\n\nWhen you have deleted these items, they are still visible in the 'Unused items' bin. To permanently delete these items, click on the 'Unused items' bin, and then click on the 'Permanently delete unused items' button.\n\nFinally, give the experiment a good title, such as 'Visual search'. To do this, open the general-properties tab (by clicking on 'Extended template' in the overview area) and click on the experiment name to edit it.\n\nThe overview area should now look like %FigStep1:\n\n%--\nfigure:\n id: FigStep1\n source: step1.png\n caption: |\n  The overview area at the end of step 1.\n--%\n\n## Step 2: Define experimental variables that are varied between blocks\n\nAs described above, two variables are varied between blocks in our experiment: `target_shape` and `target_color`. We therefore need to define these variables in the *experimental_loop*. To understand why, consider the structure shown in %FigStep1, starting from the bottom (i.e. the most indented level).\n\n- *trial_sequence* corresponds to a single trial\n- *block_loop* corresponds to a block of a trials\n\t- Therefore, variables defined here vary for each run of *trial_sequence*; in other words, variables defined in *block_loop* are varied __within blocks__.\n- *block_sequence* corresponds to a block of trials, preceded by resetting of the feedback variables, and followed by participant feedback\n- *experimental_loop* corresponds to multiple blocks of trials\n\t- Therefore, variables defined here vary for each run of *block_sequence*; in other words, variables defined in *experimental_loop* are varied __between blocks__.\n- *experiment* corresponds to the entire experimental, which is an instruction screen, followed by multiple blocks of trials, followed by an end-of-experiment screen\n\nClick on experimental loop, and define:\n\n- `target_shape`, which can be 'square' or 'circle'; and\n- `target_color`, which can be 'yellow' or 'blue'.\n\nWe have a full-factorial design, which means that all 2 \u00d7 2 = 4 combinations must occur. The table of *experimental_loop* should now look like %FigStep2:\n\n%--\nfigure:\n id: FigStep2\n source: step2.png\n caption: |\n  The table of *experimental_loop* at the end of step 2.\n--%\n\n## Step 3: Give instructions at the start of each block\n\nRight now, the experiment starts with a single *instructions* screen. In our case, we want to give instructions before each block of trials, to tell the participant what target to look for (because the identity of the target varies between blocks).\n\n__Move the instructions into block_sequence__\n\nTherefore, pick up the *instructions* item and drag it onto *block_sequence*. A pop-up will appear, asking you if you want to:\n\n- Insert the item into *block_sequence*, in which case *instructions* would become the first item of *block_sequence*; or\n- Insert the item after *block_sequence*, in which case *instructions* would move to a position after *block_sequence*.\n\nSelect the first option ('Insert into'). Now *block_sequence* starts with an instructions screen, which is what we want.\n\n__Add instructional text__\n\nClick on *instructions* to open it, and add a good instructional text, such as:\n\n```text\nINSTRUCTIONS\n\nSearch for the {target_color} {target_shape}\n\nPress the right-arrow key if you find it\nPress the left-arrow key if you don't\n\nPress any key to begin\n```\n\nThe curly braces brackets around '{target_color}' and '{target_shape}' indicate that these are not literal text, but refer to the variables that we have defined in *experimental_loop*. When the experiment runs, the values of these variables will appear here, and the participant will see (for example), 'Search for the yellow circle'.\n\n__Give a visual preview of the target__\n\nIt also good to show the participant the actual stimulus that she needs to find. To do this:\n\n- Draw a filled circle at the center of the display (make sure it doesn't overlap with the text);\n- Change the color of the circle to '{target_color}'. This means that the color of the circle depends on the value of the variable `target_color`; and\n- Change the show-if expression to `target_shape == 'circle'`. This is a Python expression that checks if the variable `target_shape` has the value 'circle'.\n\nIn other words, we have drawn a circle of which the color is determined by `target_color`; furthermore, this circle is only shown when the variable `target_shape` has the value 'circle'. For more information about variables and show-if statements, see:\n\n- %link:manual/variables%\n\nWe use the same trick to draw a square:\n\n- Draw a filled square at the center of the display;\n- Change the color of the square to '{target_color}'; and\n- Change the show-if statement to `target_shape == 'square'`\n\nThe *instructions*  screen should now look like %FigStep3:\n\n%--\nfigure:\n id: FigStep3\n source: step3.png\n caption: |\n  The *instructions* screen at the end of step 3.\n--%\n\n## Step 4: Define experimental variables that are varied within blocks\n\nThree variables are varied within blocks in our experiment: `condition`, `set_size`, and `target_present`. As described under Step 2, we need to define these variables in the *block_loop* so that they vary for each run of *trial_sequence*.\n\nThe three variables make a total of 3 \u00d7 3 \u00d7 2 = 18 different combinations. We can type these into the table manually, but, because we have full-factorial design, we can also use the full-factorial-design wizard. To do this, first open *block_loop* and click on the 'Full-factorial design' button.\n\nIn the table that appears, put the variable names on the first row, and the values on the rows below, as shown in %FigFullFactorial.\n\n%--\nfigure:\n id: FigFullFactorial\n source: fullfactorial.png\n caption: |\n  The *instructions* screen at the end of step 3.\n--%\n\nNow click on 'Ok' to generate the full design. The table of *block_loop* should now look like %FigStep4.\n\n%--\nfigure:\n id: FigStep4\n source: step4.png\n caption: |\n  The table of *block_loop* at the end of step 4.\n--%\n\n## Step 5: Create the trial sequence\n\nWe want our trial sequence to look as follows:\n\n- A fixation dot, for which we will use a SKETCHPAD.\n- A search display, which we will create in Python with a custom INLINE_SCRIPT.\n- Response collection, for which we will use a KEYBOARD_RESPONSE.\n- Data logging, for which we will use a LOGGER.\n- (We also want immediate feedback after each trial, but we will get back to this later.)\n\nSo the only thing that is missing is an INLINE_SCRIPT.\n\n- Insert a new INLINE_SCRIPT after *sketchpad* and rename it to *search_display_script*.\n- Rename *sketchpad* to *fixation_dot*, so that its function is clear; and\n- Change the duration of *fixation_dot* to 500, so that the fixation dot is shown for 500 ms. (There should already be a fixation dot drawn; if not, draw one in the center of *fixation_dot*.)\n\nThe overview area should now look like %FigStep5.\n\n%--\nfigure:\n id: FigStep5\n source: step5.png\n caption: |\n  The overview area at the end of step 5.\n--%\n\n## Step 6: Generate the search display\n\n__Top-down and defensive programming__\n\nNow things will get interesting: We will start programming in Python. We will use two guiding principles: *top-down* and *defensive* programming.\n\n- *Top-down programming* means that we start with the most abstract logic, without bothering with how this logic is implemented. Once the most abstract logic is in place, we will move down to a slightly less abstract logic, and so on, until we arrive at the details of the implementation. This technique helps to keep the code structured.\n- *Defensive programming* means that we assume that we make mistakes. Therefore, to protect us from ourselves, we build sanity checks into the code.\n\n*Note:* The explanation below assumes that you're somewhat familiar with Python code. If concepts like `list`, `tuple`, and functions don't mean anything to you, then it's best to first walk through an introductory Python tutorial, such as this one:\n\n- <https://pythontutorials.eu/>\n\nThe logic of the code is shown in %FigHierarchy. The numbers indicate the order in which we will implement the functionality, starting at the abstract level.\n\n%--\nfigure:\n id: FigHierarchy\n source: hierarchy.svg\n caption: |\n  The logic of the code to draw a visual-search display.\n--%\n\n__The Prepare and Run phases__\n\nOpen *search_display_script* and switch to the Prepare tab. OpenSesame distinguishes two phases of execution:\n\n- During the Prepare phase, each item is given the opportunity to prepare itself; what this means depends on the item: For a SKETCHPAD, it means drawing a canvas (but not showing it); for a SAMPLER, it means loading a sound file (but not playing it); etc.\n- During the Run phase, each item is actually executed; again, what this means depends on the item: For a SKETCHPAD, it means showing the previously prepared canvas; for a SAMPLER, it means playing a previously loaded sound file.\n\nFor an INLINE_SCRIPT, you have to decide yourself what to put in the Prepare phase, and what to put in the Run phase. The distinction is usually quite clear: In our case, we put the code for drawing the canvas in the Prepare phase, and the code for showing the canvas (which is small) in the Run phase.\n\nSee also:\n\n- %link:prepare-run%\n\n__Implement the abstract level__\n\nWe start at the most abstract level: defining a function that draws a visual-search display. We don't specify *how* this is done; we simply assume that there is a function that does this, and we will worry about the details later\u2014that's top-down programming.\n\nIn the Prepare tab, enter the following code:\n\n~~~ .python\nc = draw_canvas()\n~~~\n\nWhat happens here? We \u2026\n\n- Call `draw_canvas()`, which returns a `Canvas` object that we store as `c`; in other words, `c` is a `Canvas` object that corresponds the search display. This assumes that there is a function `draw_canvas()`, even though we haven't defined it yet.\n\nA `Canvas` object is a single display; it is, in a sense, the Python counterpart of a SKETCHPAD. See also:\n\n- %link:manual/python/canvas%\n\nWe now go one step down by defining `draw_canvas()` (above the rest of the script so far):\n\n~~~ .python\ndef draw_canvas():\n    \"\"\"Draws the search canvas.\n\n    Returns\n    -------\n    Canvas\n    \"\"\"\n    c = Canvas()\n    xy_list = xy_random(n=set_size, width=500, height=500, min_dist=75)\n    if target_present == 'present':\n        x, y = xy_list.pop()\n        draw_target(c, x, y)\n    elif target_present != 'absent':\n        raise Exception(f'Invalid value for target_present: {target_present}')\n    for x, y in xy_list:\n        draw_distractor(c, x, y)\n    return c\n~~~\n\n\nWhat happens here? We \u2026\n\n- Create an empty canvas, `c`, using the factory function `Canvas()`.\n- Generate a list of random `x, y` coordinates, called `xy_list`, using another common function, `xy_random()`. This list determines where the stimuli are shown.\n- Check if the experimental variable `target_present` has the value 'present'; if so, `pop()` one `x, y` tuple from `xy_list`, and draw the target at this location. This assumes that there is a function `draw_target()`, even though we haven't defined it yet.\n- If `target_present` is neither 'present' nor 'absent', we raise an `Exception`; this is defensive programming, and protects us from typos (e.g. if we had accidentally entered 'presenr' instead of 'present').\n- Loop through all remaining `x, y` tuples and draw a distractor at each position. This assumes that there is a function `draw_distractor()`, even though we haven't defined it yet.\n- Return `c`, which now has the search display drawn onto it.\n\nThere are several common functions, such as `Canvas()` and `xy_random()`, which are always available. See:\n\n- %link:manual/python/common%\n\nExperimental variables are global variables. That's why you can refer to `set_size`, which is defined in *block_loop*, even though the variable `set_size` is never explicitly defined in the script. The same is true for `target_shape`, `target_color`, `condition`, etc. See:\n\n- %link:var%\n\n__Implement the intermediate level__\n\nWe now go one more step down by defining `draw_target` (above the rest of the script so far):\n\n~~~ .python\ndef draw_target(c, x, y):\n    \"\"\"Draws the target.\n\n    Parameters\n    ----------\n    c: Canvas\n    x: int\n    y: int\n    \"\"\"\n    draw_shape(c, x, y, color=target_color, shape=target_shape)\n~~~\n\nWhat happens here? We \u2026\n\n- Call another function, `draw_shape()`, and specify the color and shape that needs to be drawn. This assumes that there is a function `draw_shape()`, even though we haven't defined it yet.\n\nWe also define `draw_distractor` (above the rest of the script so far):\n\n~~~ .python\ndef draw_distractor(c, x, y):\n    \"\"\"Draws a single distractor.\n\n    Parameters\n    ----------\n    c: Canvas\n    x: int\n    y: int\n    \"\"\"\n    if condition == 'conjunction':\n        draw_conjunction_distractor(c, x, y)\n    elif condition == 'feature_shape':\n        draw_feature_shape_distractor(c, x, y)\n    elif condition == 'feature_color':\n        draw_feature_color_distractor(c, x, y)\n    else:\n        raise Exception(f'Invalid condition: {condition}')\n~~~\n\nWhat happens here? We \u2026\n\n- Call another function to draw a more specific distractor depending on the Condition.\n- Check whether `condition` has any of the expected values. If not, we raise an `Exception`. This is defensive programming! Without this check, if we made a typo somewhere, the distractor might simply not be shown without causing an error message.\n\nNow we define the function that draws distractors in the Conjunction condition (above the rest of the script so far):\n\n~~~ .python\nimport random\n\n\ndef draw_conjunction_distractor(c, x, y):\n    \"\"\"Draws a single distractor in the conjunction condition: an object that\n    can have any shape and color, but cannot be identical to the target.\n\n    Parameters\n    ----------\n    c: Canvas\n    x: int\n    y: int\n    \"\"\"\n    conjunctions = [('yellow', 'circle'),\n                    ('blue',   'circle'),\n                    ('yellow', 'square'),\n                    ('blue',   'square')]\n    conjunctions.remove((target_color, target_shape))\n    color, shape = random.choice(conjunctions)\n    draw_shape(c, x, y, color=color, shape=shape)\n~~~\n\nWhat happens here? We \u2026\n\n- Define a list, `conjunctions`, of all possible color and shape combinations.\n- Remove the target from this list; this is necessary, because the distractor cannot be identical to the target.\n- Randomly select one of the color and shape combinations from `conjunctions`.\n- Call another function, `draw_shape()`, and specify the color and shape of the to-be-drawn distractor. This assumes that there is a function `draw_shape()`, even though we haven't defined it yet.\n\nIn addition, we \u2026\n\n- Add the line `import random` to the top of the script. This is necessary so that we can use functions that are part of the `random` module, such as `random.choice()`.\n\nNow we define the function that draws distractors in the Shape Feature condition (right below the `import` statement):\n\n~~~ .python\ndef draw_feature_shape_distractor(c, x, y):\n    \"\"\"Draws a single distractor in the feature-shape condition: an object that\n    has a different shape from the target, but can have any color.\n\n    Parameters\n    ----------\n    c: Canvas\n    x: int\n    y: int\n    \"\"\"\n    colors = ['yellow', 'blue']\n    color = random.choice(colors)\n    if target_shape == 'circle':\n        shape = 'square'\n    elif target_shape == 'square':\n        shape = 'circle'\n    else:\n        raise Exception(f'Invalid target_shape: {target_shape}')\n    draw_shape(c, x, y, color=color, shape=shape)\n~~~\n\nWhat happens here? We \u2026\n\n- Randomly select a color.\n- Choose a square shape if the target is a circle, and a circle shape if the target is square.\n- If `target_shape` is neither 'circle' nor 'square', raise an `Exception`\u2014more defensive programming!\n- Call another function, `draw_shape()`, and specify the color and shape of the to-be-drawn distractor. This assumes that there is a function `draw_shape()`, even though we haven't defined it yet.\n\nNow we define the function that draws distractors in the Color Feature condition (right below the `import` statement):\n\n~~~ .python\ndef draw_feature_color_distractor(c, x, y):\n    \"\"\"Draws a single distractor in the feature-color condition: an object that\n    has a different color from the target, but can have any shape.\n\n    Parameters\n    ----------\n    c: Canvas\n    x: int\n    y: int\n    \"\"\"\n    shapes = ['circle', 'square']\n    shape = random.choice(shapes)\n    if target_color == 'yellow':\n        color = 'blue'\n    elif target_color == 'blue':\n        color = 'yellow'\n    else:\n        raise Exception(f'Invalid target_color: {target_color}')\n    draw_shape(c, x, y, color=color, shape=shape)\n~~~\n\nWhat happens here? We \u2026\n\n- Randomly select a shape.\n- Choose a blue color if the target is yellow, and a yellow color if the target is blue.\n- If `target_color` is neither 'yellow' nor 'blue', raise an `Exception`\u2014more defensive programming!\n- Call another function, `draw_shape()`, and specify the color and shape of the to-be-drawn distractor. This assumes that there is a function `draw_shape()`, even though we haven't defined it yet.\n\n__Implement the detailed level__\n\nNow we go all the way down to the details by defining the function that actually draws a shape to the canvas (right below the `import` statement):\n\n~~~ .python\ndef draw_shape(c, x, y, color, shape):\n    \"\"\"Draws a single shape.\n\n    Parameters\n    ----------\n    c: Canvas\n    x: int\n    y: int\n    color: str\n    shape: str\n    \"\"\"\n    if shape == 'square':\n        c += Rect(x=x-25, y=y-25, w=50, h=50, color=color, fill=True)\n    elif shape == 'circle':\n        c += Circle(x=x, y=y, r=25, color=color, fill=True)\n    else:\n        raise Exception(f'Invalid shape: {shape}')\n    if color not in ['yellow', 'blue']:\n        raise Exception(f'Invalid color: {color}')\n~~~\n\nWhat happens here? We \u2026\n\n- Check which shape should be drawn. For squares, we add a `Rect()` element to the canvas. For circles, we add a `Circle()` element.\n- Check if the the shape is either a square or a circle, and if not raise an `Exception`. This is another example of defensive programming! We're making sure that we haven't accidentally specified an invalid shape.\n- Check if the the color is neither yellow nor blue, and if not raise an `Exception`.\n\n__Implement the Run phase__\n\nBecause we have done all the hard work in the Prepare phase, the Run phase is just:\n\n~~~ .python\nc.show()\n~~~\n\nThat's it! Now you have drawn a full visual-search display. And, importantly, you have done so in a way that is easy to understand, because of top-down programming, and safe, because of defensive programming.\n\n", "url": "https://osdoc.cogsci.nl/4.0/tutorials/intermediate", "title": "Intermediate tutorial (Python) visual search"}
{"content": "# Intermediate tutorial (Python) visual search\n\n## Step 7: Define the correct response\n\nTo know if the participant responds correctly, we need to know the correct response. You can define this explicitly in the *block_loop* (as done in the beginner tutorial); but here we're going to use a simple Python script that checks whether the target is present or not, and defines the correct response accordingly.\n\nTo do this, insert a new INLINE_SCRIPT at the start of *trial_sequence*, and rename it to *correct_response_script*. In the Prepare phase (not the Run phase!), enter the following code:\n\n~~~ .python\nif target_present == 'present':\n    correct_response = 'right'\nelif target_present == 'absent':\n    correct_response = 'left'\nelse:\n    raise Exception(f'target_present should be absent or present, not {target}')\n~~~\n\nWhat happens here? We \u2026\n\n- Check whether the target is present or not. If the target is present, the correct response is 'right' (the right arrow key); if the target is absent, the correct response is 'left' (the left arrow key). The experimental (global) variable `correct_response` is automatically recognized by *keyboard_response*; therefore, we don't need to explicitly indicate that this variable contains the correct response.\n- Check if the target is either present or absent, and if not raise an `Exception`\u2014another example of defensive programming.\n\n## Step 8: Give per-trial feedback\n\nFeedback after every trial can motivate participants; however, per-trial feedback should not interfere with the flow of the experiment. A good way to give per-trial feedback is to briefly show a green fixation dot after a correct response, and a red fixation dot after an incorrect response.\n\nTo do this:\n\n- Insert two new SKETCHPADs into *trial_sequence*, just after *keyboard_response*.\n- Rename one SKETCHPAD to *green_dot*, draw a central green fixation dot onto it, and change its duration to 500.\n- Rename the other SKETCHPAD to *red_dot*, draw a central red fixation dot onto it, and change its duration to 500.\n\nOf course, only one of the two dots should be shown on each trial. To accomplish this, we will specify run-if expressions in *trial_sequence*:\n\n- Change the run-if expression for *green_dot* to 'correct == 1', indicating that it should only be shown after a correct response.\n- Change the run-if expression for *red_dot* to 'correct == 0', indicating that it should only be shown after an incorrect response.\n\nThe variable `correct` is automatically created if the variable `correct_response` is available; that's why we defined `correct_response` in step 7. For more information about variables and run-if statements, see:\n\n- %link:manual/variables%\n\nThe *trial_sequence* should now look like %FigStep8.\n\n%--\nfigure:\n id: FigStep8\n source: step8.png\n caption: |\n  The *trial_sequence* at the end of step 8.\n--%\n\n## Finished!\n\nCongratulations, the experiment is complete! You can give it a test run by pressing on the blue double-arrow button (shortcut: `Ctrl+W`).\n\nIf the experiment doesn't work on the first try: Don't worry, and calmly figure out where the mistake comes from. Crashes are part of the normal development process. But you can save yourself a lot of time and headache by working in a structured way, as we have done in this tutorial.\n\n## References\n\n<div class='reference' markdown='1'>\n\nMath\u00f4t, S., Schreij, D., & Theeuwes, J. (2012). OpenSesame: An open-source, graphical experiment builder for the social sciences. *Behavior Research Methods*, *44*(2), 314-324. doi:10.3758/s13428-011-0168-7\n\nTreisman, A. M., & Gelade, G. (1980). A feature-integration theory of attention. *Cognitive Psychology*, 12(1), 97\u2013136. doi:10.1016/0010-0285(80)90005-5\n\n</div>\n\n[references]: #references\n[gpl]: http://www.gnu.org/licenses/gpl-3.0.en.html", "url": "https://osdoc.cogsci.nl/4.0/tutorials/intermediate", "title": "Intermediate tutorial (Python) visual search"}
{"content": "# Touch response\n\ntitle: Touch response\n\nThe `touch_response` plug-in allows you to work with touch responses (or mouse clicks) in an easy way, by dividing the display into rows and columns. Each response is encoded by a single number, which corresponds to the position counting from left-to-right and top-down. For example, if you have specified 2 columns and 3 rows, the display is divided into the following response regions:\n\n```bash\n1\t2\n3\t4\n5\t6\n```\n\nSimilarly, if you have specified 4 columns and 1 row, the display is sliced horizontally into the following response regions:\n\n```bash\n1\t2\t3\t4\n```", "url": "https://osdoc.cogsci.nl/4.0/items/touch_response", "title": "Touch response"}
{"content": "# Advanced_delay\n\ntitle: Advanced_delay\n\nThe `advanced_delay` plug-in delays the experiment for a pre-specified average duration plus a random margin.\n\n- *Duration* is the average duration of the delay in milliseconds.\n- *Jitter* is the size of the variation in the delay in milliseconds.\n- *Jitter mode* is the how the jitter is calculated:\n\t- *Standard deviation* will draw the variation from a Gaussian distribution with Jitter as the standard deviation.\n\t- *Uniform* will draw the variation in duration from a uniform distribution.", "url": "https://osdoc.cogsci.nl/4.0/items/advanced_delay", "title": "Advanced_delay"}
{"content": "# Quest staircase next\n\ntitle: Quest staircase next\n\nProcesses a response and updates the Quest test value.", "url": "https://osdoc.cogsci.nl/4.0/items/quest_staircase_next", "title": "Quest staircase next"}
{"content": "# Repeat_cycle\n\ntitle: Repeat_cycle\n\nThis plug-in allows you to repeat cycles from a `loop`. Most commonly, this will be to repeat a trial when a participant made a mistake or was too slow.\n\nFor example, to repeat all trials on which a response was slower than 3000 ms, you can add a `repeat_cycle` item after (typically) the `keyboard_response` and add the following repeat-if expression:\n\n```bash\nresponse_time > 3000\n```\n\nYou can also force a cycle to be repeated by setting the variable `repeat_cycle` to 1 in an `inline_script`, like so:\n\n```python\nrepeat_cycle = 1\n```", "url": "https://osdoc.cogsci.nl/4.0/items/repeat_cycle", "title": "Repeat_cycle"}
{"content": "# Reset_feedback\n\ntitle: Reset_feedback\n\nThis plug-in has the same effect as presenting a FEEDBACK item with a duration of 0 ms\n{: .page-notification}\n\nIf you do not reset feedback variables, you may confound your feedback with responses that are not relevant to the task. For example, the key presses made during the instruction phase may affect the feedback during the first block of the experiment. Therefore, you will need to reset the feedback variables at appropriate moments.\n\nThis plug-in will reset the following variables to 0:\n\n- `total_response_time`\n- `total_response`\n- `acc`\n- `accuracy`\n- `avg_rt`\n- `average_response_time`", "url": "https://osdoc.cogsci.nl/4.0/items/reset_feedback", "title": "Reset_feedback"}
{"content": "# Quest staircase init\n\ntitle: Quest staircase init\n\nInitializes a new Quest staircase procedure.", "url": "https://osdoc.cogsci.nl/4.0/items/quest_staircase_init", "title": "Quest staircase init"}
{"content": "# Runners\n\ntitle: Runners\n\n\n[TOC]\n\n\n## About runners\n\nThere are several technically different ways in which you can execute your experiment. Each of these corresponds to a *runner*. You can select a runner under Menu \u2192 Tools \u2192 Preferences \u2192 Runner.\n\nUnless you have a reason not to, you should use the *multiprocess* runner. However, if OpenSesame sometimes crashes, you can try whether selecting a different runner resolves this.\n\n\n## Available runners\n\n### Multiprocess\n\nThe *multiprocess* runner executes your experiment in a different process. The benefit of this approach is that your experiment can crash without bringing the user interface down with it. Another advantage of the *multiprocess* runner is that it allows the variable inspector to show your experimental variables while the experiment is running.\n\n### Inprocess\n\nThe *inprocess* runner executes the experiment in the same process as the user interface. The benefit of this approach is its simplicity. The downside is that the user interface may crash if the experiment crashes, and vice versa.\n\n### External\n\nThe *external* runner executes the experiment by launching opensesamerun as a separate application. The benefit of this approach is that your experiment can crash without bringing the user interface down with it.", "url": "https://osdoc.cogsci.nl/4.0/manual/runners", "title": "Runners"}
{"content": "# OpenSesame script\n\ntitle: OpenSesame script\nreviewed: false\n\n[TOC]\n\n## About OpenSesame script\n\nOpenSesame script is a simple definitional language that defines an experiment. It is not a full fledged programming language, and does not include features such a `for` loops. The OpenSesame script is interpreted by an OpenSesame runtime environment.\n\nOpenSesame script is different from the Python scripts that are used in inline_script items. Python is a real programming language with all the flexibility and complexities that this entails. In contrast, OpenSesame script is used to define experiments in a simple, human-readable way.\n\n## General remarks\n\n### Keywords\n\nSome items, such as form_base and sketchpad accept keywords. Keywords are of the form `keyword=value`. Keywords are optional and should fall back to a default value.\n\n### Comments\n\nStrings preceded by a hash should be interpreted as comments.\n\n*Example*\n\n\t# This is a comment\n\n### Quotation\n\nQuotation is not necessary, except around strings that contain spaces or other forms of punctuation. So the following lines should be interpreted as identical:\n\n\tset my_var 'my_value'\n\tset my_var \"my_value\"\n\tset my_var my_value\n\nHowever, the following lines are not. In fact, the first line is not valid, because it has an unexpected third parameter.\n\n\tset my_var my value\n\tset my_var \"my value\"\n\n### Types\n\nThere are no types. No distinction is made between strings, integers, etc.\n\n### Item-specific syntax\n\nSome items have a specific syntax. This is indicated in the \u201cApplies to\u201d section for each of the keywords discussed below.\n\n### Resolving path names\n\nTODO\n\n## *define* statement\n\nStarts the definition of an item. After a define statement, all lines are indented by a single tab. The end of the item definition is the first string that is no longer indented. Nested define statements are not allowed.\n\n*Applies to*\n\nAll items\n\n*Format*\n\n\tdefine [item name] [item type]\n\t\t[item definition]\n\n*Parameters*\n\n|`item name`\t|the name of the item\t|\n|`item type`\t|the type of the item\t|\n\n*Example*\n\n\tdefine get_key keyboard_response\n\t\tset allowed_responses \"a;x\"\n\t\tset description \"Collects keyboard responses\"\n\t\tset timeout \"infinite\"\n\t\tset flush \"yes\"\n\n## *draw* statement\n\nDefines a visual element of a sketchpad or feedback item.\n\n*Applies to*\n\nsketchpad, feedback\n\n*Format*\n\nThe format depends on the element.\n\n\tdraw ellipse [left] [top] [width] [height] [keywords]\n\tdraw circle [x] [y] [radius] [keywords]\n\tdraw line [left] [right] [top] [bottom] [keywords]\n\tdraw arrow [left] [right] [top] [bottom] [keywords]\n\tdraw textline [x] [y] [text]\n\tdraw image [x] [y] [path]\n\tdraw gabor [x] [y]\n\tdraw noise [x] [y]\n\tdraw fixdot [x] [y]\n\n*Parameters*\n\n|`left` \t\t|the left-most x-coordinate\t\t|\n|`right`\t\t|the right-most x-coordinate\t|\n|`top`\t\t\t|the top y-coordinate\t\t\t|\n|`bottom`\t\t|the bottom y-coordinate\t\t|\n|`x` \t\t\t|the x-coordinate\t\t\t\t|\n|`y`\t\t\t|the y-coordinate\t\t\t\t|\n|`text` \t\t|text string\t\t\t\t\t|\n|`path` \t\t|the path to an image file\t\t|\n\n*Keywords*\n\nTODO\n\n*Example*\n\n\tdraw fixdot 0 0\n\n## *log* statement\n\nIndicates that a variable should be written to the log-file.\n\n*Applies to*\n\nlogger\n\n*Format*\n\n\tlog [variable name]\n\n*Parameters*\n\n|`variable name`\t\t|the name of a variable\t|\n\n*Example*\n\n\tlog response_time\n\n## *run* statement\n\nIndicates that an item should be run. In the case of the sequence, the order of the run statements determines the order in which items are called. In the case of the coroutines plugin all items are called at the same time.\n\n*Applies to*\n\nsequence\n\n*Format*\n\n\trun [item name] [optional: condition] [optional: disabled]\n\n*Parameters*\n\n|`item name`\t\t\t|the name of the item to run\t|\n|`condition` (optional)\t|the conditional statement, which determines the item is actually called. If no condition is provided, the item is always called.|\n\n*Example*\n\n\trun correct_feedback '[correct] = 1'\n\n## *set* statement\n\nDefines single-line variables.\n\n*Applies to*\n\nAll items\n\n*Format*\n\n\tset [variable name] [value]\n\n*Parameters*\n\n|`variable name`\t|the variable name\t|\n|`value`\t\t\t|the variable value\t|\n\n*Example*\n\n\tset timeout 1000\n\n*Notes*\n\nMulti-line variables are defined using the `__[variable name]__` notation. This is mostly useful for items that require large blocks of text. Within an item definition, each line is preceded by a single tab, which should not be interpreted as part of the text. `__end__` indicates the end of the variable.\n\n*For example:*\n\n\t__my_variable__\n\tThis is the first line.\n\tThis is the second line.\n\t__end__\n\n## *setcycle* statement\n\nSimilar to the regular \u201cset\u201d statement, but sets a variable only during a specific cycle of a loop. This is the script equivalent of the loop table.\n\n*Applies to*\n\nLoop\n\n*Format*\n\n\tsetcycle [cycle #] [variable name] [variable value]\n\n*Parameters*\n\n|`Cycle #`\t\t\t|the number of the cycle, where 0 is the first\t|\n|`variable name` \t|the variable name\t\t\t\t\t\t\t\t|\n|`value`\t\t\t|the variable value\t\t\t\t\t\t\t\t|\n\n*Example*\n\n\tsetcycle 0 cue valid\n\n## *widget* statement\n\nAdds a widget (buttons, labels, etc.) to a form. Valid keywords depend on the type of widget. The widget statement is not strictly part of the core OpenSesame syntax, but is used by the form_base plugin.\n\n*Applies to*\n\nform_base (plugin)\n\n*Format*\n\n\twidget [column] [row] [column span] [row span] [widget type] [keywords]\n\n*Parameters*\n\n|`column`\t\t|the widget's column position in the form, where 0 is left-most\t\t\t\t\t\t\t\t|\n|`row`\t\t\t|the widget's row position in the form, where 0 is top\t\t\t\t\t\t\t\t\t\t|\n|`column span`\t|the number of columns that the widget occupies\t\t\t\t\t\t\t\t\t\t\t\t|\n|`row span`\t\t|the number of rows that the widget occupies\t\t\t\t\t\t\t\t\t\t\t\t|\n|`widget type`\t|'button', 'checkbox', 'image', 'image_button', 'label', 'rating_scale', or 'text_input'\t|\n\n*Keywords*\n\nTODO\n\n*Example*\n\n\twidget 0 0 1 1 label text='This is a label'", "url": "https://osdoc.cogsci.nl/4.0/manual/opensesame-script", "title": "OpenSesame script"}
{"content": "# Counterbalancing\n\ntitle: Counterbalancing\n\nCounterbalancing is a way to remove confounding factors from an experiment by having slightly different tasks for different groups of participants. This sounds abstract, so let's consider two examples.\n\n[TOC]\n\n### Example 1: Counterbalancing response rule\n\nConsider a lexical-decision experiment in which participants classify words as verbs by pressing 'z' with their left hand, or as nouns by pressing 'm' with their right hand. This design has a problem: If you find that participants respond faster to nouns than to verbs, this could be because nouns are processed faster than verbs, or because participants respond faster with their right hand than with their left hand. You can fix this problem by counterbalancing the response rule.\n\nFor even participant numbers:\n\n- verb \u2192 z\n- noun \u2192 m\n\nFor uneven participant numbers:\n\n- verb \u2192 m\n- noun \u2192 z\n\n### Example 2: Rotating stimulus conditions\n\nConsider a masked-priming experiment in which participants read target words aloud. On each trial, the target word is preceded by one of three types of priming words:\n\n- An unrelated prime, e.g. priming with 'berry' for target 'house'.\n- An ortoghraphically related prime, e.g. priming with 'mouse' for target 'house'\n- A semantically related prime, e.g. priming with 'garden' for target 'house'\n\nTo avoid repetition effects, you only want to show target words only once per participant. Therefore, you create three different sets of target words, one for each prime type. This is a between-word design, which has less statistical power than a within-word design, in which each target word occurs in each condition. (For the same reason that between-subject designs are less powerful than within-subject designs.)\n\nYou can use counterbalancing to change this experiment into a within-word design by 'rotating' the condition in which each word occurs between participants. We have three conditions, and we therefore have three groups of participants:\n\n- Participants 1, 4, 7, etc.\n    - Word A in condition 1\n    - Word B in condition 2\n    - Word C in condition 3\n- Participants 2, 5, 8, etc.\n    - Word A in condition 2\n    - Word B in condition 3\n    - Word C in condition 1\n- Participants 3, 6, 9, etc.\n    - Word A in condition 3\n    - Word B in condition 1\n    - Word C in condition 2\n\n\n## Implementing counterbalancing\n\n\n### Using the subject number\n\nWhen you run an experiment in OpenSesame on the desktop, you are asked for a subject number. When you run an experiment online, a subject number is randomly selected from the list of possible subject numbers that you have specified in the [OSWeb extension](%url:osweb). (This means that for online experiments you cannot ensure that the number of participants is exactly equal for the different conditions that you want to counterbalance, at least not if you rely on the subject number.)\n\nThis subject number is available as the experimental variable `subject_nr`. In  addition, the experimental variable `subject_parity` has the value 'odd' or 'even', depending on whether the subject number is odd or even. Now say that you want to counterbalance the response rule as in Example 1, you could add the following INLINE_SCRIPT to the start of the experiment.\n\n```python\nif subject_parity == 'odd':\n    verb_response = 'z'\n    noun_response = 'm'\nelse:\n    verb_response = 'm'\n    noun_response = 'z'\n```\n\nOr, when creating an OSWeb experiment, add the following INLINE_JAVASCRIPT to the start of the experiment:\n\n```javascript\nif (subject_parity === 'odd') {\n    verb_response = 'z'\n    noun_response = 'm'\n} else {\n    verb_response = 'm'\n    noun_response = 'z'\n}\n```\n\nNow, in your *block_loop*, instead of setting `correct_response` to a fixed value, you set it to a variable: `{verb_response}` or `{noun_response}`. You can take a look at the *lexical-decision task* example to see how this works (Menu -> Tools -> Example experiments).\n\n\n### Using Batch Session Data (JATOS and OSWeb only)\n\nWhen running an OSWeb experiment that is hosted on JATOS, you can make use of [Batch Session Data](https://www.jatos.org/jatos.js-Reference.html#functions-to-access-the-batch-session). This is data that is shared between all experimental sessions that are part of the same worker batch. Therefore, you can use this data to define a list of conditions that should be distributed across participants. At the start of each experimental session, one condition is removed from this list and used for the current session. This is the most sophisticated way to implement counterbalancing for OSWeb experiments that are hosted on JATOS.\n\nYou can download a template experiment here:\n\n- %static:attachments/counterbalancing-osweb-jatos.osexp%\n\nWhen running from JATOS, the experiment retrieves a single condition from the Batch Session Data (see below) and registers this as the experimental variable `condition`. When doing a test run, `condition` is set to a default value specified at the end of *init_condition*.\n\nThe experiment itself should be implemented in the *experiment* SEQUENCE, which in the template contains only the *show_condition* SKETCHPAD (see %FigCounterbalancingOSWebJATOS).\n\n%--\nfigure:\n    source: counterbalancing-osweb-jatos.png\n    id: FigCounterbalancingOSWebJATOS\n    caption: |\n        The overview area of the template experiment for implementing counterbalancing with JATOS Batch Session Data.\n--%\n\nWhen importing the experiment into JATOS, all conditions should be specified in the Batch Session Data as the `pending` list (under Worker & Batch Manager; see %FigBatchSessionData). Each condition from `pending` corresponds to a single experimental session; therefore, if condition `a` should be used for two experimental sessions, then `a` needs to occur twice in the `pending` list. The conditions are used in the order in which they are defined.\n\n%--\nfigure:\n    source: batch-session-data.png\n    id: FigBatchSessionData\n    caption: |\n        The conditions should be specified in the Batch Session Data in JATOS.\n--%\n\nAt the start of an experimental session, a single condition is moved from `pending` to `started`. (When the `pending` list is empty, the participant is informed that he or she can no longer participate in the experiment.) At the end of the experimental session, the condition is appended to the `finished` list.\n\nTo make this more concrete, let's say that you've defined the Batch Session Data as shown in %FigBatchSessionData. Then, four experimental sessions are started, but the second experimental session, with condition `a`, never finishes, for example because the participant closes the browser halfway the experiment. The Batch Session Data will then look as in %FigBatchSessionAfter:\n\n%--\nfigure:\n    source: batch-session-data-after.png\n    id: FigBatchSessionAfter\n    caption: |\n        The Batch Session Data after all conditions have been consumed. One session, with condition `a`, never finished.\n--%\n\nYou can tell from the Batch Session Data that one experimental session started with condition `a` but never finished. To nevertheless collect an experimental session with this condition, you have to manually add a new `a` to the `pending` list and collect a new session.", "url": "https://osdoc.cogsci.nl/4.0/manual/counterbalancing", "title": "Counterbalancing"}
{"content": "# Variables\n\ntitle: Variables\n\n[TOC]\n\n## What is an experimental variable in OpenSesame?\n\nExperimental variables in OpenSesame are those variables that:\n\n- You can refer to in the user interface with the '{variable_name}' syntax.\n- Are available as global variables in a Python INLINE_SCRIPT.\n- Are available as global variables in a JavaScript INLINE_JAVASCRIPT.\n- Contain things like:\n\t- The variables that you have defined in a LOOP item.\n\t- The responses that you have collected.\n\t- Various properties of the experiment.\n\t- Etc.\n\n## The variable inspector\n\nThe variable inspector (`Ctrl+I`) provides an overview of available variables (%FigVariableInspector). When the experiment is not running, this overview is based on a best guess of which variables will become available during the experiment. However, when the experiment is running, the variable inspector shows a live overview of variables and their values. This is useful for debugging your experiment.\n\n%--\nfigure:\n id: FigVariableInspector\n source: variable-inspector.png\n caption: The variable inspector provides an overview of all variables that OpenSesame knows about.\n--%\n\n## Defining variables\n\nThe simplest way to define a variable is through the LOOP item. For example, %FigLoop shows how to define a variable named `gaze_cue`. In this example, *trial_sequence* item is called four times while `gaze_cue` is 'left' and another four times while 'gaze_cue' is 'right'.\n\n%--\nfigure:\n id: FigLoop\n source: defining-variables-in-a-loop.png\n caption: The most common way to define independent variables is using the LOOP table.\n--%\n\n## Built-in variables\n\nThe following variables are always available:\n\n### Experiment variables\n\n|Variable name\t\t\t|Description|\n|-----------------------|-----------|\n|`title`\t\t\t\t|The title of the experiment|\n|`description`\t\t\t|The description of the experiment|\n|`foreground`\t\t\t|The default foreground color. E.g., 'white' or '#FFFFFF'.|\n|`background`\t\t\t|The default background color. E.g., 'black' or '#000000'.|\n|`height`\t\t\t\t|The height-part of the display resolution. E.g., '768'|\n|`width`\t\t\t\t|The width-part of the display resolution. E.g., '1024'|\n|`subject_nr`\t\t\t|The subject number, which is asked when the experiment is started.|\n|`subject_parity`\t\t|Is 'odd' if `subject_nr` is odd and 'even' if `subject_nr` is even. Useful for counterbalancing.|\n|`experiment_path`\t\t|The folder of the current experiment, without the experiment filename itself. If the experiment is unsaved, it has the value `None`.|\n|`pool_folder`\t\t\t|The folder where the contents of the file pool have been extracted to. This is generally a temporary folder.|\n|`logfile`\t\t\t\t|The path to the logfile.|\n\n### Item variables\n\nThere are also variables that keep track of all the items in the experiment.\n\n|Variable name\t\t\t|Description|\n|-----------------------|-----------|\n|`time_[item_name]`\t\t|Contains a timestamp of when the item was last executed. For SKETCHPAD items, this can be used to verify the timing of display presentation.|\n|`count_[item_name]`\t|Is equal the number of times minus one (starting at 0, in other words) that an item has been called. This can, for example, be used as a trial or block counter.|\n\n### Response variables\n\nWhen you use the standard response items, such as the KEYBOARD_RESPONSE and MOUSE_RESPONSE, a number of variables are set based on the participant's response.\n\n|Variable name\t\t\t\t\t|Description|\n|-------------------------------|-----------|\n|`response`\t\t\t\t\t\t|Contains the last response that has been given.|\n|`response_[item_name]`\t\t\t|Contains the last response for a specific response item. This is useful in case there are multiple response items.|\n|`response_time`\t\t\t\t|Contains the interval in milliseconds between the start of the response interval and the last response.|\n|`response_time_[item_name]`\t|Contains the response time for a specific response item.|\n|`correct`\t\t\t\t\t\t|Is set to '1' if the last `response` matches the variable `correct_response`, '0' if not, and 'undefined' if the variable `correct_response` has not been set.|\n|`correct_[item_name]`\t\t\t|As `correct` but for a specifc response item.|\n\n### Feedback variables\n\nFeedback variables maintain a running average of accuracy and response times.\n\n|Variable name\t\t\t\t\t|Description|\n|-------------------------------|-----------|\n|`average_response_time`\t\t|The average response time. This is variable is useful for presenting feedback to the participant.|\n|`avg_rt`\t\t\t\t\t\t|Synonym for `average_response_time`|\n|`accuracy`\t\t\t\t\t\t|The average percentage of correct responses. This is variable is useful for presenting feedback to the participant.|\n|`acc`\t\t\t\t\t\t\t|Synonym for `accuracy`|\n\n\n## Using variables in the user interface\n\nWherever you see a value in the user interface, you can replace that value by a variable using the '{variable name}' notation. For example, if you have defined a variable `soa` in a LOOP item, you can use this variable for the duration of a sketchpad as shown in %FigSketchpad.\n\n%--\nfigure:\n id: FigSketchpad\n source: variable-duration.png\n caption: The duration '{soa}' indicates that the duration of the SKETCHPAD depends on the variable `soa`.\n--%\n\nThis works throughout the user interface. For example, if you have the defined a variable `my_freq`, you can use this variable as the frequency in a SYNTH item, as shown in %FigSynth.\n\n%--\nfigure:\n id: FigSynth\n source: variable-frequency.png\n caption: The frequency '{my_freq}' indicates that the frequency of the SYNTH depends on the variable `my_freq`.\n--%\n\nSometimes, the user interface doesn't let you type in arbitrary text. For example, the elements of a SKETCHPAD are shown visually, and you cannot directly change an X coordinate to a variable. However, you can click on the *Select view \u2192 View script* button on the top right, and edit the script directly.\n\nFor example, you can change the position of a fixation dot from the center:\n\n```text\ndraw fixdot x=0 y=0\n```\n\n\u2026 to a position defined by the variables `xpos` and `ypos`:\n\n```text\ndraw fixdot x={xpos} y={ypos}\n```\n\n\n## Using Python expressions in the user interface\n\nWhen referring to variables using the `{my_var}` notation, you are in fact using a so-called [f-string](https://peps.python.org/pep-0498/), which is a way to embed Python code in strings of text. You can also use f-strings to evaluate arbitrary Python code. For example, you can multiply the variables `width` and `height` and include the result in a SKETCHPAD, like so:\n\n%--\nfigure:\n id: FigFString\n source: fstrings.png\n caption: You can embed Python expressions using f-strings.\n--%\n\nf-strings are Python code, and are therefore only supported on the desktop, but see below for a JavaScript alternative for browser experiments.\n\n\n## Using JavaScript expressions in the user interface\n\nWhen using OSWeb, expressions included between curly braces are interpreted as [template literals](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Template_literals). This is very similar to f-strings in Python, with the important difference that it uses JavaScript.\n\nIn normal JavaScript, expressions inside template literals are prefixed with a `$`, like so: `${expression}`. This is allowed in OpenSesame but not necessary: the prefix is automatically added to improve compatibility between browser and desktop experiments. In most cases, as in the figure below, the exact same expression is valid as a Python f-string on the desktop and a JavaScript template literal in the browser.\n\n\n%--\nfigure:\n id: FigTempalteLiteral\n source: template-literals.png\n caption: You can embed JavaScript expressions using template literals.\n--%\n\n\n## Using variables in Python\n\nIn an INLINE_SCRIPT, experimental variables are available as global variables. For example, if you have defined `example_variable` in a LOOP, then the following will print the value `example_variable` to the debug window:\n\n~~~ .python\nprint(example_variable)\n~~~\n\nYou can set the experimental variable `example_variable` to the value 'some value' as follows:\n\n~~~ .python\nexample_variable = 'some value'\n~~~\n\n\n## Using variables in JavaScript\n\nIn an INLINE_JAVASCRIPT, experimental variables are available as global variables. For example, if you have defined `example_variable` in a LOOP, then the following will print the value `example_variable` to the browser console:\n\n```js\nconsole.log(example_variable)\n```\n\nYou can set the experimental variable `example_variable` to the value 'some value' as follows:\n\n```js\nexample_variable = 'some value'\n```\n\n\n## Using conditional (\"if\") statements\n\nConditional statements, or 'if statements', provide a way to indicate that something should happen only under specific circumstances, such when some variable has a specific value. Conditional statements are regular Python expressions.\n\nThe most commonly used if-statement in OpenSesame is the run-if statement of the SEQUENCE, which allows you to specify the conditions under which a particular element is executed. If you open a SEQUENCE item, you see that every item from the sequence has a 'Run if \u2026'' option. The default value is 'always', which means that the item is always run; but you can also enter a condition here. For example, if you want to show a green fixation dot after a correct response, and a red fixation dot after an incorrect response, you can create a SEQUENCE like the following (this makes use of the fact that a KEYBOARD_RESPONSE item automatically sets the `correct` variable, as discussed above) as shown in %FigRunIf.\n\n*Important:* Run-if statements only apply to the Run phase of items. The Prepare phase is always executed. See also [this page](%link:prepare-run%).\n\n%--\nfigure:\n id: FigRunIf\n source: run-if.png\n caption: |\n  'Run if' statements can be used to indicate that certain items from a SEQUENCE should only be executed under specific circumstances.\n--%\n\nYou can use more complex conditions as well. Let's take a look at a few examples:\n\n```python\ncorrect == 1 and response_time > 2000\ncorrect != 1 or response_time > max_response_time or response_time < min_response_time\n```\n\nThe same principle applies to 'Show if' fields in SKETCHPAD items. For example, if you want to draw a right-upwards-pointing arrow only if the variable `quadrant` has been set to 'upper right', simply type the proper condition in the 'Show if ...' field and draw the arrow, as in %FigShowIf. Make sure that you draw the arrow after you have set the condition.\n\n%--\nfigure:\n id: FigShowIf\n source: show-if.png\n caption: \"'Show if' statements can be used to indicate that certain elements from a SKETCHPAD or FEEDBACK item should only be shown under specific circumstances.\"\n--%\n\nImportant: The moment at which a conditional statement is evaluated may affect how your experiment works. This is related to the prepare-run strategy employed by OpenSesame, which is explained here:\n\n- %link:prepare-run%", "url": "https://osdoc.cogsci.nl/4.0/manual/variables", "title": "Variables"}
{"content": "# Examples\n\ntitle: Examples\n\nExample experiments are included with OpenSesame. A list of curated examples is available through Menu \u2192 Tools \u2192 Example experiments. You can also search for publicly available experiments on the OpenScienceFramework by using 'osexp' as search term.\n\n- <https://osf.io/search/?q=osexp>", "url": "https://osdoc.cogsci.nl/4.0/manual/examples", "title": "Examples"}
{"content": "# Mouse tracking\n\ntitle: Mouse tracking\n\nMousetrap is a third-party plugin, and is not maintained by the OpenSesame team.\n{: .alert .alert-info}\n\n## About\n\nPascal Kieslich and Felix Henninger have developed the [mousetrap plugins](https://github.com/PascalKieslich/mousetrap-os) for OpenSesame [(Kieslich & Henninger, 2017)](https://dx.doi.org/10.3758/s13428-017-0900-z). These plugins allow you to track the movement of the mouse cursor, which has been used to investigate the time course of cognitive processes in many psychological domains [(Freeman, Dale, & Farmer, 2011)](https://dx.doi.org/10.3389/fpsyg.2011.00059).\n\nMousetrap offers two plugins for mouse tracking in OpenSesame that can be included in the experiment via drag-and-drop.\nThe [mousetrap response plugin](https://github.com/PascalKieslich/mousetrap-os/blob/master/plugins/mousetrap_response/mousetrap_response.md) tracks mouse movements while another stimulus (e.g., a sketchpad) is shown, analogous to a keyboard or mouse response item.\nThe [mousetrap form plugin](https://github.com/PascalKieslich/mousetrap-os/blob/master/plugins/mousetrap_form/mousetrap_form.md) allows for tracking of mouse movements in [custom forms](%link:manual/forms/custom%).\nBesides, both plugins also provide Python classes, which can be used in Python inline scripts for maximum customizability.\n\nOnce data have been collected with the plugins, the data can be processed, analyzed and visualized using the [mousetrap R package](http://pascalkieslich.github.io/mousetrap/).\n\n## Installation\n\nInformation about how to install the mousetrap plugin can be found on its [GitHub page](https://github.com/PascalKieslich/mousetrap-os#installation). A number of example experiments that demonstrate the basic features are available in the [examples folder](https://github.com/PascalKieslich/mousetrap-os/tree/master/examples#example-experiments).\n\n\nSee also:\n\n- <https://rapunzel.cogsci.nl/manual/environment/>", "url": "https://osdoc.cogsci.nl/4.0/manual/mousetracking", "title": "Mouse tracking"}
{"content": "# Running experiments online\n\ntitle: Running experiments online\n\n\nThis page has been moved to:\n\n- %link:manual/osweb/workflow%", "url": "https://osdoc.cogsci.nl/4.0/manual/osweb", "title": "Running experiments online"}
{"content": "# Integration with the Open Science Framework\n\ntitle: Integration with the Open Science Framework\n\n[TOC]\n\n## About\n\nThe OpenScienceFramework extension connects OpenSesame to the [Open Science Framework](https://osf.io) (OSF), which is a web platform for sharing, connecting, and streamlining scientific workflows. To use this extension, [you need an OSF account](https://osf.io/login/?sign_up=True).\n\nWith the OpenScienceFramework extension, you can:\n\n- Automatically save your experiment to the OSF\n- Automatically upload data to the OSF\n- Open experiments from the OSF\n- Share your experiment and data with other researchers, by giving them access through the OSF\n\n## Logging in to the OSF\n\nTo log into the OSF:\n\n- Create an account on <https://osf.io>. (You cannot create an account from within OpenSesame.)\n- In OpenSesame, click on the log-in button in the main toolbar, and enter your credentials.\n- Once logged in, you can open the OSF Explorer by clicking on your name where the login button used to be, and selecting *Show explorer*. The explorer will show an overview of all your OSF projects, and all repositories/ cloud services that are linked to your projects.\n\n## Linking an experiment to the OSF\n\nIf you link an experiment to the OSF, each time that you save the experiment in OpenSesame, a new version is also uploaded to the OSF.\n\nTo link an experiment:\n\n- Save the experiment on your computer.\n- Open the OSF explorer and select a folder or repository where you would like your experiment to be stored on the OSF. Right-click on this folder and select *Sync experiment to this folder*. The OSF node to which the experiment is linked will be shown at the top of the explorer.\n- The experiment is then uploaded to the selected location.\n- If you check *Always upload experiment on save*, a new version is automatically saved to OSF on each save; if you don't enable this option, you will be asked every time whether or not you want to do this.\n\nTo unlink an experiment:\n\n- Open the OSF explorer, and click the *Unlink* button next to the *Experiment linked to* link.\n\n## Linking data to the OSF\n\nIf you link data to the OSF, each time that data has been collected (normally after every experimental session), this data is also uploaded to the OSF.\n\nTo link data to the OSF:\n\n- Save the experiment on your computer.\n- Open the OSF explorer, right-click on the folder that you want the data to be uploaded to, and select *Sync data to this folder*. The OSF node that the data is linked to will be shown at the top of the explorer.\n- If you check *Always upload collected data*, data files will be automatically saved to OSF after they have been collected; if you don't enable this option, you will be asked every time whether or not you want to do this.\n\nTo unlink data from the OSF:\n\n- Open the OSF explorer, and click the *Unlink* button next to the *Data stored to* link.\n\n## Opening an experiment stored on the OSF\n\nTo open an experiment from the OSF:\n\n- Open the OSF explorer, and find the experiment.\n- Right-click on the experiment and select *Open experiment*.\n- Save the experiment on your computer.\n\n## Handling non-matching versions\n\nIf you open an experiment on your computer that is linked to the OSF, but differs from the version on the OSF, you will be asked what you want to do:\n\n- Use the version from your computer; or\n- Use the version from the OSF. If you choose to use the version from the OSF, it will be downloaded and overwrite the experiment on your computer.\n\n## Installing the OpenScienceFramework extension\n\nThe OpenScienceFramework extension is installed by default in the Windows package of OpenSesame. If the extension is not installed, you can install it as follows:\n\nFrom PyPi:\n\n~~~\npip install opensesame-extension-osf\n~~~\n\nIn an Anaconda environment\n\n~~~\nconda install -c cogsci opensesame-extension-osf\n~~~\n\nThe source code of the extension is available on GitHub:\n\n- <https://github.com/dschreij/opensesame-extension-osf>\n\nAnd for the `python-qosf` module, which is used by the extension:\n\n- <https://github.com/dschreij/python-qosf>", "url": "https://osdoc.cogsci.nl/4.0/manual/osf", "title": "Integration with the Open Science Framework"}
{"content": "# Installing packages, plugins, and extensions\n\ntitle: Installing packages, plugins, and extensions\n\n\nThis page has moved to:\n\n- <https://rapunzel.cogsci.nl/manual/environment/>", "url": "https://osdoc.cogsci.nl/4.0/manual/environment", "title": "Installing packages, plugins, and extensions"}
{"content": "# Using the interface\n\ntitle: Using the interface\n\nOpenSesame has a powerful graphical interface that consists of several components (%FigInterface).\n\n%--\nfigure:\n id: FigInterface\n source: interface.png\n caption: The OpenSesame user interface.\n--%\n\n\n[TOC]\n\n## Toolbars and menubar\n\n### The menubar\n\nThe menubar (%FigMenubar) is shown at the top of the window, or, on some operating systems, is integrated into the border around the window. The menubar contains general functionality, such as saving and opening experiments, running experiments, etc.\n\n%--\nfigure:\n id: FigMenubar\n source: menubar.png\n caption: The menubar.\n--%\n\n### The main toolbar\n\nThe main toolbar (%FigMainToolbar) is (by default) shown at the top of the window, just below the menubar. The main toolbar contains a selection of the most relevant functionality from the menubar.\n\n%--\nfigure:\n id: FigMainToolbar\n source: main-toolbar.png\n caption: The main toolbar.\n--%\n\n### The item toolbar\n\nThe item toolbar (%FigItemToolbar) is (by default) shown at the left of the window. The item toolbar contains all items, that is, all building blocks of an experiment. You can add items to your experiment by dragging them from the item toolbar into the overview area.\n\n%--\nfigure:\n id: FigItemToolbar\n source: item-toolbar.png\n caption: The item toolbar.\n--%\n\n## The tab area\n\nThe tab area is the central part of the window (%FigTabArea). The tab area is where item controls, documentation, important messages, etc. are shown. The tab area can contain multiple tabs, and functions much like a tabbed web browser.\n\n%--\nfigure:\n id: FigTabArea\n source: tab-area.png\n caption: The tab area.\n--%\n\n## The overview area\n\nThe overview area (%FigOverviewArea) is (by default) shown at the left of the window, to the right of the item toolbar. The overview area shows the structure of your experiment as a tree. You can re-order the items in your experiment by dragging them from one position to another in the overview area.\n\n- Shortcut to hide/ show: `Ctrl+\\`\n\n%--\nfigure:\n id: FigOverviewArea\n source: overview-area.png\n caption: The overview area.\n--%\n\n## The file pool\n\nThe file pool (%FigFilePool) is (by default) shown at the right of the window. It provides an overview of all files that are bundled with the experiment.\n\n- Shortcut to hide/ show: `Ctrl+P`\n\n%--\nfigure:\n id: FigFilePool\n source: file-pool.png\n caption: The file pool.\n--%\n\n## The debug window\n\nThe debug window (%FigDebugWindow) is (by default) shown at the bottom of the window. It provides an [IPython interpreter](https://ipython.org/), and is used as the standard output while an experiment is running. That is, if you use the Python `print()` function, the result will be printed to the debug window.\n\n- Shortcut to hide/ show: `Ctrl+D`\n\n%--\nfigure:\n id: FigDebugWindow\n source: debug-window.png\n caption: The debug window.\n--%\n\n## The variable inspector\n\nThe variable inspector (%FigVariableInspector) is (by default) shown at the right of the window. It provides a list of all variables that are detected in your experiment. When you are running an experiment, the variable inspector also provides a real-time overview of variables and their values.\n\n- Shortcut to hide/ show: `Ctrl+I`\n\n%--\nfigure:\n id: FigVariableInspector\n source: variable-inspector.png\n caption: The variable inspector.\n--%\n\n## Keyboard shortcuts\n\nThe keyboard shortcuts listed below are default values. Many of them can be changed through *Menu \u2192 Tools \u2192 Preferences*.\n\n### General shortcuts\n\nThe following keyboard shortcuts are available everywhere:\n\n- Quick switcher: `Ctrl+Space`\n- Command palette: `Ctrl+Shift+P`\n- New experiment: `Ctrl+N`\n- Open experiment: `Ctrl+O`\n- Save experiment: `Ctrl+S`\n- Save experiment as: `Ctrl+Shift+S`\n- Undo: `Ctrl+Alt+Z`\n- Redo: `Ctrl+Alt+Shift+Z`\n- Run experiment fullscreen: `Ctrl+R`\n- Run experiment in window: `Ctrl+W`\n- Quick-run experiment: `Ctrl+Shift+W`\n- Test experiment in browser: `Alt+Ctrl+W`\n- Show/ hide overview area: `Ctrl+\\`\n- Show/ hide debug window: `Ctrl+D`\n- Show/ hide file pool: `Ctrl+P`\n- Show/ hide variable inspector: `Ctrl+I`\n- Focus overview area: `Ctrl+1`\n- Focus tab area: `Ctrl+2`\n- Focus debug window: `Ctrl+3`\n- Focus file pool: `Ctrl+4`\n- Focus variable inspector: `Ctrl+5`\n\n### Editor shortcuts\n\nThe following keyboard shortcuts are available in editor components, such as the INLINE_SCRIPT:\n\n- (Un)comment selected line(s): `Ctrl+/`\n- Find text: `Ctrl+F`\n- Replace text: `Ctrl+H`\n- Hide find/ replace dialog: `Escape`\n- Duplicate line: `Ctrl+Shift+D`\n- Undo: `Ctrl+Z`\n- Redo: `Ctrl+Shift+Z`\n- Copy: `Ctrl+C`\n- Cut: `Ctrl+X`\n- Paste: `Ctrl+V`\n\n### Tab-area shortcuts\n\nThe following keyboard shortcuts are available in the tab area:\n\n- Next tab: `Ctrl+Tab`\n- Previous tab: `Ctrl+Shift+Tab`\n- Close other tabs: `Ctrl+T`\n- Close all tabs: `Ctrl+Alt+T`\n- Close current tab: `Alt+T`\n\n### Overview-area and sequence shortcuts\n\nThe following keyboard shortcuts are available in the overview area and the SEQUENCE item:\n\n- Context menu: `+`\n- Copy item (unlinked): `Ctrl+C`\n- Copy item (linked): `Ctrl+Shift+C`\n- Paste item: `Ctrl+V`\n- Delete item: `Del`\n- Permanently delete item: `Shift+Del`\n- Rename: `F2`\n- Change run-if statement (if applicable): `F3`", "url": "https://osdoc.cogsci.nl/4.0/manual/interface", "title": "Using the interface"}
{"content": "# Runtime for Android\n\ntitle: Runtime for Android\n\n\n__Important note:__ The OpenSesame runtime for Android is based on software by others that is no longer developed. As a result, we are unable to make sure that the runtime works with recent versions of Android. Windows 10 tablets with Intel processors are a good alternative.\n{: .alert .alert-warning}\n\n\n[TOC]\n\n\n## OpenSesame runtime for Android\n\n### Download\n\nYou can download the OpenSesame runtime for Android through the Google Play Store:\n\n<a href=\"https://play.google.com/store/apps/details?id=nl.cogsci.opensesame\" style=\"border:none;\">\n  <img alt=\"Get it on Google Play\"\n       src=\"https://developer.android.com/images/brand/en_generic_rgb_wo_45.png\" />\n</a>\n\n### Usage\n\nWhen you start the OpenSesame runtime, you will be asked where your experiments are located. By default, OpenSesame assumes that they are in the `/sdcard/` folder, or (if it exists) in the `/sdcard/Experiments/` folder. If you have no experiments on your device, pressing `enter` will show the example experiments that are bundled with the `.apk`.\n\nThe `Back` button serves the same purpose as the `Escape` key on regular systems, and will exit OpenSesame.\n\n### Supported devices\n\nOpenSesame is developed with the Nexus 4 and 9 as reference devices. In general, any device that runs Android 2.2. 'Froyo' or later appears to work.\n\n### Disabling automatic updates\n\nIf you are using the OpenSesame runtime for Android in a production environment (e.g., while you are running an experiment), it is recommended to disable the Auto-update feature of the Google Play Store, at least for OpenSesame. This will prevent the app from being updated and potentially changing its behavior. In case you need to downgrade to a previous version of the Android runtime, you can find the `.apk` files for previous releases [here](https://github.com/smathot/OpenSesame/releases).\n\n### Automatically start an experiment\n\nIf you want to directly launch a specific experiment when the OpenSesame runtime for Android is started, you can create a file called `opensesame-autorun.yml` in the `/sdcard/` folder of your device. This is a YAML file with the following structure:\n\n~~~\nexperiment: /sdcard/experiments/my_experiment.opensesame\nsubject_nr: 3\nlogfile: /sdcard/data/subject03.csv\n~~~\n\n## Developing experiments for Android\n\n### backend\n\nThe OpenSesame runtime for Android requires the *droid* backend.\n\n### Design tips\n\nImplement most user interactions through the MOUSE_RESPONSE item or TOUCH_RESPONSE plugin. In general, screen touches are registered as mouse clicks. Using keyboard input will work as well, but it will show and hide the virtual keyboard after every key that is entered, which looks messy.\n\nThe resolution for the DROID backend is fixed at 1280x800 (landscape). On Android, your experiment will be automatically scaled up or down depending on the resolution of the device, but the resolution that you design with is always 1280x800.\n\n### Debugging\n\nDebug output is written to `/sdcard/opensesame-debug.txt`.\n\n### Limitations\n\n- The SYNTH item and `openexp.synth` module are not functional.\n- The SAMPLER item and `openexp.sampler` module will ignore panning and pitching.\n\n## Know issue: Frozen or misbehaving virtual keyboard\n\nOn some devices, the default virtual keyboard is unresponsive (i.e. it shows but doesn't respond to taps) or doesn't respond normally. This appears to happen on phones with recent versions of Android. To work around this issue, you can install a third-party keyboard. Keyboards that have been reported to work are:\n\n- [GO Keyboard](https://play.google.com/store/apps/details?id=com.jb.emoji.gokeyboard&hl=en)\n- [Smart Keyboard Trial](https://play.google.com/store/apps/details?id=net.cdeguet.smartkeyboardtrial&hl=en)\n\n## Available Python modules\n\nBelow is a list of Python modules that should be available in the OpenSesame runtime for android. (This list is copied from the pgs4a now-defunct website.)\n\n~~~\npygame\npygame.base\npygame.bufferproxy\npygame.colordict\npygame.color\npygame.compat\npygame.constants\npygame.cursors\npygame.display\npygame.draw\npygame.event\npygame.fastevent\npygame.font\npygame.gfxdraw\npygame.imageext\npygame.image\npygame.joystick\npygame.key\npygame.locals\npygame.mask\npygame.mouse\npygame.overlay\npygame.rect\npygame.rwobject\npygame.sprite\npygame.surface\npygame.surflock\npygame.sysfont\npygame.time\npygame.transform\npygame.version\n_abcoll\nabc\naliases\narray\nast\natexit\nbase64\nbisect\nbinascii\ncalendar\ncmath\ncodecs\ncollections\ncompileall\ncontextlib\ncopy\ncopy_reg\ncStringIO\ncPickle\ndatetime\ndifflib\ndis\ndummy_threading\ndummy_thread\nencodings\nencodings.raw_unicode_escape\nencodings.utf_8\nencodings.zlib_codec\nerrno\nfcntl\nfnmatch\nfunctools\n__future__\ngenericpath\ngetopt\nglob\ngzip\nhashlib\nheapq\nhttplib\ninspect\nitertools\nkeyword\nlinecache\nmath\nmd5\nmimetools\nopcode\noptparse\nos\noperator\nparser\npickle\nplatform\nposix\nposixpath\npprint\npy_compile\npwd\nQueue\nrandom\nrepr\nre\nrfc822\nselect\nsets\nshlex\nshutil\nsite\nsocket\nsre_compile\nsre_constants\nsre_parse\nssl\nstat\nStringIO\nstring\nstruct\nsubprocess\nsymbol\nsymtable\nstrop\ntarfile\ntempfile\ntextwrap\n_threading_local\nthreading\ntime\ntokenize\ntoken\ntraceback\ntypes\nurllib\nurllib2\nurlparse\nUserDict\nwarnings\nweakref\nwebbrowser\nzipfile\nzipimport\nzlib\n~~~\n\n[google-play]: https://play.google.com/store/apps/details?id=nl.cogsci.opensesame\n[forum]: http://forum.cogsci.nl/index.php?p=/discussion/333/a-video-of-opensesame-running-natively-on-android\n[droid]: /backends/droid\n[pgs4a]: http://pygame.renpy.org/", "url": "https://osdoc.cogsci.nl/4.0/manual/android", "title": "Runtime for Android"}
{"content": "# OpenSesameRun (no GUI)\n\ntitle: OpenSesameRun (no GUI)\n\n## About\n\n`opensesamerun` is a simple tool that allows you to execute OpenSesame experiments with a minimal GUI, or directly, by specifying all necessary options via the command line. A minimal GUI will automatically appear if not all command line options have been specified, notably the experiment file, the subject number, and the log file.\n\n~~~\nUsage: opensesamerun [experiment] [options]\n\nOptions:\n  --version             show program's version number and exit\n  -h, --help            show this help message and exit\n\n  Subject and log file options:\n    -s SUBJECT, --subject=SUBJECT\n                        Subject number\n    -l LOGFILE, --logfile=LOGFILE\n                        Logfile\n\n  Display options:\n    -f, --fullscreen    Run fullscreen\n    -c, --custom_resolution\n                        Do not use the display resolution specified in the\n                        experiment file\n    -w WIDTH, --width=WIDTH\n                        Display width\n    -e HEIGHT, --height=HEIGHT\n                        Display height\n\n  Miscellaneous options:\n    -d, --debug         Print lots of debugging messages to the standard\n                        output\n    --stack             Print stack information\n\n  Miscellaneous options:\n    --pylink            Load PyLink before PyGame (necessary for using the\n                        Eyelink plug-ins in non-dummy mode)\n~~~\n\n## Example\n\nLet's say that you want to run the gaze cuing example experiment, for subject #1, and save the log file in your Documents folder (this example assumes Linux, but it works analogously on other platforms):\n\n~~~\nopensesamerun /usr/share/opensesame/examples/gaze_cuing.opensesame.tar.gz -s 1 -l /home/sebastiaan/Documents/subject1.tsv -f \n~~~\n\n\n## Alternative `libopensesame`\n\nYou can also start experiments without using the GUI through the `libopensesame` Python module:\n\n- %link:manual/python/nogui%", "url": "https://osdoc.cogsci.nl/4.0/manual/opensesamerun", "title": "OpenSesameRun (no GUI)"}
{"content": "# Debugging\n\ntitle: Debugging\n\nWhile designing a new experiment, you will inevitably encounter bugs. Bugs can manifest as crashes accompanied by error messages, or as unexpected behaviors without any explicit error message.\n\nDebugging, the art and skill of diagnosing and rectifying these errors and unanticipated behaviors, is a critical part of the experimental design process.\n\n\n[TOC]\n\n\n## Debugging in the user interface\n\n### Using the variable inspector\n\nThe Variable Inspector in OpenSesame provides an overview of all variables that are currently active within your experiment. This includes:\n\n- Variables explicitly defined in the user interface, typically in a LOOP item.\n- Response variables, which are set by various response items such as a KEYBOARD_RESPONSE item.\n- Variables that are defined using Python INLINE_SCRIPT items.\n\nWhen an experiment is running, the Variable Inspector dynamically updates, providing a live overview of variables and their values. This feature allows you to monitor the behavior of your experiment in real-time, assisting you in identifying any potential issues or bugs.\n\nFor example, consider a situation where you have defined a variable `left_letter` to define which letter should appearing on the left side of a SKETCHPAD. However, during execution, you notice a mismatch in the Variable Inspector: `left_letter` is actually being shown on the right side of your display. This is indicates a bug such that you have misplaced the right and left letters on the SKETCHPAD.\n\n%--\nfigure:\n id: FigVariableInspector\n source: variable-inspector.png\n caption: You can use the variable inspector to check whether your experiment behaves as it should. In this example, there is a bug such that the letter that is defined through the variable `left_letter` actually appears on the right and vice versa.\n--%\n\nUsing the Variable Inspector regularly to monitor variables helps ensure that your experiment is behaving as expected and aids in identifying problems early on.\n\n\n### Printing debug messages to the IPython/ Jupyter console\n\nThe Python `print()` function is a simple-yet-powerful debugging tool when used inside INLINE_SCRIPT items, and serves a similar purpose to the Variable Inspector. For instance, you can print the values of the variables `left_letter` and `right_letter` during the Prepare phase of an INLINE_SCRIPT at the beginning of each trial.\n\nTo view these debug messages, open the Jupyter/ IPython console and monitor the output while running the experiment. By doing so, you can verify whether the output displayed in the console aligns with the experiment's actual behavior.\n\n%--\nfigure:\n id: FigPrintingOutput\n source: printing-output.png\n caption: The Python `print()` function can be used to output debug messages to the console.\n--%\n\nIn the above example, it becomes evident that the letter assigned to the `left_letter` variable (hence expected to appear on the left) is actually appearing on the right, and vice versa.\n\n\n### Interpreting user-interface error messages\n\nWhen a bug in your experiment causes a crash, OpenSesame displays an error message, also referred to as an 'Exception'. An error message typically consists of the following components:\n\n- **Error type:** Indicates the general class of error. In the example below this is an `FStringError`.\n- **Description:** Provides a more specific explanation of what triggered the error. In this case, 'Failed to evaluate \u2026'.\n- **Source:** Specifies the item that triggered the error and whether it occurred during the Run or Prepare phase.\n- **Traceback:** A detailed Python error message. This information is only shown if the error occurred while evaluating custom Python code, which includes INLINE_SCRIPT items, but also conditional expressions (e.g. run-if expressions), and text with embedded variable references.\n- **Learn more about this error:** An interactive button you can click to get more detailed information about the error message.\n\nLet's look at an example to better understand these components and learn how to fix a common error:\n\n%--\nfigure:\n id: FigFStringError\n source: fstring-error.png\n caption: An `FStringError` indicates an issue when trying to evaluate a text string containing a Python expression.\n--%\n\nThis is an `FStringError`, which means there was an issue while interpreting a text string that includes a Python expression. In this example, the problematic text is `{right_leter}`. Anything enclosed within curly braces is interpreted as a Python expression, and therefore in this case the Python expression is `right_leter`\u2014which is simply a variable name. Trying to evaluate the Python expression `right_leter` triggered a `NameError` because `right_leter` is not defined.\n\nThat's pretty technical, but what exactly went wrong here in simple terms? The issue arises from referring to a non-existent variable: `right_leter`. Looking at the variable name, it seems likely that there's a typo: the intended variable is likely `right_letter`, with a double 't'.\n\nWhere should we correct this mistake? The error message indicates that the source of the error is an item called *target*, which is a SKETCHPAD. To resolve the error, we need to open *target* and change the text from '{right_leter}' to '{right_letter}'. \n\n\n### Interpreting Python error messages\n\nIn Python, errors fall into two categories: syntax errors and exceptions (or runtime errors).\n\n\n#### Python syntax errors\n\nA syntax error occurs when the Python interpreter cannot parse code because it violates Python's syntax rules. This could be due to mismatched parentheses, missing commas, incorrect indentation, and so on. In OpenSesame, this results in a `PythonSyntaxError`.\n\n%--\nfigure:\n id: FigPythonSyntaxError\n source: python-syntax-error.png\n caption: A `PythonSyntaxError` is triggered when the code violates Python's syntax rules and cannot be parsed.\n--%\n\nThe error message above indicates that a syntax error has occurred on line 16 of the Prepare phase of an item named *constants*. Here's the problematic line:\n\n```python\ntarget_orientations = [('z', 0), ('/', 90]\n```\n\nThe message also hints at mismatched parentheses as the potential source of the error. Taking that into consideration, we can fix the issue by adding a missing parenthesis `)` before the closing bracket `]`:\n\n```python\ntarget_orientations = [('z', 0), ('/', 90)]\n```\n\n\n#### Python Exceptions\n\nWhen Python code is syntactically correct but encounters a problem during execution, an exception is raised. In OpenSesame, such exceptions result in a `PythonError`.\n\n%--\nfigure:\n id: FigPythonError\n source: python-error.png\n caption: A `PythonError` is triggered when an exception is raised during the execution of syntactically correct Python code.\n--%\n\nThe error message above indicates that a `NameError` was raised on line 2 of the Run phase of an item named *trial_script*. Specifically, the identifier 'clock_sleep' is not recognized. Looking at the error-causing line, it's apparent that we've used an underscore (`_`) instead of a dot (`.`), incorrectly implying that `clock_sleep()` is a function.\n\n```python\nclock_sleep(495)\n```\n\nTo rectify this, we should correctly reference the `sleep()` function as part of the `clock` object:\n\n```python\nclock.sleep(495)\n```\n\n## Debugging in a web browser (OSWeb)\n\n\n### Printing output to the browser console\n\nThe JavaScript `console.log()` function is a simple-yet-powerful debugging tool when used inside INLINE_JAVASCRIPT items. It serves a similar purpose to the Python `print()` function and the Variable Inspector, neither of which are available in OSWeb. For instance, you can print the values of the variables `left_letter` and `right_letter` during the Prepare phase of an INLINE_SCRIPT at the beginning of each trial.\n\nTo view these debug messages, you need to open the browser console. Here's how to do it in Chrome, Firefox, and Edge:\n\n- **Google Chrome:** Press Ctrl + Shift + J (Windows / Linux) or Cmd + Option + J (Mac).\n- **Mozilla Firefox:** Press Ctrl + Shift + K (Windows / Linux) or Cmd + Option + K (Mac).\n- **Microsoft Edge:** Press F12 to open the developer tools, then select the \"Console\" tab.\n\nOnce the console is open, you can monitor the output while running the experiment, allowing you to check whether the output displayed in the console aligns with the experiment's actual behavior.\n\n%--\nfigure:\n id: FigPrintingOutputOSWeb\n source: printing-output-osweb.png\n caption: The JavaScript `console.log()` function can be used to output debug messages to the browser console.\n--%\n\nIn the above example, it becomes evident that the letter assigned to the `left_letter` variable (which should appear on the left) is actually appearing on the right, and vice versa.\n\n\n### Understanding error messages\n\nWhen your browser-based experiment crashes, OSWeb will show an error message in the browser. An error message typically consists of the following components:\n\n- **Error type:** Indicates the general class of error. In this example below this is a `ReferenceError`.\n- **Description:** Provides a more specific explanation of what triggered the error. In this case, 'right_leter is not defined'.\n- **Source:** Specifies the item that triggered the error and whether it occurred during the Run or Prepare phase.\n- **Source script:** The JavaScript code that caused the error. This information is only shown if the error occurred while evaluating custom JavaScript, which includes INLINE_JAVASCRIPT items, but also conditional expressions (e.g. run-if expressions), and text with embedded variable references.\n\nLet's look at an example to better understand these components and learn how to fix a common error:\n\n%--\nfigure:\n id: FigOSWebError\n source: osweb-error.png\n caption: A `ReferenceError` indicates a reference to a non-existent variable or other non-existent object.\n--%\n\nThis is a `ReferenceError`, which indicates that the experiment refers to a non-existent variable or other non-existent object. In this example, the error arose from the text `${right_leter}`. Anything enclosed within curly braces and prefixed by a `$` is interpreted as JavaScript expression, and in this case, the JavaScript expression is `right_leter`\u2014which is simply a variable name. Trying to evaluate the JavaScript expression `right_leter` triggered a `ReferenceError` because `right_leter` is not defined.\n\nThat's pretty technical, but what exactly went wrong here in simple terms? The issue arises from referring to a non-existent variable: `right_leter`. Looking at the variable name, it seems likely that there's a typographical error: the intended variable is likely `right_letter`, with a double 't'.\n\nWhere should we correct this mistake? The error message indicates that the source of the error is an item called *target*, which is a SKETCHPAD. To resolve the error, we need to open *target* and change the text from '{right_leter}' to '{right_letter}'. \n\n\n### Using the `debugger` statement in INLINE_JAVASCRIPT items\n\nThe JavaScript `debugger` statement is a powerful tool for debugging `INLINE_JAVASCRIPT` items in OpenSesame/OSWeb experiments. It allows you to insert breakpoints in your code, causing the browser's JavaScript execution to pause at that point. This allows you to inspect the current state of the JavaScript workspace.\n\nUsing the `debugger` statement is straightforward. Simply insert the statement `debugger` on the line where you want to pause execution. For example:\n\n```javascript\nconsole.log(`left_letter = ${left_letter}`)\nconsole.log(`right_letter = ${right_letter}`)\ndebugger // Execution will pause here\n```\n\nOnce you've inserted the `debugger` statement into your code, you need to open the browser console as explained above. After you open the browser console, run your experiment. When the JavaScript interpreter reaches the `debugger` statement, it will pause execution, and the developer tools will switch to the \"Sources\" (Chrome/Edge) or \"Debugger\" (Firefox) tab, highlighting the breakpoint line.\n\n%--\nfigure:\n id: FigJavaScriptDebugger\n source: javascript-debugger.png\n caption: When the JavaScript interpreter reaches the `debugger` statement, it will pause execution and allow you to inspect the JavaScript workspace. The `debugger` statement only works when the browser console is open.\n--%\n\nWhile execution is paused, you can inspect variable values, step through the code line by line, and investigate the call stack to better understand the state of your program at the breakpoint.\n\nRemember to remove or comment out the `debugger` statements when you're finished debugging, as leaving them in can interfere with the normal operation of your experiment.\n\n\n## Handling ExperimentProcessDied errors\n\nOccasionally, you might encounter an `ExperimentProcessDied` error during an experiment.\n\n%--\nfigure:\n id: FigExperimentProcessDied\n source: experiment-process-died.png\n caption: The `ExperimentProcessDied` error generally indicates an issue with the underlying Python process or associated libraries, not your experiment's code.\n--%\n\nThis error implies that the Python process in which the experiment was running terminated unexpectedly. It typically doesn't indicate a bug in your experiment, but rather suggests a problem in one of the low-level libraries used by OpenSesame, or even a bug in Python itself.\n\nDetermining the exact cause of this error can be challenging, and fixing it may be even more so. However, there are a few workarounds you can try to mitigate the issue:\n\n- **Change the backend:** Select a different backend under 'Run Experiment' in the experiment properties. This might resolve the issue as different backends use different sets of low-level libraries.\n- **Update OpenSesame and relevant packages:** Regularly updating OpenSesame and all associated packages can potentially resolve this issue, as bugs are routinely fixed in new versions.", "url": "https://osdoc.cogsci.nl/4.0/manual/debugging", "title": "Debugging"}
{"content": "# Logging and reading data files\n\ntitle: Logging and reading data files\n\nAlways triple check whether your data has been logged correctly before running your experiment!\n{: .page-notification}\n\n[TOC]\n\n\n## Using the logger item\n\nOpenSesame will not log your data automatically. Instead, you need to insert a LOGGER item, typically at the end of your trial sequence.\n\n%--\nfigure:\n id: FigLogger\n source: logger.png\n caption: |\n  The LOGGER item.\n--%\n\nThe simplest way to use the LOGGER is by leaving the option 'Automatically log all variables' enabled. That way, all variables that OpenSesame knows about are written the log file, except for those that are explicitly excluded (see below).\n\nYou can explicitly *include* which variables you want to log. The main reason for doing so is when you find that some variables are missing (because OpenSesame did not automatically detect them), or if you have disabled the option 'Automatically log all variables', \n\nYou can also explicitly exclude certain variables from the log file. The main reason for doing so is to keep the log files clean by excluding variables that are generally not useful.\n\nIn general, you should create only one logger item, and reuse that LOGGER at different locations in your experiment if necessary (i.e. use linked copies of the same LOGGER item). If you create multiple LOGGERs (rather than using a single LOGGER multiple times), they will all write to the same log file, and the result will be a mess!\n\n## Using Python inline script\n\nYou can write to the log file using the `log` object:\n\n~~~ .python\nlog.write('This will be written to the log file!')\n~~~\n\nFor more information, see:\n\n- %link:log%\n\nYou should generally not write to the log file directly and use a LOGGER item at the same time; doing so will result in messy log files.\n\n## Format of the data files\n\nIf you have used the standard LOGGER item, data files are in the following format format (simply standard csv):\n\n- plain-text\n- comma-separated\n- double-quoted (literal double-quotes are escaped with backward slashes)\n- unix-style line endings\n- UTF-8 encoded\n- column names on the first row\n\n## Which variables are logged?\n\nBy default, variables that are defined in the user interface, such as columns in a `loop` table or response variables are always logged.\n\nBy default, variables that are defined in an `inline_script` or `inline_javascript` are logged if they are numbers (`int` and `float`), strings (`str` and `bytes`), and `None` values. This is to avoid log files from becoming unreasonably large due to logging of long lists and other large values. (As of OpenSesame 4.0, there is no longer a need to use the `var` (Python) or `vars` (JavaScript) object.)\n\nIf you want to explicitly log a variable that is not logged by default, you can use the 'Include' field in the LOGGER item.\n\n\n## Reading and processing data files\n\n### In Python with pandas or DataMatrix\n\nIn Python, you can use [pandas](http://pandas.pydata.org/) to read csv files.\n\n```python\nimport pandas\ndf = pandas.read_csv('subject-1.csv')\nprint(df)\n```\n\nOr [DataMatrix](https://datamatrix.cogsci.nl/):\n\n```python\nfrom datamatrix import io\ndm = io.readtxt('subject-1.csv')\nprint(dm)\n```\n\n### In R\n\nIn R, you can simply use the `read.csv()` function to read a single data file.\n\n~~~ .R\ndf = read.csv('subject-1.csv', encoding = 'UTF-8')\nhead(df)\n~~~\n\nIn addition, you can use the `read_opensesame()` function from the [readbulk](https://github.com/pascalkieslich/readbulk) package to easily read and merge multiple data files into one large data frame. The package is available on CRAN and can be installed via `install.packages('readbulk')`.\n\n~~~ .R\n# Read and merge all data files stored in the folder 'raw_data'\nlibrary(readbulk)\ndf = read_opensesame('raw_data')\n~~~\n\n### In JASP\n\n[JASP](http://jasp-stats.org/), an open-source statistics package, opens csv files straight away.\n\n### In LibreOffice Calc\n\nIf you open a csv file in LibreOffice Calc, you have to indicate the exact data format, as indicated in %FigLibreOffice. (The default settings are often correct.)\n\n%--\nfigure:\n source: libreoffice.png\n id: FigLibreOffice\n--%\n\n### In Microsoft Excel\n\nIn Microsoft Excel, you need to use the Text Import Wizard.\n\n### Merging multiple data files into one large file\n\nFor some purposes, such as using pivot tables, it may be convenient to merge all data files into one large file. With Python DataMatrix, you can do this with the following script:\n\n```python\nimport os\nfrom datamatrix import DataMatrix, io, operations as ops\n\n# Change this to the folder that contains the .csv files\nSRC_FOLDER = 'student_data'\n# Change this to a list of column names that you want to keep\nCOLUMNS_TO_KEEP = [\n    'RT_search',\n    'load',\n    'memory_resp'\n]\n\n\ndm = DataMatrix()\nfor basename in os.listdir(SRC_FOLDER):\n    path = os.path.join(SRC_FOLDER, basename)\n    print('Reading {}'.format(path))\n    dm <<= ops.keep_only(io.readtxt(path), *COLUMNS_TO_KEEP)\nio.writetxt(dm, 'merged-data.csv')\n```\n\n\n## Logging in OSWeb\n\nWhen you run an experiment in a browser with OSWeb, logging works differently from when you run an experiment on the desktop.\n\nSpecifically, when you launch an OSWeb experiment directly from within OpenSesame, the log file is downloaded at the end of the experiment. This log file is in `.json` format. When you launch an OSWeb experiment from JATOS, there is no log file as such, but rather all data is sent to JATOS from where it can be downloaded.\n\nSee also:\n\n- %link:manual/osweb/workflow%\n\n\n\n[libreoffice]: http://www.libreoffice.org/\n[openoffice]: http://www.openoffice.org/\n[gnumeric]: http://projects.gnome.org/gnumeric/\n[log-func]: /python/inline-script/#inline_script.log\n[codecs]: http://docs.python.org/2/library/codecs.html\n[ppa]: https://launchpad.net/~smathot/+archive/cogscinl/", "url": "https://osdoc.cogsci.nl/4.0/manual/logging", "title": "Logging and reading data files"}
{"content": "# Timing\n\ntitle: Timing\nreviewed: false\n\nThis page describes various issues related to timing, and provides benchmark results and tips for testing your own system. If you experience problems with timing, please take the time to read this page. Many issues are resolved by taking into account things such as stimulus preparation and the properties of your monitor.\n\n[TOC]\n\n## Is OpenSesame capable of millisecond precision timing?\n\nThe short answer is: yes. The long answer is the rest of this page.\n\n\n## Important considerations for time-critical experiments\n\n### Check your timing!\n\nOpenSesame allows you to control your experimental timing very accurately. But this does not guarantee accurate timing in every specific experiment! For any number of reasons, many of which are described on this page, you may experience issues with timing. Therefore, in time-critical experiments you should always check whether the timing in your experiment is as intended. The easiest way to do this is by checking the display timestamps reported by OpenSesame.\n\nEvery SKETCHPAD item has a variable called `time_[sketchpad name]` that contains the timestamp of the last time that the SKETCHPAD was shown. Therefore, if you want the SKETCHPAD *target* to be shown for 100 ms, followed by the SKETCHPAD *mask*, you should verify that `time_mask` - `time_target` is indeed 100. When using Python inline code, you can make use of the fact that `canvas.show()` returns the display timestamp.\n\n\n### Understanding your monitor\n\nComputer monitors refresh periodically. For example, if the refresh rate of your monitor is 100 Hz, the display is refreshed every 10 ms (1000 ms / 100 Hz). This means that a visual stimulus is always presented for a duration that is a multiple of 10 ms, and you will not be able to present a stimulus for, say, 5 or 37 ms. The most common refresh rate is 60 Hz (= 16.67 ms refresh cycle), although monitors with much higher refresh rates are sometimes used for experimental systems.\n\nIn %VidRefresh you can see what a monitor refresh looks like in slow motion. On CRT monitors (i.e. non-flatscreen, center) the refresh is a single pixel that traces across the monitor from left to right and top to bottom. Therefore, only one pixel is lighted at a time, which is why CRT monitors flicker slightly. On LCD or TFT monitors (flatscreen, left and right) the refresh is a 'flood fill' from top to bottom. Therefore, LCD and TFT monitors do not flicker. (Unless you present a flickering stimulus, of course.)\n\n%--\nvideo:\n id: VidRefresh\n source: vimeo\n videoid: 24216910\n width: 640\n height: 240\n caption: A slow-motion video of the refresh cycle on CRT (center) and LCD/ TFT monitors. Video courtesy of Jarik den Hartog and the VU University Amsterdam technical support staff.\n--%\n\nIf a new stimulus display is presented while the refresh cycle is halfway, you will observe 'tearing'. That is, the upper half of the monitor will show the old display, while the lower part will show the new display. This is generally considered undesirable, and therefore a new display should be presented at the exact moment that the refresh cycle starts from the top. This is called 'synchronization to the vertical refresh' or simply 'v-sync'. When v-sync is enabled, tearing is no longer visible, because the tear coincides with the upper edge of the monitor. However, v-sync does not change anything about the fact that a monitor does not refresh instantaneously and will therefore always, for some time, show both the old and the new display.\n\nAnother important concept is that of 'blocking on the vertical retrace' or the 'blocking flip'. Usually, when you send a command to show a new display, the computer will accept this command right away and put the to-be-shown display in a queue. However, the display may not actually appear on the monitor until some time later, typically until the start of the next refresh cycle (assuming that v-sync is enabled). Therefore, you don't know exactly when the display has appeared, because your timestamp reflects the moment that the display was queued, rather than the moment that it was presented. To get around this issue, you can use a so-called 'blocking flip'. This basically means that when you send a command to show a new display, the computer will freeze until the display actually appears. This allows you to get very accurate display timestamps, at the cost of a significant performance hit due to the computer being frozen for much of the time while it is waiting for a display to be shown. But for the purpose of experiments, a blocking flip is generally considered the optimal strategy.\n\nFinally, LCD monitors may suffer from 'input lag'. This means that there is an additional and sometimes variable delay between the moment that the computer 'thinks' that a display appears, and the moment that the display actually appears. This delay results from various forms of digital processing that are performed by the monitor, such as color correction or image smoothing. As far as I know, input lag is not something that can be resolved programmatically, and you should avoid monitors with significant input lag for time-critical experiments. \n\nFor a related discussion, see:\n\n- <http://docs.expyriment.org/Timing.html#visual>\n\n\n### Making the refresh deadline\n\nImagine that you arrive at a train station at 10:30. Your train leaves at 11:00, which gives you exactly 30 minutes to get a cup of coffee. However, if you have coffee for exactly 30 minutes, then you will arrive back at the platform just in time to see your train depart, and you will have to wait for the next train. Therefore, if you have 30 minutes waiting time, you should have a coffee for slightly less than 30 minutes, such as 25 minutes.\n\nThe situation is analogous when specifying intervals for visual-stimulus presentation. Let's say that you have a 100 Hz monitor (so 1 refresh every 10 ms) and want to present a target stimulus for 100 ms, followed by a mask. Your first inclination might be to specify an interval of 100 ms between the target and the mask, because that's after all what you want. However, specifying an interval of exactly 100 ms will likely cause the mask to 'miss the refresh deadline', and the mask will be presented only on the next refresh cycle, which is 10 ms later (assuming that v-sync is enabled). So if you specify an interval of 100 ms, you will in most cases end up with an interval of 110 ms!\n\nThe solution is simple: You should specify an interval that is slightly shorter than what you are aiming for, such as 95 ms. Don't worry about the interval being too short, because on a 100 Hz monitor the interval between two stimulus displays is necessarily a multiple of 10 ms. Therefore, 95 ms will become 100 ms (10 frames), 1 ms will become 10 ms (1 frame), etc. Phrased differently, intervals will be rounded up (and never rounded down!) to the nearest interval that is consistent with your monitor's refresh rate.\n\n\n### Disabling desktop effects\n\nMany modern operating systems make use of graphical desktop effects. These provide, for example, the transparency effects and the smooth window minimization and maximization effects that you see on most modern operating systems. Although the software that underlies these effects differs from system to system, they generally form an additional layer between your application and the display. This additional layer may prevent OpenSesame from synchronizing to the vertical refresh and/ or from implementing a blocking flip.\n\nAlthough desktop effects *may* cause problems, they usually don't. This appears to vary from system to system and from video card to video card. Nevertheless, when the operating systems allows it, it's best to disable desktop effects on systems that are used for experimental testing.\n\nSome tips regarding desktop effects for the various operating systems:\n\n- Under *Windows XP* there are no desktop effects at all.\n- Under *Windows 7* desktop effects can be disabled by selecting any of the themes listed under 'Basic and High Contrast Themes' in the 'Personalization' section.\n- Under *Windows 10* there is no way to completely disable desktop effects.\n- Under *Ubuntu and other Linux distributions using Gnome 3* there is no way to completely disable desktop effects.\n- Under *Linux distributions using KDE* you can disable desktop effects in the 'Desktop Effects' section of the System Settings.\n- Under *Mac OS* there is apparently no way to completely disable desktop effects.\n\n\n### Taking into account stimulus-preparation time/ the prepare-run structure\n\nIf you care about accurate timing during visual-stimulus presentation, you should prepare your stimuli in advance. That way, you will not get any unpredictable delays due to stimulus preparation during the time-critical parts of your experiment.\n\nLet's first consider a script (you can paste this into an INLINE_SCRIPT item) that includes stimulus-preparation time in the interval between `canvas1` and `canvas2` (%LstStimPrepBad). The interval that is specified is 95 ms, so--taking into account the 'rounding up' rule described in [Making the refresh deadline]--you would expect an interval of 100 ms on my 60 Hz monitor. However, on my test system the script below results in an interval of 150 ms, which corresponds to 9 frames on a 60 Hz monitor. This is an unexpected delay of 50 ms, or 3 frames, due to the preparation of `canvas2`.\n\n%--\ncode:\n id: LstStimPrepBad\n syntax: python\n source: stimulus-preparation-bad.py\n caption: \"In this script, the duration between `canvas1` and `canvas2` is confounded by stimulus-preparation time.\"\n--%\n\nNow let's consider a simple variation of the script above (%LstStimPrepGood). This time, we first prepare both `canvas1` and `canvas2` and only afterwards present them. On my test system, this results in a consistent 100 ms interval, just as it should!\n\n%--\ncode:\n id: LstStimPrepGood\n syntax: python\n source: stimulus-preparation-good.py\n caption: \"In this script, the duration between `canvas1` and `canvas2` is not confounded by stimulus-preparation time.\"\n--%\n\nWhen using the graphical interface, the same considerations apply, but OpenSesame helps you by automatically handling most of the stimulus preparation in advance. However, you have to take into account that this preparation occurs at the level of SEQUENCE items, and not at the level of LOOP items. Practically speaking, this means that the timing *within* a SEQUENCE is not confounded by stimulus-preparation time. But the timing *between* SEQUENCEs is.\n\nTo make this more concrete, let's consider the structure shown below (%FigStimPrepBad). Suppose that the duration of the SKETCHPAD item is set to 95 ms, thus aiming for a 100 ms duration, or 6 frames on a 60 Hz monitor. On my test system the actual duration is 133 ms, or 8 frames, because the timing is confounded by preparation of the SKETCHPAD item, which occurs each time that that the sequence is executed. So this is an example of how you should *not* implement time-critical parts of your experiment.\n\n%--\nfigure:\n id: FigStimPrepBad\n source: stimulus-preparation-incorrect.png\n caption: \"An example of an experimental structure in which the timing between successive presentations of SKETCHPAD is confounded by stimulus-preparation time. The sequence of events in this case is as follows: prepare SKETCHPAD (2 frames), show SKETCHPAD (6 frames), prepare SKETCHPAD (2 frames), show SKETCHPAD (6 frames), etc.\"\n--%\n\nNow let's consider the structure shown below (%FigStimPrepGood). Suppose that the duration of `sketchpad1` is set to 95 ms, thus aiming for a 100 ms interval between `sketchpad1` and `sketchpad2`. In this case, both items are shown as part of the same SEQUENCE and the timing will not be confounded by stimulus-preparation time. On my test system the actual interval between `sketchpad1` and `sketchpad2` is therefore indeed 100 ms, or 6 frames on a 60 Hz monitor.\n\nNote that this only applies to the interval between `sketchpad1` and `sketchpad2`, because they are executed in that order as part of the same sequence. The interval between `sketchpad2` on run *i* and `sketchpad1` on run *i+1* is again confounded by stimulus-preparation time.\n\n%--\nfigure:\n id: FigStimPrepGood\n source: stimulus-preparation-correct.png\n caption: \"An example of an experimental structure in which the timing between the presentation of `sketchpad1` and `sketchpad2` is not confounded by stimulus-preparation time. The sequence of events in this case is as follows: prepare `sketchpad1` (2 frames), prepare `sketchpad2` (2 frames), show `sketchpad1` (6 frames), show `sketchpad2` (6 frames), prepare `sketchpad1` (2 frames), prepare `sketchpad2` (2 frames), show `sketchpad1` (6 frames), show `sketchpad2` (6 frames), etc.\"\n--%\n\nFor more information, see:\n\n- [usage/prepare-run]\n\n### Differences between backends\n\nOpenSesame is not tied to one specific way of controlling the display, system timer, etc. Therefore, OpenSesame *per se* does not have specific timing properties, because these depend on the backend that is used. The performance characteristics of the various backends are not perfectly correlated: It is possible that on some system the [psycho] backend works best, whereas on another system the [xpyriment] backend works best. Therefore, one of the great things about OpenSesame is that you can choose which backend works best for you!\n\nIn general, the [xpyriment] and [psycho] backends are preferable for time-critical experiments, because they use a blocking flip. On the other hand, the [legacy] backend is slightly more stable and also considerably faster when using [forms].\n\nUnder normal circumstances the three current OpenSesame backends have the properties shown in %TblBackendInfo.\n\n%--\ntable:\n id: TblBackendInfo\n source: backend-info.csv\n caption: backend properties.\n--%\n\nSee also:\n\n- [backends]\n\n## Benchmark results and tips for testing your own system\n\n### Checking whether v-sync is enabled\n\nAs described in [Understanding your monitor], the presentation of a new display should ideally coincide with the start of a new refresh cycle (i.e. 'v-sync'). You can test whether this is the case by presenting displays of different colors in rapid alternation. If v-sync is not enabled you will clearly observe horizontal lines running across the monitor (i.e. 'tearing'). To perform this test, run an experiment with the following script in an INLINE_SCRIPT item (%LstVSync):\n\n%--\ncode:\n id: LstVSync\n syntax: python\n source: v-sync-check.py\n caption: A script that presents yellow and blue displays in rapid alternation. A lack of synchronization with the vertical refresh can be observed as horizontal lines running through the monitor.\n--%\n\n### Testing precision and accuracy of timing\n\nTiming is precise or consistent when you can present visual stimuli over and over again with the same timing. Timestamps are accurate when they accurately reflect when visual stimuli appear on the monitor. The script below shows how you can check precision and accuracy of timing. This test can be performed both with and without an external photodiode, although the use of a photodiode provides extra verification.\n\nTo keep things simple, let's assume that your monitor is running at 100 Hz, which means that a single frame takes 10 ms. The script then presents a white canvas for 1 frame (10 ms). Next, the script presents a black canvas for 9 frames (90 ms). Note that we have specified a duration of 85, which is rounded up as explained under [Making the refresh deadline]. Therefore, we expect that the interval between the onsets of two consecutive white displays will be 10 frames or 100 ms (= 10 ms + 90 ms).\n\nWe can use two ways to verify whether the interval between two white displays is indeed 100 ms:\n\n1. Using the timestamps reported by OpenSesame. This is the easiest way and is generally accurate when the backend uses a blocking flip.\n2. Using a photodiode that responds to the onsets of the white displays and logs the timestamps of these onsets to an external computer. This is the best way to verify the timing, because it does not rely on introspection of the software. Certain issues, such as TFT input lag, discussed above, will come out only using external photodiode measurement.\n\n%--\ncode:\n id: LstIntervalBenchmark\n syntax: python\n source: interval-benchmark.py\n caption: A Python script to test the timing consistency and accuracy of display timestamps. You can paste this code into an INLINE_SCRIPT item.\n--%\n\nI ran %LstIntervalBenchmark on Windows XP, using all three backends. I also recorded the onsets of the white displays using a photodiode connected to a second computer. The results are summarized in %TblBenchmarkResults.\n\n%--\ntable:\n id: TblBenchmarkResults\n source: benchmark-results.csv\n caption: Benchmark results for %LstIntervalBenchmark. Tested with Windows XP, HP Compaq dc7900, Intel Core 2 Quad Q9400 @ 2.66Ghz, 3GB, 21\" ViewSonic P227f CRT. Each test was conducted twice (i.e. two sessions). The column `Session` corresponds to different test runs. The column `Source` indicates whether the measurements are from an external photiodiode, or based on OpenSesame's internal timestamps.\n--%\n\nAs you can see, the [xpyriment] and [psycho] backends consistently show a 100 ms interval. This is good and just as we would expect. However, the [legacy] backend shows a 90 ms interval. This discrepancy is due to the fact that the [legacy] backend does not use a blocking flip (see [Understanding your monitor]), which leads to some unpredictability in display timing. Note also that there is close agreement between the timestamps as recorded by the external photodiode and the timestamps reported by OpenSesame. This agreement demonstrates that OpenSesame's timestamps are reliable, although, again, they are slightly less reliable for the [legacy] backend due to the lack of a blocking-flip.\n\n", "url": "https://osdoc.cogsci.nl/4.0/manual/timing", "title": "Timing"}
{"content": "# Timing\n\n## Expyriment benchmarks and test suite\n\nA very nice set of benchmarks is available on the Expyriment website. This information is applicable to OpenSesame experiments using the [xpyriment] backend.\n\n- <http://docs.expyriment.org/Timing.html>\n\nExpyriment includes a very useful test suite. You can launch this test suite by running the `test_suite.opensesame` example experiment, or by adding a simple INLINE_SCRIPT to your experiment with the following lines of code (%LstExpyrimentTestSuite):\n\n%--\ncode:\n id: LstExpyrimentTestSuite\n syntax: python\n source: expyriment-test-suite.py\n caption: A script to start the Expyriment test suite.\n--%\n\nFor more information, please visit:\n\n- <http://docs.expyriment.org/Testsuite.html>\n\n## PsychoPy benchmarks and timing-related information\n\nSome information about timing is available on the PsychoPy documentation site. This information is applicable to OpenSesame experiments using the [psycho] backend.\n\n- <http://www.psychopy.org/general/timing/timing.html>\n\n[psycho]: /backends/xpyriment/\n[xpyriment]: /backends/xpyriment/\n[legacy]: /backends/legacy/\n[miscellaneous/clock-drift]: /miscellaneous/clock-drift\n[usage/prepare-run]: /usage/prepare-run\n[backends]: /backends\n[forms]: /forms", "url": "https://osdoc.cogsci.nl/4.0/manual/timing", "title": "Timing"}
{"content": "# Backends\n\ntitle: Backends\n\nThe *backend* is the software layer that deals with input (keyboard input, mouse input, etc.) and output (display presentation, sound playback, etc.). There are many libraries that offer this type of functionality and OpenSesame could, in principle, use any one of them. For this reason, OpenSesame is backend-independent, in the sense that you can choose which backend should be used. Currently there are four backends: *legacy*, *psycho*, *xpyriment*, and *osweb*.\n\n[TOC]\n\n## Differences and some tips\n\nUsually, you won't notice which backend is used. The differences between backends are largely technical, and, as long as you use the graphical user interface, all backends work more ore less the same way. However, there are a few reasons to prefer one backend over another:\n\n- If you want to run the experiment in a browser, you need to select the *osweb* backend.\n- Backend differs in [temporal precision](%link:timing%).\n\t- Tip: If you care about millisecond temporal precision, use *xpyriment* or *psycho*.\n- Backends differ in how long stimulus preparation takes.\n\t- Tip: If [forms](%link:manual/forms/about%) are slow, use *legacy*.\n\t- Tip: If the intertrial interval is long (due to stimulus preparation), use *legacy*.\n- You can use backend-specific functionality when writing Python code.\n\t- Tip: If you want to use PsychoPy functionality, use *psycho*.\n\t- Tip: If you want to use Expyriment functionality, use *xpyriment*.\n\t- Tip: If you want to use PyGame functionality, use *legacy*.\n- Some backends are not available on all platforms.\n\n## Selecting a backend\n\nYou can select a backend in the general properties of the experiment (%FigSelect).\n\n%--\nfigure:\n id: FigSelect\n source: fig-select.png\n caption: \"Selecting a backend\"\n--%\n\nIf you view the general script (select \"Show script editor\"), you will see that there are actually six distinct backends: canvas, keyboard, mouse, sampler, color, and clock. The combobox-method automatically selects an appropriate, predefined combination of backends, but you could, in theory, mix and match.\n\nFor example, if you select the *xpyriment* backend, the following code will be generated:\n\n\tset sampler_backend legacy\n\tset mouse_backend xpyriment\n\tset keyboard_backend legacy\n\tset color_backend legacy\n\tset clock_backend legacy\n\tset canvas_backend xpyriment\n\n## xpyriment\n\nThe *xpyriment* backend is built on top of [Expyriment][], a library designed for creating psychology experiments. It is a light-weight hardware-accelerated backend with excellent timing properties. If you care about temporal precision, but do not plan on generating complex stimuli (i.e. Gabor patches, random-dot gratings, etc.) *xpyriment* is a good choice.\n\n### Using Expyriment directly\n\nYou can find extensive documentation on Expyriment at <http://www.expyriment.org/doc>. The following code snippet shows a line of text:\n\n~~~ .python\nfrom expyriment import stimuli\ntext = stimuli.TextLine('This is expyriment!')\ntext.present()\n~~~\n\n### Citation\n\nAlthough Expyriment is bundled with the binary distributions of OpenSesame, it is a separate project. When appropriate, please provide the following citation in addition to citing OpenSesame:\n\nKrause, F., & Lindemann, O. (in press). Expyriment: A Python library for cognitive and neuroscientific experiments. *Behavior Research Methods*.\n{: .reference}\n\n## psycho\n\nThe psycho backend is built on top of [PsychoPy][], a library designed for creating psychology experiments. It is hardware accelerated and provides high-level routines for creating complex visual stimuli (drifting gratings, etc.). If you care about timing and plan on creating complex stimuli, Psycho is a good choice.\n\n### Using PsychoPy directly\n\nYou can find extensive documentation on PsychoPy at <http://www.psychopy.org/>. When using PsychoPy in OpenSesame, it is important to know that the main window can be accessed as `self.experiment.window` or simply `win`. So the following code snippet draws a Gabor patch:\n\n~~~ .python\nfrom psychopy import visual\ngabor = visual.PatchStim(win, tex=\"sin\", size=256, mask=\"gauss\", sf=0.05, ori=45)\ngabor.draw()\nwin.flip()\n~~~\n\n### Tutorials\n\nA tutorial specifically for using PsychoPy from within OpenSesame:\n\n- <http://www.cogsci.nl/blog/tutorials/211-a-bit-about-patches-textures-and-masks-in-psychopy>\n\nAnd a more general PsychoPy tutorial:\n\n- <http://gestaltrevision.be/wiki/coding>\n\n### Citation\n\nAlthough PsychoPy is bundled with the binary distributions of OpenSesame, it is a separate project. When appropriate, please cite the following papers in addition to citing OpenSesame:\n\nPeirce, J. W. (2007). PsychoPy: Psychophysics software in Python. *Journal of Neuroscience Methods*, *162*(1-2), 8-13. doi:10.1016/j.jneumeth.2006.11.017\n{: .reference}\n\nPeirce, J. W. (2009). Generating stimuli for neuroscience using PsychoPy. *Frontiers in Neuroinformatics*, *2*(10). doi:10.3389/neuro.11.010.2008\n{: .reference}\n\n## legacy\n\nThe legacy backend is built on top of [PyGame][] in non-OpenGL mode. The downside of this is that there is no hardware acceleration, and the timing properties are not as good as that of the psycho or xpyriment backends. The upside is that PyGame is very easy to use, very reliable, and well supported on a wide range of platforms.\n\n### Mouse-cursor visibility\n\nOn some systems, the mouse cursor is not visible when using the *legacy* backend in fullscreen mode. You can work around this is the following ways:\n\n1. Open the *legacy* backend settings and set \"Double buffering\" to \"no\".\n\t- *Note:* This may disable v-sync, which can be important for time critical experiments, as discussed [here](%link:timing%).\n2. Open the *legacy* backend settings and set \"Custom cursor\" to \"yes\".\n3. Switch to another backend.\n\n### Using PyGame directly\n\nPyGame is well documented and you can find everything you need to know about using PyGame on <http://www.pygame.org/docs/>. Specific to OpenSesame is the fact that the display surface is stored as `self.experiment.window` or simply `win`. So the following code snippet, which you could paste into an INLINE_SCRIPT item, draws a red rectangle to the display:\n\n~~~ .python\nimport pygame # Import the PyGame module\npygame.draw.rect(self.experiment.window, pygame.Color(\"red\"),\n\t[20, 20, 100, 100]) # Draw a red rectangle. Not shown yet...\npygame.display.flip() # Update the display to show the red rectangle.\n~~~\n\n\n## osweb\n\nThe *osweb* backend is built on top of OSWeb and allows you run experiments in a browser. For more information, see:\n\n- %link:manual/osweb/workflow%", "url": "https://osdoc.cogsci.nl/4.0/manual/backends", "title": "Backends"}
{"content": "# The prepare-run strategy\n\ntitle: The prepare-run strategy\n\n[TOC]\n\n## About\n\nExperiments typically consist of short intervals ('trials') during which participants perceive stimuli and perform a task. Timing should be controlled during a trial, but some unpredictable variation in the duration of the interval between trials is acceptable. Therefore, a good strategy is to perform time-consuming tasks before a trial, and to keep the operations that are performed during a trial to a minimum.\n\nOpenSesame does this by calling each element from a SEQUENCE item twice. This is the *prepare-run strategy*:\n\n- During the Prepare phase, items are given the opportunity to prepare. For example, a SYNTH generates a sound (but doesn't play it); and a SKETCHPAD draws a canvas (but doesn't show it).\n- During the Run phase, items do as a little as possible. For example, a SYNTH plays back a previously prepared sound; and a SKETCHPAD shows a previously prepared canvas.\n\nThis reduces the risk of timing glitches. The prepare-run strategy is implemented at the level of SEQUENCE items, which typically contains the time-critical parts of an experiment. This means that before a SEQUENCE is started, there is some unpredictable temporal jitter.\n\n## Item-specific notes\n\n### loop items\n\nA LOOP item is not prepared in advance. It is important to take this into account when using a LOOP to implement time-critical parts. For example, you may be tempted to implement an RSVP stream using a LOOP item as follows:\n\n~~~text\nrsvp_loop item (4 cycles)\n- stimulus_item\n~~~\n\nIn this construction, *stimulus_item* will be prepared and run four times in alternation, like so:\n\n~~~text\nprepare stimulus_item\nrun stimulus_item\nprepare stimulus_item\nrun stimulus_item\nprepare stimulus_item\nrun stimulus_item\nprepare stimulus_item\nrun stimulus_item\n~~~\n\nTherefore, you need to verify that the preparation of *stimulus_item* does not cause any timing glitches.\n\n### sequence items\n\nAll items that are part of a SEQUENCE are prepared in advance. Therefore, the following construction ...\n\n~~~text\ntrial_sequence\n- fixation_sketchpad\n- target_sketchpad\n- keyboard_response\n- logger\n~~~\n\n... will be executed as follows ...\n\n~~~text\nprepare fixation_sketchpad\nprepare target_sketchpad\nprepare keyboard_response\nprepare logger\nrun fixation_sketchpad\nrun target_sketchpad\nrun keyboard_response\nrun logger\n~~~\n\n### sketchpad and feedback items\n\nSKETCHPAD and FEEDBACK items differ in when they are prepared. For SKETCHPADs preparation occurs during the Prepare phase; for FEEDBACK items, preparation occurs only during the Run phase.\n\nFor more information, see:\n\n- %link:manual/stimuli/visual%\n\n### synth and sampler items\n\nFor SYNTH and SAMPLER items, the sound is generated and preloaded during the Prepare phase.\n\n### inline_script items\n\nIn an INLINE_SCRIPT item, you can choose how you want to implement the run and prepare strategy. In general, it is good practice to adhere to the following guidelines:\n\n- Time-consuming, preparatory functionality goes in the Prepare phase. For example, creating canvas objects, and generating sounds.\n- A minimum amount of code is put in the run phase. For example, only showing a previously prepared canvas.\n\n### Other items and plugins\n\nIn general, items should follow the principle of performing as much as possible time-consuming preparation during the Prepare phase, and minimizing the Run phase. However, every plugin is implemented differently. If you are unsure about a specific case, please post a query on the forum.\n\n## Conditional expressions (run if, show if, break if, etc)\n\nIn SEQUENCE items, the 'Run if' condition is evaluated at the last moment, during the run phase. Therefore, you can use a condition like `correct == 0` which depends on the results of a KEYBOARD_RESPONSE item which has been called just before. It is important to take into account that the 'Run if' expression applies *only* to the run phase of an item\u2014The prepare phase is *always* executed.\n\nIn COROUTINES items, the 'Run if' condition is evaluated during the Prepare phase. Therefore, the conditions cannot depend on events that occur during the execution of the COROUTINES.\n\nIn SKETCHPAD items, the 'Show if' condition is evaluated during the Prepare phase, when the canvas is constructed. In FEEDBACK items, the 'Show if' condition is evaluated during the Run phase (because the canvas is only constructed in the Run phase).", "url": "https://osdoc.cogsci.nl/4.0/manual/prepare-run", "title": "The prepare-run strategy"}
{"content": "# Oculus rift (virtual reality)\n\n---\nlayout: osdoc\ntitle: Oculus rift (virtual reality)\ngroup: Devices\npermalink: /oculus-rift/\n---\n\n<iframe src=\"http://wl.figshare.com/articles/1394986/embed?show_title=1\" width=\"640\" height=\"861\" frameborder=\"0\"></iframe>\n\nHern\u00e1ndez-Sande, A., Lorca, J. A. (2015): OpenSesame: An example of stimulus presentation in Virtual Reality headsets (Oculus Rift DK1). *Figshare*. doi:10.6084/m9.figshare.1394986", "url": "https://osdoc.cogsci.nl/4.0/manual/devices/oculusrift", "title": "Oculus rift (virtual reality)"}
{"content": "# Ambulatory Monitoring System (VU-AMS)\n\ntitle: Ambulatory Monitoring System (VU-AMS)\n\nVU-AMS is a third-party plugin, and is not maintained by the OpenSesame team.\n{: .alert .alert-info}\n\n\nThe VU University Ambulatory Monitoring System (VU-AMS) is a device that can be used to measure a variety of factors related to heart rate, respiration, and body movement. The developers offer an OpenSesame template on their website.\n\nFor more information, see:\n\n- <http://www.vu-ams.nl> (product website)\n- <http://www.vu-ams.nl/support/downloads/extras/> (OpenSesame template)", "url": "https://osdoc.cogsci.nl/4.0/manual/devices/vuams", "title": "Ambulatory Monitoring System (VU-AMS)"}
{"content": "# StimSync\n\ntitle: StimSync\n\nStimSync is an open-source open-hardware device for handling input (e.g., button presses) and output (e.g., triggers) in psychological and neuroscientific experiments. StimSync offers examples for use with OpenSesame.\n\nFor more information, see:\n\n- <http://www.mccauslandcenter.sc.edu/crnl/stimsync-0>", "url": "https://osdoc.cogsci.nl/4.0/manual/devices/stimsync", "title": "StimSync"}
{"content": "# Serial port\n\ntitle: Serial port\n\nPySerial is an easy to use Python library for serial port communications, which is bundled with all OpenSesame packages. For more information, see:\n\n- <http://pyserial.sourceforge.net/>", "url": "https://osdoc.cogsci.nl/4.0/manual/devices/serial", "title": "Serial port"}
{"content": "# Parallel port (EEG triggers)\n\ntitle: Parallel port (EEG triggers)\nreviewed: false\n\nIn EEG/ ERP studies it is common to send triggers to mark the timestamp for significant events (e.g., the onset of a trial, presentation of a particular stimulus, etc.). Triggers are typically bytes that are sent via the parallel port to the EEG apparatus.\n\n[TOC]\n\n\n## Using the `parallel_port_trigger` plugin\n\nParallel_port_trigger is a third-party plugin and not maintained by the OpenSesame team.\n{: .page-notification}\n\nAn OpenSesame plug-in for sending stimulus synchronization triggers through the parallel port to data acquisition systems.\n\n- <https://github.com/dev-jam/opensesame-plugin-parallel_port_trigger/>\n\nYou can install the `parallel_port_trigger` plugin from PyPi:\n\n```\npip install pip install opensesame-plugin-parallel-port-trigger\n```\n\n\n## Using `dportio.dll` in a Python inline Script (Windows only)\n\nInstead of using the `parallel_port_trigger` plugin, it is also possible to send triggers with `dlportio.dll` through a Python inline script. This approach is Windows only. To do so, first add an INLINE_SCRIPT to the start of the experiment with the following code in the prepare phase:\n\n~~~ .python\ntry:\n\tfrom ctypes import windll\n\tglobal io\n\tio = windll.dlportio # requires dlportio.dll !!!\nexcept:\n\tprint('The parallel port couldn\\'t be opened')\n~~~\n\nThis will load `dlportio.dll` as a global object called `io`. Please note that failure will not crash the experiment, so make sure to check the debug window for error messages!\n\nNow use the following code in an INLINE_SCRIPT anywhere in the experiment to send a trigger:\n\n~~~ .python\nglobal io\ntrigger = 1\nport = 0x378\ntry:\n\tio.DlPortWritePortUchar(port, trigger)\nexcept:\n\tprint('Failed to send trigger!')\n~~~\n\nNote that this sends trigger 1 to port 0x378 (=888). Change these values according to your set-up.\n\n## Getting access to the parallel port\n\n### Linux\n\nIn Linux we use the `parport_pc` module (tested in Debian Wheezy) and we need to provide ourselves with permissions to do so. We can accomplish this by executing the following commands:\n\n\tsudo rmmod lp\n\tsudo rmmod parport_pc\n\tsudo modprobe parport_pc\n\tsudo adduser [user] lp\n\nHere, `[user]` should be replaced by your username. Next, logout and login, and you are ready to go!\n\n### Windows XP and Windows Vista (32 bit)\n\n1. Download the 32-bit DLPortIO driver from [here][win32-dll] and uncompress the zip archive.\n2. Go to `DriverLINX/drivers` folder and copy `dlportio.dll` and `dlportio.sys` to the `install` folder. This is the folder  where `install.exe` is located. Then run `install.exe`\n3. You need to copy `dlportio.dll` to the OpenSesame folder (that is, the same folder that contains `opensesame.exe`).\n\n### Windows 7 (32 and 64 bit)\n\n1. Download the 32-bit or 64bit DLPortIO driver [here][win7-dll] and uncompress the zip archive.\n2. As Windows 7 has a strengthened security system (at least compared to XP) one cannot simply install the DLPortIO driver. This won't work as Windows 7 will block all attempts of installing a not-officially-signed (by Microsoft) driver. Good for the security of an average user -- bad for us. To bypass this restriction one has to use a little helper program called \"Digital Signature Enforcement Overrider\" (DSEO) which can be downloaded [here][dseo] (of course there are other possible ways to do this but this program is mentioned in the DLPortIO `readme.txt` and one does not have to dive deeper into MS Windows 7 architecture specialities).\n3. Start DSEO with administrator privileges (right click on `dseo13b.exe`, select \"run as administrator\"). Now the DSEO window pops up. It just presents a list of options which operation to run next.\n4. Choose the option \"sign driver/sys-file\" and press ok. Now another window appears where you have to type in the absolute path to the `DLPortIO.sys` file (only this one, not the dll!). Remember to escape spaces in the path if you have any (don't ask how long that took me) otherwise your files will not be found. Pressing ok will sign the sys-file.\n5. Back in the DSEO list choose \"enable test mode\" and press ok. Then choose \"exit\" and restart your PC. Windows 7 wrongly complains that DSEO might not be installed correctly -- just click on \"yes, the software is installed correctly\".\n6. After boot-up is completed you'll see that something like \"Windows 7 test mode built #number#\" is written on the desktop just above the clock in the starter-bar. That's necessary. You have to be in test mode to run this unofficially signed driver.\n7. Now run `DLPortIO_install.bat` with administrator privileges (in Windows Explorer, right click the file, ...). Answer \"yes\" if Windows warns you about registry changes.\n8. Reboot.\n9. Copy `DLPortIO.dll` to the Opensesame folder, that is, the same folder that contains `opensesame.exe`.\n\nSource: [Forum post by Absurd][post-3]\n\n## Recommendations\n\n- Start your experiment with a 'zero' trigger to make sure all the pins are set to zero.\n- It's recommended to use the [psycho] or [xpyriment] backends instead of the [legacy] backend (using PyGame) for time-critical experiments. This is because [psycho] and [xpyriment] takes the refresh rate of the monitor into account when returning timestamps, whereas [legacy] does not. For more information, see [miscellaneous/timing].\n- Send the trigger code right after (instead of just before) the presentation of your stimulus (assuming that it's the stimulus onset you want to mark). By doing so you'll make sure that the time stamp is as accurately as possible and will not suffer from a small random jitter due to your monitor's refresh rate. [Source: lvanderlinden][post-2]\n\n## Troubleshooting\n\nThere are a number of relevant forum topics in which trigger-related problems are discussed (and, for the most, solved!).\n\n- A post about ghost triggers, i.e. unwanted triggers that are mysteriously registered by the EEG apparatus: [link][post-2]\n- A post with elaborate installation instructions for DLPortIO on Windows 7 ([Source: absurd][post-3]).\n\nPlease don't hesitate to post questions on the forum, or to let us know of your experiences (good or bad).\n\n[win32-dll]: http://files.cogsci.nl/misc/dlportio.zip\n[win7-dll]: http://real.kiev.ua/avreal/download/#DLPORTIO_TABLE\n[dseo]: http://www.ngohq.com/home.php?page=dseo\n[post-2]: http://forum.cogsci.nl/index.php?p=/discussion/comment/780#Comment_780\n[post-3]: http://forum.cogsci.nl/index.php?p=/discussion/comment/745#Comment_745\n[miscellaneous/timing]: /miscellaneous/timing\n[legacy]: /backends/legacy\n[xpyriment]: /backends/xpyriment\n[psycho]: /backends/psycho", "url": "https://osdoc.cogsci.nl/4.0/manual/devices/parallel", "title": "Parallel port (EEG triggers)"}
{"content": "# Emotiv EEG\n\n---\nlayout: osdoc\ntitle: Emotiv EEG\ngroup: Devices\npermalink: /emotiv/\n---\n\n[Emotiv](https://emotiv.com/) is a low-cost EEG headset. Dimitrios Adamos (Neuroinformatics.GRoup of the Aristotle University of Thessaloniki) has written a tutorial for using the Emotiv with OpenSesame:\n\n- <http://neuroinformatics.gr/node/37>\n\n%--\nfigure:\n source: emotiv.png\n id: FigEmotiv\n caption: Emotiv is a low-cost EEG headset.\n--%", "url": "https://osdoc.cogsci.nl/4.0/manual/devices/emotiv", "title": "Emotiv EEG"}
{"content": "# Using the form plugins\n\ntitle: Using the form plugins\n\nA number of commonly used forms are available as ready-made plugins. These allow you to use common forms, without any need for scripting.\n\n- FORM_CONSENT is a simple digital consent form (disclaimer: some journals may require *written* consent)\n- FORM_MULTIPLE_CHOICE allows you to present multiple choice questions\n- FORM_TEXT_DISPLAY is a simple text display that you can use to show instructions etc.\n- FORM_TEXT_INPUT is a simple text input display that allows you to ask a question and collect a multi-character response from the participant\n\nThe FORM_BASE plugin is special. It allows you to define custom forms using OpenSesame script, as described here:\n\n- %link:manual/forms/custom%\n\n%--\nfigure:\n id: FigFormPlugins\n source: form-plugins.png\n caption: The FORM plugins in the item toolbar.\n--%", "url": "https://osdoc.cogsci.nl/4.0/manual/forms/readymade", "title": "Using the form plugins"}
{"content": "# Form variables\n\ntitle: Form variables\n\n[TOC]\n\n## About form variables\n\nWhen you present a form with multiple `checkbox`es, you generally want to know which `checkbox` the user has checked. Similarly, when you present a form with two `button`s, you want to know which `button` the user has clicked. This information is available through variables that are automatically set when the user interacts with a form. You can specify yourself which response variables should be used. How this is done depends on how you have created your form.\n\n### In ready-made form plugins\n\nWhen you use one of the ready-made form plugins, such as FORM_TEXT_INPUT, you can specify the name of the response variable directly in the plugin controls.\n\n### In custom forms\n\nYou can use the `var` keyword to indicate which variable should be used. For example, the following OpenSesame script, which you can enter into a FORM_BASE plugin, indicates that the response from a `text_input` widget should be stored in a variable called `my_response_var`:\n\n```python\nwidget 0 0 1 1 text_input var=my_response_var\n```\n\nThe equivalent Python code is:\n\n~~~ .python\nmy_widget = TextInput(var='my_response_var')\n~~~\n\nSee also:\n\n- %link:manual/forms/widgets%\n\n## Widget-specific information\n\nEach widget uses its response variable in a slightly different way.\n\n### button\n\nThe `button` widget sets the response variable to 'yes' if it has been clicked and to 'no' if it has not.\n\n### checkbox\n\nThe `checkbox` widget sets the response variable to a semicolon-separated list of the text on all checkboxes that have been checked (for that variable), or 'no' if no `checkbox` has been checked (for that variable). This sounds a bit complicated, so let's see a few examples.\n\n```python\nwidget 0 0 1 1 checkbox group=\"1\" text=\"A\" var=\"my_response_var\"\nwidget 1 0 1 1 checkbox group=\"1\" text=\"B\" var=\"my_response_var\"\nwidget 1 1 1 1 button text=\"Next\"\n```\n\nHere there are two `checkbox`es with the text 'A' and 'B'. Both part of the same group, called '1'. Both have the same response variable, called `my_response_var`. If 'A' is checked, `my_response_var` will be 'A'. If 'B' is checked, `my_response_var` will be 'B'. If neither is checked, `my_response_var` will be 'no'. Note that only one `checkbox` in the same group can be checked, so `my_response_var` will *never* be 'A;B' in this example.\n\nNow let's consider the same script, with the sole difference that the two `checkbox`es are not part of a group:\n\n```python\nwidget 0 0 1 1 checkbox text=\"A\" var=\"my_response_var\"\nwidget 1 0 1 1 checkbox text=\"B\" var=\"my_response_var\"\nwidget 1 1 1 1 button text=\"Next\"\n```\n\nIn this case, the situation is much like described above, with the exception that both `checkbox`es can be checked at the same time, in which case `my_response_var` will be set to 'A;B'.\n\nYou cannot use the same response variable for `checkbox`es in different groups.\n\n### image\n\nVariables are not applicable to the `image` widget.\n\n### image_button\n\nThe `image_button` widget sets the response variable to 'yes' if it has been clicked and to 'no' if it has not.\n\n### label\n\nVariables are not applicable to the `label` widget.\n\n### rating_scale\n\nThe `rating_scale` widget sets the response variable to the number of the option that has been clicked, where '0' is the first option (zero-based indexing). If no option has been selected, the response variable is set to 'None'.\n\n### text_input\n\nThe `text_input` widget sets the response variable to the entered text.", "url": "https://osdoc.cogsci.nl/4.0/manual/forms/variables", "title": "Form variables"}
{"content": "# About forms\n\ntitle: About forms\n\nForms are simple interactive displays that can be used to implement questionnaires, instructions, text input displays, etc. You can use forms in four ways.\n\n- Use the form plugins, such as FORM_TEXT_INPUT, which offer ready-made forms. This is the easiest, but least flexible way of using forms. This works both on the desktop and in a browser.\n\t- %link:manual/forms/readymade%\n- Define custom forms using OpenSesame script and the form_base plugin. This offers considerable flexibility, and does not require any real programming skills. This only works on the desktop.\n\t- %link:manual/forms/custom%\n- Create custom forms using Python inline script. This offers the most flexibility, but requires some knowledge of Python programming. This only works on the desktop.\n\t- %link:manual/forms/custom%\n- Create custom forms using HTML code. This only works when running experiments in a browser with OSWeb.\n\t- %link:manual/forms/html%\n\n%--\nfigure:\n id: FigAbout\n source: about.png\n caption: An example form.\n--%", "url": "https://osdoc.cogsci.nl/4.0/manual/forms/about", "title": "About forms"}
{"content": "# Custom HTML forms\n\ntitle: Custom HTML forms\n\n\nThe INLINE_HTML item allows you to implement forms using custom HTML.\n\n- The `name` attribute of `input` tags corresponds to an experimental variable. Therefore, the text that is entered into the text input of Example 1 will be stored as the experimental variable `text_response`.\n- For `checkbox` and `radio` elements, you can use the `id` attribute to assign a specific value to the associated experimental variable.\n- You can use the `required` attribute to indicate that a form cannot be submitted before a field has been filled out.\n- The form is closed when the participant clicks on an input of type submit.\n- To include images from the file pool in a custom HTML form, first retrieve the URL to the file, assign it to an experimental variable, and then use this variable as the source for the `<img>` tag (see Example 3).\n\n\nExample 1:\n\nA very basic text input form:\n\n```html\n<input type='text' name='text_response'>\n<input type='submit' value='click here to continue'>\n```\n\nExample 2:\n\nA form with multiple radio buttons:\n\n```html\n<p>Please select your age:</p>\n<input type=\"radio\" id=\"age1\" name=\"age\" value=\"30\" required>\n<label for=\"age1\">0 - 30</label><br>\n<input type=\"radio\" id=\"age2\" name=\"age\" value=\"60\">\n<label for=\"age2\">31 - 60</label><br>  \n<input type=\"radio\" id=\"age3\" name=\"age\" value=\"100\">\n<label for=\"age3\">61 - 100</label><br><br>\n<input type=\"submit\" value=\"Submit\">\n```\n\nExample 3:\n\nYou can include variable references (except within `<script>` tags, where curly braces are simply interpreted as part of JavaScript code):\n\n```html\n<p>You age group is {age}</p>\n<input type='submit' value='ok'>\n```\n\nExample 4:\n\nYou can JavaScript through `<script>` tags. For example, you can get an image from the file pool and assign to an initially empty `<img>` tag like this:\n\n```html\n<img id='capybara'>\n<input type='submit' value='ok'>\n\n<script>\ndocument.getElementById('capybara').src = pool['capybara.png'].data.src\n</script>\n```", "url": "https://osdoc.cogsci.nl/4.0/manual/forms/html", "title": "Custom HTML forms"}
{"content": "# Form widgets and keywords\n\ntitle: Form widgets and keywords\n\n\n[TOC]\n\n\n## Screenshot\n\n%--\nfigure:\n id: FigWidgets\n source: widgets.png\n caption: A list of available FORM widgets.\n--%\n\n\n## Widgets and keywords\n\nAll keywords are optional, instead otherwise indicated.\n\n### Form\n\nThe `cols` and `rows` keywords can either be single `int` values, in which case they specify the number of equally sized columns and rows, or lists of `int`, in which case they specify the relative sizes of each column and row. For more information about form geometry, see:\n\n- %link:manual/forms/custom%\n\nThe `validator` keyword can be used to validate form input. For more information, see:\n\n- %link:manual/forms/validation%\n\n(In OpenSesame script, you do not need to explicitly create a form.)\n\nPython script:\n\n~~~ .python\nform = Form(\n    cols=2, rows=2, spacing=10, margins=(100, 100, 100, 100), theme='gray',\n    timeout=None, clicks=False, validator=None\n)\nbutton = Button(text='Ok!')\nform.set_widget(button, (0, 0))\nform._exec()\n~~~\n\n\n### button / Button\n\nOpenSesame script:\n\n~~~python\nwidget 0 0 1 1 button text=\"Click me!\" center=yes frame=yes var=response\n~~~\n\nPython script:\n\n~~~ .python\nform = Form()\nbutton = Button(text='Click me!', frame=True, center=True, var='response')\nform.set_widget(button, (0, 0))\nform._exec()\n~~~\n\n\n### checkbox / Checkbox\n\nIf a group is specified, checking one checkbox from that group will uncheck all other checkboxes from that group. Checkboxes that are part of a group cannot be unchecked, except by clicking on another checkbox in that group.\n\nThe `group` keyword also affects how variables are stored, as described here:\n\n- %link:manual/forms/variables%\n\nOpenSesame script:\n\n~~~python\nwidget 0 0 1 1 checkbox group=group text=\"Option 1\"\nwidget 0 1 1 1 checkbox group=group text=\"Option 2\"\n~~~\n\nPython script:\n\n~~~ .python\nform = Form()\ncheckbox1 = Checkbox(text='Option 1', group='group')\ncheckbox2 = Checkbox(text='Option 2', group='group')\nform.set_widget(checkbox1, (0, 0))\nform.set_widget(checkbox2, (0, 1))\nform._exec()\n~~~\n\n\n### image / ImageWidget\n\nThe Python object is called `ImageWidget` to distinguish it from the `Image` canvas element.\n\nOpenSesame script:\n\n~~~python\n# Only path is a required keyword\nwidget 0 0 1 1 image path=\"my_image.png\" adjust=yes frame=no\n~~~\n\nPython script:\n\n~~~ .python\n# Only path is a required keyword\nform = Form()\nimage = ImageWidget(path=pool['my_image.png'], adjust=True, frame=False)\nform.set_widget(image, (0, 0))\nform._exec()\n~~~\n\n\n### image_button / ImageButton\n\nThe `image_id` keyword is used to identify the image button when it is clicked. If no `image_id` is provided, the path to the image is used as id.\n\nOpenSesame script:\n\n~~~python\n# Only path is a required keyword\nwidget 0 0 1 1 image_button path=\"my_image.png\" adjust=yes frame=no image_id=my_image var=response\n~~~\n\nPython script:\n\n~~~ .python\n# Only path is a required keyword\nform = Form()\nimage_button = ImageButton(\n    path=pool['my_image.png'], adjust=True, frame=False,\n    image_id='my_image', var='response'\n)\nform.set_widget(image_button, (0, 0))\nform._exec()\n~~~\n\n\n### label / Label\n\nOpenSesame script:\n\n~~~python\nwidget 0 0 1 1 label text=\"My text\" frame=no center=yes\n~~~\n\nPython script:\n\n~~~ .python\nform = Form()\nlabel = Label(text='My text', frame=False, center=True)\nform.set_widget(label, (0,0))\nform._exec()\n~~~\n\n\n### rating_scale / RatingScale\n\nThe `nodes` keyword can be an `int` or a semicolon-separated list of labels. If `nodes` is an `int`, it specified the number of (unlabeled) nodes.\n\nThe `default` keyword indicates which node number is selected by default, where the first node is 0.\n\nOpenSesame script:\n\n~~~python\nwidget 0 1 1 1 rating_scale var=response nodes=\"Agree;Don't know;Disagree\" click_accepts=no orientation=horizontal var=response default=0\n~~~\n\nPython script:\n\n~~~ .python\nform = Form()\nrating_scale = RatingScale(\n    nodes=['Agree', u\"Don't know\", 'Disagree'], click_accepts=False,\n    orientation='horizontal', var='response', default=0\n)\nform.set_widget(rating_scale, (0, 0))\nform._exec()\n~~~\n\n\n### text_input / TextInput\n\nThe `stub` keyword indicates placeholder text that is shown when no text has been entered. The `key_filter` keyword, available only in Python, specifies a function to filter key presses. This is described in more detail under:\n\n- %link:manual/forms/validation%\n\nOpenSesame script:\n\n~~~python\nwidget 0 0 1 1 text_input text=\"Initial text\" frame=yes center=no stub=\"Type here \u2026\" return_accepts=yes var=response\n~~~\n\nPython script:\n\n~~~ .python\nform = Form()\ntext_input = TextInput(\n    text='Initial text', frame=True, center=False, stub='Type here \u2026',\n    return_accepts=True, var='response', key_filter=my_filter_function\n)\nform.set_widget(text_input, (0, 0))\nform._exec()\n~~~", "url": "https://osdoc.cogsci.nl/4.0/manual/forms/widgets", "title": "Form widgets and keywords"}
{"content": "# Creating custom forms\n\ntitle: Creating custom forms\n\n\n[TOC]\n\n\n## About forms, geometries, and widgets\n\nA form is a set of widgets (buttons, labels, text-input fields, etc.) arranged into a grid with a particular geometry. In the image below you see an example of a 2 (columns) \u00d7 3 (rows) form. A form geometry is simple, and consists of the following properties:\n\n- *margins* ensure that the widgets do not touch the edge of the display. You can have different margins for the top, right, bottom, and left.\n- *spacing* ensure that the widgets do not touch each other. The horizontal and vertical spacing is the same.\n- There are one or more *rows*, possibly of different sizes.\n- There are one or more *columns*, possibly of different sizes.\n\n%--\nfigure:\n id: FigGeometry\n source: geometry.png\n caption: A schematic of FORM geometries.\n--%\n\nOf course, an empty form is no fun. So let's add the following widgets to create a simple question form:\n\n- A `label` that spans the two columns of the top row. We use this label to give a title to the form.\n- Another `label` that spans the two columns of the middle row. This label contains the actual question.\n- A `button` in the bottom right widget area. This button allows the user to give the $0.05 response.\n- Another `button` in the bottom left widget area. This button allows the user to give the $0.10 response.\n\n%--\nfigure:\n id: FigSchematicExample1\n source: schematic-example1.png\n caption: A schematic example FORM.\n--%\n\nThe images above are schematic examples. How this form actually looks in OpenSesame depends on your settings (notably your font and colors), but it may look something like this:\n\n%--\nfigure:\n id: FigExample1\n source: example1.png\n caption: A example FORM.\n--%\n\n## Creating custom forms\n\nThere are two ways to create custom forms. You can:\n\n- Use the FORM_BASE item, and specify your form using OpenSesame script.\n- Using Python in an INLINE_SCRIPT item. The Python way is slightly more flexible, but for most purposes both ways can be used.\n\n### Creating forms using OpenSesame script\n\nWe will create the form described above using OpenSesame script. First, drag the FORM_BASE plugin into your experiment. Click on the newly created item to open its tab. Next, click on the 'Edit script' button (with the terminal icon), in the top-right of the tab area. This will open the script editor. Enter the following script to generate the form described above (see the comments for explanations).\n\n~~~\n# Margins are defined as \"top;right;bottom;left\". Each value corresponds to a\n# margin in pixels.\nset margins \"50;100;50;100\"\n# The spacing is simply a value in pixels.\nset spacing \"25\"\n# The sizes of the rows are relative. \"1;2;1\" means that there are three rows,\n# where the middle one is twice as large as the bottom and top ones. So \"1;2;1\"\n# means exactly the same thing as \"3;6;3\". Please note that \"3\" does not mean\n# that there are three equally-sized rows (but \"1;1;1\" does).\nset rows \"1;2;1\"\n# Columns are defined in the same way. \"1;1\" simply means that there\n# are two columns of the same size.\nset cols \"1;1\"\n# Widgets are defined as follows:\n# widget [column] [row] [column span] [row span] [widget type] [keywords]\n#\n# The columns and rows start counting at 0. If you do not want to have your widget\n# span multiple columns and rows, you simply set the column and row span to 1.\nwidget 0 0 2 1 label text=\"Question\"\nwidget 0 1 2 1 label center=\"no\" text=\"A bat and a baseball together cost $1.10. The bat costs one dollar more than the ball. How much does the ball cost?\"\nwidget 0 2 1 1 button text=\"$0.10\"\nwidget 1 2 1 1 button text=\"$0.05\"\n~~~\n\nIf you want a specific widget to receive the focus when the form is executed, you can apply the `focus=yes` keyword to one of the widgets:\n\n```\nwidget 0 0 1 1 text_input text=\"Initial text\" frame=yes center=no stub=\"Type here \u2026\" return_accepts=yes var=response focus=yes\n```\n\n\n### Creating forms using Python inline script\n\nThe exact same form can be created using an INLINE_SCRIPT and a bit of Python code. You will notice that the Python code somewhat resembles the OpenSesame script shown above. This is no wonder: The FORM_BASE plugin essentially translates the OpenSesame script into Python code.\n\nFirst, drag an INLINE_SCRIPT into your experiment. Select the newly created item to open its tab, and add the following script into the Run phase of the INLINE_SCRIPT item (see the comments for explanations).\n\n~~~ .python\n# Create a form\nform = Form(\n    cols=[1,1], rows=[1,2,1],\n    margins=(50,100,50,100), spacing=25\n)\n# Create four widgets\nlabelTitle = Label(text='Question')\nlabelQuestion = Label(\n    text='A bat and a baseball together cost $1.10. The bat costs one dollar more than the ball. How much does the ball cost?',\n    center=False\n)\nbutton5cts = Button(text='$0.05')\nbutton10cts = Button(text='$0.10')\n# Add the widgets to the form. The position in the form is indicated as a\n# (column, row) tuple.\nform.set_widget(labelTitle, (0,0), colspan=2)\nform.set_widget(labelQuestion, (0,1), colspan=2)\nform.set_widget(button5cts, (0,2))\nform.set_widget(button10cts, (1,2))\n# Execute the form! In this case, the form will return the text of the button that\n# was clicked. This is one way to get a return value out of the form. Another way\n# is to use the 'var' keyword, supported some of the widgets.\nbutton_clicked = form._exec()\n~~~\n\nIf you want a specific widget to receive the focus when the form is executed, you can use the `focus_wiget` keyword:\n\n~~~ .python\nbutton_clicked = form._exec(focus_widget=button5cts)\n~~~\n\n### Non-interactive forms\n\nUsually, a form will have an input field, a button, or some other interactive element. However, you can also use forms without having any interactive element. To do this in OpenSesame script, you set `only_render` to \"yes\":\n\n```python\nset only_render yes\n```\n\nTo this in a Python INLINE_SCRIPT, you call `form.render()`, instead of `form._exec()`.\n\n### Themes\n\nForms support theming. Currently, two themes are available: 'gray' and 'plain'. The 'gray' theme is the default. Although the 'gray' theme is already quite plain, the 'plain' theme is even more basic. You can choose a theme like this in OpenSesame script:\n\n```python\nset theme plain\n```\n\nAnd by using the `theme` keyword in Python inline script:\n\n~~~ .python\nform = Form(theme='plain')\n~~~\n\n### Available widgets and keywords\n\nFor a list of available widgets and keywords, see:\n\n- %link:manual/forms/widgets%\n\n### Validating input\n\nTo see how you can validate form input, see:\n\n- %link:manual/forms/validation%\n\n## Another example\n\nThe following OpenSesame script (in a FORM_BASE plugin) will produce a questionnaire of three rating scales plus a next button:\n\n```python\nset rows \"1;1;1;1;1\"\nset cols \"1;1\"\nwidget 0 0 2 1 label text=\"Indicate how much you agree with the following statements\"\nwidget 0 1 1 1 label center=\"no\" text=\"Forms are easy\"\nwidget 1 1 1 1 rating_scale var=\"question1\" nodes=\"Agree;Don't know;Disagree\"\nwidget 0 2 1 1 label center=\"no\" text=\"I like data\"\nwidget 1 2 1 1 rating_scale var=\"question2\" nodes=\"Agree;Don't know;Disagree\"\nwidget 0 3 1 1 label center=\"no\" text=\"I like questionnaires\"\nwidget 1 3 1 1 rating_scale var=\"question3\" nodes=\"Agree;Don't know;Disagree\"\nwidget 0 4 2 1 button text=\"Next\"\n```\n\nThe following Python inline_script will produce the same questionnaire.\n\n~~~ .python\nform = Form(cols=[1,1], rows=[1,1,1,1,1])\ntitle = Label(\n    text='Indicate how much you agree with the following statement'\n)\nquestion1 = Label(text='Forms are easy', center=False)\nquestion2 = Label(text='I like data', center=False)\nquestion3 = Label(text='I like questionnaires', center=False)\nratingScale1 = RatingScale(\n    var='question1',\n    nodes=['Agree', u\"Don't know\", 'Disagree']\n)\nratingScale2 = RatingScale(\n    var='question2',\n    nodes=['Agree', u\"Don't know\", 'Disagree']\n)\nratingScale3 = RatingScale(var='question3',\n    nodes=['Agree', u\"Don't know\", 'Disagree'])\nnextButton = Button(text='Next')\nform.set_widget(title, (0, 0), colspan=2)\nform.set_widget(question1, (0, 1))\nform.set_widget(question2, (0, 2))\nform.set_widget(question3, (0, 3))\nform.set_widget(ratingScale1, (1, 1))\nform.set_widget(ratingScale2, (1, 2))\nform.set_widget(ratingScale3, (1, 3))\nform.set_widget(nextButton, (0, 4), colspan=2)\nform._exec()\n~~~\n\nThe resulting form looks something like this. (The exact appearance depends on your font, colors, etc.)\n\n%--\nfigure:\n id: FigExample2\n source: example2.png\n caption: Another example FORM.\n--%", "url": "https://osdoc.cogsci.nl/4.0/manual/forms/custom", "title": "Creating custom forms"}
{"content": "# Validating form input\n\ntitle: Validating form input\n\n\nTo validate a form, pass a function with the `validator` keyword to `Form()`. In the example below, `my_form_validator()` is used in this way. A validator function should not expect any arguments, and should return a `bool` to indicate whether or not the form validates. If the form does not validate, no error message is shown, but the form simply stays open.\n\nIn addition, you can validate (or filter) input to a `TextInput` widget to exclude certain characters as input. To do so, pass a function with the `key_filter` keyword to `TextInput()`. In the example below, `filter_digits()` is used in this way. A key-filter function should accept a single argument, which corresponds to a single key press, and should return a `bool` to indicate whether or not the key is accepted as input.\n\n~~~ .python\ndef my_form_validator():\n    \"\"\"Checks whether both the gender and age fields have been filled out\"\"\"\n    return gender != 'no' and age != ''\n\n\ndef filter_digits(ch):\n    \"\"\"Allows only digit characters as input\"\"\"\n    return ch in '0123456789'\n\n\n# Define all widgets\nbutton_ok = Button(text='Ok')\nlabel_gender= Label('Your gender')\ncheckbox_male = Checkbox(text='Male', group='gender', var='gender')\ncheckbox_female = Checkbox(text='Female', group='gender', var='gender')\nlabel_age = Label('Your age')\n# Specify a key filter so that only digits are accepted as text input\ninput_age = TextInput(stub='Age here \u2026', var='age', key_filter=filter_digits)\n# Build the form. Specify a validator function to make sure that the form is\n# completed.\nmy_form = Form(validator=my_form_validator, rows=[1,1,1], cols=[1,1,1])\nmy_form.set_widget(label_gender, (0, 0))\nmy_form.set_widget(checkbox_male, (1, 0))\nmy_form.set_widget(checkbox_female, (2, 0))\nmy_form.set_widget(label_age, (0, 1))\nmy_form.set_widget(input_age, (1, 1), colspan=2)\nmy_form.set_widget(button_ok, (1, 2))\nmy_form._exec()\n~~~", "url": "https://osdoc.cogsci.nl/4.0/manual/forms/validation", "title": "Validating form input"}
{"content": "# CSV functions (csv-parse)\n\ntitle: CSV functions (csv-parse)\n\nThe synchronous `parse()` function from the `csv-parse` library is available. This allows you to parse CSV-formatted text, for example from a CSV file in the file pool, into an Object.\n\n__Example:__\n\n```js\nconst conditions = csvParse(\n    pool['attentional-capture-jobs.csv'].data,\n    {columns: true}\n)\nfor (const trial of conditions) {\n    console.log(trial.distractor)\n}\n```\n\nFor an overview, see:\n\n- <https://csv.js.org/parse/api/sync/#sync-api>", "url": "https://osdoc.cogsci.nl/4.0/manual/javascript/csv", "title": "CSV functions (csv-parse)"}
{"content": "# Python-like iterators (pythonic)\n\ntitle: Python-like iterators (pythonic)\n\nThe `pythonic` library provides Python-like functions for iterating over arrays. Available functions are: `range()`, `enumerate()`, `items()`, `zip()`, and `zipLongest()`.\n\n__Example:__\n\nDraw a five by five grid of incrementing numbers:\n\n```js\nlet positions = xy_grid(5, 50)\nconst cnv = Canvas()\nfor (const [i, [x, y]] of enumerate(positions)) {\n    cnv.text({text: i, x: x, y: y})\n}\ncnv.show()\n```\n\nFor an overview, see:\n\n- <https://www.npmjs.com/package/pythonic>", "url": "https://osdoc.cogsci.nl/4.0/manual/javascript/pythonic", "title": "Python-like iterators (pythonic)"}
{"content": "# About JavaScript\n\ntitle: About JavaScript\n\nIn OpenSesame you can create complex experiments using only the graphical user interface (GUI). But you will sometimes encounter situations in which the functionality provided by the GUI is insufficient. In these cases you can add JavaScript code to your experiment.\n\nJavaScript is for experiments that run in a browser with OSWeb. If you need to run your experiment on the desktop, you need to use [Python](%url:manual/python/about%) instead of JavaScript.\n\n__Version note:__ Desktop support for JavaScript was removed in OpeSesame 4.0. This is because JavaScript support on the desktop was incomplete and was perceived by users as confusing without adding much benefit.\n{: .page-notification}\n\n[TOC]\n\n\n## Learning JavaScript\n\nThere are many JavaScript tutorials available online. One good resource is Code Academy:\n\n- <https://www.codecademy.com/learn/introduction-to-javascript>\n\n\n## JavaScript in the OpenSesame GUI\n\n\n### Inline_javascript items\n\nIn order to use JavaScript code you need to add an INLINE_JAVASCRIPT item to your experiment. After you have done this you will see something like %FigInlineJavaScript.\n\n%--\nfigure:\n id: FigInlineJavaScript\n source: inline-javascript.png\n caption: The INLINE_JAVASCRIPT item.\n--%\n\nAs you can see, the INLINE_JAVASCRIPT item consists of two tabs: one for the Prepare phase and one for the Run phase. The Prepare phase is executed first, to allow items to prepare for the time-critical run phase. It is good practice to construct `Canvas` objects during the Prepare phase, so that they can be presented without delay during the Run phase. But this is only convention; you can execute arbitrary JavaScript code during both phases.\n\nFor more information about the prepare-run strategy, see:\n\n- %link:prepare-run%\n\n\n### Printing output to the console\n\nYou can print to the console with the `console.log()` command:\n\n```js\nconsole.log('This will appear in the console!')\n```\n\nWhen running on the desktop, the output will appear in the OpenSesame console (or: debug window). When running in a browser, the output will appear in the browser console.\n\n\n## Things to know\n\n### Common functions\n\nMany common functions are directly available in an INLINE_JAVASCRIPT item. For example:\n\n```js\n// `Canvas()` is a factory function that returns a `Canvas` object\nlet fixdotCanvas = Canvas()\nif (sometimes()) {  // Sometimes the fixdot is green\n    fixdotCanvas.fixdot({color: 'green'})\n} else {  // Sometimes it is red\n    fixdotCanvas.fixdot({color: 'red'})\n}\nfixdotCanvas.show()\n```\n\nFor a list of common functions, see:\n\n- %link:manual/javascript/common%\n\n\n### Declaring variables (let and var)\n\nINLINE_JAVASCRIPT items are executed in non-strict (or: sloppy) mode. This means that you can assign a value to a variable that was not explicitly declared. When you do this, the variable is implicitly declared using `var` if it wasn't already declared.\n\n```js\nmy_variable = 'my value'  // implicitly declared using var\n```\n\nVariables that are declared implicitly or explicitly using `var` are global, which primarily means that they may be logged by a LOGGER. Variables that are declared using `let` are not global, which primarily means that they are not logged by a LOGGER.\n\n```js\nthis_is_a_global_variable = 'my value'\nvar this_is_also_a_global_variable = 'my value'\nlet this_is_not_a_global_variable = 'my value'\n```\n\n\n### The `persistent` object: preserving objects across scripts\n\n__Version note__ As of OSWeb 2.0, all JavaScript code is executed in the same workspace and objects are therefore preserved across scripts. This means that you no longer need the `persistent` object.\n{:.page-notification}\n\nEach INLINE_JAVASCRIPT item is executed in its own workspace. This means\u2014and this is different from Python INLINE_SCRIPT items!\u2014that you cannot use variables or functions that you've declared in one script in another script. As a workaround, you can attach variables or functions as properties to the `persistent` object, which serves as a container of things that you want to preserve across scripts.\n\nThis way you can construct a `Canvas` in one INLINE_JAVASCRIPT ...\n\n```js\npersistent.myCanvas = Canvas()\npersistent.myCanvas.fixdot()\n```\n\n.. and show it in another INLINE_JAVASCRIPT:\n\n```js\npersistent.myCanvas.show()\n```\n\n\n### The `vars` object: Access to experimental variables\n\n__Version note__ As of OSWeb 2.0, all experimental variables are available as globals. This means that you no longer need the `vars` object.\n{:.page-notification}\n\nYou can access experimental variables through the `vars` object:\n\n```js\n// OSWeb <= 1.4 (with vars object)\n// Get an experimental variable\nconsole.log('my_variable is: ' + vars.my_variable)\n// Set an experimental variable\nvars.my_variable = 'my_value'\n\n// OSWeb >= 2.0 (without vars object)\n// Get an experimental variable\nconsole.log('my_variable is: ' + my_variable)\n// Set an experimental variable\nmy_variable = 'my_value'\n```\n\n\n### The `pool` object: Access to the file pool\n\nYou access 'files' from the file pool through the `pool` object. The most obvious use of this is to parse CSV files, for example with experimental conditions, from the file pool using the `csv-parse` library (described in more detail below).\n\n```js\nconst conditions = csvParse(\n    pool['attentional-capture-jobs.csv'].data,\n    {columns: true}\n)\nfor (const trial of conditions) {\n    console.log(trial.distractor)\n}\n```\n\nYou can also play sound files from the file pool directly. Assuming that there is a file called `bark.ogg` in the file pool, you can play it like so:\n\n```js\npool['bark.ogg'].data.play()\n```\n\n\n### The `Canvas` class: Presenting visual stimuli\n\nThe `Canvas` class is used to present visual stimuli. For example, you can show a fixation dot as follows:\n\n```js\nlet myCanvas = Canvas()\nmyCanvas.fixdot()\nmyCanvas.show()\n```\n\nA full overview of the `Canvas` class can be found here:\n\n- %link:manual/javascript/canvas%\n\n## Available JavaScript libraries\n\nThe following JavaScript libraries are included by default:\n\n- [random functions (`random-ext`)](%url:manual/javascript/random%)\n- [Color-conversion functions (`color-convert`)](%url:manual/javascript/color-convert%)\n- [CSV functions (`csv-parse`)](%url:manual/javascript/csv%)\n- [Python-like iterators (`pythonic`)](%url:manual/javascript/pythonic%)\n\nYou can include additional JavaScript libraries by URLs to the libraries in the 'External JavaScript' libraries field of the OSWeb control panel.\n\n\n## Debugging\n\nSee:\n\n- %link:debugging%", "url": "https://osdoc.cogsci.nl/4.0/manual/javascript/about", "title": "About JavaScript"}
{"content": "# Common functions\n\nThe provided API is a JavaScript API designed for use with OpenSesame, a software platform widely used for creating and conducting psychology experiments. This API consists of a suite of functions that can be employed within OpenSesame to add interactivity, collect data, and manipulate the experiment environment programmatically.\n\nThis API is particularly relevant for users who wish to enhance their psychology experiments with custom scripts and functionalities. It is designed to be used in conjunction with `Canvas` functions, which are part of OpenSesame's feature set for drawing stimuli and interfacing with the participant's visual input.\n\nUnfortunately, the actual list of functions and their parameters is not provided in the snippet above. The snippet indicates that there is a markdown document (likely containing the API documentation) included within the text, but the contents of this document are not directly visible. Normally, one would expect to see a bulleted list of functions here, each with a brief description of its purpose and the parameters it accepts.\n\nTo summarize, the API provides:\n\n- A set of JavaScript functions tailored for use in OpenSesame.\n- Capabilities that complement `Canvas` functions for visual stimuli presentation.\n- Tools to enhance the interactivity and data collection capabilities of psychology experiments.\n\nTo fully understand the API's capabilities, access to the included markdown document (javascript_workspace_api.md) would be necessary. That document would contain the specific details about each function, including their names, parameters, and descriptions of what they do.", "url": "https://osdoc.cogsci.nl/4.0/manual/javascript/common", "title": "Common functions"}
{"content": "# Common functions\n\ntitle: Common functions\n\n<summary_prompt>\nWrite a summary for the API below:\n\n- Describe the API's overall functionality\n- Explain that this is a JavaScript API for OpenSesame, software for implementing psychology experiments\n- Explain that these functions are commonly used in combination with `Canvas` functions\n- Provide a bulleted list of all available functions and their parameters. Don't just name the functions, but create one bullet per function.\n\nYour response should be a comprehensive summary.\n\n```markdown\n{content}\n```\n</summary_prompt>\n\n[TOC]\n\n\nThe following functions are available in INLINE_JAVASCRIPT items:\n\n<div class=\"cogsci-jsdoc\" markdown=\"1\">\n\n%-- include: include/javascript-api/javascript_workspace_api.md --%\n\n</div>", "url": "https://osdoc.cogsci.nl/4.0/manual/javascript/common", "title": "Common functions"}
{"content": "# random functions (random-ext)\n\ntitle: random functions (random-ext)\n\n\nThe `random-ext` library is available as `random`. This library provides many convenient, higher-level functions for randomization.\n\n__Example:__\n\nDraw eight circle with a random color and a location that is randomly sampled from a five by five grid:\n\n```js\nlet positions = xy_grid(5, 50)\npositions = random.subArray(positions, 8)\nconst cnv = Canvas()\ncnv.fixdot()\nfor (const [x, y] of positions) {\n    cnv.circle({x: x, y: y, r: 20, fill: true, color: random.color()})\n}\ncnv.show()\n```\n\nFor an overview, see:\n\n- <https://www.npmjs.com/package/random-ext>", "url": "https://osdoc.cogsci.nl/4.0/manual/javascript/random", "title": "random functions (random-ext)"}
{"content": "# Canvas functions\n\nThe API described is a JavaScript-based Application Programming Interface (API) designed specifically for OpenSesame, which is a software platform used for conducting psychological experiments. The overall functionality of this API centers around providing a means for experiment designers to create, manipulate, and display visual content on a digital canvas as part of their experimental setups.\n\nTo utilize this API for visual experiments, one must first initialize a `Canvas` object. Initializing a `Canvas` typically involves specifying its dimensions and optionally, the initial content that should be displayed. The canvas acts as a drawing surface where visual elements can be added or modified.\n\nThe `styleArgs` parameter is used to define the styling of the canvas and its elements. This could include details such as color, font, line thickness, and more. By setting `styleArgs`, users can customize the appearance of text, shapes, and other graphical elements to match their experimental design.\n\nIn terms of coordinates, the API uses a coordinate system where x=0 and y=0 represent the center of the display. This central origin allows for a more intuitive placement of elements on the canvas, especially in psychology experiments where stimuli often need to be positioned relative to a participant's focal point.\n\nThe available functions in the API cover a range of operations related to the `Canvas` object, including but not limited to:\n\n- **Creation of a new Canvas**: This function would initialize a new canvas with specified dimensions.\n- **Drawing shapes**: Parameters would include shape type (e.g., rectangle, circle), position, size, and style arguments.\n- **Adding text**: Parameters would include the text string, position, font specifications, and styling options.\n- **Clearing the canvas**: This function would remove all elements from the canvas, possibly with parameters to specify a certain area to clear.\n- **Updating elements**: Parameters would include the identifier of the element to update and the new values for its properties, such as position or style.\n- **Saving the canvas state**: This would allow the current state of the canvas to be saved for later restoration.\n- **Restoring a saved state**: This function would revert the canvas to a previously saved state.\n- **Exporting the canvas content**: Parameters could include the file format and options for what part of the canvas to export.\n\nPlease note that the exact names and parameters of the functions cannot be provided, as the actual API documentation content is not included in the provided text snippet. The bullet points listed are generic descriptions of common functions that one might expect to find in a canvas-manipulation API for psychological experiments.", "url": "https://osdoc.cogsci.nl/4.0/manual/javascript/canvas", "title": "Canvas functions"}
{"content": "# Canvas functions\n\ntitle: Canvas functions\n\n<summary_prompt>\nWrite a summary for the API below:\n\n- Describe the API's overall functionality\n- Explain that this is a JavaScript API for OpenSesame, software for implementing psychology experiments\n- Explain the process to initialize a `Canvas`\n- Define the usage of `styleArgs`\n- Explain coordinates: x=0, y=0 is the display center\n- Provide a bulleted list of all available functions and their parameters. Important: Don't just name the functions, but create one bullet per function.\n\nYour response should be a comprehensive summary.\n\n```markdown\n{content}\n```\n</summary_prompt>\n\n<div class=\"cogsci-jsdoc\" markdown=\"1\">\n\n%-- include: include/javascript-api/canvas.md --%\n\n</div>", "url": "https://osdoc.cogsci.nl/4.0/manual/javascript/canvas", "title": "Canvas functions"}
{"content": "# Color conversion functions (color-convert)\n\ntitle: Color conversion functions (color-convert)\n\n\nThe `color-convert` library is available as `convert`. It provides convenient high level functions for converting from one color specification to another.\n\n__Example:__\n\n```js\nconsole.log('The RGB values for blue are ' + convert.keyword.rgb('blue'))\n```\n\nFor an overview, see:\n\n- <https://www.npmjs.com/package/color-convert>", "url": "https://osdoc.cogsci.nl/4.0/manual/javascript/color-convert", "title": "Color conversion functions (color-convert)"}
{"content": "# Downloading and converting data\n\ntitle: Downloading and converting data\n\nAfter collecting data with OSWeb through JATOS, you can download and process this data for analysis. To download, navigate to your study within JATOS, click on 'Results', select all Result entries, and then choose 'Export Results \u2192 JATOS Results Archive' (see %FigJatosExportResults).\n\n%--\nfigure:\n id: FigJatosExportResults\n source: jatos-export-results.png\n caption: Procedure for exporting results collected with OSWeb through JATOS.\n--%\n\nThe downloaded file, typically named in the format `jatos_results_<timestamp>.jzip`, contains various folders and files corresponding to metadata and participant data. This format can be difficult to work with directly for data analysis.\n\nTo simplify data analysis, you can convert this file to a more accessible format like `.csv` or `.xlsx`. This conversion can be easily achieved by using the 'Convert OSWeb results to csv/xlsx' option found in the OSWeb extension.", "url": "https://osdoc.cogsci.nl/4.0/manual/osweb/data", "title": "Downloading and converting data"}
{"content": "# Running experiments online with OSWeb\n\ntitle: Running experiments online with OSWeb\n\n\n[TOC]\n\n\n## The workflow\n\nFor an introduction to the workflow, see also:\n\nMath\u00f4t, S., & March, J. (2022). Conducting linguistic experiments online with OpenSesame and OSWeb. *Language Learning*. doi:10.1111/lang.12509\n<br /><small>[Related preprint (not identical to published manuscript)](https://doi.org/10.31234/osf.io/wnryc)</small>\n\n\n### Developing your experiment\n\nFirst, you develop your experiment as you ordinarily would, using the OpenSesame desktop application. Not all functionality is available in online experiments. Notably, you cannot use Python INLINE_SCRIPT items, but have to use JavaScript INLINE_JAVASCRIPT items instead. During the development of your experiment, it is therefore important to check that your experiment is compatible with OSWeb.\n\n- %link:manual/osweb/osweb%\n- %link:manual/javascript/about%\n\n\n### Uploading your experiment to JATOS\n\nOnce you have developed your experiment, you publish it to JATOS. JATOS is a web server that manages experiments: it allows you to generate links that you can distribute participants, and it stores data that has been collected.\n\nThere is not a single JATOS server. Rather, many institutions maintain their own JATOS server. In addition, <https://mindprobe.eu> is a free JATOS server, sponsored by ESCoP and OpenSesame.\n\n- %link:jatos%\n\n\n### Collecting data\n\nOne you have published your experiment to JATOS, you can start collecting data. You can do this by manually sending links to participants, for example through email. Or you can use a platform for participant recruitment, such as Prolific, Mechanical Turk, or Sona Systems.\n\n- %link:prolific%\n- %link:mturk%\n- %link:sonasystems%\n\n\n### Analyzing data\n\nOnce data collection is finished, you can download the data from JATOS and convert it to `.xlsx` or `.csv` format for further analysis:\n\n- %link:manual/osweb/data%\n\n\n## Tutorials\n\n- %link:tutorials/intermediate-javascript%\n- %link:wcst%", "url": "https://osdoc.cogsci.nl/4.0/manual/osweb/workflow", "title": "Running experiments online with OSWeb"}
{"content": "# JATOS\n\ntitle: JATOS\n\n\n[TOC]\n\n\n## Introduction to JATOS\n\n[JATOS](https://www.jatos.org/) is a system for managing online experiments. It allows you to create accounts for experimenters, upload experiments, and generate links that you can distribute to participants. OpenSesame integrates closely with JATOS.\n\nTo access a JATOS server, you have three main options:\n\n- Request a free account on [MindProbe](https://mindprobe.eu/), a public JATOS server sponsored by ESCoP and OpenSesame.\n- se a JATOS server provided by your institution.\n- Download JATOS and install it on your own server.\n\n## Linking OpenSesame with JATOS/MindProbe\n\nOpenSesame requires an API token to access your account on a JATOS server such as MindProbe. Follow these steps to generate an API token:\n\n1. **Log into JATOS.**\n2. **Open your user profile** by clicking on your name located in the top right corner of the page.\n3. **Create an API token** by clicking on 'API tokens' to view all your current tokens, and then click 'New Token'.\n4. **Assign a name to your token**. This name serves as a descriptor indicating its intended use, such as 'OpenSesame integration'.\n5. **Set an expiration for your token**. Tokens default to expire after 30 days, requiring you to generate a new token each month. You can select 'No Expiration' for convenience, but be aware that it is less secure. If someone gains access to a non-expiring token, they can use it indefinitely, or until you revoke the token.\n\n%--\nfigure:\n id: FigAPIToken\n source: api-token.png\n caption: API tokens can be generated within your JATOS user profile.\n--%\n\nNote: An API token always begins with `jap_`, followed by a series of characters and numbers. Keep your token secure!\n\nOnce you have your API token, open the OSWeb and JATOS control panel in OpenSesame. Enter your API token into the corresponding field and also adjust the JATOS server URL, if necessary.\n\n%--\nfigure:\n id: FigJATOSControlPanel\n source: jatos-control-panel.png\n caption: Specify the JATOS server and your API token in the OSWeb and JATOS control panel.\n--%\n\n\n## Publishing experiments to, and downloading from, JATOS/MindProbe\n\nAfter successfully connecting OpenSesame to JATOS, as explained above, you can publish your experiment to JATOS. To do this, select the 'Publish to JATOS/MindProbe' option from the File menu. Upon initial publication, your experiment will be assigned a unique identifier (UUID) that links it to a study on JATOS.\n\nYou can then visit your JATOS server and observe that the newly published experiment has been added to your list of studies.\n\nFrom that point forward, each time you publish the experiment, the existing JATOS study will be updated with the new version. If you wish to publish the experiment as a completely new study on JATOS, you will need to reset the JATOS UUID via the OSWeb and JATOS control panel.\n\nTo download an experiment from JATOS, select the 'Open from JATOS/MindProbe' option from the File menu. Please note, this function is only applicable if the corresponding JATOS study is compatible with OSWeb 2.", "url": "https://osdoc.cogsci.nl/4.0/manual/osweb/jatos", "title": "JATOS"}
{"content": "# Inline JavaScript\n\ntitle: Inline JavaScript\n\nThis page has moved to:\n\n- %link:manual/javascript/about%", "url": "https://osdoc.cogsci.nl/4.0/manual/osweb/javascript", "title": "Inline JavaScript"}
{"content": "# Sona Systems\n\ntitle: Sona Systems\n\n\n[TOC]\n\n\n## About Sona Systems\n\nSona Systems is an online tool that many universities use for recruiting participants, granting course credit to student participants, etc.\n\nSee also:\n\n- <https://www.sona-systems.com/help/integration_test.aspx>\n\n\n## Create a study on JATOS\n\nFirst, import your experiment into JATOS, as described above. Next, go the Worker & Batch Manager, activate the General Multiple Worker, get a URL by clicking on Get Link, and copy it.\n\n\n## Create a study on Sona Systems\n\nNext, create a study on Sona Systems. Insert the JATOS study URL in the field labeled \"Study URL\". This will tell Sona Systems how to start the experiment. Importantly, add the following to the end of the URL (this will pass the participant's Sona ID to your experiment):\n\n```bash\n?SONA_ID=%SURVEY_CODE%  \n```\n\nSona Systems does not use a Redirect URL. This means that Sona Systems will not automatically know whether or not the participant finished the study.\n\n\n## Register the Sona ID in your experiment\n\nEvery participant from Sona is identified by a unique ID. It's important to log this ID in your experiment, because this allows you to tell which participant from Sona corresponds to which entry in the JATOS results. You can do this by adding the script below in the Prepare phase of an `inline_javascript` item at the very start of your experiment.\n\nWhen running the experiment through Sona, this will make the Sona ID available as the experimental variable `sona_participant_id`. When the running the experiment in any other way (e.g. during testing), the variable `sona_participant_id` will be set to -1. \n\n\n```javascript\nif (window.jatos && jatos.urlQueryParameters.SONA_ID) {\n    console.log('Sona information is available')\n    var sona_participant_id = jatos.urlQueryParameters.SONA_ID\n} else {\n    console.log('Sona information is not available (setting value to -1)')\n    var sona_participant_id = -1\n}\nconsole.log('sona_participant_id = ' + sona_participant_id)\n```\n\n\n## Automatically grant credits on study completion\n\nSona Systems provides a completion URL (client-side), which should be called when a study is succesfully completed, so that Sona Systems can grant credit to the participant (see %FigCompletionURL).\n\n%--\nfigure:\n id: FigCompletionURL\n source: completion-url.png\n caption: The completion URL in the Sona Systems study information.\n--%\n\nThe completion URL (client side) has three arguments in it:\n\n- `experiment_id` which identifies the study and is the same for all participants\n- `credit_token` which (apparently) changes when you change the study information, but is otherwise the same for all participants\n- `survey_code` which corresponds to the Sona Participant ID, and is therefore different for each participant\n\nCopy the completion URL, and replace the `XXX` by `[SONA_ID]`. Go to Study Properties on JATOS, and insert the resulting URL into the End Redirect URL field.\n\n%--\nfigure:\n id: FigEndRedirectURL\n source: end-redirect-url.png\n caption: The end-redirect URL in the JATOS study properties.\n--%", "url": "https://osdoc.cogsci.nl/4.0/manual/osweb/sonasystems", "title": "Sona Systems"}
{"content": "# OSWeb\n\ntitle: OSWeb\n\n\n[TOC]\n\n\n## About OSWeb\n\nOSWeb is an online runtime for OpenSesame experiments. It is a JavaScript library that executes OpenSesame experiments in a browser. To use OSWeb, you need the `opensesame-extension-osweb` package, which comes pre-installed with the Windows and macOS distributions of OpenSesame.\n\n\n## Executing an experiment in a web browser\n\nTo run an experiment in a web browser using OSWeb, follow these steps:\n\n1. Open the Experiment Properties and select 'In a browser with OSWeb (osweb)' in the 'Run experiment' section.\n2. Click any of the 'Run' buttons to start the experiment.\n3. If the experiment is not compatible with OSWeb, an error message will appear that details the compatibility issues. (Refer to the 'supported functionality' section for more details.)\n4. If there are no compatibility issues, the experiment will open in a new browser window. Note that even though the experiment is running in a web browser, it is still executing locally on your own computer. To host the experiment online, you need to publish it to [JATOS](%url:jatos%).\n5. When the experiment is finished, the data will be downloaded in `.json` format. This data file can then be [converted to `.xlsx` or `.csv` format](%url:manual/osweb/data%) for further analysis.\n\n\n%--\nfigure:\n id: FigTestRun\n source: testrun.png\n caption: Open the Experiment Properties and select 'In a browser with OSWeb (osweb)' under 'Run experiment'.\n--%\n\n\n## OSWeb control panel\n\nFor more control over OSWeb experiments, you can access the OSWeb and JATOS control panel from the Tools menu. This panel offers a range of configuration options:\n\n- **Possible subject numbers:** When running an experiment from within JATOS, a subject number is randomly selected from this list. You can specify individual numbers using commas (e.g., '1,2,3') or number ranges (e.g., '1-10'). When running an experiment from within OpenSesame, this option does not apply, as the subject number is specified when the experiment starts.\n- **Make browser fullscreen:** This option determines whether the browser should switch to fullscreen mode when an experiment starts within JATOS. If you're running an experiment directly from OpenSesame, this option is ignored; instead, you can run the experiment fullscreen by using the regular Run button, while the Quick Run button does not enable fullscreen.\n- **Show OSWeb Welcome Screen:** This toggle controls whether participants will see a welcome screen before the experiment starts. The welcome screen can convey crucial information to participants. Additionally, it serves a technical purpose\u2014due to browser-security policies, media playback and certain functionality is only available if the experiment is initiated by a user action. Therefore, it is generally recommended to leave this option enabled.\n- **Bypass Compatibility Check:** Enabling this option allows you to run the experiment even when the OSWeb compatibility check fails. Note that doing so will not automagically resolve compatibility issues!\n- **Welcome Text:** This field allows you to customize the welcome message displayed to participants on the welcome screen.\n- **External Libraries:** This field lets you specify any external libraries that should be loaded with your experiment. The use of external libraries is explained in more detail in the section below.\n\n\n%--\nfigure:\n id: FigOSWebControlPanel\n source: osweb-control-panel.png\n caption: The OSWeb and JATOS control panel offers a range of configuration options for your OSWeb experiments.\n--%\n\n\n## Supported functionality\n\nWhen you run the experiment from within OpenSesame, a compatibility check is automatically performed. However, this check is fairly superficial. A more complete overview of supported functionality can be found below.\n\n\n- `advanced_delay`\n- `feedback`\n    - See `sketchpad`\n- `form_consent` (supported >= v1.4)\n- `form_text_display` (supported >= 1.4)\n- `form_text_input` (supported >= 1.4)\n    - Unsupported: fullscreen mode\n- `form_multiple_choice` (supported >= 1.4)\n- `inline_html` (supported >= 1.4)\n- `inline_javascript`\n- `keyboard`\n    - Unsupported: key release\n    - Unsupported: HSV, HSL, and CIELab color spaces\n- `logger`\n- `loop`\n    - Unsupported: resume after break\n    - Unsupported: Disabling of evaluate on first cycle\n    - Unsupported: constraints (pseudorandomization)\n    - Supported >= 1.4: file source\n- `mouse`\n    - Unsupported: mouse release\n    - Unsupported: linked sketchpad\n- `notepad`\n- `repeat_cycle`\n- `reset_feedback`\n- `sampler`\n    - Supported >= 1.4.12: panning, pitch, and fade in\n    - Supported >= 1.4.12: Sound playback on Safari on Mac OS or any browser on iOS\n    - Unsupported: stop after\n- `sequence`\n- `sketchpad`\n    - Unsupported: named elements\n    - Supported >= 1.4: image rotation\n    - Unsupported: HSV, HSL, and CIELab color spaces\n- `touch_response`\n\n\nThe compatibility check may also indicate errors of the following type:\n\n> The prepare phase for item new_logger is called multiple times in a row\n\nThis error results from how the experiment is structured, and specifically the use of linked copies. It's not always easy to understand where this error comes from, but you can read more about the prepare-run strategy in [this article](%url:prepare-run%). As a workaround, you can put the problematic items in a dummy LOOP, that is, a LOOP that simply calls the item once.\n\n\n## Including external JavaScript packages\n\nYou can include external JavaScript packages by entering URLs to these packages (one URL per line) in the input field labeled 'External JavaScript libraries'. These packages are then included with `<script>` tags in the head of the HTML.\n\nFor example, you can include [WebGazer](%url:webgazer%) for in-browser by entering the following link:\n\n```\nhttps://webgazer.cs.brown.edu/webgazer.js\n```\n\n\n## Debugging\n\nSee:\n\n- %link:debugging%", "url": "https://osdoc.cogsci.nl/4.0/manual/osweb/osweb", "title": "OSWeb"}
{"content": "# Questionnaires in OSWeb\n\ntitle: Questionnaires in OSWeb\n\n\n## Forms and custom HTML\n\nForms and custom HTML are supported as of OSWeb 1.4\n{:.page-notification}\n\nYou can use the form plugins as described here:\n\n- %link:manual/forms/about%\n\nThe FORM_BASE plugin is *not* supported in OSWeb. Instead, you can use the INLINE_HTML item to implement custom HTML forms, as described here:\n\n- %link:manual/forms/html%\n\n\n## Linking to a different platform\n\nAs an alternative, you can implement a questionnaire using another platform, such as [LimeSurvey](https://www.limesurvey.org/), and then link to this questionnaire from your OSWeb experiment. The video below shows how to do this in such a way that you can tell afterwards which questionnaire data belongs to which OSWeb data.\n\n%--\nvideo:\n source: youtube\n id: BeginnerTutorial\n videoid: 1WvTUQr0JL0\n width: 640\n height: 360\n caption: |\n  Combining OSWeb and LimeSurvey.\n--%", "url": "https://osdoc.cogsci.nl/4.0/manual/osweb/questionnaires", "title": "Questionnaires in OSWeb"}
{"content": "# Mechanical Turk\n\ntitle: Mechanical Turk\n\n\nThere is currently no information that is specific to running OSWeb experiments on Mechanical Turk. For general information about connecting JATOS to Mechanical Turk, see:\n\n- <http://www.jatos.org/Connect-to-Mechanical-Turk.html>", "url": "https://osdoc.cogsci.nl/4.0/manual/osweb/mturk", "title": "Mechanical Turk"}
{"content": "# Prolific\n\ntitle: Prolific\n\n\n[TOC]\n\n\n## About Prolific\n\n[Prolific](https://prolific.co/) is a commercial tool for recruiting participants for research. To run OSWeb experiments on Prolific, you need to follow the steps explained below.\n\nSee also:\n\n- <http://www.jatos.org/Use-Prolific.html>\n\n\n## Create a study on JATOS\n\nFirst, import your experiment into JATOS, as described above. Next, go the Worker & Batch Manager, activate the General Multiple Worker, get a URL by clicking on Get Link, and copy it (%FigJatosURL).\n\n\n%--\nfigure:\n id: FigJatosURL\n source: jatos-url.png\n caption: Get a study URL from JATOS.\n--%\n\n\n\n## Create a study on Prolific\n\nNext, create a study on Prolific. Under Study Details (%FigProlific), insert the JATOS study URL in the field labeled \"What is the URL of your study?\". This will tell Prolific how to start the experiment. Importantly, add the following to the end of the URL (this will pass important information from Prolific to your experiment):\n\n{% raw %}\n```bash\n&PROLIFIC_PID={{%PROLIFIC_PID%}}&STUDY_ID={{%STUDY_ID%}}&SESSION_ID={{%SESSION_ID%}}\n```\n{% endraw %}\n\nWhen the experiment is finished, Prolific needs to know about it. For this purpose, Prolific uses an End Redirect URL, which is listed in the field labeled \"To prove that participants have completed your study \u2026\". Copy this End Redirect URL. Also check the box labeled \"I've set up my study to redirect to this url at the end\".\n\n%--\nfigure:\n id: FigProlific\n source: prolific.png\n caption: Study details on Prolific.\n--%\n\n\n\n## Set an End Redirect URL in JATOS\n\nNow go back to JATOS, and open the Properties of your study (%FigJatosProperties). There, paste the End Redirect URL that you have copied from Prolific in the field labeled \"End Redirect URL\". This will tell JATOS that the participant should be redirected back to Prolific when the experiment is finished, so that Prolific knows that the participant completed the experiment.\n\n\n%--\nfigure:\n id: FigJatosProperties\n source: jatos-properties.png\n caption: Set the End Redirect URL in JATOS.\n--%\n\n\n## Register Prolific information in your experiment\n\nEvery participant from Prolific is identified by a unique ID. It's important to log this ID in your experiment, because this allows you to tell which participant from Prolific corresponds to which entry in the JATOS results. You can do this by adding the script below in the Prepare phase of an `inline_javascript` item at the very start of your experiment.\n\nWhen running the experiment through Prolific, this will make the Prolific ID available as the experimental variable `prolific_participant_id`. When the running the experiment in any other way (e.g. during testing), the variable `prolific_participant_id` will be set to -1. The same logic applied to the Prolific Study ID (`prolific_study_id`) and the Prolific Session ID (`prolific_session_id`).\n\n\n```javascript\nif (window.jatos && jatos.urlQueryParameters.PROLIFIC_PID) {\n    console.log('Prolific information is available')\n    var prolific_participant_id = jatos.urlQueryParameters.PROLIFIC_PID\n    var prolific_study_id = jatos.urlQueryParameters.STUDY_ID\n    var prolific_session_id = jatos.urlQueryParameters.SESSION_ID\n} else {\n    console.log('Prolific information is not available (setting values to -1)')\n    var prolific_participant_id = -1\n    var prolific_study_id = -1\n    var prolific_session_id = -1\n}\nconsole.log('prolific_participant_id = ' + prolific_participant_id)\nconsole.log('prolific_study_id = ' + prolific_study_id)\nconsole.log('prolific_session_id = ' + prolific_session_id)\n```\n\n\n## Test the study\n\nGo back to the Study Details page on Prolific. At the bottom of the page, there is a Preview button. This allows you to test the experiment by acting as a participant yourself. Don't forget to check the JATOS results to make sure that the experiment has successfully finished, and that all the necessary information (including the Prolific information) has been logged!", "url": "https://osdoc.cogsci.nl/4.0/manual/osweb/prolific", "title": "Prolific"}
{"content": "# Looping and independent variables\n\ntitle: Looping and independent variables\n\nThe LOOP item has two important functions:\n\n- It runs another item multiple times.\n- It is where you usually define your independent variables; that is, the variables that you manipulate in your experiment.\n\n[TOC]\n\n## The item to run\n\nA LOOP is always connected to a single other item: the item to run. You select the item to run in the box labeled \"Run\". In most cases, the item to run is a SEQUENCE, which runs multiple items sequentially.\n\nTwo common SEQUENCE-LOOP structures are:\n\n- If a SEQUENCE corresponds to a single trial (by convention called *trial_sequence*), then a LOOP that is connected to this sequence corresponds to multiple trials, or a block (by convention called *block_loop*).\n- If a SEQUENCE corresponds to a block of trials followed by a feedback display (by convention called *block_sequence*), then a loop that is connected to this sequence corresponds to multiple blocks, or a complete experimental session (by convention called *experimental_loop*).\n\n## Defining independent variables\n\nThe loop table is a powerful-yet-simple way to define independent variables. Every column in the table corresponds to a variable; every row corresponds to a cycle, that is, a level of the variable. For example, a simple loop with one variable (`animal`) that has two cycles (\"cat\" and \"dog\") looks like this:\n\nanimal |\n------ |\ncat    |\ndog    |\n\nThe loop has a few important options:\n\n*Repeat* indicates how often each cycle should be executed. In the example above, repeat is set to 2, which means that *trial_sequence* is called twice while the variable `animal` has the value \"cat\", and twice while `animal` has the value \"dog\" (so four times in total).\n\n*Order* indicates whether cycles should be executed sequentially or in random order. Randomization is complete, in the sense that the complete list of number-of-cycles \u00d7 repeat trials is randomized.\n\n## Reading independent variables from file\n\nIf you want to read independent variables from file, rather than entering them into the loop table, you can do so as follows:\n\n- Set *Source* to *file*.\n- Select an Excel (`.xlsx`) or CSV (`.csv`) file in the *File* entry.\n\nThe source file follows the same conventions as the loop table; that is, each column corresponds to a variable, and each row corresponds to a cycle.\n\nCSV files are expected to be in the following format:\n\n- plain-text\n- comma-separated\n- double-quoted (literal double-quotes are escaped with backward slashes)\n- UTF-8 encoded\n\n## Breaking the loop\n\nIf you want to break the loop before all cycles have been executed, you can specify a break-if expression. This break-if expression follows the same syntax as other conditional expressions, as described on:\n\n- %link:manual/variables%\n\nFor example, the following break-if statement would break the loop as soon as a correct response is given:\n\n```python\ncorrect == 1\n```\n\nThe *Evaluate on first cycle* option indicates whether the break-if statement should be evaluated before the first cycle, in which case no cycles may be executed at all, or only before the second cycle, in which case at least one cycle is always executed. In some cases, the break-if statement will refer to a variable that is only defined after the first cycle, in which case you should disable the 'Evaluate on first cycle' option to avoid a 'Variable does not exist' error.\n\n## Generating a full-factorial design\n\nBy clicking on the *Full-factorial design* you open a wizard that allows you to easily generate a full-factorial design, that is, a design in which each combination of factors occurs.\n\n## Pseudorandomization\n\nYou can add constraints for pseudorandomization to the script of the loop item. This shuffles the rows, even if Order is set to sequential. (Currently, this is not possible through the GUI.)\n\nExample: Make sure that repetitions of the same word (given by the `word` variable) are separated by at least 4 cycles:\n\n```python\nconstrain word mindist=4\n```\n\nExample: Make sure that the same word is not repeated:\n\n```python\nconstrain word maxrep=1\n```\n\n`constrain` commands must come *after* `setcycle` commands.\n\n## Advanced loop operations\n\nCommands for advanced loop operations must come *after* `constrain` and `setcycle` commands.\n\n### fullfactorial\n\nThe `fullfactorial` instruction treats the loop table as the input for a full-factorial design. For example, the following loop table:\n\ncue   | duration\n----- | --------\nleft  | 0\nright | 100\n      | 200\n\nWould result in:\n\ncue   | duration\n----- | --------\nleft  | 0\nleft  | 100\nleft  | 200\nright | 0\nright | 100\nright | 200\n\n### shuffle\n\n`shuffle` without argument randomizes the entire table. When a column name is specified (`shuffle cue`), only that column is randomized.\n\n### shuffle_horiz\n\n`shuffle_horiz` shuffles all columns horizontally. When multiple columns are specified, only those columns are shuffled horizontally.\n\nFor example, when `shuffle_horiz word1 word2` is applied to the following table:\n\nword1 | word2 | word3\n----- | ----- | -----\ncat   | dog   | bunny\ncat   | dog   | bunny\ncat   | dog   | bunny\n\nThe result could be (i.e. values are randomly swapped between `word1` and `word2`, but not `word3`):\n\nword1 | word2 | word3\n----- | ----- | -----\ndog   | cat   | bunny\ndog   | cat   | bunny\ncat   | dog   | bunny\n\n### slice\n\n`slice [from] [to]` selects a slice from the loop. It requires a start and an end index, where 0 is the first row, and negative values are counted from the end backwards. (Just like list slicing in Python, in other words.)\n\nFor example, when `slice 1 -1` is applied to the following table:\n\nword  |\n----- |\ncat   |\ndog   |\nbunny |\nhorse |\n\nThe result would be:\n\nword  |\n----- |\ndog   |\nbunny |\n\n### sort\n\n`sort [column]` sorts a single column, without changing any of the other columns.\n\n### sortby\n\n`sortby [column]` sorts the entire table by a single column.\n\n### reverse\n\n`reverse` reverses the order of the entire table. If a column name is specified (e.g. `reverse word`), only that column is reversed, without changing any of the other columns.\n\n### roll\n\n`roll [value]` rolls the entire table forward (for positive values) or backward (for negative values). If a column name is specified (e.g. `roll 1 word`), only that column is rolled, without changing any of the other columns.\n\nFor example, if `roll 1` is applied to the following table:\n\nword  |\n----- |\ncat   |\ndog   |\nbunny |\nhorse |\n\nThe result would be:\n\nword  |\n----- |\nhorse |\ncat   |\ndog   |\nbunny |\n\n### weight\n\n`weight [column]` repeats each row by a weighting value specified in a column.\n\nFor example, if `weight w` is applied to the following table:\n\nword  | w\n----- | -\ncat   | 0\ndog   | 0\nbunny | 2\nhorse | 1\n\nThe result would be:\n\nword  | w\n----- | -\nbunny | 2\nbunny | 2\nhorse | 1\n\n## Previewing the loop\n\nIf you have specified constraints, or have used advanced loop operations, then it is a good idea to check that the result is as expected. To do so, you can generate a preview of the loop table as it will be (or could be, in case of randomization) when you run the experiment.\n\nTo generate a preview, click on the *Preview* button.\n\n\n## Accessing the loop table in Python inline script\n\nThe original LOOP table, as you see it in the OpenSesame user interface, is a [`DataMatrix`](http://datamatrix.cogsci.nl/) object called `dm`, and is a property of the LOOP item.\n\nThis original LOOP table is usually transformed in various ways; for example, the order of the rows can be randomized, and rows can be repeated multiple times. The transformed LOOP is also a `DataMatrix` object, and is called `live_dm`. `live_dm` is created just before the loop is executed and is set to `None` when the loop is finished; that is, `live_dm` is only available during the *run* phase of the LOOP.\n\nFinally, the index of the current row is stored as the experimental variable `live_row`. That is, `live_row` indicates the currently active row of `live_dm`.\n\nSo let's say that we have a LOOP called *block_loop*. We could then access the LOOP table in a Python inline script as follows:\n\n~~~ .python\nprint('The original loop table:')\nprint(items['block_loop'].dm)\n\nprint('The transformed loop table:')\nprint(items['block_loop'].live_dm)\n\nprint('The current row:')\nprint(items['block_loop'].live_dm[var.live_row])\n~~~\n\nYou can even programatically define the LOOP table. You have to do this in the Prepare phase of an INLINE_SCRIPT that precedes the LOOP.\n\n```python\nfrom datamatrix import DataMatrix\n\nitems['block_loop'].dm = DataMatrix(length=4)\nitems['block_loop'].dm.cue_side = 'left', 'right', 'left', 'right'\nitems['block_loop'].dm.cue_validity = 'valid', 'valid', 'invalid', 'invalid'\n```\n\n`DataMatrix` objects are powerful structures for working with tabular data. For more information, see:\n\n- <https://pydatamatrix.eu/>", "url": "https://osdoc.cogsci.nl/4.0/manual/structure/loop", "title": "Looping and independent variables"}
{"content": "# Doing things in parallel\n\ntitle: Doing things in parallel\n\n\nCoroutines run multiple items in parallel\u2014or, to be more exact, they run items in rapid alternation in a way that looks parallel. Not all items support coroutines.\n\n\n[TOC]\n\n\n## Using coroutines\n\nYou can use coroutines through the COROUTINES plugin (see %FigCoroutinesInterface).\n\n\n%--\nfigure:\n source: FigCoroutinesInterface.png\n caption: The interface of the coroutines plugin.\n id: FigCoroutinesInterface\n--%\n\n\nAs you can see, the COROUTINES plugin looks similar to the SEQUENCE item, but has a few extra options:\n\n- *Duration* indicates the total duration of the coroutines.\n- *End after item (optional)* indicates that the coroutines should end when a specific item has ended. This allows you, for example, to indicate that the coroutines should end when a key press has been collected, by selecting a KEYBOARD_RESPONSE item here.\n- Each item has a *Start time*. Most items also have an *End time*. The end time does not apply to one-shot items; for example, SKETCHPADs show a display and terminate immediately, so they have no end time.\n\nSpecifically, the example from %FigCoroutinesInterface (from the stop-signal-task example) does the following:\n\n- It shows a target display immediately.\n- If the `stop_after` variable is not empty, it shows the stop_signal display after an interval specified by the `stop_after` variable.\n- During the entire (2000 ms) interval, a keyboard response is collected.\n\nThe temporal flow is controlled by the COROUTINES plugin. Therefore, the timeout and duration values specified in the items are not used. For example, in %FigCoroutinesInterface, the KEYBOARD_RESPONSE will run for 2000 ms, regardless of the timeout that is specified in the item.\n\n\n## Supported items\n\nCurrently, the following items are supported (this list may not be exhaustive):\n\n- FEEDBACK\n- INLINE_SCRIPT\n- KEYBOARD_RESPONSE\n- LOGGER\n- MOUSE_RESPONSE\n- SAMPLER\n- SYNTH\n- SKETCHPAD\n\n\n## Using inline_script items in coroutines\n\nWhen you use an INLINE_SCRIPT item in a COROUTINES, the Run phase works a little differently from what you might be used to. Specifically, the Run phase is executed on every iteration of the COROUTINES. In addition, the Run phase should only contain code that takes very little time to execute; this is because time-consuming operations will block the COROUTINES, thus interfering with the timing of other items in the COROUTINES as well. To end the COROUTINES, you can raise an `AbortCoroutines()` exception.\n\nFor example, say that you have a COROUTINES with two KEYBOARD_RESPONSE items, *kb1* and *kb2*, and you want to run the COROUTINES until two key presses have been collected, with a timeout of 5000 ms. You could then create the following COROUTINES structure:\n\n\n%--\nfigure:\n source: FigCoroutinesTwoResponses.png\n caption: A coroutines that collects two keypress responses\n id: FigCoroutinesTwoResponses\n--%\n\nThe *check_responses* INLINE_SCRIPT would then first set both responses variables to an empty string in the Prepare phase:\n\n```python\n# This is executed at the start of the coroutines\nresponse_kb1 = ''\nresponse_kb2 = ''\n```\n\nAnd then, in the Run phase, check if both variables have been set, and abort the coroutines if this is the case:\n\n```python\n# Values that are not an empty string are True for Python\n# This code will be executed many times!\nif response_kb1 and response_kb2:\n    raise AbortCoroutines()\n```\n\n## Run-if expressions\n\nThe behavior of run-if expressions in COROUTINES is a bit different from that in SEQUENCE items. Specifically, run-if expressions in COROUTINES are evaluated during the prepare phase. See also:\n\n- %link:prepare-run%", "url": "https://osdoc.cogsci.nl/4.0/manual/structure/coroutines", "title": "Doing things in parallel"}
{"content": "# Doing things in sequence\n\ntitle: Doing things in sequence\n\nThe SEQUENCE item has two important functions:\n\n- It runs multiple other items one after another.\n- It determines which items should, and which shouldn't, be run.\n\nSEQUENCEs are run from top to bottom; that is, the item at the top is run first. The order of a SEQUENCE is always sequential.\n\n## Run-if expressions\n\nYou can use run-if expressions to determine whether or not a particular item should be run. For example, if you want a display to be presented only if a participant has made an incorrect response, you can set the run-if expressions for that item to:\n\n```python\ncorrect == 0\n```\n\nIf you leave the run-if expressions empty or enter `True`, the item will always be run. Run-if expressions use the same syntax as other conditional expressions. For more information, see:\n\n- %link:manual/variables%\n\nRun-if expressions only affect which items are run, not which items are prepared. Phrased differently, the Prepare phase of all items in a SEQUENCE is always executed, regardless of the run-if expressions. See also:\n\n- %link:prepare-run%\n\n\n## Disabling items\n\nTo completely disable an item in a SEQUENCE, right-click on it and select 'Disable'. This is mostly useful during development of your experiment, for example to temporarily bypass the instructions.", "url": "https://osdoc.cogsci.nl/4.0/manual/structure/sequence", "title": "Doing things in sequence"}
{"content": "# GazePoint / OpenGaze\n\ntitle: GazePoint / OpenGaze\n\nPyGaze offers *experimental* support for GazePoint eye trackers through the OpenGaze API as of OpenSesame 3.3.11. For more information, see:\n\n- %link:pygaze%\n- <https://www.gazept.com/>", "url": "https://osdoc.cogsci.nl/4.0/manual/eyetracking/gazepoint", "title": "GazePoint / OpenGaze"}
{"content": "# WebGazer.js\n\ntitle: WebGazer.js\n\nRequires OSWeb v1.4.6.1\n{:.page-notification}\n\n[TOC]\n\n\n## About WebGazer\n\nWebGazer.js is an eye-tracking library written in JavaScript. You can include it with OSWeb to perform eye tracking in online experiments.\n\n- <https://webgazer.cs.brown.edu/>\n\n\n## Including WebGazer.js in the experiment\n\nWebGazer.js is not bundled with OSWeb by default. However, you can include it as an external library by entering a link to `webgazer.js` under External JavaScript libraries. Currently, a functional link is:\n\n```\nhttps://webgazer.cs.brown.edu/webgazer.js\n```\n\nSee also:\n\n- %link:manual/osweb/osweb%\n\n\n## Example experiment\n\nBelow you can download an example experiment that uses WebGazer.js. Participants are first asked to click on and look at a set of dots; this will cause WebGazer.js to automatically perform something akin to a calibration procedure. Next, the experiment shows a simple screen to test the accuracy of gaze-position recording. In general, fine-grained eye tracking is not feasible, but you can tell which quadrant of the screen a participant is looking at. To run this experiment, you need include WebGazer.js in the experiment, as described above. \n\n- %static:attachments/webgazer.osexp%\n\nYou can also launch the experiment directly in the browser:\n\n- <https://jatos.mindprobe.eu/publix/BowSAFY2VWl>", "url": "https://osdoc.cogsci.nl/4.0/manual/eyetracking/webgazer", "title": "WebGazer.js"}
{"content": "# Tobii\n\ntitle: Tobii\n\nPyGaze offers *experimental* support for Tobii eye trackers.\n\n`tobii-research` is the Python library for Tobii support. As of July 2023, `tobii-research` requires Python 3.10, whereas OpenSesame by default uses Python 3.11. Therefore, until `tobii-research` is updated for Python 3.11, the easiest way to install OpenSesame with Tobii support is by building a Python 3.10 environment through Anaconda.\n\nThis sounds complicated, but it is really not. To do so, first read the general procedure for installing OpenSesame through Anaconda as described on the Downloads page:\n\n- %link:download%\n\nNext, once you understand the general procedure, start by creating a Python 3.10 environment, continue with the instructions from the Downloads page, and then install `tobii-research`:\n\n```\n# Start by creating a Python 3.10 environment\nconda create -n opensesame-py3 python=3.10\nconda activate opensesame-py3\n# Now follow the instructions from the downloads page\n# ...\n# Then install Tobii support\npip install tobii-research\n# And now launch OpenSesame!\nopensesame\n```\n\nFor more information, see:\n\n- %link:pygaze%\n- <https://rapunzel.cogsci.nl/manual/environment/>\n- <http://www.tobii.com/en/eye-tracking-research/global/>", "url": "https://osdoc.cogsci.nl/4.0/manual/eyetracking/tobii", "title": "Tobii"}
{"content": "# EyeTribe\n\ntitle: EyeTribe\n\nThe EyeTribe is supported through PyGaze. For more information, see:\n\n- %link:pygaze%", "url": "https://osdoc.cogsci.nl/4.0/manual/eyetracking/eyetribe", "title": "EyeTribe"}
{"content": "# Eyelink\n\ntitle: Eyelink\n\n[TOC]\n\n## About EyeLink\n\nThe Eyelink series of eye trackers, produced by SR Research, are one of the most commonly used eye trackers in psychological research. SR Research provides Python bindings for the Eyelink (called PyLink), which are used by PyGaze. The license of PyLink is incompatible with the license used by OpenSesame. For that reason, PyLink is not included in the default distribution of OpenSesame, and needs to be installed separately.\n\n\n## Windows\n\n### Installing the EyeLink Developers Kit\n\nThe Eyelink Developers Kit (sometimes called Display Software) provides the libraries that are required to communicate with the Eyelink PC. You can find it here (free registration required):\n\n- <https://www.sr-research.com/support/thread-13.html>\n\nIf you extract the `.zip`, and then run the `.exe` installer, the EyeLink display will be installed in one of the following folders (depending on your version of Windows:\n\n```\nC:\\Program Files\\SR Research\\EyeLink\\\nC:\\Program Files (x86)\\SR Research\\EyeLink\n```\n\nIn this folder, there is a `libs` subfolder, which you need to add to the system Path (this may have been added to the path automatically, but check to make sure). You can do this by opening \"My Computer\", clicking on \"View system information\", opening the \"Advanced\" tab, clicking on \"Environment Variables\" and appending `;C:\\Program Files\\SR Research\\EyeLink\\libs` or (depending on your system) `;C:\\Program Files (x86)\\SR Research\\EyeLink\\libs` to the Path variable (under System variables).\n\n\n### Installing OpenSesame with PyLink\n\nPyLink is the Python library for EyeLink support. PyLink can be installed from the SR Research PyPi repository through `pip install`:\n\n```\npip install --index-url=https://pypi.sr-research.com sr-research-pylink\n```\n\nYou can find more information about PyLink on the SR Research forum (free registration required):\n\n- <https://www.sr-research.com/support/thread-8291.html>\n\n\n## Ubuntu\n\nThe EyeLink display software can be installed directly from a repository. This also installs PyLink and various convenient tools, such ast the `edf2asc` converter.\n\n```bash\nsudo add-apt-repository 'deb [arch=amd64] https://apt.sr-research.com SRResearch main'\nsudo apt-key adv --fetch-keys https://apt.sr-research.com/SRResearch_key\nsudo apt-get update\nsudo apt-get install eyelink-display-software\n```\n\nFor more information, please visit:\n\n- <https://www.sr-support.com/thread-13.html>\n\n\n## PyGaze\n\nAfter you have install the EyeLink display software and PyLink per the instructions above, you can use the EyeLink with PyGaze! See:\n\n- %link:pygaze%", "url": "https://osdoc.cogsci.nl/4.0/manual/eyetracking/eyelink", "title": "Eyelink"}
{"content": "# PyGaze (eye tracking)\n\ntitle: PyGaze (eye tracking)\n\n[TOC]\n\n## About\n\nPyGaze is a Python library for eye tracking. A set of plugins allow you to use PyGaze from within OpenSesame. For more information on PyGaze, visit:\n\n- <http://www.pygaze.org/>\n\nPlease cite PyGaze as:\n\nDalmaijer, E., Math\u00f4t, S., & Van der Stigchel, S. (2014). PyGaze: An open-source, cross-platform toolbox for minimal-effort programming of eyetracking experiments. *Behavior Research Methods*. doi:10.3758/s13428-013-0422-2\n{: .reference}\n\n## Supported eye trackers\n\nPyGaze supports the following eye trackers:\n\n- [EyeLink](%link:eyelink%)\n- [EyeTribe](%link:eyetribe%)\n\nFor the following eye trackers, there is experimental support:\n\n- [EyeLogic](%link:eyelogic%)\n- [GazePoint / OpenGaze](%link:gazepoint%)\n- [SMI](%link:smi%)\n- [Tobii](%link:tobii%)\n\nYou can also perform basic eye tracking in online experiments with WebGazer.js:\n\n- [WebGazer.js](%link:webgazer%)\n\nPyGaze also includes two dummy eye trackers for testing purposes:\n\n- __Simple dummy__ \u2014 Does nothing.\n- __Advanced dummy__ \u2014 Mouse simulation of eye movements.\n\n## Installing PyGaze\n\n### Windows\n\nIf you use the official Windows package of OpenSesame, PyGaze is already installed.\n\n### Ubuntu\n\nIf you use Ubuntu, you can get PyGaze from the Cogsci.nl PPA:\n\n```\nsudo add-apt-repository ppa:smathot/cogscinl\nsudo apt-get update\nsudo apt-get install python-pygaze\n```\n\nOr, if you are using Python 3, change the last comment to:\n\n```\nsudo apt-get install python3-pygaze\n```\n\n## pip install (all platforms)\n\nYou can install PyGaze with `pip`:\n\n```\npip install python-pygaze\n```\n\n### Anaconda (all platforms)\n\n```\nconda install python-pygaze -c cogsci\n```\n\n## PyGaze OpenSesame plugins\n\nThe following PyGaze plugins are available:\n\n- PYGAZE_INIT \u2014 Initializes PyGaze. This plugin is generally inserted at the start of the experiment.\n- PYGAZE_DRIFT_CORRECT \u2014 Implements a drift correction procedure.\n- PYGAZE_START_RECORDING \u2014 Puts PyGaze in recording mode.\n- PYGAZE_STOP_RECORDING \u2014 Puts PyGaze out of recording mode.\n- PYGAZE_WAIT \u2014 Pauses until an event occurs, such as a saccade start.\n- PYGAZE_LOG \u2014 Logs experimental variables and arbitrary text.\n\n## Example\n\nFor an example of how to use the PyGaze plugins, see the PyGaze template that is included with OpenSesame.\n\nBelow is an example of how to use PyGaze in a Python INLINE_SCRIPT:\n\n~~~ .python\n# Create a keyboard and a canvas object\nmy_keyboard = Keyboard(timeout=0)\nmy_canvas = Canvas()\nmy_canvas['dot'] = Circle(x=0, y=0, r=10, fill=True)\n# Loop ...\nwhile True:\n\t# ... until space is pressed\n\tkey, timestamp = my_keyboard.get_key()\n\tif key == 'space':\n\t\tbreak\n\t# Get gaze position from pygaze ...\n\tx, y = eyetracker.sample()\n\t# ... and draw a gaze-contingent fixation dot!\n\tmy_canvas['dot'].x = x + my_canvas.left\n\tmy_canvas['dot'].y = y + my_canvas.top\n\tmy_canvas.show()\n~~~\n\n## Function overview\n\nTo initialize PyGaze in OpenSesame, insert the PYGAZE_INIT plugin into your experiment. Once you have done this, an `eyetracker` object will be available, which offers the following functions:\n\n%-- include: include/api/eyetracker.md --%", "url": "https://osdoc.cogsci.nl/4.0/manual/eyetracking/pygaze", "title": "PyGaze (eye tracking)"}
{"content": "# SMI\n\ntitle: SMI\n\nPyGaze offers *experimental* support for SMI eye trackers. (SMI no longer exists as a company, but its eye trackers are still used in some labs.) For more information, see:\n\n- %link:pygaze%", "url": "https://osdoc.cogsci.nl/4.0/manual/eyetracking/smi", "title": "SMI"}
{"content": "# EyeLogic\n\ntitle: EyeLogic\n\nPyGaze offers *experimental support* for EyeLogic eye trackers as of OpenSesame 3.3.11. For more information, see:\n\n- %link:pygaze%\n- <https://www.eyelogicsolutions.com/>", "url": "https://osdoc.cogsci.nl/4.0/manual/eyetracking/eyelogic", "title": "EyeLogic"}
{"content": "# Button box\n\ntitle: Button box\n\nThere are many different types of button boxes, and they all work in different ways. Therefore, there is no single OpenSesame item that works with all button boxes. (This is different from keyboards, which are standard devices that all work with the KEYBOARD_RESPONSE item.)\n\nCommon types of button boxes:\n\n- Some button boxes *emulate keypresses*. This is easy, because you can use the normal KEYBOARD_RESPONSE item.\n\t- %link:manual/response/keyboard%\n- Some button boxes *emulate a joystick*. This is also easy, because you can use the JOYSTICK plugin.\n\t- %link:joystick%\n- Some button boxes are compatible with the *Serial Response Box* that is developed by Psychology Software Tools. These button boxes are supported by the SRBOX plugin.\n\t- %link:srbox%\n- Some button boxes have their own Python libaries. In this case, you should be able to find example scripts of how to use the button box in Python, that is, in an OpenSesame INLINE_SCRIPT item.", "url": "https://osdoc.cogsci.nl/4.0/manual/response/buttonbox", "title": "Button box"}
{"content": "# Mouse responses\n\ntitle: Mouse responses\n\nMouse responses are collected with the MOUSE_RESPONSE item. The MOUSE_RESPONSE is primarily intended to collect individual mouse clicks. If you want to collect mouse-cursor trajectories, take a look at the MOUSETRAP plugins:\n\n- %link:mousetracking%\n\n[TOC]\n\n\n## Response variables\n\nThe MOUSE_RESPONSE sets the standard response variables as described here:\n\n- %link:manual/variables%\n\n\n## Mouse-button names\n\nMouse buttons have a number (`1`, etc.) as well as a name (`left_button`, etc.). Both can be used to specify correct and allowed responses, but the `response` variable will be set to a number.\n\n- `left_button` corresponds to `1`\n- `middle_button` corresponds to `2`\n- `right_button` corresponds to `3`\n- `scroll_up` corresponds to `4`\n- `scroll_down` corresponds to `5`\n\n\n## Correct response\n\nThe *Correct response* field indicates which response is considered correct. After a correct response, the `correct` variable is automatically set to 1; after an incorrect response or a timeout (i.e. everything else), `correct` is set to 0; if no correct response is specified, `correct` is set to 'undefined'.\n\nYou can indicate the correct response in three main ways:\n\n- *Leave the field empty.* If you leave the *Correct response* field empty, OpenSesame will automatically check if a variable called `correct_response` has been defined, and, if so, use this variable for the correct response.\n- *Enter a literal value.* You can explicitly enter a response, such as 1. This is only useful if the correct response is fixed.\n- *Enter a variable name.* You can enter a variable, such as '{cr}'. In this case, this variable will be used for the correct response.\n\nNote that the correct response refers to which mouse button was clicked, not to which region of interest was clicked (ROI); see the section below for more information about ROIs.\n\n## Allowed responses\n\nThe *Allowed responses* field indicates a list of allowed responses. All other responses will be ignored, except for 'Escape', which will pause the experiment. The allowed responses should be a semicolon-separated list of responses, such as '1;3' to allow the left and right mouse buttons. To accept all responses, leave the *Allowed responses* field empty.\n\nNote that the allowed responses refer to which mouse button can be clicked, not to which region of interest can be clicked (ROI); see the section below for more information about ROIs.\n\n\n%--include: include/timeout.md--%\n\n## Coordinates and regions of interest (ROIs)\n\nThe `cursor_x` and `cursor_y` variables hold the location of the mouse click.\n\nIf you indicate a linked SKETCHPAD, the variable `cursor_roi` will hold a comma-separated list of names of elements that contain the clicked coordinate. In other words, elements on the SKETCHPAD automatically serve as regions of interest for the mouse click.\n\nIf the correctness of a response depends on which ROI was clicked, you cannot use the `correct_response` variable for this, because this currently refers only to which mouse button was clicked. Instead you need to use a simple script.\n\nIn a Python INLINE_SCRIPT you can do this as follows:\n\n```python\nclicked_rois = cursor_roi.split(';')\ncorrect_roi = 'my_roi'\nif correct_roi in clicked_rois:\n    print('correct!')\n    correct = 1\nelse:\n    print('incorrect!')\n    correct = 0\n```\n\nWith OSWeb using a INLINE_JAVASCRIPT you can do this as follows:\n\n```js\nclicked_rois = cursor_roi.split(';')\ncorrect_roi = 'my_roi'\nif (clicked_rois.includes(correct_roi)) {\n    console.log('correct!')\n    correct = 1\n} else {\n    console.log('incorrect!')\n    correct = 0\n}\n```\n\n\n%--\nvideo:\n source: youtube\n id: VidMouseROI\n videoid: 21cgX_zHDiA\n width: 640\n height: 360\n caption: |\n  Collecting mouse clicks and using regions of interest.\n--%\n\n## Collecting mouse responses in Python\n\nYou can use the `mouse` object to collect mouse responses in Python:\n\n- %link:manual/python/mouse%", "url": "https://osdoc.cogsci.nl/4.0/manual/response/mouse", "title": "Mouse responses"}
{"content": "# Keyboard responses\n\ntitle: Keyboard responses\n\nKeyboard responses are collected with the KEYBOARD_RESPONSE item.\n\n[TOC]\n\n\n## Response variables\n\nThe KEYBOARD_RESPONSE sets the standard response variables as described here:\n\n- %link:manual/variables%\n\n## Key names\n\nKeys are generally identified by their character and/ or their description (depending on which is applicable). For example:\n\n- The `/` key is named 'slash' and '/'. You can use either of the two names.\n- The `a` is named 'a'.\n- The left-arrow key is named 'left'.\n\nIf you don't know what a particular key is named, you can:\n\n- Click on the 'List available keys' button; or\n- Create a simple experiment in which a KEYBOARD_RESPONSE is immediately followed by a FEEDBACK item with the text '{response}' on it. This will show the name of the previously collected response.\n\n\n## Correct response\n\nThe *Correct response* field indicates which response is considered correct. After a correct response, the `correct` variable is automatically set to 1; after an incorrect response (i.e. everything else), `correct` is set to 0; if no correct response is specified, `correct` is set to 'undefined'.\n\nYou can indicate the correct response in three main ways:\n\n- *Leave the field empty.* If you leave the *Correct response* field empty, OpenSesame will automatically check if a variable called `correct_response` has been defined, and, if so, use this variable for the correct response.\n- *Enter a literal value.* You can explicitly enter a response, such as 'left' in the case of a KEYBOARD_RESPONSE item. This is only useful if the correct response is fixed.\n- *Enter a variable name.* You can enter a variable, such as '{cr}'. In this case, this variable will be used for the correct response.\n\n\n## Allowed responses\n\nThe *Allowed responses* field indicates a list of allowed responses. All other responses will be ignored, except for 'Escape', which will pause the experiment. The allowed responses should be a semicolon-separated list of responses, such as 'a;left;/' for a KEYBOARD_RESPONSE. To accept all responses, leave the *Allowed responses* field empty.\n\n\n%--include: include/timeout.md--%\n\n## Collecting keyboard responses in Python\n\nYou can use the `keyboard` object to collect keyboard responses in Python:\n\n- %link:manual/python/keyboard%", "url": "https://osdoc.cogsci.nl/4.0/manual/response/keyboard", "title": "Keyboard responses"}
{"content": "# Sound recording\n\ntitle: Sound recording\n\n[TOC]\n\n\n## Audio Low Latency plugins\n\nThe Audio Low Latency plugins, developed by Bob Rosbag, are the recommended way to record sound input. The main goal of this set of plugins is to play and record audio with minimal and predictable latencies to achieve a high accuracy and precision. The `PyAlsaAudio` package which uses the Linux ALSA audio system provided the best results within Python. `PortAudio` and `sounddevice` are cross-platform and work on both Windows as Linux.\n\nThe plugins are not installed by default, but can be installed through pip:\n\n```bash\npip install opensesame-plugin-audio-low-latency\n```\n\nSee also:\n\n- <https://pypi.org/project/opensesame-plugin-audio-low-latency/>\n\n\n## Sound recorder plugins\n\nThe sound recorder plugins, developed by Daniel Schreij, are no longer under active development and are therefore no longer recommended. More information about this set of plugins can be found on previous version of this page:\n\n- <https://osdoc.cogsci.nl/3.2/manual/response/soundrecording/>", "url": "https://osdoc.cogsci.nl/4.0/manual/response/soundrecording", "title": "Sound recording"}
{"content": "# Joystick and gamepad\n\ntitle: Joystick and gamepad\n\nJoysticks and gamepads are supported through the JOYSTICK plugin.\n\n[TOC]\n\n%-- include: include/api/joystick.md --%", "url": "https://osdoc.cogsci.nl/4.0/manual/response/joystick", "title": "Joystick and gamepad"}
{"content": "# SR Box\n\ntitle: SR Box\n\n[TOC]\n\n## About the srbox plugin\n\nThe serial response (SR) box is a button box, specifically designed for response collection in psychological experiments. The original version, developed by Psychology Software Tools, has 5 buttons, 5 lights, and is connected to the PC trough the serial port. There are also SR Box compatible devices by other manufacturers, which may differ in the number of buttons and lights and often use a USB connection, which emulates a serial port.\n\nThe SRBOX plugin for OpenSesame allows you to use the SR Box or compatible device in your OpenSesame experiments.\n\n## Screenshot\n\n%--\nfigure:\n  source: srbox.png\n  id: FigSrbox\n  caption: The srbox plugin in OpenSesame.\n--%\n\n## Setting the device name\n\nBy default, the plugin tries to autodetect your SR Box. If this works, you don't have to change it. If your experiment freezes, OpenSesame has chosen the wrong serial port and you must enter the device name manually. Under Windows, the device is probably called something like\n\n```text\nCOM4\n```\n\nUnder Linux the device is probably called something like\n\n```text\n/dev/tty0\n```\n\n## Requirements\n\nAn SR Box or compatible button box. Not all button boxes are compatible, see:\n\n- %link:buttonbox%\n\n## Using the SR Box from Python inline code\n\nThe `srbox` object does *not* exist when the plug-in is in dummy mode.\n\n%-- include: include/api/srbox.md --%", "url": "https://osdoc.cogsci.nl/4.0/manual/response/srbox", "title": "SR Box"}
{"content": "# Access the file pool\n\ndummy", "url": "https://osdoc.cogsci.nl/4.0/manual/python/pool", "title": "Access the file pool"}
{"content": "# Access the file pool\n\ntitle: Access the file pool\n\n<summary_prompt>\nWrite a summary for the API below:\n\n- Describe the API's overall functionality\n- Explain that this is a Python API for OpenSesame, software for implementing psychology experiments\n- Explain that the `pool` object does not need to be imported\n- Give examples of how to:\n    - Check whether a file is in the file pool\n    - Retrieve the path to a file in the file pool\n- Provide a bulleted list of all available functions and their parameters. Important: Don't just name the functions, but create one bullet per function.\n\nYour response should be a comprehensive summary.\n\n```markdown\n{content}\n```\n</summary_prompt>\n\n%-- include: include/api/pool.md --%", "url": "https://osdoc.cogsci.nl/4.0/manual/python/pool", "title": "Access the file pool"}
{"content": "# Sampler functions\n\ndummy", "url": "https://osdoc.cogsci.nl/4.0/manual/python/sampler", "title": "Sampler functions"}
{"content": "# Sampler functions\n\ntitle: Sampler functions\n\n<summary_prompt>\nWrite a summary for the API below:\n\n- Describe the API's overall functionality\n- Explain that this is a Python API for OpenSesame, software for implementing psychology experiments\n- Explain that the `Sampler` class does not need to be imported\n- Explain the process to initialize a Sampler\n- Define the usage of `**playback_args`\n- Explain supported file formats\n- Provide a bulleted list of all available functions and their parameters. Important: Don't just name the functions, but create one bullet per function.\n\nYour response should be a comprehensive summary.\n\n```markdown\n{content}\n```\n</summary_prompt>\n\n%-- include: include/api/sampler.md --%", "url": "https://osdoc.cogsci.nl/4.0/manual/python/sampler", "title": "Sampler functions"}
{"content": "# Clock functions\n\ndummy", "url": "https://osdoc.cogsci.nl/4.0/manual/python/clock", "title": "Clock functions"}
{"content": "# Clock functions\n\ntitle: Clock functions\n\n<summary_prompt>\nWrite a summary for the API below:\n\n- Describe the API's overall functionality\n- Explain that this is a Python API for OpenSesame, software for implementing psychology experiments\n- Explain that the `clock` object does not need to be imported\n- Provide a bulleted list of all available functions and their parameters. Important: Don't just name the functions, but create one bullet per function.\n\nYour response should be a comprehensive summary.\n\n```markdown\n{content}\n```\n</summary_prompt>\n\n%-- include: include/api/clock.md --%", "url": "https://osdoc.cogsci.nl/4.0/manual/python/clock", "title": "Clock functions"}
{"content": "# Access response history\n\ndummy", "url": "https://osdoc.cogsci.nl/4.0/manual/python/responses", "title": "Access response history"}
{"content": "# Access response history\n\ntitle: Access response history\n\n<summary_prompt>\nWrite a summary for the API below:\n\n- Describe the API's overall functionality\n- Explain that this is a Python API for OpenSesame, software for implementing psychology experiments\n- Explain that the `responses` object does not need to be imported\n- Provide a bulleted list of all available functions and their parameters. Important: Don't just name the functions, but create one bullet per function.\n\nYour response should be a comprehensive summary.\n\n```markdown\n{content}\n```\n</summary_prompt>\n\n%-- include: include/api/responses.md --%", "url": "https://osdoc.cogsci.nl/4.0/manual/python/responses", "title": "Access response history"}
{"content": "# Mouse functions\n\ndummy", "url": "https://osdoc.cogsci.nl/4.0/manual/python/mouse", "title": "Mouse functions"}
{"content": "# Mouse functions\n\ntitle: Mouse functions\n\n<summary_prompt>\nWrite a summary for the API below:\n\n- Describe the API's overall functionality\n- Explain that this is a Python API for OpenSesame, software for implementing psychology experiments\n- Explain that the `Mouse` class does not need to be imported\n- Explain the process to initialize a Mouse\n- Define the usage of `**resp_args`\n- Explain how to specify button names/ numbers\n- Explain coordinates: x=0, y=0 is the display center\n- Provide a bulleted list of all available functions and their parameters. Important: Don't just name the functions, but create one bullet per function.\n\nYour response should be a comprehensive summary.\n\n```markdown\n{content}\n```\n</summary_prompt>\n\n%-- include: include/api/mouse.md --%", "url": "https://osdoc.cogsci.nl/4.0/manual/python/mouse", "title": "Mouse functions"}
{"content": "# Log functions\n\ndummy", "url": "https://osdoc.cogsci.nl/4.0/manual/python/log", "title": "Log functions"}
{"content": "# Log functions\n\ntitle: Log functions\n\n<summary_prompt>\nWrite a summary for the API below:\n\n- Describe the API's overall functionality\n- Explain that this is a Python API for OpenSesame, software for implementing psychology experiments\n- Explain that the `log` object does not need to be imported\n- Provide a bulleted list of all available functions and their parameters. Important: Don't just name the functions, but create one bullet per function.\n\nYour response should be a comprehensive summary.\n\n```markdown\n{content}\n```\n</summary_prompt>\n\n%-- include: include/api/log.md --%", "url": "https://osdoc.cogsci.nl/4.0/manual/python/log", "title": "Log functions"}
{"content": "# About Python\n\ntitle: About Python\n\nIn OpenSesame you can create complex experiments using only the graphical user interface (GUI). But you will sometimes encounter situations in which the functionality provided by the GUI is insufficient. In these cases you can add Python code to your experiment.\n\nPython is not supported in online experiments with OSWeb. If you need to run your experiment online, you have to use [JavaScript](%url:manual/javascript/about%) instead.\n\n[TOC]\n\n## Learning Python\n\nYou can find a set of basic tutorials and exercises to get you started with Python at <https://pythontutorials.eu/>.\n\n\n## Python in the OpenSesame GUI\n\n### A single Python workspace\n\nAll Python code is executed in a single Python workspace. This means that variables that have been defined in one INLINE_SCRIPT are accessible in all other INLINE_SCRIPTs, as well as in Python statements that are embedded in run-if statements and text strings. The same principle applies to modules: once `import`ed, they are available everywhere.\n\nFor example, you can simply construct the `Canvas` in one INLINE_SCRIPT ...\n\n~~~ .python\nmy_canvas = Canvas()\nmy_canvas.fixdot()\n~~~\n\n... and show it in another INLINE_SCRIPT ...\n\n~~~ .python\nmy_canvas.show()\n~~~\n\n### Inline_script items\n\nIn order to use Python code you need to add an INLINE_SCRIPT item to your experiment. You can do this by dragging the Python icon (the blue/yellow icon) from the item toolbar into the experiment sequence. After you have done this you will see something like %FigInlineScript.\n\n%--\nfigure:\n id: FigInlineScript\n source: inline-script.png\n caption: The INLINE_SCRIPT item.\n--%\n\nAs you can see, the INLINE_SCRIPT item consists of two tabs: one for the Prepare phase and one for the Run phase. The Prepare phase is executed first, to allow items to prepare for the time-critical run phase. It is good practice to construct `Canvas` objects, `Sampler` objects, etc. during the Prepare phase, so that they can be presented without delay during the Run phase. But this is only convention; you can execute arbitrary Python code during both phases.\n\nFor more information about the prepare-run strategy, see:\n\n- %link:prepare-run%\n\n\n### Conditional (\"if\") expressions\n\nYou can use single-line Python expressions in conditional expressions. For example, you can use the following Python script as a run-if expression (see also %FigRunIf):\n\n~~~ .python\ncorrect == 1 and response_time < 1000\n~~~\n\n%--\nfigure:\n id: FigRunIf\n source: run-if.png\n caption: Using Python script in the run-if statement of a SEQUENCE item.\n--%\n\nFor more information about conditional (\"if\") expressions, see:\n\n- %link:manual/variables%\n\n\n### Python in text strings\n\nYou can embed Python statements in text strings using the `{...} syntax. This works for simple variable references, but also for single-line expressions. For example, you could the following text to a SKETCHPAD:\n\n```text\nThe resolution is {width} x {height} px, which is a total of {width * height} pixels\n```\n\nDepending on your experiment's resolution, this might evaluate to:\n\n```text\nThe resolution is 1024 x 768 px, which is a total of 786432 pixels\n```\n\nFor more information about variables and text, see:\n\n- %link:manual/variables%\n- %link:manual/stimuli/text%\n\n\n### The Jupyter console (debug window)\n\nOpenSesame reroutes the standard output to the console (or: debug window), which you can activate using Control + D or through the menu (Menu -> View -> Show debug window; see %FigDebugNormal). You can print to the console using `print()`.\n\n~~~ .python\nprint('This will appear in the debug window!')\n~~~\n\nThe console is also an interactive Python interpreter powered by [project Jupyter](https://jupyter.org).\n\n\n## Things to know\n\n### Common functions\n\nMany common functions are directly available in an INLINE_SCRIPT item, without the need to import anything. For example:\n\n~~~ .python\n# `Canvas()` is a factory function that returns a `Canvas` object\nfixdot_canvas = Canvas()\nif sometimes(): # Sometimes the fixdot is green\n    fixdot_canvas.fixdot(color='green')\nelse: # Sometimes it is red\n    fixdot_canvas.fixdot(color='red')\nfixdot_canvas.show()\n~~~\n\nFor a list of common functions, see:\n\n- %link:manual/python/common%\n\n\n### The `var` object: Access to experimental variables\n\n__Version note__ As of OpenSesame 4.0, all experimental variables are available as globals. This means that you no longer need the `var` object.\n{:.page-notification}\n\nYou can access experimental variables through the `var` object:\n\n~~~ .python\n# OpenSesame <= 3.3 (with var object)\n# Get an experimental variable\nprint('my_variable is: %s' % var.my_variable)\n# Set an experimental variable\nvar.my_variable = 'my_value'\n\n# OpenSesame >= 4.0 (without var object)\n# Get an experimental variable\nprint('my_variable is: %s' % my_variable)\n# Set an experimental variable\nmy_variable = 'my_value'\n~~~\n\nA full overview of the `var` object can be found here:\n\n- %link:manual/python/var%\n\n\n### The `clock` object: Time functions\n\nBasic time functions are available through the `clock` object:\n\n~~~ .python\n# Get the current timestamp\nt = clock.time()\n# Wait for 1 s\nclock.sleep(1000)\n~~~\n\nA full overview of the `clock` object can be found here:\n\n- %link:manual/python/clock%\n\n\n### The `log` object: Data logging\n\nData logging is available through the `log` object:\n\n~~~ .python\n# Write one line of text\nlog.write('My custom log message')\n# Write all variables\nlog.write_vars()\n~~~\n\nA full overview of the `log` object can be found here:\n\n- %link:manual/python/log%\n\n\n### The `pool` object: Access to the file pool\n\nYou get the full path to a file in the file pool through the `pool` object:\n\n~~~ .python\n# Show an image from the file pool\npath = pool['img.png']\nmy_canvas = Canvas()\nmy_canvas.image(path)\nmy_canvas.show()\n~~~\n\nA full overview of the `pool` object can be found here:\n\n- %link:manual/python/pool%\n\n\n### The `responses` object: Access to participant responses\n\nThe `responses` object keeps track of all participant responses that have been collected during the experiment. For example, to list the correctness of all responses so far:\n\n~~~ .python\nfor response in responses:\n\tprint(response.correct)\n~~~\n\nA full overview of the `responses` object can be found here:\n\n- %link:manual/python/responses%\n\n\n### The `Canvas` class: Presenting visual stimuli\n\nThe `Canvas` class is used to present visual stimuli. For example, you can show a fixation dot as follows:\n\n~~~ .python\nmy_canvas = Canvas()\nmy_canvas.fixdot()\nmy_canvas.show()\n~~~\n\nA full overview of the `Canvas` class can be found here:\n\n- %link:manual/python/canvas%\n\n\n### The `Keyboard` class: Collecting key presses\n\nThe `Keyboard` class is used to collect key presses. For example, to collect a key press with a timeout of 1000 ms:\n\n~~~ .python\nmy_keyboard = Keyboard(timeout=1000)\nkey, time = my_keyboard.get_key()\n~~~\n\nA full overview of the `Keyboard` class can be found here:\n\n- %link:manual/python/keyboard%\n\n\n### The `Mouse` class: Collecting mouse clicks and screen touches\n\nThe `Mouse` class is used to collect mouse clicks and screen touches. (OpenSesame makes no distinction between the two.) For example, to collect a mouse click with a timeout of 1000 ms:\n\n~~~ .python\nmy_mouse = Mouse(timeout=1000)\nbutton, position, time = my_mouse.get_click()\n~~~\n\nA full overview of the `Mouse` class can be found here:\n\n- %link:manual/python/mouse%\n\n\n### The `Sampler` class: Sound playback\n\nThe `Sampler` class is used to play back sound samples. For example, to play back a simple beep:\n\n~~~ .python\nmy_sampler = Sampler()\nmy_sampler.play()\n~~~\n\nA full overview of the `Sampler` class can be found here:\n\n- %link:manual/python/sampler%\n\n\n## Alternative modules for display presentation, response collection, etc.\n\n\n### `psychopy`\n\nIf you are using the *psycho* backend, you can directly use the various [PsychoPy] modules. For more information, see:\n\n- %link:backends%\n\n\n### `expyriment`\n\nIf you are using the *xpyriment* backend, you can directly use the various [Expyriment] modules. For more information, see:\n\n- %link:backends%\n\n### `pygame`\n\nIf you are using the *legacy*, *droid*, or *xpyriment* (only with \"Use OpenGL\" set to \"no\") backend, you can directly use the various [PyGame] modules. For more information, see:\n\n- %link:backends%\n\n\n[python]: http://www.python.org/\n[backends]: /backends/about-backends\n[ipython]: http://ipython.org/\n[swaroop]: http://www.swaroopch.com/notes/Python\n[swaroop-direct]: http://www.ibiblio.org/swaroopch/byteofpython/files/120/byteofpython_120.pdf\n[downey]: http://www.greenteapress.com/thinkpython/\n[downey-direct]: http://www.greenteapress.com/thinkpython/thinkpython.pdf\n[opensesamerun]: /usage/opensesamerun/\n[psychopy]: http://www.psychopy.org/\n[expyriment]: http://www.expyriment.org/\n[pygame]: http://www.pygame.org/", "url": "https://osdoc.cogsci.nl/4.0/manual/python/about", "title": "About Python"}
{"content": "# Common functions\n\ndummy", "url": "https://osdoc.cogsci.nl/4.0/manual/python/common", "title": "Common functions"}
{"content": "# Common functions\n\ntitle: Common functions\n\n<summary_prompt>\nWrite a summary for the API below:\n\n- Describe the API's overall functionality\n- Explain that this is a Python API for OpenSesame, software for implementing psychology experiments\n- Explain that these functions are commonly used in combination with Canvas functions\n- Explain that none of the listed functions need to be imported\n- Provide a bulleted list of all available functions and their parameters. Important: Don't just name the functions, but create one bullet per function.\n\nYour response should be a comprehensive summary.\n\n```markdown\n{content}\n```\n</summary_prompt>\n\nThe following functions are available in INLINE_SCRIPT items:\n\n[TOC]\n\n%-- include: include/api/python_workspace_api.md --%", "url": "https://osdoc.cogsci.nl/4.0/manual/python/common", "title": "Common functions"}
{"content": "# Canvas functions\n\ndummy", "url": "https://osdoc.cogsci.nl/4.0/manual/python/canvas", "title": "Canvas functions"}
{"content": "# Canvas functions\n\ntitle: Canvas functions\n\n<summary_prompt>\nWrite a summary for the API below:\n\n- Describe the API's overall functionality\n- Explain that this is a Python API for OpenSesame, software for implementing psychology experiments\n- Explain that `Canvas` and Element classes do not need to be imported\n- Explain the process to initialize a `Canvas`\n- Discuss three methods of drawing elements:\n    - Naming an Element interface (`my_canvas['name'] = FixDot()`)\n    - Adding an Element interface (`my_canvas += FixDot()`)\n    - Not preferred: function interface (`my_canvas.fixdot()`)\n- Illustrate how to modify named elements with an example\n- Define the usage of `**style_args`\n- Explain how to specify colors\n- Explain coordinates: x=0, y=0 is the display center\n- Provide a bulleted list of all available functions and their parameters. Important: Don't just name the functions, but create one bullet per function.\n\nYour response should be a comprehensive summary.\n\n```markdown\n{content}\n```\n</summary_prompt>\n\n%-- include: include/api/canvas.md --%", "url": "https://osdoc.cogsci.nl/4.0/manual/python/canvas", "title": "Canvas functions"}
{"content": "# Access items\n\ndummy", "url": "https://osdoc.cogsci.nl/4.0/manual/python/items", "title": "Access items"}
{"content": "# Access items\n\ntitle: Access items\n\n<summary_prompt>\nWrite a summary for the API below:\n\n- Describe the API's overall functionality\n- Explain that this is a Python API for OpenSesame, software for implementing psychology experiments\n- Explain that the `items` object does not need to be imported\n- Provide a bulleted list of all available functions and their parameters. Important: Don't just name the functions, but create one bullet per function.\n\nYour response should be a comprehensive summary.\n\n```markdown\n{content}\n```\n</summary_prompt>\n\n%-- include: include/api/items.md --%", "url": "https://osdoc.cogsci.nl/4.0/manual/python/items", "title": "Access items"}
{"content": "# Keyboard functions\n\ndummy", "url": "https://osdoc.cogsci.nl/4.0/manual/python/keyboard", "title": "Keyboard functions"}
{"content": "# Keyboard functions\n\ntitle: Keyboard functions\n\n<summary_prompt>\nWrite a summary for the API below:\n\n- Describe the API's overall functionality\n- Explain that this is a Python API for OpenSesame, software for implementing psychology experiments\n- Explain that the `Keyboard` class does not need to be imported\n- Explain the process to initialize a Keyboard\n- Define the usage of `**resp_args`\n- Explain how to specify key names\n- Provide a bulleted list of all available functions and their parameters. Important: Don't just name the functions, but create one bullet per function.\n\nYour response should be a comprehensive summary.\n\n```markdown\n{content}\n```\n</summary_prompt>\n\n%-- include: include/api/keyboard.md --%", "url": "https://osdoc.cogsci.nl/4.0/manual/python/keyboard", "title": "Keyboard functions"}
{"content": "# Access experimental variables\n\ndummy", "url": "https://osdoc.cogsci.nl/4.0/manual/python/var", "title": "Access experimental variables"}
{"content": "# Access experimental variables\n\ntitle: Access experimental variables\n\n<summary_prompt>\nWrite a summary for the API below:\n\n- Describe the API's overall functionality\n- Explain that this is a Python API for OpenSesame, software for implementing psychology experiments\n- Explain that the `var` object does not need to be imported\n- Explain that there are two ways to refer to experimental variables:\n    - Preferred: as global variables: (`my_var = 10`)\n    - Non-preferred: as properties of the `var` object (`var.my_var = 10`)\n- Provide a bulleted list of all available functions and their parameters. Important: Don't just name the functions, but create one bullet per function.\n\nYour response should be a comprehensive summary.\n\n```markdown\n{content}\n```\n</summary_prompt>\n\n%-- include: include/api/var.md --%", "url": "https://osdoc.cogsci.nl/4.0/manual/python/var", "title": "Access experimental variables"}
{"content": "# OpenSesame as a Python library (no GUI)\n\ntitle: OpenSesame as a Python library (no GUI)\n\nYou can also write experiments fully programmatically by using OpenSesame as a Python module. This is mainly suited for people who prefer coding over using a graphical user interface.\n\nUsing OpenSesame as a Python module works much the same way as using Python `inline_script` items in the user interface, with two notable exceptions:\n\n- Functions and classes need to be explicitly imported from `libopensesame.python_workspace_api`. All functions and classes described under [Common functions](%url:manual/python/common%) are available.\n- An `experiment` object needs to be explicitly created using the `Experiment()` factory function.\n\nA simple Hello World experiment looks like this:\n\n```python\nfrom libopensesame.python_workspace_api import \\\n  Experiment, Canvas, Keyboard, Text\n\n# Initialize the experiment window using the legacy backend\nexp, win, clock, log = Experiment(canvas_backend='legacy')\n# Prepare a stimulus canvas and a keyboard\ncnv = Canvas()\ncnv += Text('Hello world')\nkb = Keyboard()\n# Show the canvas, wait for a key press, and then end the experiment\ncnv.show()\nkb.get_key()\nexp.end()\n```\n\nYou can also programmatically open a `.osexp` experiment file and execute it:\n\n```python\nfrom libopensesame.python_workspace_api import Experiment\nexp, win, clock, log = Experiment(osexp_path='my_experiment.osexp',\n                                  subject_nr=2)\nexp.run()\n```", "url": "https://osdoc.cogsci.nl/4.0/manual/python/nogui", "title": "OpenSesame as a Python library (no GUI)"}
{"content": "# Sound\n\ntitle: Sound\n\nThe most common way to play sound is using the SAMPLER item, for playback of audio files, or the SYNTH item, for playback of simple beeps, etc.\n\n[TOC]\n\n## The sampler\n\nThe SAMPLER plays back a single sound file, typically from the file pool.\n\nSound files are always played back at the sampling rate that is used by the OpenSesame sampler backend. If your sample appears to be sped up (high pitch) or slowed down (low pitch), you can adjust the sampling rate of your sound file in a sound editor, or change the sampling rate used by the OpenSesame sampler backend (under 'Show backend settings and info' in the General tab).\n\nThe SAMPLER has a few options:\n\n- *Sound file* indicates the file to be played.\n- *Volume* between 0 (silent) and 1 (normal volume).\n- *Pan* turns the right (negative values) or left (positive values) channel down. For full panning, enter 'left' or 'right',\n- *Pitch* indicates the playback speed, where 1 corresponds to the original speed.\n- *Stop after* indicates for how long the sound file should be played. For example, a value of 100 ms means that playback will be stopped after 100 ms, regardless of how long the sound file is. A value of 0 ms means that the sound file will be played back completely.\n- *Fade in* indicates the fade-in time for the sound file. For example, a value of 100 ms means that the sound file will start silent, and build up to maximum value in 100 ms.\n- *Duration* indicates the duration of the sampler item, before the next item is presented. This doesn't need to match the length of the sound file. For example, if the duration of the sampler is set to 0 ms, OpenSesame will advance directly to the item that follows the SAMPLER (e.g., a sketchpad), *while the sound file continues playing in the background*. In addition to a numeric value, you can set duration to:\n\t- 'keypress' to wait for a key press\n\t- 'mouseclick' to wait for a mouse click\n\t- 'sound' to wait until the sampler has finished playing.\n\n## The synth\n\nThe SYNTH is a basic sound synthesizer.\n\nYou can specify a\nnumber of options:\n\n- *Waveform* can be set to sine, sawtooth, square, or white noise\n- *Attack* is the time it takes for the sound the reach maximum volume (i.e. fade in).\n- *Decay* is the time it takes for the sound to die out (i.e. fade out). Note that the decay occurs within the length of the sound.\n- *Volume* between 0 and 100%\n- *Pan* turns the right (negative values) or left (positive values) channel down. Setting pan to -20 or 20 completely mutes the right or left channel, respectively.\n- *Length* indicates the length of the sound (in milliseconds).\n- *Duration* indicates the duration of the SYNTH item, before the next item is presented. This doesn't need to match the length of the sound. For example, the duration of the SYNTH may be set to 0ms, in order to advance directly to the next item (e.g., a SKETCHPAD), while the sound continues playing in the background. In addition to a numeric value, you can set the duration to 'keypress', to wait for a keyboard press, 'mouseclick', to wait for a mouse click, or 'sound', to wait until the SYNTH has finished playing.\n\n## Sound playback in Python\n\nYou can use the SAMPLER object and the SYNTH function to present visual stimuli in Python:\n\n- %link:sampler%\n- %link:manual/python/common%\n\n\n## Audio Low Latency plugins\n\nThe main goal of the Audio Low Latency plugins, developed by Bob Rosbag, is to play and record audio with minimal and predictable latencies to achieve a high accuracy and precision. The `PyAlsaAudio` package which uses the Linux ALSA audio system provided the best results within Python. `PortAudio` and `sounddevice` are cross-platform and work on both Windows as Linux.\n\nThe plugins are not installed by default, but can be installed through pip:\n\n```bash\npip install opensesame-plugin-audio-low-latency\n```\n\nSee also:\n\n- <https://pypi.org/project/opensesame-plugin-audio-low-latency/>", "url": "https://osdoc.cogsci.nl/4.0/manual/stimuli/sound", "title": "Sound"}
{"content": "# Text\n\ntitle: Text\n\n[TOC]\n\n## How can I present text?\n\nThe most common way to show text is using a SKETCHPAD or FEEDBACK item. These allow you to enter text and other visual stimuli. For a questionnaire-like way to show text, you can use [forms](%link:manual/forms/about%).\n\n\n## HTML formatting\n\nYou can use a HTML tags, which you can simply insert into your text. You can use these tags everywhere: In SKETCHPAD items, in INLINE_SCRIPTs (provided you use the `Canvas` class), in forms, etc.\n\nExample:\n\n~~~ .html\nOpenSesame supports a sub-set of HTML tags:\n- <b>Bold face</b>\n- <i>Italic</i>\n- <u>Underline</u>\n\nIn addition, you can pass 'color', 'size', and 'style' as keywords to a 'span' tag:\n- <span style='color:red;'>Color</span>\n- <span style='font-size:32px;'>Font size</span>\n- <span style='font-family:serif;'>Font style</span>\n\nFinally, you can force newlines with the 'br' tag:\nLine 1<br>Line 2\n~~~\n\n\n## Variables and inline Python\n\nYou can embed variables in text using the `{...}` syntax. For example, the following:\n\n~~~ .python\nThe subject number is {subject_nr}\n~~~\n\n... might evaluate to (for subject 1):\n\n~~~ .python\nThe subject number is 1\n~~~\n\nYou can also embed Python expression. For example, the following:\n\n~~~ .python\nThe subject number modulo five is {subject_nr % 5}\n~~~\n\n... might evaluate to (for subject 7)\n\n~~~ .python\nThe subject number modulo five is 2\n~~~\n\n\n## Fonts\n\n### Default fonts\n\nYou can select one of the default fonts from the font-selection dialogs (%FigFontSelect). These fonts are included with OpenSesame and your experiment will therefore be fully portable when you use them.\n\n%--\nfigure:\n id: FigFontSelect\n source: font-selection-dialog.png\n caption: \"A number of default fonts, which are bundled with OpenSesame, can be selected through the font-selection dialogs.\"\n--%\n\nThe fonts have been renamed for clarity, but correspond to the following open-source fonts:\n\n|__Name in OpenSesame__\t\t|__Actual font__\t\t|\n|---------------------------|-----------------------|\n|`sans`\t\t\t\t\t\t|Droid Sans\t\t\t\t|\n|`serif`\t\t\t\t\t|Droid Serif\t\t\t|\n|`mono`\t\t\t\t\t\t|Droid Sans Mono\t\t|\n|`chinese-japanese-korean`\t|WenQuanYi Micro Hei\t|\n|`arabic`\t\t\t\t\t|Droid Arabic Naskh\t\t|\n|`hebrew`\t\t\t\t\t|Droid Sans Hebrew\t\t|\n|`hindi`\t\t\t\t\t|Lohit Hindi\t\t\t|\n\n### Selecting a custom font through the font-selection dialog\n\nIf you select 'other ...' in the font selection dialog, you can select any font that is available on your operating system. If you do this, your experiment is no longer fully portable, and will require that the selected font is installed on the system that you run your experiment on.\n\n### Placing a custom font in the file pool\n\nAnother way to use a custom font is to put a font file in the file pool. For example, if you place the font file `inconsolata.ttf` in the file pool, you can use this font in a SKETCHPAD item, like so:\n\n\tdraw textline 0.0 0.0 \"This will be inconsolata\" font_family=\"inconsolata\"\n\nNote that the font file must be a truetype `.ttf` file.", "url": "https://osdoc.cogsci.nl/4.0/manual/stimuli/text", "title": "Text"}
{"content": "# Video playback\n\ntitle: Video playback\n\n[TOC]\n\n\n## media_player_mpy plugin\n\nThe MEDIA_PLAYER_MPY plugin is based on MoviePy. It is included by default with the Windows and Mac OS packages of OpenSesame. If it is not installed, you can get it by installing the `opensesame-plugin-media-player-mpy` package, as described here:\n\n- <https://rapunzel.cogsci.nl/manual/environment/>\n\nThe source code is hosted at:\n\n- <https://github.com/dschreij/opensesame-plugin-mediaplayer>\n\n\n## OpenCV\n\nOpenCV is a powerful computer vision library, which contains (among many other things) routines for reading video files.\n\n- <http://docs.opencv.org/3.0-beta/doc/py_tutorials/py_tutorials.html>\n\nThe following example shows how to play back a video file, while drawing a red square on top of the video. This example assumes that you're using the legacy backend.\n\n~~~ .python\nimport cv2\nimport numpy\nimport pygame\n# Full path to the video file in file pool\npath = pool['myvideo.avi']\n# Open the video\nvideo = cv2.VideoCapture(path)\n# A loop to play the video file. This can also be a while loop until a key\n# is pressed. etc.\nfor i in range(100):\n    # Get a frame\n    retval, frame = video.read()\n    # Rotate it, because for some reason it otherwise appears flipped.\n    frame = numpy.rot90(frame)\n    # The video uses BGR colors and PyGame needs RGB\n    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n    # Create a PyGame surface\n    surf = pygame.surfarray.make_surface(frame)\n    # Now you can draw whatever you want onto the PyGame surface!\n    pygame.draw.rect(surf, (255,0,0), (100, 100, 200, 200))\n    # Show the PyGame surface!\n    exp.surface.blit(surf, (0, 0))\n    pygame.display.flip()\n~~~", "url": "https://osdoc.cogsci.nl/4.0/manual/stimuli/video", "title": "Video playback"}
{"content": "# Visual stimuli\n\ntitle: Visual stimuli\n\nThe most common way to present visual stimuli is using the SKETCHPAD item, or, for non-time-critical stimuli, the FEEDBACK item.\n\n\n[TOC]\n\n\n## Using the sketchpad and feedback items\n\nThe SKETCHPAD and FEEDBACK item offer basic what-you-see-is-what-you get drawing tools (%FigSketchpad).\n\n%--\nfigure:\n id: FigSketchpad\n source: sketchpad.png\n caption: The SKETCHPAD provides built-in drawing tools.\n--%\n\n\n## Using show-if expressions\n\nYou can use show-if expressions to determine whether or not a particular element should be shown. For example, if you have an image of a happy face that should be shown only when the variable `valence` has the value 'positive', then you can set the show-if expression for the corresponding image element to:\n\n```python\nvalence == 'positive'\n```\n\nIf you leave a show-if expression empty or enter `True`, element will always be shown. Show-if expressions use the same syntax as other conditional expressions. For more information, see:\n\n- %link:manual/variables%\n\nShow-if expressions are evaluated at the moment that the display is prepared. This means that for SKETCHPAD items, they are evaluated during the prepare phase, whereas for FEEDBACK items, they are evaluated during the run phase (see also the section below).\n\n\n## The difference between sketchpad and feedback items\n\nThe SKETCHPAD and FEEDBACK items are identical in most ways, except for two important differences.\n\n\n### Sketchpad items are prepared in advance, feedback items are not\n\nThe contents of a SKETCHPAD are prepared during the prepare phase of the SEQUENCE that it is part of. This is necessary to ensure accurate timing: It allows the SKETCHPAD to be shown right away during the run phase, without any delays due to stimulus preparation. However, the downside of this is that the contents of a SKETCHPAD cannot depend on what happens during the SEQUENCE that it is part of. For example, you cannot use a SKETCHPAD to provide immediate feedback on the response time collected by a KEYBOARD_RESPONSE item (assuming that the SKETCHPAD and KEYBOARD_RESPONSE are part of the same sequence.)\n\nIn contrast, the contents of a FEEDBACK item are only prepared when they are actually shown, that is, during the run phase of the SEQUENCE that it is part of. This makes it possible to provide feedback on things that just happened--hence the name. However, the FEEDBACK item should not be used to present time-critical stimuli, because it suffers from delays due to stimulus preparation.\n\nFor more information about the prepare-run strategy, see:\n\n- %link:prepare-run%\n\n\n### Feedback variables are (by default) reset by feedback items\n\nThe FEEDBACK item has an option 'Reset feedback variables'. When this option is enabled (it is by default), feedback variables are reset when the FEEDBACK item is shown.\n\nFor more information about feedback variables, see:\n\n- %link:manual/variables%\n\n\n## Presenting visual stimuli in Python inline script\n\n### Accessing a SKETCHPAD in Python\n\nYou can access the `Canvas` object for a SKETCHPAD as the items `canvas` property. For example, say that your SKETCHPAD is called *my_sketchpad*, and contains an image elements with the name 'my_image'. You could then have this image rotate with the following script:\n\n~~~ .python\nmy_canvas = items['my_sketchpad'].canvas\nfor angle in range(360):\n\tmy_canvas['my_image'].rotation = angle\n\tmy_canvas.show()\n~~~\n\n\n### Creating a Canvas in Python\n\nYou can use the `Canvas` object to present visual stimuli in Python:\n\n- %link:manual/python/canvas%", "url": "https://osdoc.cogsci.nl/4.0/manual/stimuli/visual", "title": "Visual stimuli"}
{"content": "# Intermediate tutorial (JavaScript): visual search\n\ntitle: Intermediate tutorial (JavaScript): visual search\n\n[TOC]\n\n## About OpenSesame\n\nOpenSesame is a user-friendly program for the development of behavioral experiments for psychology, neuroscience, and experimental economy. For beginners, OpenSesame has a comprehensive graphical, point-and-click interface. For advanced users, OpenSesame supports Python (desktop only) and JavaScript (desktop and browser).\n\nOpenSesame is freely available under the [General Public License v3][gpl].\n\n## About this tutorial\n\nThis tutorial shows how to create a basic visual-search experiment using OpenSesame [(Math\u00f4t, Schreij, & Theeuwes, 2012)][references]. We will use both the graphical interface and JavaScript to develop an experiment that you can run online in a browser. Some experience with OpenSesame and JavaScript is recommended. This tutorial takes approximately one hour.\n\nA Python-based version of this tutorial is also available. If you don't need to run your experiments online, then the Python tutorial is likely what you need:\n\n- %link:tutorials/intermediate%\n\n\n## Resources\n\n- __Download__ \u2014 This tutorial assumes that you are running OpenSesame version 4.0.0 or later and OSWeb 2.0 or later. You can download the most recent version of OpenSesame from:\n\t- %link:download%\n- __Documentation__ \u2014 A dedicated documentation website can be found at:\n\t- <http://osdoc.cogsci.nl/>\n- __Forum__ \u2014 A support forum can be found at:\n\t- <http://forum.cogsci.nl/>\n\n\n## The experiment\n\nIn this tutorial, you will create a basic visual-search experiment. The experiment resembles the classic visual-search studies of [Treisman and Gelade (1980)][references], but it is not identical.\n\nBefore starting to *build* the experiment for yourself, you can already *participate* in it. This will give you a good idea of what you're working towards in this tutorial.\n\n<a role=\"button\" class=\"btn btn-success btn-align-left\" href=\"https://jatos.mindprobe.eu/publix/1938/start?batchId=2191&generalMultiple\">Participate in the experiment!</a>\n\nIn this experiment, participants search for a target object, which can be a yellow square, a yellow circle, a blue square, or a blue circle; the identity of the target is varied between blocks of trials. Participants indicate whether the target is present or not by pressing the right (present) or left (absent) arrow key.\n\nIn addition to the target, zero or more distractor objects are shown. There are three conditions, and the condition determines what kind of distractors there are:\n\n- In the *Conjunction* condition, distractors can have any shape and color, with the only restriction that distractors cannot be identical to the target. So, for example, if the target is a yellow square, then distractors are yellow circles, blue circles, and blue squares.\n- In the *Shape Feature* condition, distractors have a different shape from the target, but can have any color. So, for example, if the target is a yellow square, then distractors are yellow circles and blue circles.\n- In the *Color Feature* condition, distractors can have any shape, but have a different color from the target. So, for example, if the target is a yellow square, then distractors are blue squares and blue circles.\n\nImmediate feedback is shown after each trial: a green dot after a correct response, and a red dot after an incorrect response. Detailed feedback on average response times and accuracy is shown after each block of trials.\n\n%--\nfigure:\n id: FigVisualSearch\n source: visual-search.svg\n caption: |\n  The visual-search experiment that you will implement in this tutorial.\n--%\n\nExperiments like this show two typical findings:\n\n- It takes more time to find the target in the Conjunction condition than in the two Feature conditions.\n- In the Conjunction condition, response times increase as the number of distractors increases. This suggests that people search for the target one item at a time; this is called *serial search*.\n- In the Feature conditions (both shape and color), response times do not, or hardly, increase as the the number of distractors increases. This suggests that people process the entire display at once; this is called *parallel search*.\n\nAccording to Treisman and Gelade's feature-integration theory, these results reflect that the Conjunction condition requires that you combine, or *bind*, the color and shape of each object. This binding requires attention, and you therefore need to shift your attention from one object to the next; this is slow, and explains why response times depend on how many objects there are. In contrast, in the Feature conditions, color and shape do not need to be bound, and therefore the whole display can be processed in a single sweep without attention being directed at each and every object.\n\n## Experimental design\n\nThis design:\n\n- Is *within-subject*, because all participants do all conditions\n- Is *fully-crossed* (or full factorial), because all combinations of conditions occur\n- Has three conditions (or factors):\n\t- Varied within blocks:\n\t\t- `set_size` with three levels (1, 5, 15), or SS<sub>3</sub>\n\t\t- `condition` with three levels (conjunction, feature_shape, feature_color), or CN<sub>3</sub>\n\t\t- `target_present` with two levels (present, absent), or TP<sub>2</sub>\n\t- Varied between blocks:\n\t\t- `target_shape` with two levels (square, circle), or TS<sub>2</sub>\n\t\t- `target_color` with two levels (yellow, blue), or TC<sub>2</sub>\n- Has N subjects, or <u>S</u><sub>N</sub>\n\nYou can write this design as <u>S</u><sub>N</sub>\u00d7SS<sub>3</sub>\u00d7CN<sub>3</sub>\u00d7TP<sub>2</sub>\u00d7TS<sub>2</sub>\u00d7TC<sub>2</sub>\n\nFor more information about this notation for experimental design, see:\n\n- %link:experimentaldesign%\n\n## Step 1: Create the basic structure of the experiment\n\nStart OpenSesame and, in the 'Get started!' tab, select the Extended template. This template provides the basic structure that is common to many cognitive-psychology experiments, such as the one that we will create here.\n\nThe Extended template contains a few items that we don't need. Delete the following items:\n\n- *about_this_template*\n- *practice_loop*\n- *end_of_practice*\n\nWhen you have deleted these items, they are still visible in the 'Unused items' bin. To permanently delete these items, click on the 'Unused items' bin, and then click on the 'Permanently delete unused items' button.\n\nFinally, give the experiment a good title, such as 'Visual search'. To do this, open the general-properties tab (by clicking on 'Extended template' in the overview area) and click on the experiment name to edit it.\n\nAlso configure OpenSesame to run the experiment in a browser, rather than on the desktop.\n\nThe overview area should now look like %FigStep1:\n\n%--\nfigure:\n id: FigStep1\n source: step1.png\n caption: |\n  The overview area at the end of step 1.\n--%\n\n\n## Step 2: Define experimental variables that are varied between blocks\n\nAs described above, two variables are varied between blocks in our experiment: `target_shape` and `target_color`. We therefore need to define these variables in the *experimental_loop*. To understand why, consider the structure shown in %FigStep1, starting from the bottom (i.e. the most indented level).\n\n- *trial_sequence* corresponds to a single trial\n- *block_loop* corresponds to a block of a trials\n\t- Therefore, variables defined here vary for each run of *trial_sequence*; in other words, variables defined in *block_loop* are varied __within blocks__.\n- *block_sequence* corresponds to a block of trials, preceded by resetting of the feedback variables, and followed by participant feedback\n- *experimental_loop* corresponds to multiple blocks of trials\n\t- Therefore, variables defined here vary for each run of *block_sequence*; in other words, variables defined in *experimental_loop* are varied __between blocks__.\n- *experiment* corresponds to the entire experimental, which is an instruction screen, followed by multiple blocks of trials, followed by an end-of-experiment screen\n\nClick on experimental loop, and define:\n\n- `target_shape`, which can be 'square' or 'circle'; and\n- `target_color`, which can be 'yellow' or 'blue'.\n\nWe have a full-factorial design, which means that all 2 \u00d7 2 = 4 combinations must occur. The table of *experimental_loop* should now look like %FigStep2:\n\n%--\nfigure:\n id: FigStep2\n source: step2.png\n caption: |\n  The table of *experimental_loop* at the end of step 2.\n--%\n\n## Step 3: Give instructions at the start of each block\n\nRight now, the experiment starts with a single *instructions* screen. In our case, we want to give instructions before each block of trials, to tell the participant what target to look for (because the identity of the target varies between blocks).\n\n__Move the instructions into block_sequence__\n\nTherefore, pick up the *instructions* item and drag it onto *block_sequence*. A pop-up will appear, asking you if you want to:\n\n- Insert the item into *block_sequence*, in which case *instructions* would become the first item of *block_sequence*; or\n- Insert the item after *block_sequence*, in which case *instructions* would move to a position after *block_sequence*.\n\nSelect the first option ('Insert into'). Now *block_sequence* starts with an instructions screen, which is what we want.\n\n__Add instructional text__\n\nClick on *instructions* to open it, and add a good instructional text, such as:\n\n```text\nINSTRUCTIONS\n\nSearch for the {target_color} {target_shape}\n\nPress the right-arrow key if you find it\nPress the left-arrow key if you don't\n\nPress any key to begin\n```\n\nThe curly braces brackets around '{target_color}' and '{target_shape}' indicate that these are not literal text, but refer to the variables that we have defined in *experimental_loop*. When the experiment runs, the values of these variables will appear here, and the participant will see (for example), 'Search for the yellow circle'.\n\n__Give a visual preview of the target__\n\nIt also good to show the participant the actual stimulus that she needs to find. To do this:\n\n- Draw a filled circle at the center of the display (make sure it doesn't overlap with the text);\n- Change the color of the circle to '{target_color}'. This means that the color of the circle depends on the value of the variable `target_color`; and\n- Change the show-if expression to `target_shape == 'circle'`. This is a Python expression that checks if the variable `target_shape` has the value 'circle'. Note that even though you *cannot* use full-fledged Python `inline_script` items when running experiments in a browser, you *can* use Python for these simple conditional expressions.\n\nIn other words, we have drawn a circle of which the color is determined by `target_color`; furthermore, this circle is only shown when the variable `target_shape` has the value 'circle'. For more information about variables and show-if statements, see:\n\n- %link:manual/variables%\n\nWe use the same trick to draw a square:\n\n- Draw a filled square at the center of the display;\n- Change the color of the square to '{target_color}'; and\n- Change the show-if statement to `target_shape == 'square'`\n\nThe *instructions*  screen should now look like %FigStep3:\n\n%--\nfigure:\n id: FigStep3\n source: step3.png\n caption: |\n  The *instructions* screen at the end of step 3.\n--%\n\n\n## Step 4: Define experimental variables that are varied within blocks\n\nThree variables are varied within blocks in our experiment: `condition`, `set_size`, and `target_present`. As described under Step 2, we need to define these variables in the *block_loop* so that they vary for each run of *trial_sequence*.\n\nThe three variables make a total of 3 \u00d7 3 \u00d7 2 = 18 different combinations. We can type these into the table manually, but, because we have full-factorial design, we can also use the full-factorial-design wizard. To do this, first open *block_loop* and click on the 'Full-factorial design' button.\n\nIn the table that appears, put the variable names on the first row, and the values on the rows below, as shown in %FigFullFactorial.\n\n%--\nfigure:\n id: FigFullFactorial\n source: fullfactorial.png\n caption: |\n  The *instructions* screen at the end of step 3.\n--%\n\nNow click on 'Ok' to generate the full design. The table of *block_loop* should now look like %FigStep4.\n\n%--\nfigure:\n id: FigStep4\n source: step4.png\n caption: |\n  The table of *block_loop* at the end of step 4.\n--%\n\n## Step 5: Create the trial sequence and add an initialization script\n\nWe want our trial sequence to look as follows:\n\n- A fixation dot, for which we will use a SKETCHPAD.\n- A search display, which we will create in JavaScript with a custom INLINE_JAVASCRIPT.\n- Response collection, for which we will use a KEYBOARD_RESPONSE.\n- Data logging, for which we will use a LOGGER.\n- (We also want immediate feedback after each trial, but we will get back to this later.)\n\nSo the only thing that is missing from *trial_sequence* is an INLINE_JAVASCRIPT.\n\n- Insert a new INLINE_JAVASCRIPT after *sketchpad* and rename it to *search_display_script*.\n- Rename *sketchpad* to *fixation_dot*, so that its function is clear; and\n- Change the duration of *fixation_dot* to 500, so that the fixation dot is shown for 500 ms. (There should already be a fixation dot drawn; if not, draw one in the center of *fixation_dot*.)\n\nWe also need to add a initialization script to start of the experiment. We will use this only to define (`let`) a variable that will hold the `Canvas` object on which we will draw. In JavaScript, you have to define a variable exactly once, which is why we cannot do that in the *trial_sequence*.\n\n- Insert a new INLINE_JAVASCRIPT at the top of the *experiment* sequence and rename it to *init*.\n\nThe overview area should now look like %FigStep5.\n\n%--\nfigure:\n id: FigStep5\n source: step5.png\n caption: |\n  The overview area at the end of step 5.\n--%\n\n## Step 6: Generate the search display\n\n__Top-down and defensive programming__\n\nNow things will get interesting: We will start programming in JavaScript. We will use two guiding principles: *top-down* and *defensive* programming.\n\n- *Top-down programming* means that we start with the most abstract logic, without bothering with how this logic is implemented. Once the most abstract logic is in place, we will move down to a slightly less abstract logic, and so on, until we arrive at the details of the implementation. This technique helps to keep the code structured.\n- *Defensive programming* means that we assume that we make mistakes. Therefore, to protect us from ourselves, we build sanity checks into the code.\n\n*Note:* The explanation below assumes that you're somewhat familiar with JavaScript. If concepts like `Array`, `for` loop, and functions don't mean anything to you, then it's best to first walk through an introductory JavaScript tutorial. You can find links to JavaScript tutorials here:\n\n- %link:manual/javascript/about%\n\nThe logic of the code is shown in %FigHierarchy. The numbers indicate the order in which we will implement the functionality, starting at the abstract level.\n\n%--\nfigure:\n id: FigHierarchy\n source: hierarchy.svg\n caption: |\n  The logic of the code to draw a visual-search display.\n--%\n\n__Declaring variables with let, var, and const__\n\nIn JavaScript, you have to 'declare' a variable before you can use it. (In Python, this is not necessary.) In our case, we will use a variable called `c`, which we therefore need to declare. To do so, open the Prepare tab of the *init* script and use the `let` keyword to declare the variable `c`:\n\n```js\nlet c\n```\n\nThere are three different ways to declare variables:\n\n- Using `let`, as we've done here. In OpenSesame, this makes the variable available in JavaScript but not as an experimental variable in the user interface.\n- Using `var`. In OpenSesame, this makes the variable also available as an experimental variable in the user interface. (We will do that later for the variable `correct_response`.)\n- Using `const`. This is like `var` with the important difference that the variable cannot be re-assigned later.\n\n\n__The Prepare and Run phases__\n\nOpen *search_display_script* and switch to the Prepare tab. OpenSesame distinguishes two phases of execution:\n\n- During the Prepare phase, each item is given the opportunity to prepare itself; what this means depends on the item: For a SKETCHPAD, it means drawing a canvas (but not showing it); for a SAMPLER, it means loading a sound file (but not playing it); etc.\n- During the Run phase, each item is actually executed; again, what this means depends on the item: For a SKETCHPAD, it means showing the previously prepared canvas; for a SAMPLER, it means playing a previously loaded sound file.\n\nFor an INLINE_JAVASCRIPT, you have to decide yourself what to put in the Prepare phase, and what to put in the Run phase. The distinction is usually quite clear: In our case, we put the code for drawing the canvas in the Prepare phase, and the code for showing the canvas (which is small) in the Run phase.\n\nSee also:\n\n- %link:prepare-run%\n\n\n__Implement the abstract level__\n\nWe start at the most abstract level: defining a function that draws a visual-search display. We don't specify *how* this is done; we simply assume that there is a function that does this, and we will worry about the details later\u2014that's top-down programming.\n\nIn the Prepare tab, enter the following code:\n\n```js\nc = draw_canvas()\n```\n\nWhat happens here? We \u2026\n\n- Call `draw_canvas()`, which returns a `Canvas` object that we store as `c`; in other words, `c` is a `Canvas` object that corresponds the search display. This assumes that there is a function `draw_canvas()`, even though we haven't defined it yet.\n\nA `Canvas` object is a single display; it is, in a sense, the JavaScript counterpart of a SKETCHPAD. See also:\n\n- %link:manual/javascript/canvas%\n\nWe now go one step down by defining `draw_canvas()` (above the rest of the script so far):\n\n```js\n/**\n * Draws the search canvas.\n * @return A Canvas\n **/\nfunction draw_canvas() {\n    let c = Canvas()\n    let xy_list = xy_random(set_size, 500, 500, 75)\n    if (target_present === 'present') {\n        let [x, y] = xy_list.pop()\n        draw_target(c, x, y)\n    } else if (target_present !== 'absent') {\n        throw 'Invalid value for target_present ' + target_present\n    }\n    for (let [x, y] of xy_list) {\n        draw_distractor(c, x, y)\n    }\n    return c\n}\n```\n\n\nWhat happens here? We \u2026\n\n- Create an empty canvas, `c`, using the factory function `Canvas()`.\n- Generate an array of random `x, y` coordinates, called `xy_list`, using another common function, `xy_random()`. This array determines where the stimuli are shown. Locations are sampled from a 500 \u00d7 500 px area with a minimum spacing of 75 px.\n- Check if the experimental variable `target_present` has the value 'present'; if so, `pop()` one `x, y` tuple from `xy_list`, and draw the target at this location. This assumes that there is a function `draw_target()`, even though we haven't defined it yet.\n- If `target_present` is neither 'present' nor 'absent', we `throw` an error; this is defensive programming, and protects us from typos (e.g. if we had accidentally entered 'presenr' instead of 'present').\n- Loop through all remaining `x, y` values and draw a distractor at each position. This assumes that there is a function `draw_distractor()`, even though we haven't defined it yet.\n- Return `c`, which now has the search display drawn onto it.\n\nThere are several common functions, such as `Canvas()` and `xy_random()`, which are always available in an INLINE_JAVASCRIPT item. See:\n\n- %link:manual/javascript/common%\n\nExperimental variables are global variables. That's why you can refer to `set_size`, which is defined in *block_loop*, even though the variable `set_size` is never explicitly defined in the script. The same is true for `target_shape`, `target_color`, `condition`, etc. See:\n\n- %link:var%\n\n\n__Implement the intermediate level__\n\nWe now go one more step down by defining `draw_target` (above the rest of the script so far):\n\n```js\n/**\n * Draws the target.\n * @param c A Canvas\n * @param x An x coordinate\n * @param y A y coordinate\n **/\nfunction draw_target(c, x, y) {\n    draw_shape(c, x, y, target_color, target_shape)\n}\n```\n\nWhat happens here? We \u2026\n\n- Call another function, `draw_shape()`, and specify the color and shape that needs to be drawn. This assumes that there is a function `draw_shape()`, even though we haven't defined it yet.\n\nWe also define `draw_distractor` (above the rest of the script so far):\n\n```js\n/**\n * Draws a single distractor.\n * @param c A Canvas\n * @param x An x coordinate\n * @param y A y coordinate\n **/\nfunction draw_distractor(c, x, y) {\n    if (condition === 'conjunction') {\n        draw_conjunction_distractor(c, x, y)\n    } else if (condition === 'feature_shape') {\n        draw_feature_shape_distractor(c, x, y)\n    } else if (condition === 'feature_color') {\n        draw_feature_color_distractor(c, x, y)\n    } else {\n        throw 'Invalid condition: ' + condition\n    }\n}\n```\n\nWhat happens here? We \u2026\n\n- Call another function to draw a more specific distractor depending on the Condition.\n- Check whether `condition` has any of the expected values. If not, we `throw` an error. This is defensive programming! Without this check, if we made a typo somewhere, the distractor might simply not be shown without causing an error message.\n\nNow we define the function that draws distractors in the Conjunction condition (above the rest of the script so far):\n\n```js\n/**\n * Draws a single distractor in the conjunction condition: an object that\n * can have any shape and color, but cannot be identical to the target.\n * @param c A Canvas.\n * @param x An x coordinate.\n * @param y A y coordinate.\n **/\nfunction draw_conjunction_distractor(c, x, y) {\n    let conjunctions = [\n        ['yellow', 'circle'],\n        ['blue', 'circle'],\n        ['yellow', 'square'],\n        ['blue', 'square']\n    ]\n    let [color, shape] = random.pick(conjunctions)\n    while (color === target_color && shape === target_shape) {\n        [color, shape] = random.pick(conjunctions)\n    }\n    draw_shape(c, x, y, color, shape)\n}\n```\n\nWhat happens here? We \u2026\n\n- Define a list, `conjunctions`, of all possible color and shape combinations.\n- Randomly select one of the color and shape combinations from `conjunctions`.\n- Check if the selected color and shape are both equal to the color and shape of the target. If so, keep selecting a new color and shape until this is no longer the case. After all, the distractor cannot be identical to the target!\n- Call another function, `draw_shape()`, and specify the color and shape of the to-be-drawn distractor. This assumes that there is a function `draw_shape()`, even though we haven't defined it yet.\n\nIn addition, we \u2026\n\n- Use the `random` library, which is corresponds to the `random-ext` package. This library contains useful randomization functions (such as `random.pick()`) and is one of the non-standard JavaScript libraries that is included with OSWeb.\n\nNow we define the function that draws distractors in the Shape Feature condition (above the rest of the script so far):\n\n```js\n/**\n * Draws a single distractor in the feature-shape condition: an object that\n * has a different shape from the target, but can have any color.\n * @param c A Canvas.\n * @param x An x coordinate.\n * @param y A y coordinate.\n **/\nfunction draw_feature_shape_distractor(c, x, y) {\n    let colors = ['yellow', 'blue']\n    let color = random.pick(colors)\n    let shape\n    if (target_shape === 'circle') {\n        shape = 'square'\n    } else if (target_shape === 'square') {\n        shape = 'circle'\n    } else {\n        throw 'Invalid target_shape: ' + target_shape\n    }\n    draw_shape(c, x, y, color, shape)\n}\n```\n\nWhat happens here? We \u2026\n\n- Randomly select a color.\n- Choose a square shape if the target is a circle, and a circle shape if the target is square.\n- If `target_shape` is neither 'circle' nor 'square', `throw` an error\u2014more defensive programming!\n- Call another function, `draw_shape()`, and specify the color and shape of the to-be-drawn distractor. This assumes that there is a function `draw_shape()`, even though we haven't defined it yet.\n\nNow we define the function that draws distractors in the Color Feature condition (above the rest of the script so far):\n\n```js\n/**\n * Draws a single distractor in the feature-color condition: an object that\n * has a different color from the target, but can have any shape.\n * @param c A Canvas.\n * @param x An x coordinate.\n * @param y A y coordinate.\n **/\nfunction draw_feature_color_distractor(c, x, y) {\n    let shapes = ['circle', 'square']\n    let shape = random.pick(shapes)\n    let color\n    if (target_color === 'yellow') {\n        color = 'blue'\n    } else if (target_color === 'blue') {\n        color = 'yellow'\n    } else {\n        throw 'Invalid target_color: ' + target_color\n    }\n    draw_shape(c, x, y, color, shape)\n}\n```\n\nWhat happens here? We \u2026\n\n- Randomly select a shape.\n- Choose a blue color if the target is yellow, and a yellow color if the target is blue.\n- If `target_color` is neither 'yellow' nor 'blue', `throw` and error\u2014more defensive programming!\n- Call another function, `draw_shape()`, and specify the color and shape of the to-be-drawn distractor. This assumes that there is a function `draw_shape()`, even though we haven't defined it yet.\n\n__Implement the detailed level__\n\nNow we go all the way down to the details by defining the function that actually draws a shape to the canvas (above the rest of the script so far):\n\n```js\n/**\n * Draws a single shape.\n * @param c A Canvas.\n * @param x An x coordinate.\n * @param y A y coordinate.\n * @param color A color (yellow or blue)\n * @param shape A shape (square or circle)\n **/\nfunction draw_shape(c, x, y, color, shape) {\n    if (shape === 'square') {\n        // Parameters are passed as an Object!\n        c.rect({x:x-25, y:y-25, w:50, h:50, color:color, fill:true})\n    } else if (shape === 'circle') {\n        // Parameters are passed as an Object!\n        c.circle({x:x, y:y, r:25, color:color, fill:true})\n    } else {\n        throw 'Invalid shape: ' + shape\n    }\n    if (color !== 'yellow' && color !== 'blue') {\n        throw 'Invalid color: ' + color\n    }\n}\n```\n\nWhat happens here? We \u2026\n\n- Check which shape should be drawn. For squares, we add a `rect()` element to the canvas. For circles, we add a `circle()` element.\n- Check if the the shape is either a square or a circle, and if not `throw` and error. This is another example of defensive programming! We're making sure that we haven't accidentally specified an invalid shape.\n- Check if the the color is neither yellow nor blue, and if not `throw` and error.\n\nImportantly, `Canvas` functions accept a single object (`{}`) that specifies all parameters by name, like so:\n\n```js\n// Correct: pass a single object that contains all parameters by name\nc.rect({x:x-25, y:y-25, w:50, h:50, color:color, fill:true})\n// Incorrect: do not pass parameters by order\n// c.rect(x-25, y-25, 50, 50, color, true)\n// Incorrect: named parameters are not supported in JavaScript\n// c.rect(x=x-25, y=y-25, w=50, h=50, color=color, fill=true)\n```\n\n__Implement the Run phase__\n\nBecause we have done all the hard work in the Prepare phase, the Run phase is just:\n\n```js\nc.show()\n```\n\nThat's it! Now you have drawn a full visual-search display. And, importantly, you have done so in a way that is easy to understand, because of top-down programming, and safe, because of defensive programming.\n\n", "url": "https://osdoc.cogsci.nl/4.0/tutorials/intermediate-javascript", "title": "Intermediate tutorial (JavaScript): visual search"}
{"content": "# Intermediate tutorial (JavaScript): visual search\n\n## Step 7: Define the correct response\n\nTo know if the participant responds correctly, we need to know the correct response. You can define this explicitly in the *block_loop* (as done in the beginner tutorial); but here we're going to use some simple JavaScript that checks whether the target is present or not, and defines the correct response accordingly.\n\nTo do this, we first need to declare the variable in the Prepare tab of the *init* script, just below `let c`. This time, we use the `var` keyword to declare `correct_response`, because this makes the variable available in the user interface (whereas `let` does not do this):\n\n```js\nvar correct_response\n```\n\nNext, insert a new INLINE_JAVASCRIPT at the start of *trial_sequence*, and rename it to *correct_response_script*. In the Prepare phase, enter the following code:\n\n```js\nif (target_present === 'present') {\n    correct_response = 'right'\n} else if (vars.target_present === 'absent') {\n    correct_response = 'left'\n} else {\n    throw 'target_present should be absent or present, not ' + target\n}\n```\n\nWhat happens here? We \u2026\n\n- Check whether the target is present or not. If the target is present, the correct response is 'right' (the right arrow key); if the target is absent, the correct response is 'left' (the left arrow key). The experimental variable `correct_response` is automatically used by OpenSesame; therefore, we don't need to explicitly indicate that this variable contains the correct response.\n- Check if the target is either present or absent, and if not `throw` an error\u2014another example of defensive programming.\n\n## Step 8: Give per-trial feedback\n\nFeedback after every trial can motivate participants; however, per-trial feedback should not interfere with the flow of the experiment. A good way to give per-trial feedback is to briefly show a green fixation dot after a correct response, and a red fixation dot after an incorrect response.\n\nTo do this:\n\n- Insert two new SKETCHPADs into *trial_sequence*, just after *keyboard_response*.\n- Rename one SKETCHPAD to *green_dot*, draw a central green fixation dot onto it, and change its duration to 500.\n- Rename the other SKETCHPAD to *red_dot*, draw a central red fixation dot onto it, and change its duration to 500.\n\nOf course, only one of the two dots should be shown on each trial. To accomplish this, we will specify run-if statements in *trial_sequence*:\n\n- Change the run-if statement for *green_dot* to 'correct == 1', indicating that it should only be shown after a correct response.\n- Change the run-if statement for *red_dot* to 'correct == 0', indicating that it should only be shown after an incorrect response.\n\nThe variable `correct` is automatically created if the variable `correct_response` is available; that's why we defined `correct_response` in step 7. For more information about variables and run-if statements, see:\n\n- %link:manual/variables%\n\nThe *trial_sequence* should now look like %FigStep8.\n\n%--\nfigure:\n id: FigStep8\n source: step8.png\n caption: |\n  The *trial_sequence* at the end of step 8.\n--%\n\n\n## Finished!\n\nCongratulations, the experiment is complete! You can give it a test run by pressing on the toolbar button that shows a green circle with a gray play button inside (shortcut: `Alt+Ctrl+W`).\n\nIf the experiment doesn't work on the first try: Don't worry, and calmly figure out where the mistake comes from. Crashes are part of the normal development process. But you can save yourself a lot of time and headache by working in a structured way, as we have done in this tutorial.\n\n## References\n\n<div class='reference' markdown='1'>\n\nMath\u00f4t, S., Schreij, D., & Theeuwes, J. (2012). OpenSesame: An open-source, graphical experiment builder for the social sciences. *Behavior Research Methods*, *44*(2), 314-324. doi:10.3758/s13428-011-0168-7\n\nTreisman, A. M., & Gelade, G. (1980). A feature-integration theory of attention. *Cognitive Psychology*, 12(1), 97\u2013136. doi:10.1016/0010-0285(80)90005-5\n\n</div>\n\n[references]: #references\n[gpl]: http://www.gnu.org/licenses/gpl-3.0.en.html", "url": "https://osdoc.cogsci.nl/4.0/tutorials/intermediate-javascript", "title": "Intermediate tutorial (JavaScript): visual search"}
{"content": "# Beginner tutorial: gaze cuing\n\ntitle: Beginner tutorial: gaze cuing\n\n[TOC]\n\n## About OpenSesame\n\nOpenSesame is a program for easy of development of behavioral experiments for psychology, neuroscience, and experimental economy. For beginners, OpenSesame has a comprehensive graphical, point-and-click interface. For advanced users, OpenSesame supports Python scripting (not covered in this tutorial).\n\nOpenSesame is freely available under the [General Public License v3][gpl].\n\n## About this tutorial\n\nThis tutorial shows how to create a simple but complete psychological experiment using OpenSesame [(Math\u00f4t, Schreij, & Theeuwes, 2012; Math\u00f4t & March, 2022)][references]. You will use mainly the graphical user interface of OpenSesame (i.e., no Python inline coding), although you will make small modifications to the OpenSesame script. This tutorial takes approximately one hour.\n\n## Resources\n\n- __Download__ -- This tutorial assumes that you are running OpenSesame version 4.0.0 or later. To check which version you are running, see the bottom right of the 'Get started' tab (see %FigGetStarted). You can download the most recent version of OpenSesame from:\n\t- %link:download%\n- __Documentation__ -- A dedicated documentation website can be found at:\n\t- <http://osdoc.cogsci.nl/>\n- __Forum__ -- A support forum can be found at:\n\t- <http://forum.cogsci.nl/>\n\n## The experiment\n\nIn this tutorial, you will create a gaze-cuing experiment as introduced by [Friesen and Kingstone (1998)][references]. In this experiment, a face is presented in the center of the screen (%FigGazeCuing). This face looks either to the right or to the left. A target letter (an 'F' or an 'H') is presented to the left or right of the face. A distractor stimulus (the letter 'X') is presented on the other side of the face. The task is to indicate as quickly as possible whether the target letter is an 'F' or an 'H'. In the congruent condition, the face looks at the target. In the incongruent condition, the face looks at the distractor. As you may have guessed, the typical finding is that participant respond faster in the congruent condition than in the incongruent condition, even though the direction of gaze is not predictive of the target location. This shows that our attention is automatically guided by other people's gaze, even in situations where this doesn't serve any purpose. (And even when the face is just a smiley!)\n\n%--\nfigure:\n id: FigGazeCuing\n source: gaze-cuing.png\n caption: |\n  The gaze-cuing paradigm [(Friesen and Kingstone, 1998)][references] that you will implement in this tutorial. This example depicts a trial in the incongruent condition, because the smiley looks at the distractor ('X') and not at the target ('F').\n--%\n\nThe experiment consists of a practice and an experimental phase. Visual feedback will be presented after every block of trials. A sound will be played after every incorrect response.\n\n## Experimental design\n\nThis design:\n\n- is *within-subject*, because all participants do all conditions\n- is *fully crossed* (or full-factorial), because all combinations of conditions occur\n- has three factors (or factors):\n    - *gaze side* with two levels (left, right)\n    - *target side* with two levels (left, right)\n    - *target letter* with two levels (F, H)\n- has N subjects\n\n\nSee also %DesignScreencast for an explanation of the logic and design of the experiment:\n\n\n%--\nvideo:\n source: youtube\n id: DesignScreencast\n videoid: aWvibRH6D4E\n width: 640\n height: 360\n caption: |\n  An explanation of the experimental logic and design.\n--%\n\n\n## Step 1: Create the main sequence\n\nWhen you start OpenSesame, you see the 'Get started!' tab (%FigGetStarted). A list of templates is shown below 'Start a new experiment'. These templates provide convenient starting points for new experiments. After you saved an experiment the first time, recently opened experiments are shown under 'Continue with a recent experiment'. At the bottom of the page there are links to the documentation (which includes this tutorial), the community forum, and a page with professional (paid) support options. And of course a link where you can buy us a cup of coffee to help us stay awake while we are working on providing the best free software!\n\n%--\nfigure:\n id: FigGetStarted\n source: get-started.png\n caption: |\n  The 'Get started' dialog on OpenSesame start-up.\n--%\n\nClick on 'Default template' to start with a minimal experimental template.\n\nBy default there is a main SEQUENCE, which is simply called *experiment*. Click on *experiment* in the overview area (by default on the left side, see %FigInterface) to open its controls in the tab area. The *experiment* SEQUENCE consists of two items: a `notepad` called *getting started* and a SKETCHPAD called *welcome*.\n\nWe don't need these two items. Remove *getting_started* by right-clicking on it in the overview area and selecting 'Delete' (shortcut: `Del`). Remove *welcome* in the same way. The *experiment* SEQUENCE is now empty.\n\n%--\nfigure:\n id: FigInterface\n source: interface.png\n caption: \"The default layout of the OpenSesame interface.\"\n--%\n\n<div class='info-box' markdown='1'>\n\n__Background box__\n\n__Names vs types__ -- Items in OpenSesame have a name and a type. The name and type can be the same, but they are usually not. For example, a SKETCHPAD item can have the name *my_target_sketchpad*. To make this distinction clear, we will use `monospace` to indicate item types, and *italics* to indicate names.\n\n__Tip__ -- The 'Extended template' is a good starting point for many experiments. It already contains the basic structure of a trial-based experiment.\n\n__Tip__ -- You can click on the Help icons in the top right of an item's tab to get context-sensitive help.\n\n__Tip__ -- Save (shortcut: `Ctrl+S`) your experiment often! In the unfortunate (and unlikely) event of data loss, you will often be able to recover your work from the back-ups that are created automatically, by default, every 10 minutes (Menu \u2192 Tools \u2192 Open backup folder).\n\n__Tip__ -- Unless you have used 'Permanently delete' (shortcut: `Shift+Del`), deleted items are still available in the 'Unused items' bin, until you select 'Permanently delete unused items' in the 'Unused items' tab. You can re-add deleted items to a SEQUENCE by dragging them out of the 'Unused items' bin to somewhere in your experiment.\n\n__Tip__ -- %FigExperimentStructure schematically shows the structure of the experiment that you will create. If you get confused during the tutorial, you can refer to %FigExperimentStructure to see where you are.\n\n%--\nfigure:\n id: FigExperimentStructure\n source: experiment-structure.png\n caption: |\n  A schematic representation of the structure of the 'Gaze cuing' experiment. The item types are in bold face, item names in regular face.\n--%\n\n</div>\n\n__Append a form_text_display item for the instruction display__\n\nAs the name suggests, a `form_text_display` is a form that displays text. We are going to use a `form_text_display` to give instructions to the participant at the beginning of the experiment.\n\nClick on *experiment* in the overview area to open its controls in the tab area. You will see an empty SEQUENCE. Drag a `form_text_display` from the item toolbar (under 'Form', see %FigInterface) onto the *experiment* SEQUENCE in the tab area. When you let go, a new `form_text_display` item will be inserted into the SEQUENCE. (We will get back to this in Step 12.)\n\n<div class='info-box' markdown='1'>\n\n__Background box__\n\n__Tip__ -- You can drag items into the overview area and into SEQUENCE tabs.\n\n__Tip__ -- If a drop action is ambiguous, a pop-up menu will ask you what you want to do.\n\n__Tip__ -- A `form_text_display` only shows text. If you require images etc., you can use a SKETCHPAD item. We will meet the SKETCHPAD in Step 5.\n\n</div>\n\n__Append a loop item, containing a new sequence item, for the practice phase__\n\nWe need to append a LOOP item to the *experiment* SEQUENCE. We will use this LOOP for the practice phase of the experiment. Click on the *experiment* SEQUENCE to open its controls in the tab area.\n\nDrag the LOOP item from the item toolbar into the SEQUENCE just the way you added the `form_text_display`. New items are inserted below the item that they are dropped on, so if you drop the new LOOP onto the previously created `form_text_display`, it will appear where you want it: after the `form_text_display`. But don't worry if you drop a new item in the wrong place, because you can always re-order things later.\n\nBy itself, a LOOP does not do anything. A LOOP always needs another item to run. Therefore, you have to fill the new LOOP item with another item. (If you view the loop item, you will also see a warning: 'No item selected'.) Drag a SEQUENCE item from the item toolbar onto the LOOP item. A pop-up menu will appear, asking you whether you want to insert the SEQUENCE after or into the LOOP item. Select 'Insert into new_loop'. (We will get back to this in Step 2.)\n\n<div class='info-box' markdown='1'>\n\n__Background box__\n\n__What is a LOOP item?__ -- A LOOP is an item that adds structure to your experiment. It repeatedly runs another item, typically a SEQUENCE. A LOOP is also the place where you will usually define your independent variables, that is, those variables that you manipulate in your experiment.\n\n__What is a SEQUENCE item?__ -- A SEQUENCE item also adds structure to your experiment. As the name suggests, a SEQUENCE runs multiple other items one after another.\n\n__The LOOP-SEQUENCE structure__ -- You often want to repeat a sequence of events. To do this, you will need a LOOP item that contains a SEQUENCE item. By itself, a SEQUENCE does not repeat. It simply starts with the first item and ends with the last item. By 'wrapping' a LOOP item around the SEQUENCE, you can repeat the SEQUENCE multiple times. For example, a single trial usually corresponds to a single SEQUENCE called *trial_sequence*. A LOOP (often called *block_loop*) around this *trial_sequence* would then constitute a single block of trials. Similarly, but at another level of the experiment, a SEQUENCE (often called *block_sequence*) may contain a single block of trials, followed by a FEEDBACK display. A *practice_phase* LOOP around this 'block' SEQUENCE would then constitute the practice phase of the experiment. This may seem a bit abstract right now, but as you follow this tutorial, you will become familiar with the use of LOOPs and SEQUENCEs.\n\n__Tip__ -- For more information about SEQUENCEs and LOOPs, see:\n\n- %link:loop%\n- %link:sequence%\n\n</div>\n\n__Append a new form_text_display item for the end-of-practice message__\n\nAfter the practice phase, we want to inform the participant that the real experiment will begin. For this we need another `form_text_display`. Go back to the *experiment* SEQUENCE, and drag a `form_text_display` from the item toolbar onto the LOOP item. The same pop-up menu will appear as before. This time, select 'Insert after new_loop'. (We will get back to this in Step 12.)\n\n<div class='info-box' markdown='1'>\n\n__Tip__ -- Don't worry if you have accidentally changed a LOOP's item to run. You can undo this easily by clicking the 'Undo' button in the toolbar (`Ctrl+Shift+Z`).\n\n</div>\n\n__Append a new loop item, containing the previously created sequence, for the experimental phase__\n\nWe need a LOOP item for the experimental phase, just like for the practice phase. Therefore, drag a LOOP from the item toolbar menu onto *_form_text_display*.\n\nThe newly created LOOP (called *new_loop_1*) is empty, and should be filled with a SEQUENCE, just like the LOOP we created before. However, because the trials of the practice and experimental phase are identical, they can use the same SEQUENCE. Therefore, instead of dragging a new SEQUENCE from the item toolbar, you can re-use the *existing* one (i.e. create a linked copy).\n\nTo do this, right-click on the previously created *new_sequence*, and select 'Copy (linked)'. Now, right-click on *new_loop_1* and select 'Paste'. In the pop-up menu that appears, select 'Insert into new_loop 1'.\n\n<div class='info-box' markdown='1'>\n\n__Background box__\n\n__Tip__ \u2014 There is an important distinction between *linked* and *unlinked* copies. If you create a linked copy of an item, you create another occurrence of the same item. Therefore, if you modify the original item, the linked copy will change as well. In contrast, if you create an unlinked copy of an item, the copy will be initially look identical (except for its name), but you can edit the original without affecting the unlinked copy, and vice versa.\n\n</div>\n\n__Append a new form_text_display item, for the goodbye message__\n\nWhen the experiment is finished, we should say goodbye to the participant. For this we need another `form_text_display` item. Go back to the *experiment* SEQUENCE, and drag a `form_text_display` from the item toolbar onto *new_loop_1*. In the pop-up menu that appears, select 'Insert after new_loop_1'. (We will get back to this in Step 12.)\n\n__Give the new items sensible names__\n\nBy default, new items have names like *new_sequence* and *new_form_text_display_2*. It is good practice to give items sensible names. This makes it much easier to understand the structure of the experiment. If you want, you can also add a description to each item. Item names must consist of alphanumeric characters and/or underscores.\n\n- Select *new_form_text_display* in the overview area, double-click on its label in the top of the tab area and rename the item to *instructions*. (Overview-area shortcut: `F2`)\n- Rename *new_loop* to *practice_loop*.\n- Rename *new_sequence* to *block_sequence*. Because you have re-used this item in *new_loop_1*, the name automatically changes there as well. (This illustrates why it is efficient to create linked copies whenever this is possible.)\n- Rename *new_form_text_display_1* to *end_of_practice*.\n- Rename *new_loop_1* to *experimental_loop*.\n- Rename *new_form_text_display_2* to *end_of_experiment*.\n\n__Give the whole experiment a sensible name__\n\nThe experiment in its entirety also has a title and a description. Click on 'New experiment' in the overview area. You can rename the experiment in the same way as you renamed its items. The title currently is 'New experiment'. Rename the experiment to 'Tutorial: Gaze cuing'. Unlike item names, the experiment title may contain spaces etc.\n\nThe overview area of your experiment now looks like %FigStep1. This would be a good time to save your experiment (shortcut: `Ctrl+S`).\n\n%--\nfigure:\n id: FigStep1\n source: step1.png\n caption: |\n  The overview area at the end of the step 1.\n--%\n\n\n## Step 2: Create the block sequence\n\nClick on *block_sequence* in the overview. At the moment this SEQUENCE is empty. We want *block sequence* to consist of a block of trials, followed by a  FEEDBACK display. For this we need to do the following:\n\n__Append a reset_feedback item to reset the feedback variables__\n\nWe don't want our feedback to be confounded by key presses that participants have made during the instruction phase or previous blocks of trials. Therefore, we start each block of trials by resetting the feedback variables. To do this we need a `reset_feedback` item. Grab `reset_feedback` from the item toolbar (under 'Response collection') and drag it onto *block_sequence*.\n\n__Append a new loop, containing a new sequence, for a block of trials__\n\nFor a single trial we need a SEQUENCE. For a block of trials, we need to repeat this SEQUENCE multiple times. Therefore, for a block of trials we need to wrap a LOOP around a SEQUENCE. Drag a LOOP from the item toolbar onto *new_reset_feedback*. Next, drag a SEQUENCE from the item toolbar onto the newly created LOOP, and select 'Insert into new_loop' in the pop-up menu that appears. (We will get back to this in Step 3.)\n\n__Append a feedback item__\n\nAfter every block of trials we want to give feedback to the participant, so that the participant knows how well he/ she is doing. For this we need a FEEDBACK item. Drag a FEEDBACK from the item toolbar onto *new_loop*, and select 'Insert after loop' in the pop-up menu that appears. (We will get back to this in Step 10.)\n\n__Give the new items sensible names__\n\nRename: (See Step 1 if you don't remember how to do this.)\n\n- *new_loop* to *block_loop*\n- *new_sequence* to *trial_sequence*\n- *new_reset_feedback* to *reset_feedback*\n- *new_feedback* to *feedback*\n\nThe overview of your experiment now looks like %FigStep2. Remember to save your experiment regularly.\n\n%--\nfigure:\n id: FigStep2\n source: step2.png\n caption: |\n  The overview area at the end of Step 2.\n--%\n", "url": "https://osdoc.cogsci.nl/4.0/tutorials/beginner", "title": "Beginner tutorial: gaze cuing"}
{"content": "# Beginner tutorial: gaze cuing\n\n## Step 3: Fill the block loop with independent variables\n\nAs the name suggests, *block_loop* corresponds to a single block of trials. In the previous step we created the *block_loop*, but we still need to define the independent variables that will be varied within the block. Our experiment has three independent variables:\n\n- __gaze_cue__ can be 'left' or 'right'.\n- __target_pos__ (the position of the target) can be '-300' or '300'. These values reflect the X-coordinate of the target in pixels (0 = center). Using the coordinates directly, rather than 'left' and 'right', will be convenient when we create the target displays (see Step 5).\n- __target_letter__ (the target letter) can be 'F' or 'H'.\n\nTherefore, our experiment has 2 x 2 x 2 = 8 levels. Although 8 levels is not that many (most experiments will have more), we don't need to enter all possible combinations by hand. Click on *block_loop* in the overview to open its tab. Now click on the 'Full-factorial design' button. In the variable wizard, you simply define all variables by typing the name in the first row and the levels in the rows below the name (see %FigVariableWizard). If you select 'Ok', you will see that *block_loop* has been filled with all 8 possible combinations.\n\n%--\nfigure:\n id: FigVariableWizard\n source: variable-wizard.png\n caption: |\n  The loop variable wizard in Step 3.\n--%\n\nIn the resulting loop table, each row corresponds to one run of *trial_sequence*. Because, in our case, one run of *trial_sequence* corresponds to one trial, each row in our loop table corresponds to one trial. Each column corresponds to one variable, which can have a different value on each trial.\n\nBut we are not done yet. We need to add three more variables: the location of the distractor, the correct response, and the congruency.\n\n- __dist_pos__ -- On the first row of the first empty column, enter 'dist_pos'. This automatically adds a new experimental variable named 'dist_pos'. In the rows below, enter '300' wherever 'target_pos' is -300, and '-300' wherever 'target_pos' is 300. In other words, the target and the distractor should be positioned opposite from each other.\n- __correct_response__ -- Create another variable, in another empty column, with the name 'correct_response'. Set 'correct_response' to 'z' where 'target_letter' is 'F', and to 'm' where 'target_letter' is 'H'. This means that the participant should press the 'z' key if she sees an 'F' and the 'm' key if she sees an 'H'. (Feel free to choose different keys if 'z' and 'm' are awkward on your keyboard layout; for example, 'w' and 'n' are better on AZERTY keyboards.)\n- __congruency__ -- Create another variable with the name 'congruency'. Set 'congruency' to 'congruent' where 'target_pos' is '-300' and 'gaze_cue' is 'left', and where 'target_pos' is '300' and 'gaze_cue' is 'right'. In other words, a trial is congruent if the face looks at the target. Set 'congruency' to 'incronguent' for the trials on which the face looks at the distractor. The 'congruency' variable is not necessary to run the experiment; however, it is useful for analyzing the data later on.\n\nWe need to do one last thing. 'Repeat' is currently set to '1.00'. This means that each cycle will be executed once. So the block now consists of 8 trials, which is a bit short. A reasonable length for a block of trials is 24, so set 'Repeat' to 3.00 (3 repeats x 8 cycles = 24 trials). You don't need to change 'Order', because 'random' is exactly what we want.\n\nThe *block_loop* now looks like %FigStep3. Remember to save your experiment regularly.\n\n%--\nfigure:\n id: FigStep3\n source: step3.png\n caption: \"The *block_loop* at the end of Step 3.\"\n--%\n\n<div class='info-box' markdown='1'>\n\n__Background box__\n\n__Tip__ -- You can prepare your loop table in your favorite spreadsheet program and copy-paste it into the LOOP variable table.\n\n__Tip__ -- You can specify your loop table in a separate file (in `.xlsx` or `.csv`) format, and use this file directly. To do so, select 'file' under 'Source'.\n\n__Tip__ -- You can set 'Repeat' to a non-integer number. For example, by setting 'Repeat' to '0.5', only half the trials (randomly selected) are executed.\n\n</div>\n\n## Step 4: Add images and sound files to the file pool\n\nFor our stimuli, we will use images from file. In addition, we will play a sound if the participant makes an error. For this we need a sound file.\n\nYou can download the required files here (in most webbrowsers you can right-click the links and choose 'Save Link As' or a similar option):\n\n- [gaze_neutral.png](/img/beginner-tutorial/gaze_neutral.png)\n- [gaze_left.png](/img/beginner-tutorial/gaze_left.png)\n- [gaze_right.png](/img/beginner-tutorial/gaze_right.png)\n- [incorrect.ogg](/img/beginner-tutorial/incorrect.ogg)\n\nAfter you have downloaded these files (to your desktop, for example), you can add them to the file pool. If the file pool is not already visible (by default on the right side of the window), click on the 'Show file pool' button in the main toolbar (shortcut: `Ctrl+P`). The easiest way to add the four files to the file pool is to drag them from the desktop (or wherever you have downloaded the files to) into the file pool. Alternatively, you can click on the '+' button in the file pool and add files using the file select dialog that appears. The file pool will be automatically saved with your experiment.\n\nYour file pool now looks like %FigStep4. Remember to save your experiment regularly.\n\n%--\nfigure:\n id: FigStep4\n source: step4.png\n caption: \"The file pool at the end of Step 4.\"\n--%\n\n## Step 5: Fill the trial sequence with items\n\nA trial in our experiment looks as follows:\n\n1. __Fixation dot__ -- 750 ms, SKETCHPAD item\n2. __Neutral gaze__ -- 750 ms, SKETCHPAD item\n3. __Gaze cue__ -- 500 ms, SKETCHPAD item\n4. __Target__  -- 0 ms, SKETCHPAD item\n5. __Response collection__ \t-- KEYBOARD_RESPONSE item\n6. __Play a sound if response was incorrect__ --  SAMPLER item\n7. __Log response to file__ -- LOGGER item\n\nClick on *trial_sequence* in the overview to open the *trial_sequence* tab. Pick up a SKETCHPAD from the item toolbar and drag it into the *trial_sequence*. Repeat this three more times, so that *trial_sequence* contains four SKETCHPADs. Next, select and append a KEYBOARD_RESPONSE item, a SAMPLER item, and a LOGGER item.\n\nAgain, we will rename the new items, to make sure that the *trial_sequence* is easy to understand. Rename:\n\n- *new_sketchpad* to *fixation_dot*\n- *new_sketchpad_1* to *neutral_gaze*\n- *new_sketchpad_2* to *gaze_cue*\n- *new_sketchpad_3* to *target*\n- *new_keyboard_response* to *keyboard_response*\n- *new_sampler* to *incorrect_sound*\n- *new_logger* to *logger*\n\nBy default, items are always executed, which is indicated by the run-if expression `True`. However, we want to change this for the *incorrect_sound* item, which should only be executed if an error was made. To do this, we need to change the 'Run if' expression to `correct == 0` in the *trial_sequence* tab. This works, because the *keyboard_response* item automatically creates a `correct` variable, which is set to `1` (correct), `0` (incorrect), or `undefined` (this relies on the `correct_response` variable that was defined in Step 3). The double equals sign is Python syntax and indicates that you want to compare whether the two things are equal to each other, in this case whether the variable `correct` is equal to 0. To change a run-if expression, double click on it (shortcut: `F3`).\n\nThe *trial_sequence* now looks like %FigStep5.\n\n%--\nfigure:\n id: FigStep5\n source: step5.png\n caption: \"The *trial_sequence* at the end of Step 5.\"\n--%\n\n<div class='info-box' markdown='1'>\n\n__Background box__\n\n__What is a SKETCHPAD item?__ -- A SKETCHPAD is used to present visual stimuli: text, geometric shapes, fixation dots, Gabor patches, etc. You can draw on the SKETCHPAD using the built-in drawing tools.\n\n__What is a KEYBOARD_RESPONSE item?__ -- A KEYBOARD_RESPONSE item collects a single participant's response from the keyboard.\n\n__What is a SAMPLER item?__ -- A SAMPLER item plays a sound from a sound file.\n\n__What is a LOGGER item?__ -- A LOGGER item writes data to the log file. This is very important: If you forget to include a LOGGER item, no data will be logged during the experiment!\n\n__Tip__ -- Variables and conditional \"if\" expressions are very powerful! To learn more about them, see:\n\n- %link:manual/variables%\n\n</div>\n\n## Step 6: Draw the sketchpad items\n\nThe SKETCHPAD items that we have created in Step 5 are still blank. It's time to do some drawing!\n\n__Set the background color to white__\n\nClick on *fixation_dot* in the overview area to open its tab. The SKETCHPAD is still dark gray, while the images that we have downloaded have a white background. Oops, we forgot to set the background color of the experiment to white (it is dark gray by default)! Click on 'Tutorial: Gaze cuing' in the overview area to open the 'General properties' tab. Change 'Foreground' to 'black' and 'Background' to 'white'.\n\n<div class='info-box' markdown='1'>\n\n__Background box__\n\n__Tip__ -- For more fine-grained control over colors, you can also use the hexadecimal RGB notation (e.g., `#FF000` for red), use various color spaces, or use the color-picker tool. See also:\n\n- %link:manual/python/canvas%\n\n</div>\n\n__Draw the fixation dot__\n\nGo back to the *fixation_dot* by clicking on *fixation_dot* in the overview. Now select the fixation-dot element by clicking on the button with the crosshair. If you move your cursor over the sketchpad, you can see the screen coordinates in the top-right. Set the (foreground) color to 'black'. Click on the center of the screen (0, 0) to draw a central fixation dot.\n\nFinally, change the 'Duration' field from 'keypress' to '745', because we want the fixation dot to be presented for 750 ms. Wait ... *why didn't we just specify a duration of 750 ms?* The reason for this is that the actual display-presentation duration is always rounded up to a value that is compatible with your monitor's refresh rate. This may sound complicated, but for most purposes the following rules of thumb are sufficient:\n\n1. Choose a duration that is possible given your monitor's refresh rate. For example, if your monitor's refresh rate is 60 Hz, it means that every frame lasts 16.7 ms (= 1000 ms/60 Hz). Therefore, on a 60 Hz monitor, you should always select a duration that is a multiple of 16.7 ms, such as 16.7, 33.3, 50, 100, etc.\n2. In the duration field of the SKETCHPAD specify a duration that is a few milliseconds less than what you're aiming for. So if you want to present a SKETCHPAD for 50 ms, choose a duration of 45. If you want to present a SKETCHPAD for 1000 ms, choose a duration of 995. Etcetera.\n\n<div class='info-box' markdown='1'>\n\n__Background box__\n\n__Tip__ -- For a detailed discussion of experimental timing, see:\n\n- %link:timing%\n\n__Tip__ -- The duration of a SKETCHPAD can be a value in milliseconds, but you can also enter 'keypress' or 'mouseclick' to collect a keyboard press or mouse click respectively. In this case a SKETCHPAD will work much the same as a KEYBOARD_RESPONSE item (but with fewer options).\n\n__Tip__ -- Make sure that the (foreground) color is set to black. Otherwise you will draw white on white and won't see anything!\n\n</div>\n\n__Draw the neutral gaze__\n\nOpen the *neutral_gaze* SKETCHPAD. Now select the image tool by clicking on the button with the mountain-landscape-like icon. Click on the center of the screen (0, 0). The 'Select file from pool' dialog will appear. Select the file `gaze_neutral.png` and click on the 'Select' button. The neutral gaze image will now stare at you from the center of the screen! Finally, like before, change the 'Duration' field from 'keypress' to '745'. (And note again that this means a duration of 750 ms on most monitors!)\n\n<div class='info-box' markdown='1'>\n\n__Background box__\n\n__Tip__ -- OpenSesame can handle a wide variety of image formats. However, some (non-standard) `.bmp` formats are known to cause trouble. If you find that a `.bmp` image is not shown, you can convert it to a different format, such as `.png`. You can convert images easily with free tools such as [GIMP].\n</div>\n\n__Draw the gaze cue__\n\nOpen the *gaze_cue* SKETCHPAD, and again select the image tool. Click on the center of the screen (0, 0) and select the file `gaze_left.png`.\n\nBut we are not done yet! Because the gaze cue should not always be 'left', but should depend on the variable `gaze_cue`, which we have defined in Step 3. However, by drawing the `gaze_left.png` image to the SKETCHPAD, we have generated a script that needs only a tiny modification to make sure that the proper image is shown. Click on the 'Select view' button at the top-right of the *gaze_cue* tab and select 'View script'. You will now see the script that corresponds to the sketchpad that we have just created:\n\n~~~ .python\nset duration keypress\nset description \"Displays stimuli\"\ndraw image center=1 file=\"gaze_left.png\" scale=1 show_if=True x=0 y=0 z_index=0\n~~~\n\nThe only thing that we need to do is replace `gaze_left.png` with `gaze_{gaze_cue}.png`. This means that OpenSesame uses the variable `gaze_cue` (which has the values `left` and `right`) to determine which image should be shown.\n\nWhile we are at it, we might as well change the duration to '495' (rounded up to 500!). The script now looks like this:\n\n~~~ .python\nset duration 495\nset description \"Displays stimuli\"\ndraw image center=1 file=\"gaze_{gaze_cue}.png\" scale=1 show_if=True x=0 y=0 z_index=0\n~~~\n\nClick the 'Apply' button at the top right to apply your changes to the script and return to the regular item controls. OpenSesame will warn you that the image cannot be shown, because it is defined using variables, and a placeholder image will be shown instead. Don't worry, the correct image will be shown during the experiment!\n\n<div class='info-box' markdown='1'>\n\n__Background box__\n\n__Tip__ -- The variable inspector (shortcut: `Ctrl+I`) is a powerful way to find out which variables have been defined in your experiment, and which values they have (see %FigVariableInspector). When your experiment is not running, most variables don't have a value yet. But when you run your experiment in a window, while having the variable inspector visible, you can see variables changing in real time. This is very useful for debugging your experiment.\n\n%--\nfigure:\n id: FigVariableInspector\n source: variable-inspector.png\n caption: \"The variable inspector is a convenient way to get an overview of the variables that exist in your experiment.\"\n--%\n\n</div>\n\n__Draw the target__\n\nWe want three objects to be part of the target display: the target letter, the distractor letter, and the gaze cue (see %FigGazeCuing). As before, we will start by creating a static display using the SKETCHPAD editor. After this, we will only need to make minor changes to the script so that the exact display depends on the variables.\n\nClick on *target* in the overview to open the target tab and like before, draw the `gaze_left.png` image at the center of the screen. Now select the draw text tool by clicking on the button with the 'A' icon. Change the foreground color to 'black' (if it isn't already). The default font size is 18 px, which is a bit small for our purpose, so change the font size to 32 px. Now click on (-320, 0) in the SKETCHPAD (the X-coordinate does not need to be exactly 320, since we will change this to a variable anyway). Enter \"{target_letter}\" in the dialog that appears, to draw the target letter (when drawing text, you can use variables directly). Similarly, click on (320, 0) and draw an 'X' (the distractor is always an 'X').\n\nNow open the script editor by clicking on the 'Select view' button at the top-right of the tab and selecting 'View script'. The script looks like this:\n\n~~~ .python\nset duration keypress\nset duration keypress\nset description \"Displays stimuli\"\ndraw image center=1 file=\"gaze_left.png\" scale=1 show_if=True x=0 y=0 z_index=0\ndraw textline center=1 color=black font_bold=no font_family=mono font_italic=no font_size=32 html=yes show_if=True text=\"{target_letter}\" x=-320 y=0 z_index=0\ndraw textline center=1 color=black font_bold=no font_family=mono font_italic=no font_size=32 html=yes show_if=True text=X x=320 y=0 z_index=0\n~~~\n\nLike before, change `gaze_left.png` to `gaze_{gaze_cue}.png`. We also need to make the position of the target and the distractor depend on the variables `target_pos` and `dist_pos` respectively. To do this, simply change `-320` to `{target_pos}` and `320` to `{dist_pos}`. Make sure that you leave the `0`, which is the Y-coordinate. The script now looks like this:\n\n~~~ .python\nset duration keypress\nset description \"Displays stimuli\"\ndraw image center=1 file=\"gaze_{gaze_cue}.png\" scale=1 show_if=True x=0 y=0 z_index=0\ndraw textline center=1 color=black font_bold=no font_family=mono font_italic=no font_size=32 html=yes show_if=True text=\"{target_letter}\" x={target_pos} y=0 z_index=0\ndraw textline center=1 color=black font_bold=no font_family=mono font_italic=no font_size=32 html=yes show_if=True text=X x={dist_pos} y=0 z_index=0\n~~~\n\nClick on the 'Apply' button to apply the script and go back to the regular item controls.\n\nFinally, set the 'Duration' field to '0'. This does not mean that the target is presented for only 0 ms, but that the experiment will advance to the next item (the *keyboard_response*) right away. Since the *keyboard_response* waits for a response, but doesn't change what's on the screen, the target will remain visible until a response has been given.\n\nRemember to save your experiment regularly.\n\n<div class='info-box' markdown='1'>\n\n__Background box__\n\n__Tip__ -- Each element of a SKETCHPAD has a 'Show if' option, which specifies when the element should be shown. You can use this to hide/ show elements from a SKETCHPAD depending on certain variables, similar to run-if statements in a SEQUENCE.\n\n__Tip__ -- Make sure that the (foreground) color is set to black. Otherwise you will draw white on white and won't see anything!\n\n</div>\n", "url": "https://osdoc.cogsci.nl/4.0/tutorials/beginner", "title": "Beginner tutorial: gaze cuing"}
{"content": "# Beginner tutorial: gaze cuing\n\n## Step 7: Configure the keyboard response item\n\nClick on *keyboard_response* in the overview to open its tab. You see three options: Correct response, Allowed responses, Timeout, and Event type.\n\nWe have already set the `correct_response` variable in Step 3. Unless we explicitly specify a correct response, OpenSesame automatically uses the `correct_response` variable if it is available. Therefore, we don't need to change the 'Correct response' field here.\n\nWe do need to set the allowed responses. Enter 'z;m' in the allowed-responses field (or other keys if you have chosen different response keys). The semicolon is used to separate responses. The KEYBOARD_RESPONSE now only accepts 'z' and 'm' keys. All other key presses are ignored, with the exception of 'escape', which pauses the experiment.\n\nWe also want to set a timeout, which is the maximum interval that the KEYBOARD_RESPONSE waits before deciding that the response is incorrect and setting the 'response' variable to 'None'. '2000' (ms) is a good value.\n\nWe don't need to change the Event type, because we want the participant to respond by pressing a key (keypress, the default) and not by releasing a key (keyrelease).\n\nThe KEYBOARD_RESPONSE now looks like %FigStep7.\n\n%--\nfigure:\n id: FigStep7\n source: step7.png\n caption: \"The KEYBOARD_RESPONSE at the end of Step 7.\"\n--%\n\n<div class='info-box' markdown='1'>\n\n__Background box__\n\n__Tip__ -- By default, the KEYBOARD_RESPONSE will use the `correct_response` variable to determine whether a response was correct. But you can use a different variable as well. To do this, enter a variable name between curly braces (`{my_variable}`) in the correct response field.\n\n__Tip__ -- If 'flush pending key presses' is enabled (it is by default), all pending key presses are discarded when the KEYBOARD_RESPONSE item is called. This prevents carry-over effects, which might otherwise occur if the participant accidentally presses a key during a non-response part of the trial.\n\n__Tip__ -- To use special keys, such as '/' or the up-arrow key, you can use key names (e.g., 'up' and 'space') or associated characters (e.g., '/' and ']'). The 'List available keys' button provides an overview of all valid key names.\n\n</div>\n\n## Step 8: Configure the incorrect (sampler) item\n\nThe *incorrect_sound* item doesn't need much work: We only need to select the sound that should be played. Click on *incorrect_sound* in the overview to open its tab. Click on the 'Browse' button and select `incorrect.ogg` from the file pool.\n\nThe sampler now looks like %FigStep8.\n\n%--\nfigure:\n id: FigStep8\n source: step8.png\n caption: \"The *incorrect_sound* item at the end of Step 8.\"\n--%\n\n<div class='info-box' markdown='1'>\n\n__Background box__\n\n__Tip__ -- You can use variables to specify which sound should be played by using a variable name between curly braces as (part of) the file name. For example: `{a_word}.ogg`\n\n__Tip__ -- The SAMPLER handles files in `.ogg`, `.mp3`, and `.wav` format. If you have sound files in a different format, [Audacity] is a great free tool to convert sound files (and much more).\n\n</div>\n\n## Step 9: Configure the variable logger\n\nActually, we don't need to configure the variable LOGGER, but let's take a look at it anyway. Click on *logger* in the overview to open its tab. You see that the option 'Automatically log all variables' is selected. This means that OpenSesame logs everything, which is fine.\n\n<div class='info-box' markdown='1'>\n\n__Background box__\n\n__Tip__ -- If you like your log-files clean, you can disable the 'Automatically log all variables' option and manually select variables, either by entering variable names manually ('Add custom variable'), or by dragging variables from the variable inspector into the LOGGER table. You can also leave the 'Automatically log all variables' option enabled and exclude variables that you are not interested in.\n\n__The one tip to rule them all__ -- Always triple-check whether all the necessary variables are logged in your experiment! The best way to check this is to run the experiment and investigate the resulting log files.\n\n</div>\n\n## Step 10: Draw the feedback item\n\nAfter every block of trials, we want to present feedback to the participant to let him/ her know how well he/ she is doing. Therefore, in Step 2, we added a FEEDBACK item, simply named *feedback* to the end of *block_sequence*.\n\nClick on *feedback* in the overview to open its tab, select the draw text tool, change the foreground color to 'black' (if it isn't already), and click at (0, 0). Now enter the following text:\n\n```text\nEnd of block\n\nYour average response time was {avg_rt} ms\nYour accuracy was {acc} %\n\nPress any key to continue\n```\n\nBecause we want the feedback item to remain visible as long as the participant wants (i.e. until he/ she presses a key), we leave 'Duration' field set to 'keypress'.\n\nThe feedback item now looks like %FigStep_10.\n\n%--\nfigure:\n id: FigStep_10\n source: step10.png\n caption: \"The feedback item at the end of Step 10.\"\n--%\n\n<div class='info-box' markdown='1'>\n\n__Background box__\n\n__What is a feedback item?__ -- A FEEDBACK item is almost identical to a SKETCHPAD item. The only difference is that a FEEDBACK item is not prepared in advance. This means that you can use it to present feedback, which requires up-to-date information about a participant's response. You should not use FEEDBACK items to present time-critical displays, because the fact that it is not prepared in advance means that its timing properties are not as good as that of the SKETCHPAD item. See also:\n\n- %link:visual%\n\n__Feedback and variables__ -- Response items automatically keep track of the accuracy and average response time of the participant in the variables 'acc' (synonym: 'accuracy') and 'avg_rt' (synonym: 'average_response_time') respectively. See also:\n\n- %link:manual/variables%\n\n__Tip__ -- Make sure that the (foreground) color is set to black. Otherwise you will draw white on white and won't see anything!\n\n</div>\n\n## Step 11: Set the length of the practice phase and experimental phase\n\nWe have previously created the *practice_loop* and *experiment_loop* items, which both call *block_sequence* (i.e., a block of trials). However, right now they call *block_sequence* only once, which means that both the practice and the experimental phase consist of only a single block of trials.\n\nClick on *practice_loop* to open its tab and set 'Repeat' to '2.00'. This means that the practice phase consists of two blocks.\n\nClick on *experimental_loop* to open its tab and set 'Repeat' to '8.00'. This means that the experimental phase consists of eight blocks.\n\n<div class='info-box' markdown='1'>\n\n__Background box__\n\n__Tip__ -- You can create a variable `practice` in both *practice_loop* and *experimental_loop* and set it to 'yes' and 'no' respectively. This is an easy way of keeping track of which trials were part of the practice phase.\n\n</div>\n\n## Step 12: Write the instruction, end_of_practice and end_of_experiment forms\n\nI think you can handle this step your own! Simply open the appropriate items and add some text to present instructions, an end-of-practice message, and an end-of-experiment message.\n\n<div class='info-box' markdown='1'>\n\n__Background box__\n\n__Tip__ -- You can use a subset of HTML tags to format your text. For example, *&lt;b&gt;this will be bold&lt;b&gt;* and *&lt;span color='red'&gt;this will be red&lt;span&gt;*. For more information, see:\n\n- %link:text%\n\n</div>\n\n## Step 13: Run the experiment!\n\nYou're done! Click on the 'Run in window' (shortcut: `Ctrl+W`) or 'Run fullscreen' (shortcut: `Ctrl+R`) buttons in the toolbar to run your experiment.\n\n<div class='info-box' markdown='1'>\n\n__Background box__\n\n__Tip__ -- A test run is executed even faster by clicking the orange 'Run in window' button (shortcut: `Ctrl+Shift+W`), which doesn't ask you how to save the logfile (and should therefore only be used for testing purposes).\n\n</div>\n\n\n## Understanding errors\n\nBeing able to understand error messages is a crucial skill when working with OpenSeame. After all, a newly built experiment rarely runs immediately without any errors!\n\nLet's say that we made a mistake during one of the steps above. When trying to run the experiment, we get the following error message (%FigErrorMessage):\n\n%--\nfigure:\n id: FigErrorMessage\n source: error-message.png\n caption: \"An error message in OpenSesame.\"\n--%\n\nThe error message starts with a name, in this case `FStringError`, which indicates the general type of error. This is followed by a short explanatory text, in this case 'Failed to evaluate f-string expression in the following text: gaze_{gaze_ceu}.png`. Even without understanding what an f-string is (it's a string that contains Python code between curly braces), it's clear that there is something wrong with the text '{gaze_ceu}.png'.\n\nThe error message also indicates that the error comes from the prepare phase of the *gaze_cue* item.\n\nFinally, the error message indicates what specifically went wrong when evaluating the text 'gaze_{gaze_ceu}.png': the name 'gaze_ceu' is not defined.\n\nWhile reading the error message carefully, the cause and solution probably already came to your mind: we made a simple spelling mistake in the *gaze_cue* item, writing '{gaze_ceu}' instead of '{gaze_cue}'! And this resulted in an error because there is no variable with the name `gaze_ceu`. This can be easily fixed by opening the script of the *gaze_cue* item and fixing the typo.\n\n\n## Finally: Some general considerations regarding timing and backend selection\n\nIn the 'General properties' tab of the experiment (the tab that you open by clicking on the experiment name), you can select a backend. The backend is the layer of software that controls the display, input devices, sound, etc. Most experiments work with all backends, but there are reasons to prefer one backend over the other, mostly related to timing. Currently there are four backends (depending on your system, not all three may be available):\n\n- __psycho__ -- a hardware-accelerated backend based on PsychoPy [(Peirce, 2007)][references]. This is the default.\n- __xpyriment__ -- a hardware-accelerated backend based on Expyriment [(Krause & Lindeman, 2013)][references]\n- __legacy__ -- a 'safe' backend, based on PyGame. It provides reliable performance on most platforms, but, due to a lack of hardware acceleration, its timing properties are not as good as those of the other backends.\n- __osweb__ -- runs experiments in a browser [(Math\u00f4t & March, 2022)][references].\n\nSee also:\n\n- %link:backends%\n- %link:timing%\n\n\n## References\n\n<div class='reference' markdown='1'>\n\nBrand, A., & Bradley, M. T. (2011). Assessing the effects of technical variance on the statistical outcomes of web experiments measuring response times. *Social Science Computer Review*. doi:10.1177/0894439311415604\n\nDamian, M. F. (2010). Does variability in human performance outweigh imprecision in response devices such as computer keyboards? *Behavior Research Methods*, *42*, 205-211. doi:10.3758/BRM.42.1.205\n\nFriesen, C. K., & Kingstone, A. (1998). The eyes have it! Reflexive orienting is triggered by nonpredictive gaze. *Psychonomic Bulletin & Review*, *5*, 490\u2013495. doi:10.3758/BF03208827\n\nKrause, F., & Lindemann, O. (2013). Expyriment: A Python library for cognitive and neuroscientific experiments. *Behavior Research Methods*. doi:10.3758/s13428-013-0390-6\n\nMath\u00f4t, S., Schreij, D., & Theeuwes, J. (2012). OpenSesame: An open-source, graphical experiment builder for the social sciences. *Behavior Research Methods*, *44*(2), 314-324. doi:10.3758/s13428-011-0168-7\n\nMath\u00f4t, S., & March, J. (2022). Conducting linguistic experiments online with OpenSesame and OSWeb. *Language Learning*. doi:10.1111/lang.12509\n\nPeirce, J. W. (2007). PsychoPy: Psychophysics software in Python. *Journal of Neuroscience Methods*, *162*(1-2), 8-13. doi:10.1016/j.jneumeth.2006.11.017\n\nUlrich, R., & Giray, M. (1989). Time resolution of clocks: Effects on reaction time measurement\u2014Good news for bad clocks. *British Journal of Mathematical and Statistical Psychology*, *42*(1), 1-12. doi:10.1111/j.2044-8317.1989.tb01111.x\n\n</div>\n\n[references]: #references\n[gpl]: http://www.gnu.org/licenses/gpl-3.0.en.html\n[gimp]: http://www.gimp.org/\n[audacity]: http://audacity.sourceforge.net/\n[python inline scripting]: /python/about", "url": "https://osdoc.cogsci.nl/4.0/tutorials/beginner", "title": "Beginner tutorial: gaze cuing"}
{"content": "# Intermediate tutorial (Python) visual search\n\ntitle: Intermediate tutorial (Python) visual search\n\n[TOC]\n\n## About OpenSesame\n\nOpenSesame is a user-friendly program for the development of behavioral experiments for psychology, neuroscience, and experimental economy. For beginners, OpenSesame has a comprehensive graphical, point-and-click interface.  For advanced users, OpenSesame supports Python (desktop only) and JavaScript (desktop and browser).\n\nOpenSesame is freely available under the [General Public License v3][gpl].\n\n## About this tutorial\n\nThis tutorial shows how to create a basic visual-search experiment using OpenSesame [(Math\u00f4t, Schreij, & Theeuwes, 2012)][references]. We will use both the graphical interface and Python scripting to develop an experiment that you can run on the desktop in a traditional lab-based setting. Some experience with OpenSesame and Python is recommended. This tutorial takes approximately one hour.\n\nA JavaScript-based version of this tutorial is also available. If you want to run your experiments online in a browser (with OSWeb), then the JavaScript tutorial is what you need:\n\n- %link:tutorials/intermediate-javascript%\n\n## Resources\n\n- __Download__ \u2014 This tutorial assumes that you are running OpenSesame version 4.0.0 or later. You can download the most recent version of OpenSesame from:\n\t- %link:download%\n- __Documentation__ \u2014 A dedicated documentation website can be found at:\n\t- <http://osdoc.cogsci.nl/>\n- __Forum__ \u2014 A support forum can be found at:\n\t- <http://forum.cogsci.nl/>\n\n## The experiment\n\nIn this tutorial, you will create a basic visual-search experiment. The experiment resembles the classic visual-search studies of [Treisman and Gelade (1980)][references], but it is not identical.\n\nIn this experiment, participants search for a target object, which can be a yellow square, a yellow circle, a blue square, or a blue circle; the identity of the target is varied between blocks of trials. Participants indicate whether the target is present or not by pressing the right (present) or left (absent) arrow key.\n\nIn addition to the target, zero or more distractor objects are shown. There are three conditions, and the condition determines what kind of distractors there are:\n\n- In the *Conjunction* condition, distractors can have any shape and color, with the only restriction that distractors cannot be identical to the target. So, for example, if the target is a yellow square, then distractors are yellow circles, blue circles, and blue squares.\n- In the *Shape Feature* condition, distractors have a different shape from the target, but can have any color. So, for example, if the target is a yellow square, then distractors are yellow circles and blue circles.\n- In the *Color Feature* condition, distractors can have any shape, but have a different color from the target. So, for example, if the target is a yellow square, then distractors are blue squares and blue circles.\n\nImmediate feedback is shown after each trial: a green dot after a correct response, and a red dot after an incorrect response. Detailed feedback on average response times and accuracy is shown after each block of trials.\n\n%--\nfigure:\n id: FigVisualSearch\n source: visual-search.svg\n caption: |\n  The visual-search experiment that you will implement in this tutorial.\n--%\n\nExperiments like this show two typical findings:\n\n- It takes more time to find the target in the Conjunction condition than in the two Feature conditions.\n- In the Conjunction condition, response times increase as the number of distractors increases. This suggests that people search for the target one item at a time; this is called *serial search*.\n- In the Feature conditions (both shape and color), response times do not, or hardly, increase as the the number of distractors increases. This suggests that people process the entire display at once; this is called *parallel search*.\n\nAccording to Treisman and Gelade's feature-integration theory, these results reflect that the Conjunction condition requires that you combine, or *bind*, the color and shape of each object. This binding requires attention, and you therefore need to shift your attention from one object to the next; this is slow, and explains why response times depend on how many objects there are. In contrast, in the Feature conditions, color and shape do not need to be bound, and therefore the whole display can be processed in a single sweep without attention being directed at each and every object.\n\n## Experimental design\n\nThis design:\n\n- Is *within-subject*, because all participants do all conditions\n- Is *fully crossed* (or full-factorial), because all combinations of conditions occur\n- Has three conditions (or factors):\n\t- Varied within blocks:\n\t\t- `set_size` with three levels (1, 5, 15), or SS<sub>3</sub>\n\t\t- `condition` with three levels (conjunction, feature_shape, feature_color), or CN<sub>3</sub>\n\t\t- `target_present` with two levels (present, absent), or TP<sub>2</sub>\n\t- Varied between blocks:\n\t\t- `target_shape` with two levels (square, circle), or TS<sub>2</sub>\n\t\t- `target_color` with two levels (yellow, blue), or TC<sub>2</sub>\n- Has N subjects, or <u>S</u><sub>N</sub>\n\nYou can write this design as <u>S</u><sub>N</sub>\u00d7SS<sub>3</sub>\u00d7CN<sub>3</sub>\u00d7TP<sub>2</sub>\u00d7TS<sub>2</sub>\u00d7TC<sub>2</sub>\n\nFor more information about this notation for experimental design, see:\n\n- %link:experimentaldesign%\n\n## Step 1: Create the basic structure of the experiment\n\nStart OpenSesame and, in the 'Get started!' tab, select the Extended template. This template provides the basic structure that is common to many cognitive-psychology experiments, such as the one that we will create here.\n\nThe Extended template contains a few items that we don't need. Delete the following items:\n\n- *about_this_template*\n- *practice_loop*\n- *end_of_practice*\n\nWhen you have deleted these items, they are still visible in the 'Unused items' bin. To permanently delete these items, click on the 'Unused items' bin, and then click on the 'Permanently delete unused items' button.\n\nFinally, give the experiment a good title, such as 'Visual search'. To do this, open the general-properties tab (by clicking on 'Extended template' in the overview area) and click on the experiment name to edit it.\n\nThe overview area should now look like %FigStep1:\n\n%--\nfigure:\n id: FigStep1\n source: step1.png\n caption: |\n  The overview area at the end of step 1.\n--%\n\n## Step 2: Define experimental variables that are varied between blocks\n\nAs described above, two variables are varied between blocks in our experiment: `target_shape` and `target_color`. We therefore need to define these variables in the *experimental_loop*. To understand why, consider the structure shown in %FigStep1, starting from the bottom (i.e. the most indented level).\n\n- *trial_sequence* corresponds to a single trial\n- *block_loop* corresponds to a block of a trials\n\t- Therefore, variables defined here vary for each run of *trial_sequence*; in other words, variables defined in *block_loop* are varied __within blocks__.\n- *block_sequence* corresponds to a block of trials, preceded by resetting of the feedback variables, and followed by participant feedback\n- *experimental_loop* corresponds to multiple blocks of trials\n\t- Therefore, variables defined here vary for each run of *block_sequence*; in other words, variables defined in *experimental_loop* are varied __between blocks__.\n- *experiment* corresponds to the entire experimental, which is an instruction screen, followed by multiple blocks of trials, followed by an end-of-experiment screen\n\nClick on experimental loop, and define:\n\n- `target_shape`, which can be 'square' or 'circle'; and\n- `target_color`, which can be 'yellow' or 'blue'.\n\nWe have a full-factorial design, which means that all 2 \u00d7 2 = 4 combinations must occur. The table of *experimental_loop* should now look like %FigStep2:\n\n%--\nfigure:\n id: FigStep2\n source: step2.png\n caption: |\n  The table of *experimental_loop* at the end of step 2.\n--%\n\n## Step 3: Give instructions at the start of each block\n\nRight now, the experiment starts with a single *instructions* screen. In our case, we want to give instructions before each block of trials, to tell the participant what target to look for (because the identity of the target varies between blocks).\n\n__Move the instructions into block_sequence__\n\nTherefore, pick up the *instructions* item and drag it onto *block_sequence*. A pop-up will appear, asking you if you want to:\n\n- Insert the item into *block_sequence*, in which case *instructions* would become the first item of *block_sequence*; or\n- Insert the item after *block_sequence*, in which case *instructions* would move to a position after *block_sequence*.\n\nSelect the first option ('Insert into'). Now *block_sequence* starts with an instructions screen, which is what we want.\n\n__Add instructional text__\n\nClick on *instructions* to open it, and add a good instructional text, such as:\n\n```text\nINSTRUCTIONS\n\nSearch for the {target_color} {target_shape}\n\nPress the right-arrow key if you find it\nPress the left-arrow key if you don't\n\nPress any key to begin\n```\n\nThe curly braces brackets around '{target_color}' and '{target_shape}' indicate that these are not literal text, but refer to the variables that we have defined in *experimental_loop*. When the experiment runs, the values of these variables will appear here, and the participant will see (for example), 'Search for the yellow circle'.\n\n__Give a visual preview of the target__\n\nIt also good to show the participant the actual stimulus that she needs to find. To do this:\n\n- Draw a filled circle at the center of the display (make sure it doesn't overlap with the text);\n- Change the color of the circle to '{target_color}'. This means that the color of the circle depends on the value of the variable `target_color`; and\n- Change the show-if expression to `target_shape == 'circle'`. This is a Python expression that checks if the variable `target_shape` has the value 'circle'.\n\nIn other words, we have drawn a circle of which the color is determined by `target_color`; furthermore, this circle is only shown when the variable `target_shape` has the value 'circle'. For more information about variables and show-if statements, see:\n\n- %link:manual/variables%\n\nWe use the same trick to draw a square:\n\n- Draw a filled square at the center of the display;\n- Change the color of the square to '{target_color}'; and\n- Change the show-if statement to `target_shape == 'square'`\n\nThe *instructions*  screen should now look like %FigStep3:\n\n%--\nfigure:\n id: FigStep3\n source: step3.png\n caption: |\n  The *instructions* screen at the end of step 3.\n--%\n\n## Step 4: Define experimental variables that are varied within blocks\n\nThree variables are varied within blocks in our experiment: `condition`, `set_size`, and `target_present`. As described under Step 2, we need to define these variables in the *block_loop* so that they vary for each run of *trial_sequence*.\n\nThe three variables make a total of 3 \u00d7 3 \u00d7 2 = 18 different combinations. We can type these into the table manually, but, because we have full-factorial design, we can also use the full-factorial-design wizard. To do this, first open *block_loop* and click on the 'Full-factorial design' button.\n\nIn the table that appears, put the variable names on the first row, and the values on the rows below, as shown in %FigFullFactorial.\n\n%--\nfigure:\n id: FigFullFactorial\n source: fullfactorial.png\n caption: |\n  The *instructions* screen at the end of step 3.\n--%\n\nNow click on 'Ok' to generate the full design. The table of *block_loop* should now look like %FigStep4.\n\n%--\nfigure:\n id: FigStep4\n source: step4.png\n caption: |\n  The table of *block_loop* at the end of step 4.\n--%\n\n## Step 5: Create the trial sequence\n\nWe want our trial sequence to look as follows:\n\n- A fixation dot, for which we will use a SKETCHPAD.\n- A search display, which we will create in Python with a custom INLINE_SCRIPT.\n- Response collection, for which we will use a KEYBOARD_RESPONSE.\n- Data logging, for which we will use a LOGGER.\n- (We also want immediate feedback after each trial, but we will get back to this later.)\n\nSo the only thing that is missing is an INLINE_SCRIPT.\n\n- Insert a new INLINE_SCRIPT after *sketchpad* and rename it to *search_display_script*.\n- Rename *sketchpad* to *fixation_dot*, so that its function is clear; and\n- Change the duration of *fixation_dot* to 500, so that the fixation dot is shown for 500 ms. (There should already be a fixation dot drawn; if not, draw one in the center of *fixation_dot*.)\n\nThe overview area should now look like %FigStep5.\n\n%--\nfigure:\n id: FigStep5\n source: step5.png\n caption: |\n  The overview area at the end of step 5.\n--%\n\n## Step 6: Generate the search display\n\n__Top-down and defensive programming__\n\nNow things will get interesting: We will start programming in Python. We will use two guiding principles: *top-down* and *defensive* programming.\n\n- *Top-down programming* means that we start with the most abstract logic, without bothering with how this logic is implemented. Once the most abstract logic is in place, we will move down to a slightly less abstract logic, and so on, until we arrive at the details of the implementation. This technique helps to keep the code structured.\n- *Defensive programming* means that we assume that we make mistakes. Therefore, to protect us from ourselves, we build sanity checks into the code.\n\n*Note:* The explanation below assumes that you're somewhat familiar with Python code. If concepts like `list`, `tuple`, and functions don't mean anything to you, then it's best to first walk through an introductory Python tutorial, such as this one:\n\n- <https://pythontutorials.eu/>\n\nThe logic of the code is shown in %FigHierarchy. The numbers indicate the order in which we will implement the functionality, starting at the abstract level.\n\n%--\nfigure:\n id: FigHierarchy\n source: hierarchy.svg\n caption: |\n  The logic of the code to draw a visual-search display.\n--%\n\n__The Prepare and Run phases__\n\nOpen *search_display_script* and switch to the Prepare tab. OpenSesame distinguishes two phases of execution:\n\n- During the Prepare phase, each item is given the opportunity to prepare itself; what this means depends on the item: For a SKETCHPAD, it means drawing a canvas (but not showing it); for a SAMPLER, it means loading a sound file (but not playing it); etc.\n- During the Run phase, each item is actually executed; again, what this means depends on the item: For a SKETCHPAD, it means showing the previously prepared canvas; for a SAMPLER, it means playing a previously loaded sound file.\n\nFor an INLINE_SCRIPT, you have to decide yourself what to put in the Prepare phase, and what to put in the Run phase. The distinction is usually quite clear: In our case, we put the code for drawing the canvas in the Prepare phase, and the code for showing the canvas (which is small) in the Run phase.\n\nSee also:\n\n- %link:prepare-run%\n\n__Implement the abstract level__\n\nWe start at the most abstract level: defining a function that draws a visual-search display. We don't specify *how* this is done; we simply assume that there is a function that does this, and we will worry about the details later\u2014that's top-down programming.\n\nIn the Prepare tab, enter the following code:\n\n~~~ .python\nc = draw_canvas()\n~~~\n\nWhat happens here? We \u2026\n\n- Call `draw_canvas()`, which returns a `Canvas` object that we store as `c`; in other words, `c` is a `Canvas` object that corresponds the search display. This assumes that there is a function `draw_canvas()`, even though we haven't defined it yet.\n\nA `Canvas` object is a single display; it is, in a sense, the Python counterpart of a SKETCHPAD. See also:\n\n- %link:manual/python/canvas%\n\nWe now go one step down by defining `draw_canvas()` (above the rest of the script so far):\n\n~~~ .python\ndef draw_canvas():\n    \"\"\"Draws the search canvas.\n\n    Returns\n    -------\n    Canvas\n    \"\"\"\n    c = Canvas()\n    xy_list = xy_random(n=set_size, width=500, height=500, min_dist=75)\n    if target_present == 'present':\n        x, y = xy_list.pop()\n        draw_target(c, x, y)\n    elif target_present != 'absent':\n        raise Exception(f'Invalid value for target_present: {target_present}')\n    for x, y in xy_list:\n        draw_distractor(c, x, y)\n    return c\n~~~\n\n\nWhat happens here? We \u2026\n\n- Create an empty canvas, `c`, using the factory function `Canvas()`.\n- Generate a list of random `x, y` coordinates, called `xy_list`, using another common function, `xy_random()`. This list determines where the stimuli are shown.\n- Check if the experimental variable `target_present` has the value 'present'; if so, `pop()` one `x, y` tuple from `xy_list`, and draw the target at this location. This assumes that there is a function `draw_target()`, even though we haven't defined it yet.\n- If `target_present` is neither 'present' nor 'absent', we raise an `Exception`; this is defensive programming, and protects us from typos (e.g. if we had accidentally entered 'presenr' instead of 'present').\n- Loop through all remaining `x, y` tuples and draw a distractor at each position. This assumes that there is a function `draw_distractor()`, even though we haven't defined it yet.\n- Return `c`, which now has the search display drawn onto it.\n\nThere are several common functions, such as `Canvas()` and `xy_random()`, which are always available. See:\n\n- %link:manual/python/common%\n\nExperimental variables are global variables. That's why you can refer to `set_size`, which is defined in *block_loop*, even though the variable `set_size` is never explicitly defined in the script. The same is true for `target_shape`, `target_color`, `condition`, etc. See:\n\n- %link:var%\n\n__Implement the intermediate level__\n\nWe now go one more step down by defining `draw_target` (above the rest of the script so far):\n\n~~~ .python\ndef draw_target(c, x, y):\n    \"\"\"Draws the target.\n\n    Parameters\n    ----------\n    c: Canvas\n    x: int\n    y: int\n    \"\"\"\n    draw_shape(c, x, y, color=target_color, shape=target_shape)\n~~~\n\nWhat happens here? We \u2026\n\n- Call another function, `draw_shape()`, and specify the color and shape that needs to be drawn. This assumes that there is a function `draw_shape()`, even though we haven't defined it yet.\n\nWe also define `draw_distractor` (above the rest of the script so far):\n\n~~~ .python\ndef draw_distractor(c, x, y):\n    \"\"\"Draws a single distractor.\n\n    Parameters\n    ----------\n    c: Canvas\n    x: int\n    y: int\n    \"\"\"\n    if condition == 'conjunction':\n        draw_conjunction_distractor(c, x, y)\n    elif condition == 'feature_shape':\n        draw_feature_shape_distractor(c, x, y)\n    elif condition == 'feature_color':\n        draw_feature_color_distractor(c, x, y)\n    else:\n        raise Exception(f'Invalid condition: {condition}')\n~~~\n\nWhat happens here? We \u2026\n\n- Call another function to draw a more specific distractor depending on the Condition.\n- Check whether `condition` has any of the expected values. If not, we raise an `Exception`. This is defensive programming! Without this check, if we made a typo somewhere, the distractor might simply not be shown without causing an error message.\n\nNow we define the function that draws distractors in the Conjunction condition (above the rest of the script so far):\n\n~~~ .python\nimport random\n\n\ndef draw_conjunction_distractor(c, x, y):\n    \"\"\"Draws a single distractor in the conjunction condition: an object that\n    can have any shape and color, but cannot be identical to the target.\n\n    Parameters\n    ----------\n    c: Canvas\n    x: int\n    y: int\n    \"\"\"\n    conjunctions = [('yellow', 'circle'),\n                    ('blue',   'circle'),\n                    ('yellow', 'square'),\n                    ('blue',   'square')]\n    conjunctions.remove((target_color, target_shape))\n    color, shape = random.choice(conjunctions)\n    draw_shape(c, x, y, color=color, shape=shape)\n~~~\n\nWhat happens here? We \u2026\n\n- Define a list, `conjunctions`, of all possible color and shape combinations.\n- Remove the target from this list; this is necessary, because the distractor cannot be identical to the target.\n- Randomly select one of the color and shape combinations from `conjunctions`.\n- Call another function, `draw_shape()`, and specify the color and shape of the to-be-drawn distractor. This assumes that there is a function `draw_shape()`, even though we haven't defined it yet.\n\nIn addition, we \u2026\n\n- Add the line `import random` to the top of the script. This is necessary so that we can use functions that are part of the `random` module, such as `random.choice()`.\n\nNow we define the function that draws distractors in the Shape Feature condition (right below the `import` statement):\n\n~~~ .python\ndef draw_feature_shape_distractor(c, x, y):\n    \"\"\"Draws a single distractor in the feature-shape condition: an object that\n    has a different shape from the target, but can have any color.\n\n    Parameters\n    ----------\n    c: Canvas\n    x: int\n    y: int\n    \"\"\"\n    colors = ['yellow', 'blue']\n    color = random.choice(colors)\n    if target_shape == 'circle':\n        shape = 'square'\n    elif target_shape == 'square':\n        shape = 'circle'\n    else:\n        raise Exception(f'Invalid target_shape: {target_shape}')\n    draw_shape(c, x, y, color=color, shape=shape)\n~~~\n\nWhat happens here? We \u2026\n\n- Randomly select a color.\n- Choose a square shape if the target is a circle, and a circle shape if the target is square.\n- If `target_shape` is neither 'circle' nor 'square', raise an `Exception`\u2014more defensive programming!\n- Call another function, `draw_shape()`, and specify the color and shape of the to-be-drawn distractor. This assumes that there is a function `draw_shape()`, even though we haven't defined it yet.\n\nNow we define the function that draws distractors in the Color Feature condition (right below the `import` statement):\n\n~~~ .python\ndef draw_feature_color_distractor(c, x, y):\n    \"\"\"Draws a single distractor in the feature-color condition: an object that\n    has a different color from the target, but can have any shape.\n\n    Parameters\n    ----------\n    c: Canvas\n    x: int\n    y: int\n    \"\"\"\n    shapes = ['circle', 'square']\n    shape = random.choice(shapes)\n    if target_color == 'yellow':\n        color = 'blue'\n    elif target_color == 'blue':\n        color = 'yellow'\n    else:\n        raise Exception(f'Invalid target_color: {target_color}')\n    draw_shape(c, x, y, color=color, shape=shape)\n~~~\n\nWhat happens here? We \u2026\n\n- Randomly select a shape.\n- Choose a blue color if the target is yellow, and a yellow color if the target is blue.\n- If `target_color` is neither 'yellow' nor 'blue', raise an `Exception`\u2014more defensive programming!\n- Call another function, `draw_shape()`, and specify the color and shape of the to-be-drawn distractor. This assumes that there is a function `draw_shape()`, even though we haven't defined it yet.\n\n__Implement the detailed level__\n\nNow we go all the way down to the details by defining the function that actually draws a shape to the canvas (right below the `import` statement):\n\n~~~ .python\ndef draw_shape(c, x, y, color, shape):\n    \"\"\"Draws a single shape.\n\n    Parameters\n    ----------\n    c: Canvas\n    x: int\n    y: int\n    color: str\n    shape: str\n    \"\"\"\n    if shape == 'square':\n        c += Rect(x=x-25, y=y-25, w=50, h=50, color=color, fill=True)\n    elif shape == 'circle':\n        c += Circle(x=x, y=y, r=25, color=color, fill=True)\n    else:\n        raise Exception(f'Invalid shape: {shape}')\n    if color not in ['yellow', 'blue']:\n        raise Exception(f'Invalid color: {color}')\n~~~\n\nWhat happens here? We \u2026\n\n- Check which shape should be drawn. For squares, we add a `Rect()` element to the canvas. For circles, we add a `Circle()` element.\n- Check if the the shape is either a square or a circle, and if not raise an `Exception`. This is another example of defensive programming! We're making sure that we haven't accidentally specified an invalid shape.\n- Check if the the color is neither yellow nor blue, and if not raise an `Exception`.\n\n__Implement the Run phase__\n\nBecause we have done all the hard work in the Prepare phase, the Run phase is just:\n\n~~~ .python\nc.show()\n~~~\n\nThat's it! Now you have drawn a full visual-search display. And, importantly, you have done so in a way that is easy to understand, because of top-down programming, and safe, because of defensive programming.\n\n", "url": "https://osdoc.cogsci.nl/4.0/tutorials/intermediate", "title": "Intermediate tutorial (Python) visual search"}
{"content": "# Intermediate tutorial (Python) visual search\n\n## Step 7: Define the correct response\n\nTo know if the participant responds correctly, we need to know the correct response. You can define this explicitly in the *block_loop* (as done in the beginner tutorial); but here we're going to use a simple Python script that checks whether the target is present or not, and defines the correct response accordingly.\n\nTo do this, insert a new INLINE_SCRIPT at the start of *trial_sequence*, and rename it to *correct_response_script*. In the Prepare phase (not the Run phase!), enter the following code:\n\n~~~ .python\nif target_present == 'present':\n    correct_response = 'right'\nelif target_present == 'absent':\n    correct_response = 'left'\nelse:\n    raise Exception(f'target_present should be absent or present, not {target}')\n~~~\n\nWhat happens here? We \u2026\n\n- Check whether the target is present or not. If the target is present, the correct response is 'right' (the right arrow key); if the target is absent, the correct response is 'left' (the left arrow key). The experimental (global) variable `correct_response` is automatically recognized by *keyboard_response*; therefore, we don't need to explicitly indicate that this variable contains the correct response.\n- Check if the target is either present or absent, and if not raise an `Exception`\u2014another example of defensive programming.\n\n## Step 8: Give per-trial feedback\n\nFeedback after every trial can motivate participants; however, per-trial feedback should not interfere with the flow of the experiment. A good way to give per-trial feedback is to briefly show a green fixation dot after a correct response, and a red fixation dot after an incorrect response.\n\nTo do this:\n\n- Insert two new SKETCHPADs into *trial_sequence*, just after *keyboard_response*.\n- Rename one SKETCHPAD to *green_dot*, draw a central green fixation dot onto it, and change its duration to 500.\n- Rename the other SKETCHPAD to *red_dot*, draw a central red fixation dot onto it, and change its duration to 500.\n\nOf course, only one of the two dots should be shown on each trial. To accomplish this, we will specify run-if expressions in *trial_sequence*:\n\n- Change the run-if expression for *green_dot* to 'correct == 1', indicating that it should only be shown after a correct response.\n- Change the run-if expression for *red_dot* to 'correct == 0', indicating that it should only be shown after an incorrect response.\n\nThe variable `correct` is automatically created if the variable `correct_response` is available; that's why we defined `correct_response` in step 7. For more information about variables and run-if statements, see:\n\n- %link:manual/variables%\n\nThe *trial_sequence* should now look like %FigStep8.\n\n%--\nfigure:\n id: FigStep8\n source: step8.png\n caption: |\n  The *trial_sequence* at the end of step 8.\n--%\n\n## Finished!\n\nCongratulations, the experiment is complete! You can give it a test run by pressing on the blue double-arrow button (shortcut: `Ctrl+W`).\n\nIf the experiment doesn't work on the first try: Don't worry, and calmly figure out where the mistake comes from. Crashes are part of the normal development process. But you can save yourself a lot of time and headache by working in a structured way, as we have done in this tutorial.\n\n## References\n\n<div class='reference' markdown='1'>\n\nMath\u00f4t, S., Schreij, D., & Theeuwes, J. (2012). OpenSesame: An open-source, graphical experiment builder for the social sciences. *Behavior Research Methods*, *44*(2), 314-324. doi:10.3758/s13428-011-0168-7\n\nTreisman, A. M., & Gelade, G. (1980). A feature-integration theory of attention. *Cognitive Psychology*, 12(1), 97\u2013136. doi:10.1016/0010-0285(80)90005-5\n\n</div>\n\n[references]: #references\n[gpl]: http://www.gnu.org/licenses/gpl-3.0.en.html", "url": "https://osdoc.cogsci.nl/4.0/tutorials/intermediate", "title": "Intermediate tutorial (Python) visual search"}
{"content": "# Touch response\n\ntitle: Touch response\n\nThe `touch_response` plug-in allows you to work with touch responses (or mouse clicks) in an easy way, by dividing the display into rows and columns. Each response is encoded by a single number, which corresponds to the position counting from left-to-right and top-down. For example, if you have specified 2 columns and 3 rows, the display is divided into the following response regions:\n\n```bash\n1\t2\n3\t4\n5\t6\n```\n\nSimilarly, if you have specified 4 columns and 1 row, the display is sliced horizontally into the following response regions:\n\n```bash\n1\t2\t3\t4\n```", "url": "https://osdoc.cogsci.nl/4.0/items/touch_response", "title": "Touch response"}
{"content": "# Advanced_delay\n\ntitle: Advanced_delay\n\nThe `advanced_delay` plug-in delays the experiment for a pre-specified average duration plus a random margin.\n\n- *Duration* is the average duration of the delay in milliseconds.\n- *Jitter* is the size of the variation in the delay in milliseconds.\n- *Jitter mode* is the how the jitter is calculated:\n\t- *Standard deviation* will draw the variation from a Gaussian distribution with Jitter as the standard deviation.\n\t- *Uniform* will draw the variation in duration from a uniform distribution.", "url": "https://osdoc.cogsci.nl/4.0/items/advanced_delay", "title": "Advanced_delay"}
{"content": "# Quest staircase next\n\ntitle: Quest staircase next\n\nProcesses a response and updates the Quest test value.", "url": "https://osdoc.cogsci.nl/4.0/items/quest_staircase_next", "title": "Quest staircase next"}
{"content": "# Repeat_cycle\n\ntitle: Repeat_cycle\n\nThis plug-in allows you to repeat cycles from a `loop`. Most commonly, this will be to repeat a trial when a participant made a mistake or was too slow.\n\nFor example, to repeat all trials on which a response was slower than 3000 ms, you can add a `repeat_cycle` item after (typically) the `keyboard_response` and add the following repeat-if expression:\n\n```bash\nresponse_time > 3000\n```\n\nYou can also force a cycle to be repeated by setting the variable `repeat_cycle` to 1 in an `inline_script`, like so:\n\n```python\nrepeat_cycle = 1\n```", "url": "https://osdoc.cogsci.nl/4.0/items/repeat_cycle", "title": "Repeat_cycle"}
{"content": "# Reset_feedback\n\ntitle: Reset_feedback\n\nThis plug-in has the same effect as presenting a FEEDBACK item with a duration of 0 ms\n{: .page-notification}\n\nIf you do not reset feedback variables, you may confound your feedback with responses that are not relevant to the task. For example, the key presses made during the instruction phase may affect the feedback during the first block of the experiment. Therefore, you will need to reset the feedback variables at appropriate moments.\n\nThis plug-in will reset the following variables to 0:\n\n- `total_response_time`\n- `total_response`\n- `acc`\n- `accuracy`\n- `avg_rt`\n- `average_response_time`", "url": "https://osdoc.cogsci.nl/4.0/items/reset_feedback", "title": "Reset_feedback"}
{"content": "# Quest staircase init\n\ntitle: Quest staircase init\n\nInitializes a new Quest staircase procedure.", "url": "https://osdoc.cogsci.nl/4.0/items/quest_staircase_init", "title": "Quest staircase init"}
{"content": "# Runners\n\ntitle: Runners\n\n\n[TOC]\n\n\n## About runners\n\nThere are several technically different ways in which you can execute your experiment. Each of these corresponds to a *runner*. You can select a runner under Menu \u2192 Tools \u2192 Preferences \u2192 Runner.\n\nUnless you have a reason not to, you should use the *multiprocess* runner. However, if OpenSesame sometimes crashes, you can try whether selecting a different runner resolves this.\n\n\n## Available runners\n\n### Multiprocess\n\nThe *multiprocess* runner executes your experiment in a different process. The benefit of this approach is that your experiment can crash without bringing the user interface down with it. Another advantage of the *multiprocess* runner is that it allows the variable inspector to show your experimental variables while the experiment is running.\n\n### Inprocess\n\nThe *inprocess* runner executes the experiment in the same process as the user interface. The benefit of this approach is its simplicity. The downside is that the user interface may crash if the experiment crashes, and vice versa.\n\n### External\n\nThe *external* runner executes the experiment by launching opensesamerun as a separate application. The benefit of this approach is that your experiment can crash without bringing the user interface down with it.", "url": "https://osdoc.cogsci.nl/4.0/manual/runners", "title": "Runners"}
{"content": "# OpenSesame script\n\ntitle: OpenSesame script\nreviewed: false\n\n[TOC]\n\n## About OpenSesame script\n\nOpenSesame script is a simple definitional language that defines an experiment. It is not a full fledged programming language, and does not include features such a `for` loops. The OpenSesame script is interpreted by an OpenSesame runtime environment.\n\nOpenSesame script is different from the Python scripts that are used in inline_script items. Python is a real programming language with all the flexibility and complexities that this entails. In contrast, OpenSesame script is used to define experiments in a simple, human-readable way.\n\n## General remarks\n\n### Keywords\n\nSome items, such as form_base and sketchpad accept keywords. Keywords are of the form `keyword=value`. Keywords are optional and should fall back to a default value.\n\n### Comments\n\nStrings preceded by a hash should be interpreted as comments.\n\n*Example*\n\n\t# This is a comment\n\n### Quotation\n\nQuotation is not necessary, except around strings that contain spaces or other forms of punctuation. So the following lines should be interpreted as identical:\n\n\tset my_var 'my_value'\n\tset my_var \"my_value\"\n\tset my_var my_value\n\nHowever, the following lines are not. In fact, the first line is not valid, because it has an unexpected third parameter.\n\n\tset my_var my value\n\tset my_var \"my value\"\n\n### Types\n\nThere are no types. No distinction is made between strings, integers, etc.\n\n### Item-specific syntax\n\nSome items have a specific syntax. This is indicated in the \u201cApplies to\u201d section for each of the keywords discussed below.\n\n### Resolving path names\n\nTODO\n\n## *define* statement\n\nStarts the definition of an item. After a define statement, all lines are indented by a single tab. The end of the item definition is the first string that is no longer indented. Nested define statements are not allowed.\n\n*Applies to*\n\nAll items\n\n*Format*\n\n\tdefine [item name] [item type]\n\t\t[item definition]\n\n*Parameters*\n\n|`item name`\t|the name of the item\t|\n|`item type`\t|the type of the item\t|\n\n*Example*\n\n\tdefine get_key keyboard_response\n\t\tset allowed_responses \"a;x\"\n\t\tset description \"Collects keyboard responses\"\n\t\tset timeout \"infinite\"\n\t\tset flush \"yes\"\n\n## *draw* statement\n\nDefines a visual element of a sketchpad or feedback item.\n\n*Applies to*\n\nsketchpad, feedback\n\n*Format*\n\nThe format depends on the element.\n\n\tdraw ellipse [left] [top] [width] [height] [keywords]\n\tdraw circle [x] [y] [radius] [keywords]\n\tdraw line [left] [right] [top] [bottom] [keywords]\n\tdraw arrow [left] [right] [top] [bottom] [keywords]\n\tdraw textline [x] [y] [text]\n\tdraw image [x] [y] [path]\n\tdraw gabor [x] [y]\n\tdraw noise [x] [y]\n\tdraw fixdot [x] [y]\n\n*Parameters*\n\n|`left` \t\t|the left-most x-coordinate\t\t|\n|`right`\t\t|the right-most x-coordinate\t|\n|`top`\t\t\t|the top y-coordinate\t\t\t|\n|`bottom`\t\t|the bottom y-coordinate\t\t|\n|`x` \t\t\t|the x-coordinate\t\t\t\t|\n|`y`\t\t\t|the y-coordinate\t\t\t\t|\n|`text` \t\t|text string\t\t\t\t\t|\n|`path` \t\t|the path to an image file\t\t|\n\n*Keywords*\n\nTODO\n\n*Example*\n\n\tdraw fixdot 0 0\n\n## *log* statement\n\nIndicates that a variable should be written to the log-file.\n\n*Applies to*\n\nlogger\n\n*Format*\n\n\tlog [variable name]\n\n*Parameters*\n\n|`variable name`\t\t|the name of a variable\t|\n\n*Example*\n\n\tlog response_time\n\n## *run* statement\n\nIndicates that an item should be run. In the case of the sequence, the order of the run statements determines the order in which items are called. In the case of the coroutines plugin all items are called at the same time.\n\n*Applies to*\n\nsequence\n\n*Format*\n\n\trun [item name] [optional: condition] [optional: disabled]\n\n*Parameters*\n\n|`item name`\t\t\t|the name of the item to run\t|\n|`condition` (optional)\t|the conditional statement, which determines the item is actually called. If no condition is provided, the item is always called.|\n\n*Example*\n\n\trun correct_feedback '[correct] = 1'\n\n## *set* statement\n\nDefines single-line variables.\n\n*Applies to*\n\nAll items\n\n*Format*\n\n\tset [variable name] [value]\n\n*Parameters*\n\n|`variable name`\t|the variable name\t|\n|`value`\t\t\t|the variable value\t|\n\n*Example*\n\n\tset timeout 1000\n\n*Notes*\n\nMulti-line variables are defined using the `__[variable name]__` notation. This is mostly useful for items that require large blocks of text. Within an item definition, each line is preceded by a single tab, which should not be interpreted as part of the text. `__end__` indicates the end of the variable.\n\n*For example:*\n\n\t__my_variable__\n\tThis is the first line.\n\tThis is the second line.\n\t__end__\n\n## *setcycle* statement\n\nSimilar to the regular \u201cset\u201d statement, but sets a variable only during a specific cycle of a loop. This is the script equivalent of the loop table.\n\n*Applies to*\n\nLoop\n\n*Format*\n\n\tsetcycle [cycle #] [variable name] [variable value]\n\n*Parameters*\n\n|`Cycle #`\t\t\t|the number of the cycle, where 0 is the first\t|\n|`variable name` \t|the variable name\t\t\t\t\t\t\t\t|\n|`value`\t\t\t|the variable value\t\t\t\t\t\t\t\t|\n\n*Example*\n\n\tsetcycle 0 cue valid\n\n## *widget* statement\n\nAdds a widget (buttons, labels, etc.) to a form. Valid keywords depend on the type of widget. The widget statement is not strictly part of the core OpenSesame syntax, but is used by the form_base plugin.\n\n*Applies to*\n\nform_base (plugin)\n\n*Format*\n\n\twidget [column] [row] [column span] [row span] [widget type] [keywords]\n\n*Parameters*\n\n|`column`\t\t|the widget's column position in the form, where 0 is left-most\t\t\t\t\t\t\t\t|\n|`row`\t\t\t|the widget's row position in the form, where 0 is top\t\t\t\t\t\t\t\t\t\t|\n|`column span`\t|the number of columns that the widget occupies\t\t\t\t\t\t\t\t\t\t\t\t|\n|`row span`\t\t|the number of rows that the widget occupies\t\t\t\t\t\t\t\t\t\t\t\t|\n|`widget type`\t|'button', 'checkbox', 'image', 'image_button', 'label', 'rating_scale', or 'text_input'\t|\n\n*Keywords*\n\nTODO\n\n*Example*\n\n\twidget 0 0 1 1 label text='This is a label'", "url": "https://osdoc.cogsci.nl/4.0/manual/opensesame-script", "title": "OpenSesame script"}
{"content": "# Counterbalancing\n\ntitle: Counterbalancing\n\nCounterbalancing is a way to remove confounding factors from an experiment by having slightly different tasks for different groups of participants. This sounds abstract, so let's consider two examples.\n\n[TOC]\n\n### Example 1: Counterbalancing response rule\n\nConsider a lexical-decision experiment in which participants classify words as verbs by pressing 'z' with their left hand, or as nouns by pressing 'm' with their right hand. This design has a problem: If you find that participants respond faster to nouns than to verbs, this could be because nouns are processed faster than verbs, or because participants respond faster with their right hand than with their left hand. You can fix this problem by counterbalancing the response rule.\n\nFor even participant numbers:\n\n- verb \u2192 z\n- noun \u2192 m\n\nFor uneven participant numbers:\n\n- verb \u2192 m\n- noun \u2192 z\n\n### Example 2: Rotating stimulus conditions\n\nConsider a masked-priming experiment in which participants read target words aloud. On each trial, the target word is preceded by one of three types of priming words:\n\n- An unrelated prime, e.g. priming with 'berry' for target 'house'.\n- An ortoghraphically related prime, e.g. priming with 'mouse' for target 'house'\n- A semantically related prime, e.g. priming with 'garden' for target 'house'\n\nTo avoid repetition effects, you only want to show target words only once per participant. Therefore, you create three different sets of target words, one for each prime type. This is a between-word design, which has less statistical power than a within-word design, in which each target word occurs in each condition. (For the same reason that between-subject designs are less powerful than within-subject designs.)\n\nYou can use counterbalancing to change this experiment into a within-word design by 'rotating' the condition in which each word occurs between participants. We have three conditions, and we therefore have three groups of participants:\n\n- Participants 1, 4, 7, etc.\n    - Word A in condition 1\n    - Word B in condition 2\n    - Word C in condition 3\n- Participants 2, 5, 8, etc.\n    - Word A in condition 2\n    - Word B in condition 3\n    - Word C in condition 1\n- Participants 3, 6, 9, etc.\n    - Word A in condition 3\n    - Word B in condition 1\n    - Word C in condition 2\n\n\n## Implementing counterbalancing\n\n\n### Using the subject number\n\nWhen you run an experiment in OpenSesame on the desktop, you are asked for a subject number. When you run an experiment online, a subject number is randomly selected from the list of possible subject numbers that you have specified in the [OSWeb extension](%url:osweb). (This means that for online experiments you cannot ensure that the number of participants is exactly equal for the different conditions that you want to counterbalance, at least not if you rely on the subject number.)\n\nThis subject number is available as the experimental variable `subject_nr`. In  addition, the experimental variable `subject_parity` has the value 'odd' or 'even', depending on whether the subject number is odd or even. Now say that you want to counterbalance the response rule as in Example 1, you could add the following INLINE_SCRIPT to the start of the experiment.\n\n```python\nif subject_parity == 'odd':\n    verb_response = 'z'\n    noun_response = 'm'\nelse:\n    verb_response = 'm'\n    noun_response = 'z'\n```\n\nOr, when creating an OSWeb experiment, add the following INLINE_JAVASCRIPT to the start of the experiment:\n\n```javascript\nif (subject_parity === 'odd') {\n    verb_response = 'z'\n    noun_response = 'm'\n} else {\n    verb_response = 'm'\n    noun_response = 'z'\n}\n```\n\nNow, in your *block_loop*, instead of setting `correct_response` to a fixed value, you set it to a variable: `{verb_response}` or `{noun_response}`. You can take a look at the *lexical-decision task* example to see how this works (Menu -> Tools -> Example experiments).\n\n\n### Using Batch Session Data (JATOS and OSWeb only)\n\nWhen running an OSWeb experiment that is hosted on JATOS, you can make use of [Batch Session Data](https://www.jatos.org/jatos.js-Reference.html#functions-to-access-the-batch-session). This is data that is shared between all experimental sessions that are part of the same worker batch. Therefore, you can use this data to define a list of conditions that should be distributed across participants. At the start of each experimental session, one condition is removed from this list and used for the current session. This is the most sophisticated way to implement counterbalancing for OSWeb experiments that are hosted on JATOS.\n\nYou can download a template experiment here:\n\n- %static:attachments/counterbalancing-osweb-jatos.osexp%\n\nWhen running from JATOS, the experiment retrieves a single condition from the Batch Session Data (see below) and registers this as the experimental variable `condition`. When doing a test run, `condition` is set to a default value specified at the end of *init_condition*.\n\nThe experiment itself should be implemented in the *experiment* SEQUENCE, which in the template contains only the *show_condition* SKETCHPAD (see %FigCounterbalancingOSWebJATOS).\n\n%--\nfigure:\n    source: counterbalancing-osweb-jatos.png\n    id: FigCounterbalancingOSWebJATOS\n    caption: |\n        The overview area of the template experiment for implementing counterbalancing with JATOS Batch Session Data.\n--%\n\nWhen importing the experiment into JATOS, all conditions should be specified in the Batch Session Data as the `pending` list (under Worker & Batch Manager; see %FigBatchSessionData). Each condition from `pending` corresponds to a single experimental session; therefore, if condition `a` should be used for two experimental sessions, then `a` needs to occur twice in the `pending` list. The conditions are used in the order in which they are defined.\n\n%--\nfigure:\n    source: batch-session-data.png\n    id: FigBatchSessionData\n    caption: |\n        The conditions should be specified in the Batch Session Data in JATOS.\n--%\n\nAt the start of an experimental session, a single condition is moved from `pending` to `started`. (When the `pending` list is empty, the participant is informed that he or she can no longer participate in the experiment.) At the end of the experimental session, the condition is appended to the `finished` list.\n\nTo make this more concrete, let's say that you've defined the Batch Session Data as shown in %FigBatchSessionData. Then, four experimental sessions are started, but the second experimental session, with condition `a`, never finishes, for example because the participant closes the browser halfway the experiment. The Batch Session Data will then look as in %FigBatchSessionAfter:\n\n%--\nfigure:\n    source: batch-session-data-after.png\n    id: FigBatchSessionAfter\n    caption: |\n        The Batch Session Data after all conditions have been consumed. One session, with condition `a`, never finished.\n--%\n\nYou can tell from the Batch Session Data that one experimental session started with condition `a` but never finished. To nevertheless collect an experimental session with this condition, you have to manually add a new `a` to the `pending` list and collect a new session.", "url": "https://osdoc.cogsci.nl/4.0/manual/counterbalancing", "title": "Counterbalancing"}
{"content": "# Variables\n\ntitle: Variables\n\n[TOC]\n\n## What is an experimental variable in OpenSesame?\n\nExperimental variables in OpenSesame are those variables that:\n\n- You can refer to in the user interface with the '{variable_name}' syntax.\n- Are available as global variables in a Python INLINE_SCRIPT.\n- Are available as global variables in a JavaScript INLINE_JAVASCRIPT.\n- Contain things like:\n\t- The variables that you have defined in a LOOP item.\n\t- The responses that you have collected.\n\t- Various properties of the experiment.\n\t- Etc.\n\n## The variable inspector\n\nThe variable inspector (`Ctrl+I`) provides an overview of available variables (%FigVariableInspector). When the experiment is not running, this overview is based on a best guess of which variables will become available during the experiment. However, when the experiment is running, the variable inspector shows a live overview of variables and their values. This is useful for debugging your experiment.\n\n%--\nfigure:\n id: FigVariableInspector\n source: variable-inspector.png\n caption: The variable inspector provides an overview of all variables that OpenSesame knows about.\n--%\n\n## Defining variables\n\nThe simplest way to define a variable is through the LOOP item. For example, %FigLoop shows how to define a variable named `gaze_cue`. In this example, *trial_sequence* item is called four times while `gaze_cue` is 'left' and another four times while 'gaze_cue' is 'right'.\n\n%--\nfigure:\n id: FigLoop\n source: defining-variables-in-a-loop.png\n caption: The most common way to define independent variables is using the LOOP table.\n--%\n\n## Built-in variables\n\nThe following variables are always available:\n\n### Experiment variables\n\n|Variable name\t\t\t|Description|\n|-----------------------|-----------|\n|`title`\t\t\t\t|The title of the experiment|\n|`description`\t\t\t|The description of the experiment|\n|`foreground`\t\t\t|The default foreground color. E.g., 'white' or '#FFFFFF'.|\n|`background`\t\t\t|The default background color. E.g., 'black' or '#000000'.|\n|`height`\t\t\t\t|The height-part of the display resolution. E.g., '768'|\n|`width`\t\t\t\t|The width-part of the display resolution. E.g., '1024'|\n|`subject_nr`\t\t\t|The subject number, which is asked when the experiment is started.|\n|`subject_parity`\t\t|Is 'odd' if `subject_nr` is odd and 'even' if `subject_nr` is even. Useful for counterbalancing.|\n|`experiment_path`\t\t|The folder of the current experiment, without the experiment filename itself. If the experiment is unsaved, it has the value `None`.|\n|`pool_folder`\t\t\t|The folder where the contents of the file pool have been extracted to. This is generally a temporary folder.|\n|`logfile`\t\t\t\t|The path to the logfile.|\n\n### Item variables\n\nThere are also variables that keep track of all the items in the experiment.\n\n|Variable name\t\t\t|Description|\n|-----------------------|-----------|\n|`time_[item_name]`\t\t|Contains a timestamp of when the item was last executed. For SKETCHPAD items, this can be used to verify the timing of display presentation.|\n|`count_[item_name]`\t|Is equal the number of times minus one (starting at 0, in other words) that an item has been called. This can, for example, be used as a trial or block counter.|\n\n### Response variables\n\nWhen you use the standard response items, such as the KEYBOARD_RESPONSE and MOUSE_RESPONSE, a number of variables are set based on the participant's response.\n\n|Variable name\t\t\t\t\t|Description|\n|-------------------------------|-----------|\n|`response`\t\t\t\t\t\t|Contains the last response that has been given.|\n|`response_[item_name]`\t\t\t|Contains the last response for a specific response item. This is useful in case there are multiple response items.|\n|`response_time`\t\t\t\t|Contains the interval in milliseconds between the start of the response interval and the last response.|\n|`response_time_[item_name]`\t|Contains the response time for a specific response item.|\n|`correct`\t\t\t\t\t\t|Is set to '1' if the last `response` matches the variable `correct_response`, '0' if not, and 'undefined' if the variable `correct_response` has not been set.|\n|`correct_[item_name]`\t\t\t|As `correct` but for a specifc response item.|\n\n### Feedback variables\n\nFeedback variables maintain a running average of accuracy and response times.\n\n|Variable name\t\t\t\t\t|Description|\n|-------------------------------|-----------|\n|`average_response_time`\t\t|The average response time. This is variable is useful for presenting feedback to the participant.|\n|`avg_rt`\t\t\t\t\t\t|Synonym for `average_response_time`|\n|`accuracy`\t\t\t\t\t\t|The average percentage of correct responses. This is variable is useful for presenting feedback to the participant.|\n|`acc`\t\t\t\t\t\t\t|Synonym for `accuracy`|\n\n\n## Using variables in the user interface\n\nWherever you see a value in the user interface, you can replace that value by a variable using the '{variable name}' notation. For example, if you have defined a variable `soa` in a LOOP item, you can use this variable for the duration of a sketchpad as shown in %FigSketchpad.\n\n%--\nfigure:\n id: FigSketchpad\n source: variable-duration.png\n caption: The duration '{soa}' indicates that the duration of the SKETCHPAD depends on the variable `soa`.\n--%\n\nThis works throughout the user interface. For example, if you have the defined a variable `my_freq`, you can use this variable as the frequency in a SYNTH item, as shown in %FigSynth.\n\n%--\nfigure:\n id: FigSynth\n source: variable-frequency.png\n caption: The frequency '{my_freq}' indicates that the frequency of the SYNTH depends on the variable `my_freq`.\n--%\n\nSometimes, the user interface doesn't let you type in arbitrary text. For example, the elements of a SKETCHPAD are shown visually, and you cannot directly change an X coordinate to a variable. However, you can click on the *Select view \u2192 View script* button on the top right, and edit the script directly.\n\nFor example, you can change the position of a fixation dot from the center:\n\n```text\ndraw fixdot x=0 y=0\n```\n\n\u2026 to a position defined by the variables `xpos` and `ypos`:\n\n```text\ndraw fixdot x={xpos} y={ypos}\n```\n\n\n## Using Python expressions in the user interface\n\nWhen referring to variables using the `{my_var}` notation, you are in fact using a so-called [f-string](https://peps.python.org/pep-0498/), which is a way to embed Python code in strings of text. You can also use f-strings to evaluate arbitrary Python code. For example, you can multiply the variables `width` and `height` and include the result in a SKETCHPAD, like so:\n\n%--\nfigure:\n id: FigFString\n source: fstrings.png\n caption: You can embed Python expressions using f-strings.\n--%\n\nf-strings are Python code, and are therefore only supported on the desktop, but see below for a JavaScript alternative for browser experiments.\n\n\n## Using JavaScript expressions in the user interface\n\nWhen using OSWeb, expressions included between curly braces are interpreted as [template literals](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Template_literals). This is very similar to f-strings in Python, with the important difference that it uses JavaScript.\n\nIn normal JavaScript, expressions inside template literals are prefixed with a `$`, like so: `${expression}`. This is allowed in OpenSesame but not necessary: the prefix is automatically added to improve compatibility between browser and desktop experiments. In most cases, as in the figure below, the exact same expression is valid as a Python f-string on the desktop and a JavaScript template literal in the browser.\n\n\n%--\nfigure:\n id: FigTempalteLiteral\n source: template-literals.png\n caption: You can embed JavaScript expressions using template literals.\n--%\n\n\n## Using variables in Python\n\nIn an INLINE_SCRIPT, experimental variables are available as global variables. For example, if you have defined `example_variable` in a LOOP, then the following will print the value `example_variable` to the debug window:\n\n~~~ .python\nprint(example_variable)\n~~~\n\nYou can set the experimental variable `example_variable` to the value 'some value' as follows:\n\n~~~ .python\nexample_variable = 'some value'\n~~~\n\n\n## Using variables in JavaScript\n\nIn an INLINE_JAVASCRIPT, experimental variables are available as global variables. For example, if you have defined `example_variable` in a LOOP, then the following will print the value `example_variable` to the browser console:\n\n```js\nconsole.log(example_variable)\n```\n\nYou can set the experimental variable `example_variable` to the value 'some value' as follows:\n\n```js\nexample_variable = 'some value'\n```\n\n\n## Using conditional (\"if\") statements\n\nConditional statements, or 'if statements', provide a way to indicate that something should happen only under specific circumstances, such when some variable has a specific value. Conditional statements are regular Python expressions.\n\nThe most commonly used if-statement in OpenSesame is the run-if statement of the SEQUENCE, which allows you to specify the conditions under which a particular element is executed. If you open a SEQUENCE item, you see that every item from the sequence has a 'Run if \u2026'' option. The default value is 'always', which means that the item is always run; but you can also enter a condition here. For example, if you want to show a green fixation dot after a correct response, and a red fixation dot after an incorrect response, you can create a SEQUENCE like the following (this makes use of the fact that a KEYBOARD_RESPONSE item automatically sets the `correct` variable, as discussed above) as shown in %FigRunIf.\n\n*Important:* Run-if statements only apply to the Run phase of items. The Prepare phase is always executed. See also [this page](%link:prepare-run%).\n\n%--\nfigure:\n id: FigRunIf\n source: run-if.png\n caption: |\n  'Run if' statements can be used to indicate that certain items from a SEQUENCE should only be executed under specific circumstances.\n--%\n\nYou can use more complex conditions as well. Let's take a look at a few examples:\n\n```python\ncorrect == 1 and response_time > 2000\ncorrect != 1 or response_time > max_response_time or response_time < min_response_time\n```\n\nThe same principle applies to 'Show if' fields in SKETCHPAD items. For example, if you want to draw a right-upwards-pointing arrow only if the variable `quadrant` has been set to 'upper right', simply type the proper condition in the 'Show if ...' field and draw the arrow, as in %FigShowIf. Make sure that you draw the arrow after you have set the condition.\n\n%--\nfigure:\n id: FigShowIf\n source: show-if.png\n caption: \"'Show if' statements can be used to indicate that certain elements from a SKETCHPAD or FEEDBACK item should only be shown under specific circumstances.\"\n--%\n\nImportant: The moment at which a conditional statement is evaluated may affect how your experiment works. This is related to the prepare-run strategy employed by OpenSesame, which is explained here:\n\n- %link:prepare-run%", "url": "https://osdoc.cogsci.nl/4.0/manual/variables", "title": "Variables"}
{"content": "# Examples\n\ntitle: Examples\n\nExample experiments are included with OpenSesame. A list of curated examples is available through Menu \u2192 Tools \u2192 Example experiments. You can also search for publicly available experiments on the OpenScienceFramework by using 'osexp' as search term.\n\n- <https://osf.io/search/?q=osexp>", "url": "https://osdoc.cogsci.nl/4.0/manual/examples", "title": "Examples"}
{"content": "# Mouse tracking\n\ntitle: Mouse tracking\n\nMousetrap is a third-party plugin, and is not maintained by the OpenSesame team.\n{: .alert .alert-info}\n\n## About\n\nPascal Kieslich and Felix Henninger have developed the [mousetrap plugins](https://github.com/PascalKieslich/mousetrap-os) for OpenSesame [(Kieslich & Henninger, 2017)](https://dx.doi.org/10.3758/s13428-017-0900-z). These plugins allow you to track the movement of the mouse cursor, which has been used to investigate the time course of cognitive processes in many psychological domains [(Freeman, Dale, & Farmer, 2011)](https://dx.doi.org/10.3389/fpsyg.2011.00059).\n\nMousetrap offers two plugins for mouse tracking in OpenSesame that can be included in the experiment via drag-and-drop.\nThe [mousetrap response plugin](https://github.com/PascalKieslich/mousetrap-os/blob/master/plugins/mousetrap_response/mousetrap_response.md) tracks mouse movements while another stimulus (e.g., a sketchpad) is shown, analogous to a keyboard or mouse response item.\nThe [mousetrap form plugin](https://github.com/PascalKieslich/mousetrap-os/blob/master/plugins/mousetrap_form/mousetrap_form.md) allows for tracking of mouse movements in [custom forms](%link:manual/forms/custom%).\nBesides, both plugins also provide Python classes, which can be used in Python inline scripts for maximum customizability.\n\nOnce data have been collected with the plugins, the data can be processed, analyzed and visualized using the [mousetrap R package](http://pascalkieslich.github.io/mousetrap/).\n\n## Installation\n\nInformation about how to install the mousetrap plugin can be found on its [GitHub page](https://github.com/PascalKieslich/mousetrap-os#installation). A number of example experiments that demonstrate the basic features are available in the [examples folder](https://github.com/PascalKieslich/mousetrap-os/tree/master/examples#example-experiments).\n\n\nSee also:\n\n- <https://rapunzel.cogsci.nl/manual/environment/>", "url": "https://osdoc.cogsci.nl/4.0/manual/mousetracking", "title": "Mouse tracking"}
{"content": "# Running experiments online\n\ntitle: Running experiments online\n\n\nThis page has been moved to:\n\n- %link:manual/osweb/workflow%", "url": "https://osdoc.cogsci.nl/4.0/manual/osweb", "title": "Running experiments online"}
{"content": "# Integration with the Open Science Framework\n\ntitle: Integration with the Open Science Framework\n\n[TOC]\n\n## About\n\nThe OpenScienceFramework extension connects OpenSesame to the [Open Science Framework](https://osf.io) (OSF), which is a web platform for sharing, connecting, and streamlining scientific workflows. To use this extension, [you need an OSF account](https://osf.io/login/?sign_up=True).\n\nWith the OpenScienceFramework extension, you can:\n\n- Automatically save your experiment to the OSF\n- Automatically upload data to the OSF\n- Open experiments from the OSF\n- Share your experiment and data with other researchers, by giving them access through the OSF\n\n## Logging in to the OSF\n\nTo log into the OSF:\n\n- Create an account on <https://osf.io>. (You cannot create an account from within OpenSesame.)\n- In OpenSesame, click on the log-in button in the main toolbar, and enter your credentials.\n- Once logged in, you can open the OSF Explorer by clicking on your name where the login button used to be, and selecting *Show explorer*. The explorer will show an overview of all your OSF projects, and all repositories/ cloud services that are linked to your projects.\n\n## Linking an experiment to the OSF\n\nIf you link an experiment to the OSF, each time that you save the experiment in OpenSesame, a new version is also uploaded to the OSF.\n\nTo link an experiment:\n\n- Save the experiment on your computer.\n- Open the OSF explorer and select a folder or repository where you would like your experiment to be stored on the OSF. Right-click on this folder and select *Sync experiment to this folder*. The OSF node to which the experiment is linked will be shown at the top of the explorer.\n- The experiment is then uploaded to the selected location.\n- If you check *Always upload experiment on save*, a new version is automatically saved to OSF on each save; if you don't enable this option, you will be asked every time whether or not you want to do this.\n\nTo unlink an experiment:\n\n- Open the OSF explorer, and click the *Unlink* button next to the *Experiment linked to* link.\n\n## Linking data to the OSF\n\nIf you link data to the OSF, each time that data has been collected (normally after every experimental session), this data is also uploaded to the OSF.\n\nTo link data to the OSF:\n\n- Save the experiment on your computer.\n- Open the OSF explorer, right-click on the folder that you want the data to be uploaded to, and select *Sync data to this folder*. The OSF node that the data is linked to will be shown at the top of the explorer.\n- If you check *Always upload collected data*, data files will be automatically saved to OSF after they have been collected; if you don't enable this option, you will be asked every time whether or not you want to do this.\n\nTo unlink data from the OSF:\n\n- Open the OSF explorer, and click the *Unlink* button next to the *Data stored to* link.\n\n## Opening an experiment stored on the OSF\n\nTo open an experiment from the OSF:\n\n- Open the OSF explorer, and find the experiment.\n- Right-click on the experiment and select *Open experiment*.\n- Save the experiment on your computer.\n\n## Handling non-matching versions\n\nIf you open an experiment on your computer that is linked to the OSF, but differs from the version on the OSF, you will be asked what you want to do:\n\n- Use the version from your computer; or\n- Use the version from the OSF. If you choose to use the version from the OSF, it will be downloaded and overwrite the experiment on your computer.\n\n## Installing the OpenScienceFramework extension\n\nThe OpenScienceFramework extension is installed by default in the Windows package of OpenSesame. If the extension is not installed, you can install it as follows:\n\nFrom PyPi:\n\n~~~\npip install opensesame-extension-osf\n~~~\n\nIn an Anaconda environment\n\n~~~\nconda install -c cogsci opensesame-extension-osf\n~~~\n\nThe source code of the extension is available on GitHub:\n\n- <https://github.com/dschreij/opensesame-extension-osf>\n\nAnd for the `python-qosf` module, which is used by the extension:\n\n- <https://github.com/dschreij/python-qosf>", "url": "https://osdoc.cogsci.nl/4.0/manual/osf", "title": "Integration with the Open Science Framework"}
{"content": "# Installing packages, plugins, and extensions\n\ntitle: Installing packages, plugins, and extensions\n\n\nThis page has moved to:\n\n- <https://rapunzel.cogsci.nl/manual/environment/>", "url": "https://osdoc.cogsci.nl/4.0/manual/environment", "title": "Installing packages, plugins, and extensions"}
{"content": "# Using the interface\n\ntitle: Using the interface\n\nOpenSesame has a powerful graphical interface that consists of several components (%FigInterface).\n\n%--\nfigure:\n id: FigInterface\n source: interface.png\n caption: The OpenSesame user interface.\n--%\n\n\n[TOC]\n\n## Toolbars and menubar\n\n### The menubar\n\nThe menubar (%FigMenubar) is shown at the top of the window, or, on some operating systems, is integrated into the border around the window. The menubar contains general functionality, such as saving and opening experiments, running experiments, etc.\n\n%--\nfigure:\n id: FigMenubar\n source: menubar.png\n caption: The menubar.\n--%\n\n### The main toolbar\n\nThe main toolbar (%FigMainToolbar) is (by default) shown at the top of the window, just below the menubar. The main toolbar contains a selection of the most relevant functionality from the menubar.\n\n%--\nfigure:\n id: FigMainToolbar\n source: main-toolbar.png\n caption: The main toolbar.\n--%\n\n### The item toolbar\n\nThe item toolbar (%FigItemToolbar) is (by default) shown at the left of the window. The item toolbar contains all items, that is, all building blocks of an experiment. You can add items to your experiment by dragging them from the item toolbar into the overview area.\n\n%--\nfigure:\n id: FigItemToolbar\n source: item-toolbar.png\n caption: The item toolbar.\n--%\n\n## The tab area\n\nThe tab area is the central part of the window (%FigTabArea). The tab area is where item controls, documentation, important messages, etc. are shown. The tab area can contain multiple tabs, and functions much like a tabbed web browser.\n\n%--\nfigure:\n id: FigTabArea\n source: tab-area.png\n caption: The tab area.\n--%\n\n## The overview area\n\nThe overview area (%FigOverviewArea) is (by default) shown at the left of the window, to the right of the item toolbar. The overview area shows the structure of your experiment as a tree. You can re-order the items in your experiment by dragging them from one position to another in the overview area.\n\n- Shortcut to hide/ show: `Ctrl+\\`\n\n%--\nfigure:\n id: FigOverviewArea\n source: overview-area.png\n caption: The overview area.\n--%\n\n## The file pool\n\nThe file pool (%FigFilePool) is (by default) shown at the right of the window. It provides an overview of all files that are bundled with the experiment.\n\n- Shortcut to hide/ show: `Ctrl+P`\n\n%--\nfigure:\n id: FigFilePool\n source: file-pool.png\n caption: The file pool.\n--%\n\n## The debug window\n\nThe debug window (%FigDebugWindow) is (by default) shown at the bottom of the window. It provides an [IPython interpreter](https://ipython.org/), and is used as the standard output while an experiment is running. That is, if you use the Python `print()` function, the result will be printed to the debug window.\n\n- Shortcut to hide/ show: `Ctrl+D`\n\n%--\nfigure:\n id: FigDebugWindow\n source: debug-window.png\n caption: The debug window.\n--%\n\n## The variable inspector\n\nThe variable inspector (%FigVariableInspector) is (by default) shown at the right of the window. It provides a list of all variables that are detected in your experiment. When you are running an experiment, the variable inspector also provides a real-time overview of variables and their values.\n\n- Shortcut to hide/ show: `Ctrl+I`\n\n%--\nfigure:\n id: FigVariableInspector\n source: variable-inspector.png\n caption: The variable inspector.\n--%\n\n## Keyboard shortcuts\n\nThe keyboard shortcuts listed below are default values. Many of them can be changed through *Menu \u2192 Tools \u2192 Preferences*.\n\n### General shortcuts\n\nThe following keyboard shortcuts are available everywhere:\n\n- Quick switcher: `Ctrl+Space`\n- Command palette: `Ctrl+Shift+P`\n- New experiment: `Ctrl+N`\n- Open experiment: `Ctrl+O`\n- Save experiment: `Ctrl+S`\n- Save experiment as: `Ctrl+Shift+S`\n- Undo: `Ctrl+Alt+Z`\n- Redo: `Ctrl+Alt+Shift+Z`\n- Run experiment fullscreen: `Ctrl+R`\n- Run experiment in window: `Ctrl+W`\n- Quick-run experiment: `Ctrl+Shift+W`\n- Test experiment in browser: `Alt+Ctrl+W`\n- Show/ hide overview area: `Ctrl+\\`\n- Show/ hide debug window: `Ctrl+D`\n- Show/ hide file pool: `Ctrl+P`\n- Show/ hide variable inspector: `Ctrl+I`\n- Focus overview area: `Ctrl+1`\n- Focus tab area: `Ctrl+2`\n- Focus debug window: `Ctrl+3`\n- Focus file pool: `Ctrl+4`\n- Focus variable inspector: `Ctrl+5`\n\n### Editor shortcuts\n\nThe following keyboard shortcuts are available in editor components, such as the INLINE_SCRIPT:\n\n- (Un)comment selected line(s): `Ctrl+/`\n- Find text: `Ctrl+F`\n- Replace text: `Ctrl+H`\n- Hide find/ replace dialog: `Escape`\n- Duplicate line: `Ctrl+Shift+D`\n- Undo: `Ctrl+Z`\n- Redo: `Ctrl+Shift+Z`\n- Copy: `Ctrl+C`\n- Cut: `Ctrl+X`\n- Paste: `Ctrl+V`\n\n### Tab-area shortcuts\n\nThe following keyboard shortcuts are available in the tab area:\n\n- Next tab: `Ctrl+Tab`\n- Previous tab: `Ctrl+Shift+Tab`\n- Close other tabs: `Ctrl+T`\n- Close all tabs: `Ctrl+Alt+T`\n- Close current tab: `Alt+T`\n\n### Overview-area and sequence shortcuts\n\nThe following keyboard shortcuts are available in the overview area and the SEQUENCE item:\n\n- Context menu: `+`\n- Copy item (unlinked): `Ctrl+C`\n- Copy item (linked): `Ctrl+Shift+C`\n- Paste item: `Ctrl+V`\n- Delete item: `Del`\n- Permanently delete item: `Shift+Del`\n- Rename: `F2`\n- Change run-if statement (if applicable): `F3`", "url": "https://osdoc.cogsci.nl/4.0/manual/interface", "title": "Using the interface"}
{"content": "# Runtime for Android\n\ntitle: Runtime for Android\n\n\n__Important note:__ The OpenSesame runtime for Android is based on software by others that is no longer developed. As a result, we are unable to make sure that the runtime works with recent versions of Android. Windows 10 tablets with Intel processors are a good alternative.\n{: .alert .alert-warning}\n\n\n[TOC]\n\n\n## OpenSesame runtime for Android\n\n### Download\n\nYou can download the OpenSesame runtime for Android through the Google Play Store:\n\n<a href=\"https://play.google.com/store/apps/details?id=nl.cogsci.opensesame\" style=\"border:none;\">\n  <img alt=\"Get it on Google Play\"\n       src=\"https://developer.android.com/images/brand/en_generic_rgb_wo_45.png\" />\n</a>\n\n### Usage\n\nWhen you start the OpenSesame runtime, you will be asked where your experiments are located. By default, OpenSesame assumes that they are in the `/sdcard/` folder, or (if it exists) in the `/sdcard/Experiments/` folder. If you have no experiments on your device, pressing `enter` will show the example experiments that are bundled with the `.apk`.\n\nThe `Back` button serves the same purpose as the `Escape` key on regular systems, and will exit OpenSesame.\n\n### Supported devices\n\nOpenSesame is developed with the Nexus 4 and 9 as reference devices. In general, any device that runs Android 2.2. 'Froyo' or later appears to work.\n\n### Disabling automatic updates\n\nIf you are using the OpenSesame runtime for Android in a production environment (e.g., while you are running an experiment), it is recommended to disable the Auto-update feature of the Google Play Store, at least for OpenSesame. This will prevent the app from being updated and potentially changing its behavior. In case you need to downgrade to a previous version of the Android runtime, you can find the `.apk` files for previous releases [here](https://github.com/smathot/OpenSesame/releases).\n\n### Automatically start an experiment\n\nIf you want to directly launch a specific experiment when the OpenSesame runtime for Android is started, you can create a file called `opensesame-autorun.yml` in the `/sdcard/` folder of your device. This is a YAML file with the following structure:\n\n~~~\nexperiment: /sdcard/experiments/my_experiment.opensesame\nsubject_nr: 3\nlogfile: /sdcard/data/subject03.csv\n~~~\n\n## Developing experiments for Android\n\n### backend\n\nThe OpenSesame runtime for Android requires the *droid* backend.\n\n### Design tips\n\nImplement most user interactions through the MOUSE_RESPONSE item or TOUCH_RESPONSE plugin. In general, screen touches are registered as mouse clicks. Using keyboard input will work as well, but it will show and hide the virtual keyboard after every key that is entered, which looks messy.\n\nThe resolution for the DROID backend is fixed at 1280x800 (landscape). On Android, your experiment will be automatically scaled up or down depending on the resolution of the device, but the resolution that you design with is always 1280x800.\n\n### Debugging\n\nDebug output is written to `/sdcard/opensesame-debug.txt`.\n\n### Limitations\n\n- The SYNTH item and `openexp.synth` module are not functional.\n- The SAMPLER item and `openexp.sampler` module will ignore panning and pitching.\n\n## Know issue: Frozen or misbehaving virtual keyboard\n\nOn some devices, the default virtual keyboard is unresponsive (i.e. it shows but doesn't respond to taps) or doesn't respond normally. This appears to happen on phones with recent versions of Android. To work around this issue, you can install a third-party keyboard. Keyboards that have been reported to work are:\n\n- [GO Keyboard](https://play.google.com/store/apps/details?id=com.jb.emoji.gokeyboard&hl=en)\n- [Smart Keyboard Trial](https://play.google.com/store/apps/details?id=net.cdeguet.smartkeyboardtrial&hl=en)\n\n## Available Python modules\n\nBelow is a list of Python modules that should be available in the OpenSesame runtime for android. (This list is copied from the pgs4a now-defunct website.)\n\n~~~\npygame\npygame.base\npygame.bufferproxy\npygame.colordict\npygame.color\npygame.compat\npygame.constants\npygame.cursors\npygame.display\npygame.draw\npygame.event\npygame.fastevent\npygame.font\npygame.gfxdraw\npygame.imageext\npygame.image\npygame.joystick\npygame.key\npygame.locals\npygame.mask\npygame.mouse\npygame.overlay\npygame.rect\npygame.rwobject\npygame.sprite\npygame.surface\npygame.surflock\npygame.sysfont\npygame.time\npygame.transform\npygame.version\n_abcoll\nabc\naliases\narray\nast\natexit\nbase64\nbisect\nbinascii\ncalendar\ncmath\ncodecs\ncollections\ncompileall\ncontextlib\ncopy\ncopy_reg\ncStringIO\ncPickle\ndatetime\ndifflib\ndis\ndummy_threading\ndummy_thread\nencodings\nencodings.raw_unicode_escape\nencodings.utf_8\nencodings.zlib_codec\nerrno\nfcntl\nfnmatch\nfunctools\n__future__\ngenericpath\ngetopt\nglob\ngzip\nhashlib\nheapq\nhttplib\ninspect\nitertools\nkeyword\nlinecache\nmath\nmd5\nmimetools\nopcode\noptparse\nos\noperator\nparser\npickle\nplatform\nposix\nposixpath\npprint\npy_compile\npwd\nQueue\nrandom\nrepr\nre\nrfc822\nselect\nsets\nshlex\nshutil\nsite\nsocket\nsre_compile\nsre_constants\nsre_parse\nssl\nstat\nStringIO\nstring\nstruct\nsubprocess\nsymbol\nsymtable\nstrop\ntarfile\ntempfile\ntextwrap\n_threading_local\nthreading\ntime\ntokenize\ntoken\ntraceback\ntypes\nurllib\nurllib2\nurlparse\nUserDict\nwarnings\nweakref\nwebbrowser\nzipfile\nzipimport\nzlib\n~~~\n\n[google-play]: https://play.google.com/store/apps/details?id=nl.cogsci.opensesame\n[forum]: http://forum.cogsci.nl/index.php?p=/discussion/333/a-video-of-opensesame-running-natively-on-android\n[droid]: /backends/droid\n[pgs4a]: http://pygame.renpy.org/", "url": "https://osdoc.cogsci.nl/4.0/manual/android", "title": "Runtime for Android"}
{"content": "# OpenSesameRun (no GUI)\n\ntitle: OpenSesameRun (no GUI)\n\n## About\n\n`opensesamerun` is a simple tool that allows you to execute OpenSesame experiments with a minimal GUI, or directly, by specifying all necessary options via the command line. A minimal GUI will automatically appear if not all command line options have been specified, notably the experiment file, the subject number, and the log file.\n\n~~~\nUsage: opensesamerun [experiment] [options]\n\nOptions:\n  --version             show program's version number and exit\n  -h, --help            show this help message and exit\n\n  Subject and log file options:\n    -s SUBJECT, --subject=SUBJECT\n                        Subject number\n    -l LOGFILE, --logfile=LOGFILE\n                        Logfile\n\n  Display options:\n    -f, --fullscreen    Run fullscreen\n    -c, --custom_resolution\n                        Do not use the display resolution specified in the\n                        experiment file\n    -w WIDTH, --width=WIDTH\n                        Display width\n    -e HEIGHT, --height=HEIGHT\n                        Display height\n\n  Miscellaneous options:\n    -d, --debug         Print lots of debugging messages to the standard\n                        output\n    --stack             Print stack information\n\n  Miscellaneous options:\n    --pylink            Load PyLink before PyGame (necessary for using the\n                        Eyelink plug-ins in non-dummy mode)\n~~~\n\n## Example\n\nLet's say that you want to run the gaze cuing example experiment, for subject #1, and save the log file in your Documents folder (this example assumes Linux, but it works analogously on other platforms):\n\n~~~\nopensesamerun /usr/share/opensesame/examples/gaze_cuing.opensesame.tar.gz -s 1 -l /home/sebastiaan/Documents/subject1.tsv -f \n~~~\n\n\n## Alternative `libopensesame`\n\nYou can also start experiments without using the GUI through the `libopensesame` Python module:\n\n- %link:manual/python/nogui%", "url": "https://osdoc.cogsci.nl/4.0/manual/opensesamerun", "title": "OpenSesameRun (no GUI)"}
{"content": "# Debugging\n\ntitle: Debugging\n\nWhile designing a new experiment, you will inevitably encounter bugs. Bugs can manifest as crashes accompanied by error messages, or as unexpected behaviors without any explicit error message.\n\nDebugging, the art and skill of diagnosing and rectifying these errors and unanticipated behaviors, is a critical part of the experimental design process.\n\n\n[TOC]\n\n\n## Debugging in the user interface\n\n### Using the variable inspector\n\nThe Variable Inspector in OpenSesame provides an overview of all variables that are currently active within your experiment. This includes:\n\n- Variables explicitly defined in the user interface, typically in a LOOP item.\n- Response variables, which are set by various response items such as a KEYBOARD_RESPONSE item.\n- Variables that are defined using Python INLINE_SCRIPT items.\n\nWhen an experiment is running, the Variable Inspector dynamically updates, providing a live overview of variables and their values. This feature allows you to monitor the behavior of your experiment in real-time, assisting you in identifying any potential issues or bugs.\n\nFor example, consider a situation where you have defined a variable `left_letter` to define which letter should appearing on the left side of a SKETCHPAD. However, during execution, you notice a mismatch in the Variable Inspector: `left_letter` is actually being shown on the right side of your display. This is indicates a bug such that you have misplaced the right and left letters on the SKETCHPAD.\n\n%--\nfigure:\n id: FigVariableInspector\n source: variable-inspector.png\n caption: You can use the variable inspector to check whether your experiment behaves as it should. In this example, there is a bug such that the letter that is defined through the variable `left_letter` actually appears on the right and vice versa.\n--%\n\nUsing the Variable Inspector regularly to monitor variables helps ensure that your experiment is behaving as expected and aids in identifying problems early on.\n\n\n### Printing debug messages to the IPython/ Jupyter console\n\nThe Python `print()` function is a simple-yet-powerful debugging tool when used inside INLINE_SCRIPT items, and serves a similar purpose to the Variable Inspector. For instance, you can print the values of the variables `left_letter` and `right_letter` during the Prepare phase of an INLINE_SCRIPT at the beginning of each trial.\n\nTo view these debug messages, open the Jupyter/ IPython console and monitor the output while running the experiment. By doing so, you can verify whether the output displayed in the console aligns with the experiment's actual behavior.\n\n%--\nfigure:\n id: FigPrintingOutput\n source: printing-output.png\n caption: The Python `print()` function can be used to output debug messages to the console.\n--%\n\nIn the above example, it becomes evident that the letter assigned to the `left_letter` variable (hence expected to appear on the left) is actually appearing on the right, and vice versa.\n\n\n### Interpreting user-interface error messages\n\nWhen a bug in your experiment causes a crash, OpenSesame displays an error message, also referred to as an 'Exception'. An error message typically consists of the following components:\n\n- **Error type:** Indicates the general class of error. In the example below this is an `FStringError`.\n- **Description:** Provides a more specific explanation of what triggered the error. In this case, 'Failed to evaluate \u2026'.\n- **Source:** Specifies the item that triggered the error and whether it occurred during the Run or Prepare phase.\n- **Traceback:** A detailed Python error message. This information is only shown if the error occurred while evaluating custom Python code, which includes INLINE_SCRIPT items, but also conditional expressions (e.g. run-if expressions), and text with embedded variable references.\n- **Learn more about this error:** An interactive button you can click to get more detailed information about the error message.\n\nLet's look at an example to better understand these components and learn how to fix a common error:\n\n%--\nfigure:\n id: FigFStringError\n source: fstring-error.png\n caption: An `FStringError` indicates an issue when trying to evaluate a text string containing a Python expression.\n--%\n\nThis is an `FStringError`, which means there was an issue while interpreting a text string that includes a Python expression. In this example, the problematic text is `{right_leter}`. Anything enclosed within curly braces is interpreted as a Python expression, and therefore in this case the Python expression is `right_leter`\u2014which is simply a variable name. Trying to evaluate the Python expression `right_leter` triggered a `NameError` because `right_leter` is not defined.\n\nThat's pretty technical, but what exactly went wrong here in simple terms? The issue arises from referring to a non-existent variable: `right_leter`. Looking at the variable name, it seems likely that there's a typo: the intended variable is likely `right_letter`, with a double 't'.\n\nWhere should we correct this mistake? The error message indicates that the source of the error is an item called *target*, which is a SKETCHPAD. To resolve the error, we need to open *target* and change the text from '{right_leter}' to '{right_letter}'. \n\n\n### Interpreting Python error messages\n\nIn Python, errors fall into two categories: syntax errors and exceptions (or runtime errors).\n\n\n#### Python syntax errors\n\nA syntax error occurs when the Python interpreter cannot parse code because it violates Python's syntax rules. This could be due to mismatched parentheses, missing commas, incorrect indentation, and so on. In OpenSesame, this results in a `PythonSyntaxError`.\n\n%--\nfigure:\n id: FigPythonSyntaxError\n source: python-syntax-error.png\n caption: A `PythonSyntaxError` is triggered when the code violates Python's syntax rules and cannot be parsed.\n--%\n\nThe error message above indicates that a syntax error has occurred on line 16 of the Prepare phase of an item named *constants*. Here's the problematic line:\n\n```python\ntarget_orientations = [('z', 0), ('/', 90]\n```\n\nThe message also hints at mismatched parentheses as the potential source of the error. Taking that into consideration, we can fix the issue by adding a missing parenthesis `)` before the closing bracket `]`:\n\n```python\ntarget_orientations = [('z', 0), ('/', 90)]\n```\n\n\n#### Python Exceptions\n\nWhen Python code is syntactically correct but encounters a problem during execution, an exception is raised. In OpenSesame, such exceptions result in a `PythonError`.\n\n%--\nfigure:\n id: FigPythonError\n source: python-error.png\n caption: A `PythonError` is triggered when an exception is raised during the execution of syntactically correct Python code.\n--%\n\nThe error message above indicates that a `NameError` was raised on line 2 of the Run phase of an item named *trial_script*. Specifically, the identifier 'clock_sleep' is not recognized. Looking at the error-causing line, it's apparent that we've used an underscore (`_`) instead of a dot (`.`), incorrectly implying that `clock_sleep()` is a function.\n\n```python\nclock_sleep(495)\n```\n\nTo rectify this, we should correctly reference the `sleep()` function as part of the `clock` object:\n\n```python\nclock.sleep(495)\n```\n\n## Debugging in a web browser (OSWeb)\n\n\n### Printing output to the browser console\n\nThe JavaScript `console.log()` function is a simple-yet-powerful debugging tool when used inside INLINE_JAVASCRIPT items. It serves a similar purpose to the Python `print()` function and the Variable Inspector, neither of which are available in OSWeb. For instance, you can print the values of the variables `left_letter` and `right_letter` during the Prepare phase of an INLINE_SCRIPT at the beginning of each trial.\n\nTo view these debug messages, you need to open the browser console. Here's how to do it in Chrome, Firefox, and Edge:\n\n- **Google Chrome:** Press Ctrl + Shift + J (Windows / Linux) or Cmd + Option + J (Mac).\n- **Mozilla Firefox:** Press Ctrl + Shift + K (Windows / Linux) or Cmd + Option + K (Mac).\n- **Microsoft Edge:** Press F12 to open the developer tools, then select the \"Console\" tab.\n\nOnce the console is open, you can monitor the output while running the experiment, allowing you to check whether the output displayed in the console aligns with the experiment's actual behavior.\n\n%--\nfigure:\n id: FigPrintingOutputOSWeb\n source: printing-output-osweb.png\n caption: The JavaScript `console.log()` function can be used to output debug messages to the browser console.\n--%\n\nIn the above example, it becomes evident that the letter assigned to the `left_letter` variable (which should appear on the left) is actually appearing on the right, and vice versa.\n\n\n### Understanding error messages\n\nWhen your browser-based experiment crashes, OSWeb will show an error message in the browser. An error message typically consists of the following components:\n\n- **Error type:** Indicates the general class of error. In this example below this is a `ReferenceError`.\n- **Description:** Provides a more specific explanation of what triggered the error. In this case, 'right_leter is not defined'.\n- **Source:** Specifies the item that triggered the error and whether it occurred during the Run or Prepare phase.\n- **Source script:** The JavaScript code that caused the error. This information is only shown if the error occurred while evaluating custom JavaScript, which includes INLINE_JAVASCRIPT items, but also conditional expressions (e.g. run-if expressions), and text with embedded variable references.\n\nLet's look at an example to better understand these components and learn how to fix a common error:\n\n%--\nfigure:\n id: FigOSWebError\n source: osweb-error.png\n caption: A `ReferenceError` indicates a reference to a non-existent variable or other non-existent object.\n--%\n\nThis is a `ReferenceError`, which indicates that the experiment refers to a non-existent variable or other non-existent object. In this example, the error arose from the text `${right_leter}`. Anything enclosed within curly braces and prefixed by a `$` is interpreted as JavaScript expression, and in this case, the JavaScript expression is `right_leter`\u2014which is simply a variable name. Trying to evaluate the JavaScript expression `right_leter` triggered a `ReferenceError` because `right_leter` is not defined.\n\nThat's pretty technical, but what exactly went wrong here in simple terms? The issue arises from referring to a non-existent variable: `right_leter`. Looking at the variable name, it seems likely that there's a typographical error: the intended variable is likely `right_letter`, with a double 't'.\n\nWhere should we correct this mistake? The error message indicates that the source of the error is an item called *target*, which is a SKETCHPAD. To resolve the error, we need to open *target* and change the text from '{right_leter}' to '{right_letter}'. \n\n\n### Using the `debugger` statement in INLINE_JAVASCRIPT items\n\nThe JavaScript `debugger` statement is a powerful tool for debugging `INLINE_JAVASCRIPT` items in OpenSesame/OSWeb experiments. It allows you to insert breakpoints in your code, causing the browser's JavaScript execution to pause at that point. This allows you to inspect the current state of the JavaScript workspace.\n\nUsing the `debugger` statement is straightforward. Simply insert the statement `debugger` on the line where you want to pause execution. For example:\n\n```javascript\nconsole.log(`left_letter = ${left_letter}`)\nconsole.log(`right_letter = ${right_letter}`)\ndebugger // Execution will pause here\n```\n\nOnce you've inserted the `debugger` statement into your code, you need to open the browser console as explained above. After you open the browser console, run your experiment. When the JavaScript interpreter reaches the `debugger` statement, it will pause execution, and the developer tools will switch to the \"Sources\" (Chrome/Edge) or \"Debugger\" (Firefox) tab, highlighting the breakpoint line.\n\n%--\nfigure:\n id: FigJavaScriptDebugger\n source: javascript-debugger.png\n caption: When the JavaScript interpreter reaches the `debugger` statement, it will pause execution and allow you to inspect the JavaScript workspace. The `debugger` statement only works when the browser console is open.\n--%\n\nWhile execution is paused, you can inspect variable values, step through the code line by line, and investigate the call stack to better understand the state of your program at the breakpoint.\n\nRemember to remove or comment out the `debugger` statements when you're finished debugging, as leaving them in can interfere with the normal operation of your experiment.\n\n\n## Handling ExperimentProcessDied errors\n\nOccasionally, you might encounter an `ExperimentProcessDied` error during an experiment.\n\n%--\nfigure:\n id: FigExperimentProcessDied\n source: experiment-process-died.png\n caption: The `ExperimentProcessDied` error generally indicates an issue with the underlying Python process or associated libraries, not your experiment's code.\n--%\n\nThis error implies that the Python process in which the experiment was running terminated unexpectedly. It typically doesn't indicate a bug in your experiment, but rather suggests a problem in one of the low-level libraries used by OpenSesame, or even a bug in Python itself.\n\nDetermining the exact cause of this error can be challenging, and fixing it may be even more so. However, there are a few workarounds you can try to mitigate the issue:\n\n- **Change the backend:** Select a different backend under 'Run Experiment' in the experiment properties. This might resolve the issue as different backends use different sets of low-level libraries.\n- **Update OpenSesame and relevant packages:** Regularly updating OpenSesame and all associated packages can potentially resolve this issue, as bugs are routinely fixed in new versions.", "url": "https://osdoc.cogsci.nl/4.0/manual/debugging", "title": "Debugging"}
{"content": "# Logging and reading data files\n\ntitle: Logging and reading data files\n\nAlways triple check whether your data has been logged correctly before running your experiment!\n{: .page-notification}\n\n[TOC]\n\n\n## Using the logger item\n\nOpenSesame will not log your data automatically. Instead, you need to insert a LOGGER item, typically at the end of your trial sequence.\n\n%--\nfigure:\n id: FigLogger\n source: logger.png\n caption: |\n  The LOGGER item.\n--%\n\nThe simplest way to use the LOGGER is by leaving the option 'Automatically log all variables' enabled. That way, all variables that OpenSesame knows about are written the log file, except for those that are explicitly excluded (see below).\n\nYou can explicitly *include* which variables you want to log. The main reason for doing so is when you find that some variables are missing (because OpenSesame did not automatically detect them), or if you have disabled the option 'Automatically log all variables', \n\nYou can also explicitly exclude certain variables from the log file. The main reason for doing so is to keep the log files clean by excluding variables that are generally not useful.\n\nIn general, you should create only one logger item, and reuse that LOGGER at different locations in your experiment if necessary (i.e. use linked copies of the same LOGGER item). If you create multiple LOGGERs (rather than using a single LOGGER multiple times), they will all write to the same log file, and the result will be a mess!\n\n## Using Python inline script\n\nYou can write to the log file using the `log` object:\n\n~~~ .python\nlog.write('This will be written to the log file!')\n~~~\n\nFor more information, see:\n\n- %link:log%\n\nYou should generally not write to the log file directly and use a LOGGER item at the same time; doing so will result in messy log files.\n\n## Format of the data files\n\nIf you have used the standard LOGGER item, data files are in the following format format (simply standard csv):\n\n- plain-text\n- comma-separated\n- double-quoted (literal double-quotes are escaped with backward slashes)\n- unix-style line endings\n- UTF-8 encoded\n- column names on the first row\n\n## Which variables are logged?\n\nBy default, variables that are defined in the user interface, such as columns in a `loop` table or response variables are always logged.\n\nBy default, variables that are defined in an `inline_script` or `inline_javascript` are logged if they are numbers (`int` and `float`), strings (`str` and `bytes`), and `None` values. This is to avoid log files from becoming unreasonably large due to logging of long lists and other large values. (As of OpenSesame 4.0, there is no longer a need to use the `var` (Python) or `vars` (JavaScript) object.)\n\nIf you want to explicitly log a variable that is not logged by default, you can use the 'Include' field in the LOGGER item.\n\n\n## Reading and processing data files\n\n### In Python with pandas or DataMatrix\n\nIn Python, you can use [pandas](http://pandas.pydata.org/) to read csv files.\n\n```python\nimport pandas\ndf = pandas.read_csv('subject-1.csv')\nprint(df)\n```\n\nOr [DataMatrix](https://datamatrix.cogsci.nl/):\n\n```python\nfrom datamatrix import io\ndm = io.readtxt('subject-1.csv')\nprint(dm)\n```\n\n### In R\n\nIn R, you can simply use the `read.csv()` function to read a single data file.\n\n~~~ .R\ndf = read.csv('subject-1.csv', encoding = 'UTF-8')\nhead(df)\n~~~\n\nIn addition, you can use the `read_opensesame()` function from the [readbulk](https://github.com/pascalkieslich/readbulk) package to easily read and merge multiple data files into one large data frame. The package is available on CRAN and can be installed via `install.packages('readbulk')`.\n\n~~~ .R\n# Read and merge all data files stored in the folder 'raw_data'\nlibrary(readbulk)\ndf = read_opensesame('raw_data')\n~~~\n\n### In JASP\n\n[JASP](http://jasp-stats.org/), an open-source statistics package, opens csv files straight away.\n\n### In LibreOffice Calc\n\nIf you open a csv file in LibreOffice Calc, you have to indicate the exact data format, as indicated in %FigLibreOffice. (The default settings are often correct.)\n\n%--\nfigure:\n source: libreoffice.png\n id: FigLibreOffice\n--%\n\n### In Microsoft Excel\n\nIn Microsoft Excel, you need to use the Text Import Wizard.\n\n### Merging multiple data files into one large file\n\nFor some purposes, such as using pivot tables, it may be convenient to merge all data files into one large file. With Python DataMatrix, you can do this with the following script:\n\n```python\nimport os\nfrom datamatrix import DataMatrix, io, operations as ops\n\n# Change this to the folder that contains the .csv files\nSRC_FOLDER = 'student_data'\n# Change this to a list of column names that you want to keep\nCOLUMNS_TO_KEEP = [\n    'RT_search',\n    'load',\n    'memory_resp'\n]\n\n\ndm = DataMatrix()\nfor basename in os.listdir(SRC_FOLDER):\n    path = os.path.join(SRC_FOLDER, basename)\n    print('Reading {}'.format(path))\n    dm <<= ops.keep_only(io.readtxt(path), *COLUMNS_TO_KEEP)\nio.writetxt(dm, 'merged-data.csv')\n```\n\n\n## Logging in OSWeb\n\nWhen you run an experiment in a browser with OSWeb, logging works differently from when you run an experiment on the desktop.\n\nSpecifically, when you launch an OSWeb experiment directly from within OpenSesame, the log file is downloaded at the end of the experiment. This log file is in `.json` format. When you launch an OSWeb experiment from JATOS, there is no log file as such, but rather all data is sent to JATOS from where it can be downloaded.\n\nSee also:\n\n- %link:manual/osweb/workflow%\n\n\n\n[libreoffice]: http://www.libreoffice.org/\n[openoffice]: http://www.openoffice.org/\n[gnumeric]: http://projects.gnome.org/gnumeric/\n[log-func]: /python/inline-script/#inline_script.log\n[codecs]: http://docs.python.org/2/library/codecs.html\n[ppa]: https://launchpad.net/~smathot/+archive/cogscinl/", "url": "https://osdoc.cogsci.nl/4.0/manual/logging", "title": "Logging and reading data files"}
{"content": "# Timing\n\ntitle: Timing\nreviewed: false\n\nThis page describes various issues related to timing, and provides benchmark results and tips for testing your own system. If you experience problems with timing, please take the time to read this page. Many issues are resolved by taking into account things such as stimulus preparation and the properties of your monitor.\n\n[TOC]\n\n## Is OpenSesame capable of millisecond precision timing?\n\nThe short answer is: yes. The long answer is the rest of this page.\n\n\n## Important considerations for time-critical experiments\n\n### Check your timing!\n\nOpenSesame allows you to control your experimental timing very accurately. But this does not guarantee accurate timing in every specific experiment! For any number of reasons, many of which are described on this page, you may experience issues with timing. Therefore, in time-critical experiments you should always check whether the timing in your experiment is as intended. The easiest way to do this is by checking the display timestamps reported by OpenSesame.\n\nEvery SKETCHPAD item has a variable called `time_[sketchpad name]` that contains the timestamp of the last time that the SKETCHPAD was shown. Therefore, if you want the SKETCHPAD *target* to be shown for 100 ms, followed by the SKETCHPAD *mask*, you should verify that `time_mask` - `time_target` is indeed 100. When using Python inline code, you can make use of the fact that `canvas.show()` returns the display timestamp.\n\n\n### Understanding your monitor\n\nComputer monitors refresh periodically. For example, if the refresh rate of your monitor is 100 Hz, the display is refreshed every 10 ms (1000 ms / 100 Hz). This means that a visual stimulus is always presented for a duration that is a multiple of 10 ms, and you will not be able to present a stimulus for, say, 5 or 37 ms. The most common refresh rate is 60 Hz (= 16.67 ms refresh cycle), although monitors with much higher refresh rates are sometimes used for experimental systems.\n\nIn %VidRefresh you can see what a monitor refresh looks like in slow motion. On CRT monitors (i.e. non-flatscreen, center) the refresh is a single pixel that traces across the monitor from left to right and top to bottom. Therefore, only one pixel is lighted at a time, which is why CRT monitors flicker slightly. On LCD or TFT monitors (flatscreen, left and right) the refresh is a 'flood fill' from top to bottom. Therefore, LCD and TFT monitors do not flicker. (Unless you present a flickering stimulus, of course.)\n\n%--\nvideo:\n id: VidRefresh\n source: vimeo\n videoid: 24216910\n width: 640\n height: 240\n caption: A slow-motion video of the refresh cycle on CRT (center) and LCD/ TFT monitors. Video courtesy of Jarik den Hartog and the VU University Amsterdam technical support staff.\n--%\n\nIf a new stimulus display is presented while the refresh cycle is halfway, you will observe 'tearing'. That is, the upper half of the monitor will show the old display, while the lower part will show the new display. This is generally considered undesirable, and therefore a new display should be presented at the exact moment that the refresh cycle starts from the top. This is called 'synchronization to the vertical refresh' or simply 'v-sync'. When v-sync is enabled, tearing is no longer visible, because the tear coincides with the upper edge of the monitor. However, v-sync does not change anything about the fact that a monitor does not refresh instantaneously and will therefore always, for some time, show both the old and the new display.\n\nAnother important concept is that of 'blocking on the vertical retrace' or the 'blocking flip'. Usually, when you send a command to show a new display, the computer will accept this command right away and put the to-be-shown display in a queue. However, the display may not actually appear on the monitor until some time later, typically until the start of the next refresh cycle (assuming that v-sync is enabled). Therefore, you don't know exactly when the display has appeared, because your timestamp reflects the moment that the display was queued, rather than the moment that it was presented. To get around this issue, you can use a so-called 'blocking flip'. This basically means that when you send a command to show a new display, the computer will freeze until the display actually appears. This allows you to get very accurate display timestamps, at the cost of a significant performance hit due to the computer being frozen for much of the time while it is waiting for a display to be shown. But for the purpose of experiments, a blocking flip is generally considered the optimal strategy.\n\nFinally, LCD monitors may suffer from 'input lag'. This means that there is an additional and sometimes variable delay between the moment that the computer 'thinks' that a display appears, and the moment that the display actually appears. This delay results from various forms of digital processing that are performed by the monitor, such as color correction or image smoothing. As far as I know, input lag is not something that can be resolved programmatically, and you should avoid monitors with significant input lag for time-critical experiments. \n\nFor a related discussion, see:\n\n- <http://docs.expyriment.org/Timing.html#visual>\n\n\n### Making the refresh deadline\n\nImagine that you arrive at a train station at 10:30. Your train leaves at 11:00, which gives you exactly 30 minutes to get a cup of coffee. However, if you have coffee for exactly 30 minutes, then you will arrive back at the platform just in time to see your train depart, and you will have to wait for the next train. Therefore, if you have 30 minutes waiting time, you should have a coffee for slightly less than 30 minutes, such as 25 minutes.\n\nThe situation is analogous when specifying intervals for visual-stimulus presentation. Let's say that you have a 100 Hz monitor (so 1 refresh every 10 ms) and want to present a target stimulus for 100 ms, followed by a mask. Your first inclination might be to specify an interval of 100 ms between the target and the mask, because that's after all what you want. However, specifying an interval of exactly 100 ms will likely cause the mask to 'miss the refresh deadline', and the mask will be presented only on the next refresh cycle, which is 10 ms later (assuming that v-sync is enabled). So if you specify an interval of 100 ms, you will in most cases end up with an interval of 110 ms!\n\nThe solution is simple: You should specify an interval that is slightly shorter than what you are aiming for, such as 95 ms. Don't worry about the interval being too short, because on a 100 Hz monitor the interval between two stimulus displays is necessarily a multiple of 10 ms. Therefore, 95 ms will become 100 ms (10 frames), 1 ms will become 10 ms (1 frame), etc. Phrased differently, intervals will be rounded up (and never rounded down!) to the nearest interval that is consistent with your monitor's refresh rate.\n\n\n### Disabling desktop effects\n\nMany modern operating systems make use of graphical desktop effects. These provide, for example, the transparency effects and the smooth window minimization and maximization effects that you see on most modern operating systems. Although the software that underlies these effects differs from system to system, they generally form an additional layer between your application and the display. This additional layer may prevent OpenSesame from synchronizing to the vertical refresh and/ or from implementing a blocking flip.\n\nAlthough desktop effects *may* cause problems, they usually don't. This appears to vary from system to system and from video card to video card. Nevertheless, when the operating systems allows it, it's best to disable desktop effects on systems that are used for experimental testing.\n\nSome tips regarding desktop effects for the various operating systems:\n\n- Under *Windows XP* there are no desktop effects at all.\n- Under *Windows 7* desktop effects can be disabled by selecting any of the themes listed under 'Basic and High Contrast Themes' in the 'Personalization' section.\n- Under *Windows 10* there is no way to completely disable desktop effects.\n- Under *Ubuntu and other Linux distributions using Gnome 3* there is no way to completely disable desktop effects.\n- Under *Linux distributions using KDE* you can disable desktop effects in the 'Desktop Effects' section of the System Settings.\n- Under *Mac OS* there is apparently no way to completely disable desktop effects.\n\n\n### Taking into account stimulus-preparation time/ the prepare-run structure\n\nIf you care about accurate timing during visual-stimulus presentation, you should prepare your stimuli in advance. That way, you will not get any unpredictable delays due to stimulus preparation during the time-critical parts of your experiment.\n\nLet's first consider a script (you can paste this into an INLINE_SCRIPT item) that includes stimulus-preparation time in the interval between `canvas1` and `canvas2` (%LstStimPrepBad). The interval that is specified is 95 ms, so--taking into account the 'rounding up' rule described in [Making the refresh deadline]--you would expect an interval of 100 ms on my 60 Hz monitor. However, on my test system the script below results in an interval of 150 ms, which corresponds to 9 frames on a 60 Hz monitor. This is an unexpected delay of 50 ms, or 3 frames, due to the preparation of `canvas2`.\n\n%--\ncode:\n id: LstStimPrepBad\n syntax: python\n source: stimulus-preparation-bad.py\n caption: \"In this script, the duration between `canvas1` and `canvas2` is confounded by stimulus-preparation time.\"\n--%\n\nNow let's consider a simple variation of the script above (%LstStimPrepGood). This time, we first prepare both `canvas1` and `canvas2` and only afterwards present them. On my test system, this results in a consistent 100 ms interval, just as it should!\n\n%--\ncode:\n id: LstStimPrepGood\n syntax: python\n source: stimulus-preparation-good.py\n caption: \"In this script, the duration between `canvas1` and `canvas2` is not confounded by stimulus-preparation time.\"\n--%\n\nWhen using the graphical interface, the same considerations apply, but OpenSesame helps you by automatically handling most of the stimulus preparation in advance. However, you have to take into account that this preparation occurs at the level of SEQUENCE items, and not at the level of LOOP items. Practically speaking, this means that the timing *within* a SEQUENCE is not confounded by stimulus-preparation time. But the timing *between* SEQUENCEs is.\n\nTo make this more concrete, let's consider the structure shown below (%FigStimPrepBad). Suppose that the duration of the SKETCHPAD item is set to 95 ms, thus aiming for a 100 ms duration, or 6 frames on a 60 Hz monitor. On my test system the actual duration is 133 ms, or 8 frames, because the timing is confounded by preparation of the SKETCHPAD item, which occurs each time that that the sequence is executed. So this is an example of how you should *not* implement time-critical parts of your experiment.\n\n%--\nfigure:\n id: FigStimPrepBad\n source: stimulus-preparation-incorrect.png\n caption: \"An example of an experimental structure in which the timing between successive presentations of SKETCHPAD is confounded by stimulus-preparation time. The sequence of events in this case is as follows: prepare SKETCHPAD (2 frames), show SKETCHPAD (6 frames), prepare SKETCHPAD (2 frames), show SKETCHPAD (6 frames), etc.\"\n--%\n\nNow let's consider the structure shown below (%FigStimPrepGood). Suppose that the duration of `sketchpad1` is set to 95 ms, thus aiming for a 100 ms interval between `sketchpad1` and `sketchpad2`. In this case, both items are shown as part of the same SEQUENCE and the timing will not be confounded by stimulus-preparation time. On my test system the actual interval between `sketchpad1` and `sketchpad2` is therefore indeed 100 ms, or 6 frames on a 60 Hz monitor.\n\nNote that this only applies to the interval between `sketchpad1` and `sketchpad2`, because they are executed in that order as part of the same sequence. The interval between `sketchpad2` on run *i* and `sketchpad1` on run *i+1* is again confounded by stimulus-preparation time.\n\n%--\nfigure:\n id: FigStimPrepGood\n source: stimulus-preparation-correct.png\n caption: \"An example of an experimental structure in which the timing between the presentation of `sketchpad1` and `sketchpad2` is not confounded by stimulus-preparation time. The sequence of events in this case is as follows: prepare `sketchpad1` (2 frames), prepare `sketchpad2` (2 frames), show `sketchpad1` (6 frames), show `sketchpad2` (6 frames), prepare `sketchpad1` (2 frames), prepare `sketchpad2` (2 frames), show `sketchpad1` (6 frames), show `sketchpad2` (6 frames), etc.\"\n--%\n\nFor more information, see:\n\n- [usage/prepare-run]\n\n### Differences between backends\n\nOpenSesame is not tied to one specific way of controlling the display, system timer, etc. Therefore, OpenSesame *per se* does not have specific timing properties, because these depend on the backend that is used. The performance characteristics of the various backends are not perfectly correlated: It is possible that on some system the [psycho] backend works best, whereas on another system the [xpyriment] backend works best. Therefore, one of the great things about OpenSesame is that you can choose which backend works best for you!\n\nIn general, the [xpyriment] and [psycho] backends are preferable for time-critical experiments, because they use a blocking flip. On the other hand, the [legacy] backend is slightly more stable and also considerably faster when using [forms].\n\nUnder normal circumstances the three current OpenSesame backends have the properties shown in %TblBackendInfo.\n\n%--\ntable:\n id: TblBackendInfo\n source: backend-info.csv\n caption: backend properties.\n--%\n\nSee also:\n\n- [backends]\n\n## Benchmark results and tips for testing your own system\n\n### Checking whether v-sync is enabled\n\nAs described in [Understanding your monitor], the presentation of a new display should ideally coincide with the start of a new refresh cycle (i.e. 'v-sync'). You can test whether this is the case by presenting displays of different colors in rapid alternation. If v-sync is not enabled you will clearly observe horizontal lines running across the monitor (i.e. 'tearing'). To perform this test, run an experiment with the following script in an INLINE_SCRIPT item (%LstVSync):\n\n%--\ncode:\n id: LstVSync\n syntax: python\n source: v-sync-check.py\n caption: A script that presents yellow and blue displays in rapid alternation. A lack of synchronization with the vertical refresh can be observed as horizontal lines running through the monitor.\n--%\n\n### Testing precision and accuracy of timing\n\nTiming is precise or consistent when you can present visual stimuli over and over again with the same timing. Timestamps are accurate when they accurately reflect when visual stimuli appear on the monitor. The script below shows how you can check precision and accuracy of timing. This test can be performed both with and without an external photodiode, although the use of a photodiode provides extra verification.\n\nTo keep things simple, let's assume that your monitor is running at 100 Hz, which means that a single frame takes 10 ms. The script then presents a white canvas for 1 frame (10 ms). Next, the script presents a black canvas for 9 frames (90 ms). Note that we have specified a duration of 85, which is rounded up as explained under [Making the refresh deadline]. Therefore, we expect that the interval between the onsets of two consecutive white displays will be 10 frames or 100 ms (= 10 ms + 90 ms).\n\nWe can use two ways to verify whether the interval between two white displays is indeed 100 ms:\n\n1. Using the timestamps reported by OpenSesame. This is the easiest way and is generally accurate when the backend uses a blocking flip.\n2. Using a photodiode that responds to the onsets of the white displays and logs the timestamps of these onsets to an external computer. This is the best way to verify the timing, because it does not rely on introspection of the software. Certain issues, such as TFT input lag, discussed above, will come out only using external photodiode measurement.\n\n%--\ncode:\n id: LstIntervalBenchmark\n syntax: python\n source: interval-benchmark.py\n caption: A Python script to test the timing consistency and accuracy of display timestamps. You can paste this code into an INLINE_SCRIPT item.\n--%\n\nI ran %LstIntervalBenchmark on Windows XP, using all three backends. I also recorded the onsets of the white displays using a photodiode connected to a second computer. The results are summarized in %TblBenchmarkResults.\n\n%--\ntable:\n id: TblBenchmarkResults\n source: benchmark-results.csv\n caption: Benchmark results for %LstIntervalBenchmark. Tested with Windows XP, HP Compaq dc7900, Intel Core 2 Quad Q9400 @ 2.66Ghz, 3GB, 21\" ViewSonic P227f CRT. Each test was conducted twice (i.e. two sessions). The column `Session` corresponds to different test runs. The column `Source` indicates whether the measurements are from an external photiodiode, or based on OpenSesame's internal timestamps.\n--%\n\nAs you can see, the [xpyriment] and [psycho] backends consistently show a 100 ms interval. This is good and just as we would expect. However, the [legacy] backend shows a 90 ms interval. This discrepancy is due to the fact that the [legacy] backend does not use a blocking flip (see [Understanding your monitor]), which leads to some unpredictability in display timing. Note also that there is close agreement between the timestamps as recorded by the external photodiode and the timestamps reported by OpenSesame. This agreement demonstrates that OpenSesame's timestamps are reliable, although, again, they are slightly less reliable for the [legacy] backend due to the lack of a blocking-flip.\n\n", "url": "https://osdoc.cogsci.nl/4.0/manual/timing", "title": "Timing"}
{"content": "# Timing\n\n## Expyriment benchmarks and test suite\n\nA very nice set of benchmarks is available on the Expyriment website. This information is applicable to OpenSesame experiments using the [xpyriment] backend.\n\n- <http://docs.expyriment.org/Timing.html>\n\nExpyriment includes a very useful test suite. You can launch this test suite by running the `test_suite.opensesame` example experiment, or by adding a simple INLINE_SCRIPT to your experiment with the following lines of code (%LstExpyrimentTestSuite):\n\n%--\ncode:\n id: LstExpyrimentTestSuite\n syntax: python\n source: expyriment-test-suite.py\n caption: A script to start the Expyriment test suite.\n--%\n\nFor more information, please visit:\n\n- <http://docs.expyriment.org/Testsuite.html>\n\n## PsychoPy benchmarks and timing-related information\n\nSome information about timing is available on the PsychoPy documentation site. This information is applicable to OpenSesame experiments using the [psycho] backend.\n\n- <http://www.psychopy.org/general/timing/timing.html>\n\n[psycho]: /backends/xpyriment/\n[xpyriment]: /backends/xpyriment/\n[legacy]: /backends/legacy/\n[miscellaneous/clock-drift]: /miscellaneous/clock-drift\n[usage/prepare-run]: /usage/prepare-run\n[backends]: /backends\n[forms]: /forms", "url": "https://osdoc.cogsci.nl/4.0/manual/timing", "title": "Timing"}
{"content": "# Backends\n\ntitle: Backends\n\nThe *backend* is the software layer that deals with input (keyboard input, mouse input, etc.) and output (display presentation, sound playback, etc.). There are many libraries that offer this type of functionality and OpenSesame could, in principle, use any one of them. For this reason, OpenSesame is backend-independent, in the sense that you can choose which backend should be used. Currently there are four backends: *legacy*, *psycho*, *xpyriment*, and *osweb*.\n\n[TOC]\n\n## Differences and some tips\n\nUsually, you won't notice which backend is used. The differences between backends are largely technical, and, as long as you use the graphical user interface, all backends work more ore less the same way. However, there are a few reasons to prefer one backend over another:\n\n- If you want to run the experiment in a browser, you need to select the *osweb* backend.\n- Backend differs in [temporal precision](%link:timing%).\n\t- Tip: If you care about millisecond temporal precision, use *xpyriment* or *psycho*.\n- Backends differ in how long stimulus preparation takes.\n\t- Tip: If [forms](%link:manual/forms/about%) are slow, use *legacy*.\n\t- Tip: If the intertrial interval is long (due to stimulus preparation), use *legacy*.\n- You can use backend-specific functionality when writing Python code.\n\t- Tip: If you want to use PsychoPy functionality, use *psycho*.\n\t- Tip: If you want to use Expyriment functionality, use *xpyriment*.\n\t- Tip: If you want to use PyGame functionality, use *legacy*.\n- Some backends are not available on all platforms.\n\n## Selecting a backend\n\nYou can select a backend in the general properties of the experiment (%FigSelect).\n\n%--\nfigure:\n id: FigSelect\n source: fig-select.png\n caption: \"Selecting a backend\"\n--%\n\nIf you view the general script (select \"Show script editor\"), you will see that there are actually six distinct backends: canvas, keyboard, mouse, sampler, color, and clock. The combobox-method automatically selects an appropriate, predefined combination of backends, but you could, in theory, mix and match.\n\nFor example, if you select the *xpyriment* backend, the following code will be generated:\n\n\tset sampler_backend legacy\n\tset mouse_backend xpyriment\n\tset keyboard_backend legacy\n\tset color_backend legacy\n\tset clock_backend legacy\n\tset canvas_backend xpyriment\n\n## xpyriment\n\nThe *xpyriment* backend is built on top of [Expyriment][], a library designed for creating psychology experiments. It is a light-weight hardware-accelerated backend with excellent timing properties. If you care about temporal precision, but do not plan on generating complex stimuli (i.e. Gabor patches, random-dot gratings, etc.) *xpyriment* is a good choice.\n\n### Using Expyriment directly\n\nYou can find extensive documentation on Expyriment at <http://www.expyriment.org/doc>. The following code snippet shows a line of text:\n\n~~~ .python\nfrom expyriment import stimuli\ntext = stimuli.TextLine('This is expyriment!')\ntext.present()\n~~~\n\n### Citation\n\nAlthough Expyriment is bundled with the binary distributions of OpenSesame, it is a separate project. When appropriate, please provide the following citation in addition to citing OpenSesame:\n\nKrause, F., & Lindemann, O. (in press). Expyriment: A Python library for cognitive and neuroscientific experiments. *Behavior Research Methods*.\n{: .reference}\n\n## psycho\n\nThe psycho backend is built on top of [PsychoPy][], a library designed for creating psychology experiments. It is hardware accelerated and provides high-level routines for creating complex visual stimuli (drifting gratings, etc.). If you care about timing and plan on creating complex stimuli, Psycho is a good choice.\n\n### Using PsychoPy directly\n\nYou can find extensive documentation on PsychoPy at <http://www.psychopy.org/>. When using PsychoPy in OpenSesame, it is important to know that the main window can be accessed as `self.experiment.window` or simply `win`. So the following code snippet draws a Gabor patch:\n\n~~~ .python\nfrom psychopy import visual\ngabor = visual.PatchStim(win, tex=\"sin\", size=256, mask=\"gauss\", sf=0.05, ori=45)\ngabor.draw()\nwin.flip()\n~~~\n\n### Tutorials\n\nA tutorial specifically for using PsychoPy from within OpenSesame:\n\n- <http://www.cogsci.nl/blog/tutorials/211-a-bit-about-patches-textures-and-masks-in-psychopy>\n\nAnd a more general PsychoPy tutorial:\n\n- <http://gestaltrevision.be/wiki/coding>\n\n### Citation\n\nAlthough PsychoPy is bundled with the binary distributions of OpenSesame, it is a separate project. When appropriate, please cite the following papers in addition to citing OpenSesame:\n\nPeirce, J. W. (2007). PsychoPy: Psychophysics software in Python. *Journal of Neuroscience Methods*, *162*(1-2), 8-13. doi:10.1016/j.jneumeth.2006.11.017\n{: .reference}\n\nPeirce, J. W. (2009). Generating stimuli for neuroscience using PsychoPy. *Frontiers in Neuroinformatics*, *2*(10). doi:10.3389/neuro.11.010.2008\n{: .reference}\n\n## legacy\n\nThe legacy backend is built on top of [PyGame][] in non-OpenGL mode. The downside of this is that there is no hardware acceleration, and the timing properties are not as good as that of the psycho or xpyriment backends. The upside is that PyGame is very easy to use, very reliable, and well supported on a wide range of platforms.\n\n### Mouse-cursor visibility\n\nOn some systems, the mouse cursor is not visible when using the *legacy* backend in fullscreen mode. You can work around this is the following ways:\n\n1. Open the *legacy* backend settings and set \"Double buffering\" to \"no\".\n\t- *Note:* This may disable v-sync, which can be important for time critical experiments, as discussed [here](%link:timing%).\n2. Open the *legacy* backend settings and set \"Custom cursor\" to \"yes\".\n3. Switch to another backend.\n\n### Using PyGame directly\n\nPyGame is well documented and you can find everything you need to know about using PyGame on <http://www.pygame.org/docs/>. Specific to OpenSesame is the fact that the display surface is stored as `self.experiment.window` or simply `win`. So the following code snippet, which you could paste into an INLINE_SCRIPT item, draws a red rectangle to the display:\n\n~~~ .python\nimport pygame # Import the PyGame module\npygame.draw.rect(self.experiment.window, pygame.Color(\"red\"),\n\t[20, 20, 100, 100]) # Draw a red rectangle. Not shown yet...\npygame.display.flip() # Update the display to show the red rectangle.\n~~~\n\n\n## osweb\n\nThe *osweb* backend is built on top of OSWeb and allows you run experiments in a browser. For more information, see:\n\n- %link:manual/osweb/workflow%", "url": "https://osdoc.cogsci.nl/4.0/manual/backends", "title": "Backends"}
{"content": "# The prepare-run strategy\n\ntitle: The prepare-run strategy\n\n[TOC]\n\n## About\n\nExperiments typically consist of short intervals ('trials') during which participants perceive stimuli and perform a task. Timing should be controlled during a trial, but some unpredictable variation in the duration of the interval between trials is acceptable. Therefore, a good strategy is to perform time-consuming tasks before a trial, and to keep the operations that are performed during a trial to a minimum.\n\nOpenSesame does this by calling each element from a SEQUENCE item twice. This is the *prepare-run strategy*:\n\n- During the Prepare phase, items are given the opportunity to prepare. For example, a SYNTH generates a sound (but doesn't play it); and a SKETCHPAD draws a canvas (but doesn't show it).\n- During the Run phase, items do as a little as possible. For example, a SYNTH plays back a previously prepared sound; and a SKETCHPAD shows a previously prepared canvas.\n\nThis reduces the risk of timing glitches. The prepare-run strategy is implemented at the level of SEQUENCE items, which typically contains the time-critical parts of an experiment. This means that before a SEQUENCE is started, there is some unpredictable temporal jitter.\n\n## Item-specific notes\n\n### loop items\n\nA LOOP item is not prepared in advance. It is important to take this into account when using a LOOP to implement time-critical parts. For example, you may be tempted to implement an RSVP stream using a LOOP item as follows:\n\n~~~text\nrsvp_loop item (4 cycles)\n- stimulus_item\n~~~\n\nIn this construction, *stimulus_item* will be prepared and run four times in alternation, like so:\n\n~~~text\nprepare stimulus_item\nrun stimulus_item\nprepare stimulus_item\nrun stimulus_item\nprepare stimulus_item\nrun stimulus_item\nprepare stimulus_item\nrun stimulus_item\n~~~\n\nTherefore, you need to verify that the preparation of *stimulus_item* does not cause any timing glitches.\n\n### sequence items\n\nAll items that are part of a SEQUENCE are prepared in advance. Therefore, the following construction ...\n\n~~~text\ntrial_sequence\n- fixation_sketchpad\n- target_sketchpad\n- keyboard_response\n- logger\n~~~\n\n... will be executed as follows ...\n\n~~~text\nprepare fixation_sketchpad\nprepare target_sketchpad\nprepare keyboard_response\nprepare logger\nrun fixation_sketchpad\nrun target_sketchpad\nrun keyboard_response\nrun logger\n~~~\n\n### sketchpad and feedback items\n\nSKETCHPAD and FEEDBACK items differ in when they are prepared. For SKETCHPADs preparation occurs during the Prepare phase; for FEEDBACK items, preparation occurs only during the Run phase.\n\nFor more information, see:\n\n- %link:manual/stimuli/visual%\n\n### synth and sampler items\n\nFor SYNTH and SAMPLER items, the sound is generated and preloaded during the Prepare phase.\n\n### inline_script items\n\nIn an INLINE_SCRIPT item, you can choose how you want to implement the run and prepare strategy. In general, it is good practice to adhere to the following guidelines:\n\n- Time-consuming, preparatory functionality goes in the Prepare phase. For example, creating canvas objects, and generating sounds.\n- A minimum amount of code is put in the run phase. For example, only showing a previously prepared canvas.\n\n### Other items and plugins\n\nIn general, items should follow the principle of performing as much as possible time-consuming preparation during the Prepare phase, and minimizing the Run phase. However, every plugin is implemented differently. If you are unsure about a specific case, please post a query on the forum.\n\n## Conditional expressions (run if, show if, break if, etc)\n\nIn SEQUENCE items, the 'Run if' condition is evaluated at the last moment, during the run phase. Therefore, you can use a condition like `correct == 0` which depends on the results of a KEYBOARD_RESPONSE item which has been called just before. It is important to take into account that the 'Run if' expression applies *only* to the run phase of an item\u2014The prepare phase is *always* executed.\n\nIn COROUTINES items, the 'Run if' condition is evaluated during the Prepare phase. Therefore, the conditions cannot depend on events that occur during the execution of the COROUTINES.\n\nIn SKETCHPAD items, the 'Show if' condition is evaluated during the Prepare phase, when the canvas is constructed. In FEEDBACK items, the 'Show if' condition is evaluated during the Run phase (because the canvas is only constructed in the Run phase).", "url": "https://osdoc.cogsci.nl/4.0/manual/prepare-run", "title": "The prepare-run strategy"}
{"content": "# Oculus rift (virtual reality)\n\n---\nlayout: osdoc\ntitle: Oculus rift (virtual reality)\ngroup: Devices\npermalink: /oculus-rift/\n---\n\n<iframe src=\"http://wl.figshare.com/articles/1394986/embed?show_title=1\" width=\"640\" height=\"861\" frameborder=\"0\"></iframe>\n\nHern\u00e1ndez-Sande, A., Lorca, J. A. (2015): OpenSesame: An example of stimulus presentation in Virtual Reality headsets (Oculus Rift DK1). *Figshare*. doi:10.6084/m9.figshare.1394986", "url": "https://osdoc.cogsci.nl/4.0/manual/devices/oculusrift", "title": "Oculus rift (virtual reality)"}
{"content": "# Ambulatory Monitoring System (VU-AMS)\n\ntitle: Ambulatory Monitoring System (VU-AMS)\n\nVU-AMS is a third-party plugin, and is not maintained by the OpenSesame team.\n{: .alert .alert-info}\n\n\nThe VU University Ambulatory Monitoring System (VU-AMS) is a device that can be used to measure a variety of factors related to heart rate, respiration, and body movement. The developers offer an OpenSesame template on their website.\n\nFor more information, see:\n\n- <http://www.vu-ams.nl> (product website)\n- <http://www.vu-ams.nl/support/downloads/extras/> (OpenSesame template)", "url": "https://osdoc.cogsci.nl/4.0/manual/devices/vuams", "title": "Ambulatory Monitoring System (VU-AMS)"}
{"content": "# StimSync\n\ntitle: StimSync\n\nStimSync is an open-source open-hardware device for handling input (e.g., button presses) and output (e.g., triggers) in psychological and neuroscientific experiments. StimSync offers examples for use with OpenSesame.\n\nFor more information, see:\n\n- <http://www.mccauslandcenter.sc.edu/crnl/stimsync-0>", "url": "https://osdoc.cogsci.nl/4.0/manual/devices/stimsync", "title": "StimSync"}
{"content": "# Serial port\n\ntitle: Serial port\n\nPySerial is an easy to use Python library for serial port communications, which is bundled with all OpenSesame packages. For more information, see:\n\n- <http://pyserial.sourceforge.net/>", "url": "https://osdoc.cogsci.nl/4.0/manual/devices/serial", "title": "Serial port"}
{"content": "# Parallel port (EEG triggers)\n\ntitle: Parallel port (EEG triggers)\nreviewed: false\n\nIn EEG/ ERP studies it is common to send triggers to mark the timestamp for significant events (e.g., the onset of a trial, presentation of a particular stimulus, etc.). Triggers are typically bytes that are sent via the parallel port to the EEG apparatus.\n\n[TOC]\n\n\n## Using the `parallel_port_trigger` plugin\n\nParallel_port_trigger is a third-party plugin and not maintained by the OpenSesame team.\n{: .page-notification}\n\nAn OpenSesame plug-in for sending stimulus synchronization triggers through the parallel port to data acquisition systems.\n\n- <https://github.com/dev-jam/opensesame-plugin-parallel_port_trigger/>\n\nYou can install the `parallel_port_trigger` plugin from PyPi:\n\n```\npip install pip install opensesame-plugin-parallel-port-trigger\n```\n\n\n## Using `dportio.dll` in a Python inline Script (Windows only)\n\nInstead of using the `parallel_port_trigger` plugin, it is also possible to send triggers with `dlportio.dll` through a Python inline script. This approach is Windows only. To do so, first add an INLINE_SCRIPT to the start of the experiment with the following code in the prepare phase:\n\n~~~ .python\ntry:\n\tfrom ctypes import windll\n\tglobal io\n\tio = windll.dlportio # requires dlportio.dll !!!\nexcept:\n\tprint('The parallel port couldn\\'t be opened')\n~~~\n\nThis will load `dlportio.dll` as a global object called `io`. Please note that failure will not crash the experiment, so make sure to check the debug window for error messages!\n\nNow use the following code in an INLINE_SCRIPT anywhere in the experiment to send a trigger:\n\n~~~ .python\nglobal io\ntrigger = 1\nport = 0x378\ntry:\n\tio.DlPortWritePortUchar(port, trigger)\nexcept:\n\tprint('Failed to send trigger!')\n~~~\n\nNote that this sends trigger 1 to port 0x378 (=888). Change these values according to your set-up.\n\n## Getting access to the parallel port\n\n### Linux\n\nIn Linux we use the `parport_pc` module (tested in Debian Wheezy) and we need to provide ourselves with permissions to do so. We can accomplish this by executing the following commands:\n\n\tsudo rmmod lp\n\tsudo rmmod parport_pc\n\tsudo modprobe parport_pc\n\tsudo adduser [user] lp\n\nHere, `[user]` should be replaced by your username. Next, logout and login, and you are ready to go!\n\n### Windows XP and Windows Vista (32 bit)\n\n1. Download the 32-bit DLPortIO driver from [here][win32-dll] and uncompress the zip archive.\n2. Go to `DriverLINX/drivers` folder and copy `dlportio.dll` and `dlportio.sys` to the `install` folder. This is the folder  where `install.exe` is located. Then run `install.exe`\n3. You need to copy `dlportio.dll` to the OpenSesame folder (that is, the same folder that contains `opensesame.exe`).\n\n### Windows 7 (32 and 64 bit)\n\n1. Download the 32-bit or 64bit DLPortIO driver [here][win7-dll] and uncompress the zip archive.\n2. As Windows 7 has a strengthened security system (at least compared to XP) one cannot simply install the DLPortIO driver. This won't work as Windows 7 will block all attempts of installing a not-officially-signed (by Microsoft) driver. Good for the security of an average user -- bad for us. To bypass this restriction one has to use a little helper program called \"Digital Signature Enforcement Overrider\" (DSEO) which can be downloaded [here][dseo] (of course there are other possible ways to do this but this program is mentioned in the DLPortIO `readme.txt` and one does not have to dive deeper into MS Windows 7 architecture specialities).\n3. Start DSEO with administrator privileges (right click on `dseo13b.exe`, select \"run as administrator\"). Now the DSEO window pops up. It just presents a list of options which operation to run next.\n4. Choose the option \"sign driver/sys-file\" and press ok. Now another window appears where you have to type in the absolute path to the `DLPortIO.sys` file (only this one, not the dll!). Remember to escape spaces in the path if you have any (don't ask how long that took me) otherwise your files will not be found. Pressing ok will sign the sys-file.\n5. Back in the DSEO list choose \"enable test mode\" and press ok. Then choose \"exit\" and restart your PC. Windows 7 wrongly complains that DSEO might not be installed correctly -- just click on \"yes, the software is installed correctly\".\n6. After boot-up is completed you'll see that something like \"Windows 7 test mode built #number#\" is written on the desktop just above the clock in the starter-bar. That's necessary. You have to be in test mode to run this unofficially signed driver.\n7. Now run `DLPortIO_install.bat` with administrator privileges (in Windows Explorer, right click the file, ...). Answer \"yes\" if Windows warns you about registry changes.\n8. Reboot.\n9. Copy `DLPortIO.dll` to the Opensesame folder, that is, the same folder that contains `opensesame.exe`.\n\nSource: [Forum post by Absurd][post-3]\n\n## Recommendations\n\n- Start your experiment with a 'zero' trigger to make sure all the pins are set to zero.\n- It's recommended to use the [psycho] or [xpyriment] backends instead of the [legacy] backend (using PyGame) for time-critical experiments. This is because [psycho] and [xpyriment] takes the refresh rate of the monitor into account when returning timestamps, whereas [legacy] does not. For more information, see [miscellaneous/timing].\n- Send the trigger code right after (instead of just before) the presentation of your stimulus (assuming that it's the stimulus onset you want to mark). By doing so you'll make sure that the time stamp is as accurately as possible and will not suffer from a small random jitter due to your monitor's refresh rate. [Source: lvanderlinden][post-2]\n\n## Troubleshooting\n\nThere are a number of relevant forum topics in which trigger-related problems are discussed (and, for the most, solved!).\n\n- A post about ghost triggers, i.e. unwanted triggers that are mysteriously registered by the EEG apparatus: [link][post-2]\n- A post with elaborate installation instructions for DLPortIO on Windows 7 ([Source: absurd][post-3]).\n\nPlease don't hesitate to post questions on the forum, or to let us know of your experiences (good or bad).\n\n[win32-dll]: http://files.cogsci.nl/misc/dlportio.zip\n[win7-dll]: http://real.kiev.ua/avreal/download/#DLPORTIO_TABLE\n[dseo]: http://www.ngohq.com/home.php?page=dseo\n[post-2]: http://forum.cogsci.nl/index.php?p=/discussion/comment/780#Comment_780\n[post-3]: http://forum.cogsci.nl/index.php?p=/discussion/comment/745#Comment_745\n[miscellaneous/timing]: /miscellaneous/timing\n[legacy]: /backends/legacy\n[xpyriment]: /backends/xpyriment\n[psycho]: /backends/psycho", "url": "https://osdoc.cogsci.nl/4.0/manual/devices/parallel", "title": "Parallel port (EEG triggers)"}
{"content": "# Emotiv EEG\n\n---\nlayout: osdoc\ntitle: Emotiv EEG\ngroup: Devices\npermalink: /emotiv/\n---\n\n[Emotiv](https://emotiv.com/) is a low-cost EEG headset. Dimitrios Adamos (Neuroinformatics.GRoup of the Aristotle University of Thessaloniki) has written a tutorial for using the Emotiv with OpenSesame:\n\n- <http://neuroinformatics.gr/node/37>\n\n%--\nfigure:\n source: emotiv.png\n id: FigEmotiv\n caption: Emotiv is a low-cost EEG headset.\n--%", "url": "https://osdoc.cogsci.nl/4.0/manual/devices/emotiv", "title": "Emotiv EEG"}
{"content": "# Using the form plugins\n\ntitle: Using the form plugins\n\nA number of commonly used forms are available as ready-made plugins. These allow you to use common forms, without any need for scripting.\n\n- FORM_CONSENT is a simple digital consent form (disclaimer: some journals may require *written* consent)\n- FORM_MULTIPLE_CHOICE allows you to present multiple choice questions\n- FORM_TEXT_DISPLAY is a simple text display that you can use to show instructions etc.\n- FORM_TEXT_INPUT is a simple text input display that allows you to ask a question and collect a multi-character response from the participant\n\nThe FORM_BASE plugin is special. It allows you to define custom forms using OpenSesame script, as described here:\n\n- %link:manual/forms/custom%\n\n%--\nfigure:\n id: FigFormPlugins\n source: form-plugins.png\n caption: The FORM plugins in the item toolbar.\n--%", "url": "https://osdoc.cogsci.nl/4.0/manual/forms/readymade", "title": "Using the form plugins"}
{"content": "# Form variables\n\ntitle: Form variables\n\n[TOC]\n\n## About form variables\n\nWhen you present a form with multiple `checkbox`es, you generally want to know which `checkbox` the user has checked. Similarly, when you present a form with two `button`s, you want to know which `button` the user has clicked. This information is available through variables that are automatically set when the user interacts with a form. You can specify yourself which response variables should be used. How this is done depends on how you have created your form.\n\n### In ready-made form plugins\n\nWhen you use one of the ready-made form plugins, such as FORM_TEXT_INPUT, you can specify the name of the response variable directly in the plugin controls.\n\n### In custom forms\n\nYou can use the `var` keyword to indicate which variable should be used. For example, the following OpenSesame script, which you can enter into a FORM_BASE plugin, indicates that the response from a `text_input` widget should be stored in a variable called `my_response_var`:\n\n```python\nwidget 0 0 1 1 text_input var=my_response_var\n```\n\nThe equivalent Python code is:\n\n~~~ .python\nmy_widget = TextInput(var='my_response_var')\n~~~\n\nSee also:\n\n- %link:manual/forms/widgets%\n\n## Widget-specific information\n\nEach widget uses its response variable in a slightly different way.\n\n### button\n\nThe `button` widget sets the response variable to 'yes' if it has been clicked and to 'no' if it has not.\n\n### checkbox\n\nThe `checkbox` widget sets the response variable to a semicolon-separated list of the text on all checkboxes that have been checked (for that variable), or 'no' if no `checkbox` has been checked (for that variable). This sounds a bit complicated, so let's see a few examples.\n\n```python\nwidget 0 0 1 1 checkbox group=\"1\" text=\"A\" var=\"my_response_var\"\nwidget 1 0 1 1 checkbox group=\"1\" text=\"B\" var=\"my_response_var\"\nwidget 1 1 1 1 button text=\"Next\"\n```\n\nHere there are two `checkbox`es with the text 'A' and 'B'. Both part of the same group, called '1'. Both have the same response variable, called `my_response_var`. If 'A' is checked, `my_response_var` will be 'A'. If 'B' is checked, `my_response_var` will be 'B'. If neither is checked, `my_response_var` will be 'no'. Note that only one `checkbox` in the same group can be checked, so `my_response_var` will *never* be 'A;B' in this example.\n\nNow let's consider the same script, with the sole difference that the two `checkbox`es are not part of a group:\n\n```python\nwidget 0 0 1 1 checkbox text=\"A\" var=\"my_response_var\"\nwidget 1 0 1 1 checkbox text=\"B\" var=\"my_response_var\"\nwidget 1 1 1 1 button text=\"Next\"\n```\n\nIn this case, the situation is much like described above, with the exception that both `checkbox`es can be checked at the same time, in which case `my_response_var` will be set to 'A;B'.\n\nYou cannot use the same response variable for `checkbox`es in different groups.\n\n### image\n\nVariables are not applicable to the `image` widget.\n\n### image_button\n\nThe `image_button` widget sets the response variable to 'yes' if it has been clicked and to 'no' if it has not.\n\n### label\n\nVariables are not applicable to the `label` widget.\n\n### rating_scale\n\nThe `rating_scale` widget sets the response variable to the number of the option that has been clicked, where '0' is the first option (zero-based indexing). If no option has been selected, the response variable is set to 'None'.\n\n### text_input\n\nThe `text_input` widget sets the response variable to the entered text.", "url": "https://osdoc.cogsci.nl/4.0/manual/forms/variables", "title": "Form variables"}
{"content": "# About forms\n\ntitle: About forms\n\nForms are simple interactive displays that can be used to implement questionnaires, instructions, text input displays, etc. You can use forms in four ways.\n\n- Use the form plugins, such as FORM_TEXT_INPUT, which offer ready-made forms. This is the easiest, but least flexible way of using forms. This works both on the desktop and in a browser.\n\t- %link:manual/forms/readymade%\n- Define custom forms using OpenSesame script and the form_base plugin. This offers considerable flexibility, and does not require any real programming skills. This only works on the desktop.\n\t- %link:manual/forms/custom%\n- Create custom forms using Python inline script. This offers the most flexibility, but requires some knowledge of Python programming. This only works on the desktop.\n\t- %link:manual/forms/custom%\n- Create custom forms using HTML code. This only works when running experiments in a browser with OSWeb.\n\t- %link:manual/forms/html%\n\n%--\nfigure:\n id: FigAbout\n source: about.png\n caption: An example form.\n--%", "url": "https://osdoc.cogsci.nl/4.0/manual/forms/about", "title": "About forms"}
{"content": "# Custom HTML forms\n\ntitle: Custom HTML forms\n\n\nThe INLINE_HTML item allows you to implement forms using custom HTML.\n\n- The `name` attribute of `input` tags corresponds to an experimental variable. Therefore, the text that is entered into the text input of Example 1 will be stored as the experimental variable `text_response`.\n- For `checkbox` and `radio` elements, you can use the `id` attribute to assign a specific value to the associated experimental variable.\n- You can use the `required` attribute to indicate that a form cannot be submitted before a field has been filled out.\n- The form is closed when the participant clicks on an input of type submit.\n- To include images from the file pool in a custom HTML form, first retrieve the URL to the file, assign it to an experimental variable, and then use this variable as the source for the `<img>` tag (see Example 3).\n\n\nExample 1:\n\nA very basic text input form:\n\n```html\n<input type='text' name='text_response'>\n<input type='submit' value='click here to continue'>\n```\n\nExample 2:\n\nA form with multiple radio buttons:\n\n```html\n<p>Please select your age:</p>\n<input type=\"radio\" id=\"age1\" name=\"age\" value=\"30\" required>\n<label for=\"age1\">0 - 30</label><br>\n<input type=\"radio\" id=\"age2\" name=\"age\" value=\"60\">\n<label for=\"age2\">31 - 60</label><br>  \n<input type=\"radio\" id=\"age3\" name=\"age\" value=\"100\">\n<label for=\"age3\">61 - 100</label><br><br>\n<input type=\"submit\" value=\"Submit\">\n```\n\nExample 3:\n\nYou can include variable references (except within `<script>` tags, where curly braces are simply interpreted as part of JavaScript code):\n\n```html\n<p>You age group is {age}</p>\n<input type='submit' value='ok'>\n```\n\nExample 4:\n\nYou can JavaScript through `<script>` tags. For example, you can get an image from the file pool and assign to an initially empty `<img>` tag like this:\n\n```html\n<img id='capybara'>\n<input type='submit' value='ok'>\n\n<script>\ndocument.getElementById('capybara').src = pool['capybara.png'].data.src\n</script>\n```", "url": "https://osdoc.cogsci.nl/4.0/manual/forms/html", "title": "Custom HTML forms"}
{"content": "# Form widgets and keywords\n\ntitle: Form widgets and keywords\n\n\n[TOC]\n\n\n## Screenshot\n\n%--\nfigure:\n id: FigWidgets\n source: widgets.png\n caption: A list of available FORM widgets.\n--%\n\n\n## Widgets and keywords\n\nAll keywords are optional, instead otherwise indicated.\n\n### Form\n\nThe `cols` and `rows` keywords can either be single `int` values, in which case they specify the number of equally sized columns and rows, or lists of `int`, in which case they specify the relative sizes of each column and row. For more information about form geometry, see:\n\n- %link:manual/forms/custom%\n\nThe `validator` keyword can be used to validate form input. For more information, see:\n\n- %link:manual/forms/validation%\n\n(In OpenSesame script, you do not need to explicitly create a form.)\n\nPython script:\n\n~~~ .python\nform = Form(\n    cols=2, rows=2, spacing=10, margins=(100, 100, 100, 100), theme='gray',\n    timeout=None, clicks=False, validator=None\n)\nbutton = Button(text='Ok!')\nform.set_widget(button, (0, 0))\nform._exec()\n~~~\n\n\n### button / Button\n\nOpenSesame script:\n\n~~~python\nwidget 0 0 1 1 button text=\"Click me!\" center=yes frame=yes var=response\n~~~\n\nPython script:\n\n~~~ .python\nform = Form()\nbutton = Button(text='Click me!', frame=True, center=True, var='response')\nform.set_widget(button, (0, 0))\nform._exec()\n~~~\n\n\n### checkbox / Checkbox\n\nIf a group is specified, checking one checkbox from that group will uncheck all other checkboxes from that group. Checkboxes that are part of a group cannot be unchecked, except by clicking on another checkbox in that group.\n\nThe `group` keyword also affects how variables are stored, as described here:\n\n- %link:manual/forms/variables%\n\nOpenSesame script:\n\n~~~python\nwidget 0 0 1 1 checkbox group=group text=\"Option 1\"\nwidget 0 1 1 1 checkbox group=group text=\"Option 2\"\n~~~\n\nPython script:\n\n~~~ .python\nform = Form()\ncheckbox1 = Checkbox(text='Option 1', group='group')\ncheckbox2 = Checkbox(text='Option 2', group='group')\nform.set_widget(checkbox1, (0, 0))\nform.set_widget(checkbox2, (0, 1))\nform._exec()\n~~~\n\n\n### image / ImageWidget\n\nThe Python object is called `ImageWidget` to distinguish it from the `Image` canvas element.\n\nOpenSesame script:\n\n~~~python\n# Only path is a required keyword\nwidget 0 0 1 1 image path=\"my_image.png\" adjust=yes frame=no\n~~~\n\nPython script:\n\n~~~ .python\n# Only path is a required keyword\nform = Form()\nimage = ImageWidget(path=pool['my_image.png'], adjust=True, frame=False)\nform.set_widget(image, (0, 0))\nform._exec()\n~~~\n\n\n### image_button / ImageButton\n\nThe `image_id` keyword is used to identify the image button when it is clicked. If no `image_id` is provided, the path to the image is used as id.\n\nOpenSesame script:\n\n~~~python\n# Only path is a required keyword\nwidget 0 0 1 1 image_button path=\"my_image.png\" adjust=yes frame=no image_id=my_image var=response\n~~~\n\nPython script:\n\n~~~ .python\n# Only path is a required keyword\nform = Form()\nimage_button = ImageButton(\n    path=pool['my_image.png'], adjust=True, frame=False,\n    image_id='my_image', var='response'\n)\nform.set_widget(image_button, (0, 0))\nform._exec()\n~~~\n\n\n### label / Label\n\nOpenSesame script:\n\n~~~python\nwidget 0 0 1 1 label text=\"My text\" frame=no center=yes\n~~~\n\nPython script:\n\n~~~ .python\nform = Form()\nlabel = Label(text='My text', frame=False, center=True)\nform.set_widget(label, (0,0))\nform._exec()\n~~~\n\n\n### rating_scale / RatingScale\n\nThe `nodes` keyword can be an `int` or a semicolon-separated list of labels. If `nodes` is an `int`, it specified the number of (unlabeled) nodes.\n\nThe `default` keyword indicates which node number is selected by default, where the first node is 0.\n\nOpenSesame script:\n\n~~~python\nwidget 0 1 1 1 rating_scale var=response nodes=\"Agree;Don't know;Disagree\" click_accepts=no orientation=horizontal var=response default=0\n~~~\n\nPython script:\n\n~~~ .python\nform = Form()\nrating_scale = RatingScale(\n    nodes=['Agree', u\"Don't know\", 'Disagree'], click_accepts=False,\n    orientation='horizontal', var='response', default=0\n)\nform.set_widget(rating_scale, (0, 0))\nform._exec()\n~~~\n\n\n### text_input / TextInput\n\nThe `stub` keyword indicates placeholder text that is shown when no text has been entered. The `key_filter` keyword, available only in Python, specifies a function to filter key presses. This is described in more detail under:\n\n- %link:manual/forms/validation%\n\nOpenSesame script:\n\n~~~python\nwidget 0 0 1 1 text_input text=\"Initial text\" frame=yes center=no stub=\"Type here \u2026\" return_accepts=yes var=response\n~~~\n\nPython script:\n\n~~~ .python\nform = Form()\ntext_input = TextInput(\n    text='Initial text', frame=True, center=False, stub='Type here \u2026',\n    return_accepts=True, var='response', key_filter=my_filter_function\n)\nform.set_widget(text_input, (0, 0))\nform._exec()\n~~~", "url": "https://osdoc.cogsci.nl/4.0/manual/forms/widgets", "title": "Form widgets and keywords"}
{"content": "# Creating custom forms\n\ntitle: Creating custom forms\n\n\n[TOC]\n\n\n## About forms, geometries, and widgets\n\nA form is a set of widgets (buttons, labels, text-input fields, etc.) arranged into a grid with a particular geometry. In the image below you see an example of a 2 (columns) \u00d7 3 (rows) form. A form geometry is simple, and consists of the following properties:\n\n- *margins* ensure that the widgets do not touch the edge of the display. You can have different margins for the top, right, bottom, and left.\n- *spacing* ensure that the widgets do not touch each other. The horizontal and vertical spacing is the same.\n- There are one or more *rows*, possibly of different sizes.\n- There are one or more *columns*, possibly of different sizes.\n\n%--\nfigure:\n id: FigGeometry\n source: geometry.png\n caption: A schematic of FORM geometries.\n--%\n\nOf course, an empty form is no fun. So let's add the following widgets to create a simple question form:\n\n- A `label` that spans the two columns of the top row. We use this label to give a title to the form.\n- Another `label` that spans the two columns of the middle row. This label contains the actual question.\n- A `button` in the bottom right widget area. This button allows the user to give the $0.05 response.\n- Another `button` in the bottom left widget area. This button allows the user to give the $0.10 response.\n\n%--\nfigure:\n id: FigSchematicExample1\n source: schematic-example1.png\n caption: A schematic example FORM.\n--%\n\nThe images above are schematic examples. How this form actually looks in OpenSesame depends on your settings (notably your font and colors), but it may look something like this:\n\n%--\nfigure:\n id: FigExample1\n source: example1.png\n caption: A example FORM.\n--%\n\n## Creating custom forms\n\nThere are two ways to create custom forms. You can:\n\n- Use the FORM_BASE item, and specify your form using OpenSesame script.\n- Using Python in an INLINE_SCRIPT item. The Python way is slightly more flexible, but for most purposes both ways can be used.\n\n### Creating forms using OpenSesame script\n\nWe will create the form described above using OpenSesame script. First, drag the FORM_BASE plugin into your experiment. Click on the newly created item to open its tab. Next, click on the 'Edit script' button (with the terminal icon), in the top-right of the tab area. This will open the script editor. Enter the following script to generate the form described above (see the comments for explanations).\n\n~~~\n# Margins are defined as \"top;right;bottom;left\". Each value corresponds to a\n# margin in pixels.\nset margins \"50;100;50;100\"\n# The spacing is simply a value in pixels.\nset spacing \"25\"\n# The sizes of the rows are relative. \"1;2;1\" means that there are three rows,\n# where the middle one is twice as large as the bottom and top ones. So \"1;2;1\"\n# means exactly the same thing as \"3;6;3\". Please note that \"3\" does not mean\n# that there are three equally-sized rows (but \"1;1;1\" does).\nset rows \"1;2;1\"\n# Columns are defined in the same way. \"1;1\" simply means that there\n# are two columns of the same size.\nset cols \"1;1\"\n# Widgets are defined as follows:\n# widget [column] [row] [column span] [row span] [widget type] [keywords]\n#\n# The columns and rows start counting at 0. If you do not want to have your widget\n# span multiple columns and rows, you simply set the column and row span to 1.\nwidget 0 0 2 1 label text=\"Question\"\nwidget 0 1 2 1 label center=\"no\" text=\"A bat and a baseball together cost $1.10. The bat costs one dollar more than the ball. How much does the ball cost?\"\nwidget 0 2 1 1 button text=\"$0.10\"\nwidget 1 2 1 1 button text=\"$0.05\"\n~~~\n\nIf you want a specific widget to receive the focus when the form is executed, you can apply the `focus=yes` keyword to one of the widgets:\n\n```\nwidget 0 0 1 1 text_input text=\"Initial text\" frame=yes center=no stub=\"Type here \u2026\" return_accepts=yes var=response focus=yes\n```\n\n\n### Creating forms using Python inline script\n\nThe exact same form can be created using an INLINE_SCRIPT and a bit of Python code. You will notice that the Python code somewhat resembles the OpenSesame script shown above. This is no wonder: The FORM_BASE plugin essentially translates the OpenSesame script into Python code.\n\nFirst, drag an INLINE_SCRIPT into your experiment. Select the newly created item to open its tab, and add the following script into the Run phase of the INLINE_SCRIPT item (see the comments for explanations).\n\n~~~ .python\n# Create a form\nform = Form(\n    cols=[1,1], rows=[1,2,1],\n    margins=(50,100,50,100), spacing=25\n)\n# Create four widgets\nlabelTitle = Label(text='Question')\nlabelQuestion = Label(\n    text='A bat and a baseball together cost $1.10. The bat costs one dollar more than the ball. How much does the ball cost?',\n    center=False\n)\nbutton5cts = Button(text='$0.05')\nbutton10cts = Button(text='$0.10')\n# Add the widgets to the form. The position in the form is indicated as a\n# (column, row) tuple.\nform.set_widget(labelTitle, (0,0), colspan=2)\nform.set_widget(labelQuestion, (0,1), colspan=2)\nform.set_widget(button5cts, (0,2))\nform.set_widget(button10cts, (1,2))\n# Execute the form! In this case, the form will return the text of the button that\n# was clicked. This is one way to get a return value out of the form. Another way\n# is to use the 'var' keyword, supported some of the widgets.\nbutton_clicked = form._exec()\n~~~\n\nIf you want a specific widget to receive the focus when the form is executed, you can use the `focus_wiget` keyword:\n\n~~~ .python\nbutton_clicked = form._exec(focus_widget=button5cts)\n~~~\n\n### Non-interactive forms\n\nUsually, a form will have an input field, a button, or some other interactive element. However, you can also use forms without having any interactive element. To do this in OpenSesame script, you set `only_render` to \"yes\":\n\n```python\nset only_render yes\n```\n\nTo this in a Python INLINE_SCRIPT, you call `form.render()`, instead of `form._exec()`.\n\n### Themes\n\nForms support theming. Currently, two themes are available: 'gray' and 'plain'. The 'gray' theme is the default. Although the 'gray' theme is already quite plain, the 'plain' theme is even more basic. You can choose a theme like this in OpenSesame script:\n\n```python\nset theme plain\n```\n\nAnd by using the `theme` keyword in Python inline script:\n\n~~~ .python\nform = Form(theme='plain')\n~~~\n\n### Available widgets and keywords\n\nFor a list of available widgets and keywords, see:\n\n- %link:manual/forms/widgets%\n\n### Validating input\n\nTo see how you can validate form input, see:\n\n- %link:manual/forms/validation%\n\n## Another example\n\nThe following OpenSesame script (in a FORM_BASE plugin) will produce a questionnaire of three rating scales plus a next button:\n\n```python\nset rows \"1;1;1;1;1\"\nset cols \"1;1\"\nwidget 0 0 2 1 label text=\"Indicate how much you agree with the following statements\"\nwidget 0 1 1 1 label center=\"no\" text=\"Forms are easy\"\nwidget 1 1 1 1 rating_scale var=\"question1\" nodes=\"Agree;Don't know;Disagree\"\nwidget 0 2 1 1 label center=\"no\" text=\"I like data\"\nwidget 1 2 1 1 rating_scale var=\"question2\" nodes=\"Agree;Don't know;Disagree\"\nwidget 0 3 1 1 label center=\"no\" text=\"I like questionnaires\"\nwidget 1 3 1 1 rating_scale var=\"question3\" nodes=\"Agree;Don't know;Disagree\"\nwidget 0 4 2 1 button text=\"Next\"\n```\n\nThe following Python inline_script will produce the same questionnaire.\n\n~~~ .python\nform = Form(cols=[1,1], rows=[1,1,1,1,1])\ntitle = Label(\n    text='Indicate how much you agree with the following statement'\n)\nquestion1 = Label(text='Forms are easy', center=False)\nquestion2 = Label(text='I like data', center=False)\nquestion3 = Label(text='I like questionnaires', center=False)\nratingScale1 = RatingScale(\n    var='question1',\n    nodes=['Agree', u\"Don't know\", 'Disagree']\n)\nratingScale2 = RatingScale(\n    var='question2',\n    nodes=['Agree', u\"Don't know\", 'Disagree']\n)\nratingScale3 = RatingScale(var='question3',\n    nodes=['Agree', u\"Don't know\", 'Disagree'])\nnextButton = Button(text='Next')\nform.set_widget(title, (0, 0), colspan=2)\nform.set_widget(question1, (0, 1))\nform.set_widget(question2, (0, 2))\nform.set_widget(question3, (0, 3))\nform.set_widget(ratingScale1, (1, 1))\nform.set_widget(ratingScale2, (1, 2))\nform.set_widget(ratingScale3, (1, 3))\nform.set_widget(nextButton, (0, 4), colspan=2)\nform._exec()\n~~~\n\nThe resulting form looks something like this. (The exact appearance depends on your font, colors, etc.)\n\n%--\nfigure:\n id: FigExample2\n source: example2.png\n caption: Another example FORM.\n--%", "url": "https://osdoc.cogsci.nl/4.0/manual/forms/custom", "title": "Creating custom forms"}
{"content": "# Validating form input\n\ntitle: Validating form input\n\n\nTo validate a form, pass a function with the `validator` keyword to `Form()`. In the example below, `my_form_validator()` is used in this way. A validator function should not expect any arguments, and should return a `bool` to indicate whether or not the form validates. If the form does not validate, no error message is shown, but the form simply stays open.\n\nIn addition, you can validate (or filter) input to a `TextInput` widget to exclude certain characters as input. To do so, pass a function with the `key_filter` keyword to `TextInput()`. In the example below, `filter_digits()` is used in this way. A key-filter function should accept a single argument, which corresponds to a single key press, and should return a `bool` to indicate whether or not the key is accepted as input.\n\n~~~ .python\ndef my_form_validator():\n    \"\"\"Checks whether both the gender and age fields have been filled out\"\"\"\n    return gender != 'no' and age != ''\n\n\ndef filter_digits(ch):\n    \"\"\"Allows only digit characters as input\"\"\"\n    return ch in '0123456789'\n\n\n# Define all widgets\nbutton_ok = Button(text='Ok')\nlabel_gender= Label('Your gender')\ncheckbox_male = Checkbox(text='Male', group='gender', var='gender')\ncheckbox_female = Checkbox(text='Female', group='gender', var='gender')\nlabel_age = Label('Your age')\n# Specify a key filter so that only digits are accepted as text input\ninput_age = TextInput(stub='Age here \u2026', var='age', key_filter=filter_digits)\n# Build the form. Specify a validator function to make sure that the form is\n# completed.\nmy_form = Form(validator=my_form_validator, rows=[1,1,1], cols=[1,1,1])\nmy_form.set_widget(label_gender, (0, 0))\nmy_form.set_widget(checkbox_male, (1, 0))\nmy_form.set_widget(checkbox_female, (2, 0))\nmy_form.set_widget(label_age, (0, 1))\nmy_form.set_widget(input_age, (1, 1), colspan=2)\nmy_form.set_widget(button_ok, (1, 2))\nmy_form._exec()\n~~~", "url": "https://osdoc.cogsci.nl/4.0/manual/forms/validation", "title": "Validating form input"}
{"content": "# CSV functions (csv-parse)\n\ntitle: CSV functions (csv-parse)\n\nThe synchronous `parse()` function from the `csv-parse` library is available. This allows you to parse CSV-formatted text, for example from a CSV file in the file pool, into an Object.\n\n__Example:__\n\n```js\nconst conditions = csvParse(\n    pool['attentional-capture-jobs.csv'].data,\n    {columns: true}\n)\nfor (const trial of conditions) {\n    console.log(trial.distractor)\n}\n```\n\nFor an overview, see:\n\n- <https://csv.js.org/parse/api/sync/#sync-api>", "url": "https://osdoc.cogsci.nl/4.0/manual/javascript/csv", "title": "CSV functions (csv-parse)"}
{"content": "# Python-like iterators (pythonic)\n\ntitle: Python-like iterators (pythonic)\n\nThe `pythonic` library provides Python-like functions for iterating over arrays. Available functions are: `range()`, `enumerate()`, `items()`, `zip()`, and `zipLongest()`.\n\n__Example:__\n\nDraw a five by five grid of incrementing numbers:\n\n```js\nlet positions = xy_grid(5, 50)\nconst cnv = Canvas()\nfor (const [i, [x, y]] of enumerate(positions)) {\n    cnv.text({text: i, x: x, y: y})\n}\ncnv.show()\n```\n\nFor an overview, see:\n\n- <https://www.npmjs.com/package/pythonic>", "url": "https://osdoc.cogsci.nl/4.0/manual/javascript/pythonic", "title": "Python-like iterators (pythonic)"}
{"content": "# About JavaScript\n\ntitle: About JavaScript\n\nIn OpenSesame you can create complex experiments using only the graphical user interface (GUI). But you will sometimes encounter situations in which the functionality provided by the GUI is insufficient. In these cases you can add JavaScript code to your experiment.\n\nJavaScript is for experiments that run in a browser with OSWeb. If you need to run your experiment on the desktop, you need to use [Python](%url:manual/python/about%) instead of JavaScript.\n\n__Version note:__ Desktop support for JavaScript was removed in OpeSesame 4.0. This is because JavaScript support on the desktop was incomplete and was perceived by users as confusing without adding much benefit.\n{: .page-notification}\n\n[TOC]\n\n\n## Learning JavaScript\n\nThere are many JavaScript tutorials available online. One good resource is Code Academy:\n\n- <https://www.codecademy.com/learn/introduction-to-javascript>\n\n\n## JavaScript in the OpenSesame GUI\n\n\n### Inline_javascript items\n\nIn order to use JavaScript code you need to add an INLINE_JAVASCRIPT item to your experiment. After you have done this you will see something like %FigInlineJavaScript.\n\n%--\nfigure:\n id: FigInlineJavaScript\n source: inline-javascript.png\n caption: The INLINE_JAVASCRIPT item.\n--%\n\nAs you can see, the INLINE_JAVASCRIPT item consists of two tabs: one for the Prepare phase and one for the Run phase. The Prepare phase is executed first, to allow items to prepare for the time-critical run phase. It is good practice to construct `Canvas` objects during the Prepare phase, so that they can be presented without delay during the Run phase. But this is only convention; you can execute arbitrary JavaScript code during both phases.\n\nFor more information about the prepare-run strategy, see:\n\n- %link:prepare-run%\n\n\n### Printing output to the console\n\nYou can print to the console with the `console.log()` command:\n\n```js\nconsole.log('This will appear in the console!')\n```\n\nWhen running on the desktop, the output will appear in the OpenSesame console (or: debug window). When running in a browser, the output will appear in the browser console.\n\n\n## Things to know\n\n### Common functions\n\nMany common functions are directly available in an INLINE_JAVASCRIPT item. For example:\n\n```js\n// `Canvas()` is a factory function that returns a `Canvas` object\nlet fixdotCanvas = Canvas()\nif (sometimes()) {  // Sometimes the fixdot is green\n    fixdotCanvas.fixdot({color: 'green'})\n} else {  // Sometimes it is red\n    fixdotCanvas.fixdot({color: 'red'})\n}\nfixdotCanvas.show()\n```\n\nFor a list of common functions, see:\n\n- %link:manual/javascript/common%\n\n\n### Declaring variables (let and var)\n\nINLINE_JAVASCRIPT items are executed in non-strict (or: sloppy) mode. This means that you can assign a value to a variable that was not explicitly declared. When you do this, the variable is implicitly declared using `var` if it wasn't already declared.\n\n```js\nmy_variable = 'my value'  // implicitly declared using var\n```\n\nVariables that are declared implicitly or explicitly using `var` are global, which primarily means that they may be logged by a LOGGER. Variables that are declared using `let` are not global, which primarily means that they are not logged by a LOGGER.\n\n```js\nthis_is_a_global_variable = 'my value'\nvar this_is_also_a_global_variable = 'my value'\nlet this_is_not_a_global_variable = 'my value'\n```\n\n\n### The `persistent` object: preserving objects across scripts\n\n__Version note__ As of OSWeb 2.0, all JavaScript code is executed in the same workspace and objects are therefore preserved across scripts. This means that you no longer need the `persistent` object.\n{:.page-notification}\n\nEach INLINE_JAVASCRIPT item is executed in its own workspace. This means\u2014and this is different from Python INLINE_SCRIPT items!\u2014that you cannot use variables or functions that you've declared in one script in another script. As a workaround, you can attach variables or functions as properties to the `persistent` object, which serves as a container of things that you want to preserve across scripts.\n\nThis way you can construct a `Canvas` in one INLINE_JAVASCRIPT ...\n\n```js\npersistent.myCanvas = Canvas()\npersistent.myCanvas.fixdot()\n```\n\n.. and show it in another INLINE_JAVASCRIPT:\n\n```js\npersistent.myCanvas.show()\n```\n\n\n### The `vars` object: Access to experimental variables\n\n__Version note__ As of OSWeb 2.0, all experimental variables are available as globals. This means that you no longer need the `vars` object.\n{:.page-notification}\n\nYou can access experimental variables through the `vars` object:\n\n```js\n// OSWeb <= 1.4 (with vars object)\n// Get an experimental variable\nconsole.log('my_variable is: ' + vars.my_variable)\n// Set an experimental variable\nvars.my_variable = 'my_value'\n\n// OSWeb >= 2.0 (without vars object)\n// Get an experimental variable\nconsole.log('my_variable is: ' + my_variable)\n// Set an experimental variable\nmy_variable = 'my_value'\n```\n\n\n### The `pool` object: Access to the file pool\n\nYou access 'files' from the file pool through the `pool` object. The most obvious use of this is to parse CSV files, for example with experimental conditions, from the file pool using the `csv-parse` library (described in more detail below).\n\n```js\nconst conditions = csvParse(\n    pool['attentional-capture-jobs.csv'].data,\n    {columns: true}\n)\nfor (const trial of conditions) {\n    console.log(trial.distractor)\n}\n```\n\nYou can also play sound files from the file pool directly. Assuming that there is a file called `bark.ogg` in the file pool, you can play it like so:\n\n```js\npool['bark.ogg'].data.play()\n```\n\n\n### The `Canvas` class: Presenting visual stimuli\n\nThe `Canvas` class is used to present visual stimuli. For example, you can show a fixation dot as follows:\n\n```js\nlet myCanvas = Canvas()\nmyCanvas.fixdot()\nmyCanvas.show()\n```\n\nA full overview of the `Canvas` class can be found here:\n\n- %link:manual/javascript/canvas%\n\n## Available JavaScript libraries\n\nThe following JavaScript libraries are included by default:\n\n- [random functions (`random-ext`)](%url:manual/javascript/random%)\n- [Color-conversion functions (`color-convert`)](%url:manual/javascript/color-convert%)\n- [CSV functions (`csv-parse`)](%url:manual/javascript/csv%)\n- [Python-like iterators (`pythonic`)](%url:manual/javascript/pythonic%)\n\nYou can include additional JavaScript libraries by URLs to the libraries in the 'External JavaScript' libraries field of the OSWeb control panel.\n\n\n## Debugging\n\nSee:\n\n- %link:debugging%", "url": "https://osdoc.cogsci.nl/4.0/manual/javascript/about", "title": "About JavaScript"}
{"content": "# Common functions\n\nThe API described is designed to provide a collection of functions that are integral to the JavaScript programming interface for OpenSesame, which is a software platform commonly used for the creation and implementation of psychology experiments. The API's overall functionality is aimed at enhancing the capabilities of researchers and experimenters to construct complex experimental designs and interactive tasks by scripting custom behaviors and manipulations.\n\nThis JavaScript API for OpenSesame allows for a high degree of customization and control over the experimental flow. It is tailored for use within the OpenSesame environment and is specifically geared towards those with knowledge of JavaScript or those looking to integrate more sophisticated functionality into their experiments.\n\nThe API functions described are often used in tandem with `Canvas` functions, which are a part of the HTML5 specification for drawing shapes, text, images, and other graphics on a web page. This combination allows experimenters to create dynamic and visually engaging stimuli, as well as to capture and manipulate user interactions with these stimuli.\n\nBelow is a bulleted list of the available functions within this API, including their names and parameters:\n\n- **Function Name**: description of what it does. \n  - Parameter 1: description of the parameter.\n  - Parameter 2: description of the parameter.\n  - (...additional parameters descriptions...)\n\n(Note: The actual list of functions and parameters is not provided in the provided text, so it's not possible for me to list them here. In a complete summary, this section would include a detailed list of each function from the API documentation.)\n\nIn summary, the JavaScript API provided by OpenSesame is a specialized toolset for psychologists and researchers to create complex and interactive experiments. It leverages the capabilities of JavaScript and is complemented by graphical functions such as those provided by the `Canvas` API, enabling a rich and engaging experimental environment.", "url": "https://osdoc.cogsci.nl/4.0/manual/javascript/common", "title": "Common functions"}
{"content": "# Common functions\n\ntitle: Common functions\n\n<summary_prompt>\nWrite a summary for the API below:\n\n- Describe the API's overall functionality\n- Explain that this is a JavaScript API for OpenSesame, software for implementing psychology experiments\n- Explain that these functions are commonly used in combination with `Canvas` functions\n- Provide a bulleted list of all available functions and their parameters. Don't just name the functions, but create one bullet per function.\n\nYour response should be a comprehensive summary.\n\n```markdown\n{content}\n```\n</summary_prompt>\n\n[TOC]\n\n\nThe following functions are available in INLINE_JAVASCRIPT items:\n\n<div class=\"cogsci-jsdoc\" markdown=\"1\">\n\n%-- include: include/javascript-api/javascript_workspace_api.md --%\n\n</div>", "url": "https://osdoc.cogsci.nl/4.0/manual/javascript/common", "title": "Common functions"}
{"content": "# random functions (random-ext)\n\ntitle: random functions (random-ext)\n\n\nThe `random-ext` library is available as `random`. This library provides many convenient, higher-level functions for randomization.\n\n__Example:__\n\nDraw eight circle with a random color and a location that is randomly sampled from a five by five grid:\n\n```js\nlet positions = xy_grid(5, 50)\npositions = random.subArray(positions, 8)\nconst cnv = Canvas()\ncnv.fixdot()\nfor (const [x, y] of positions) {\n    cnv.circle({x: x, y: y, r: 20, fill: true, color: random.color()})\n}\ncnv.show()\n```\n\nFor an overview, see:\n\n- <https://www.npmjs.com/package/random-ext>", "url": "https://osdoc.cogsci.nl/4.0/manual/javascript/random", "title": "random functions (random-ext)"}
{"content": "# Canvas functions\n\nThe API described is designed to provide functionality for handling the `Canvas` element within OpenSesame, which is a software platform used for creating and conducting psychological experiments. The API is specifically tailored for use with JavaScript, enabling researchers and developers to programmatically manipulate the canvas to display stimuli, collect responses, and perform various other tasks related to experimental design.\n\nTo initialize a `Canvas` in OpenSesame, one would typically create a new instance of the `Canvas` class. This process involves calling a constructor that sets up the initial state of the canvas, including its dimensions, background color, and other properties. Once initialized, the canvas serves as a drawing surface where text, images, and shapes can be rendered.\n\nThe `styleArgs` within the context of the API refers to the arguments that dictate the style of the elements drawn on the canvas. This can include parameters such as color, font size, line width, and other visual attributes that affect how the drawn elements appear on the screen.\n\nIn the coordinate system used by this Canvas API, the point x=0, y=0 represents the center of the display. This means that all drawing operations are positioned relative to the center, with positive x values moving to the right, negative x values to the left, negative y values moving up, and positive y values moving down.\n\nBelow is a comprehensive list of available functions within the API, along with their parameters:\n\n- **initialize**: Initializes the canvas with specified width and height.\n  - `width`: The width of the canvas.\n  - `height`: The height of the canvas.\n\n- **drawText**: Renders text on the canvas.\n  - `text`: The string of text to be displayed.\n  - `x`: The x-coordinate for the text position.\n  - `y`: The y-coordinate for the text position.\n  - `styleArgs`: Optional styling arguments for the text.\n\n- **drawImage**: Places an image onto the canvas.\n  - `image`: The image source to be drawn.\n  - `x`: The x-coordinate for the image position.\n  - `y`: The y-coordinate for the image position.\n  - `styleArgs`: Optional styling arguments for the image.\n\n- **drawShape**: Draws a geometric shape on the canvas.\n  - `shape`: The type of shape to draw (e.g., rectangle, circle).\n  - `x`: The x-coordinate for the shape's position.\n  - `y`: The y-coordinate for the shape's position.\n  - `styleArgs`: Optional styling arguments for the shape.\n\n- **clear**: Clears the entire canvas or a specified rectangular area.\n  - `x`: Optional x-coordinate for the top-left corner of the rectangle to clear.\n  - `y`: Optional y-coordinate for the top-left corner of the rectangle to clear.\n  - `width`: Optional width of the rectangle to clear.\n  - `height`: Optional height of the rectangle to clear.\n\n- **update**: Refreshes the display to show any changes made to the canvas.\n\n- **getWidth**: Returns the width of the canvas.\n\n- **getHeight**: Returns the height of the canvas.\n\nThe above functions collectively provide a robust set of tools for rendering and manipulating visual content on a canvas within the OpenSesame environment, facilitating the creation of dynamic and interactive psychological experiments.", "url": "https://osdoc.cogsci.nl/4.0/manual/javascript/canvas", "title": "Canvas functions"}
{"content": "# Canvas functions\n\ntitle: Canvas functions\n\n<summary_prompt>\nWrite a summary for the API below:\n\n- Describe the API's overall functionality\n- Explain that this is a JavaScript API for OpenSesame, software for implementing psychology experiments\n- Explain the process to initialize a `Canvas`\n- Define the usage of `styleArgs`\n- Explain coordinates: x=0, y=0 is the display center\n- Provide a bulleted list of all available functions and their parameters. Important: Don't just name the functions, but create one bullet per function.\n\nYour response should be a comprehensive summary.\n\n```markdown\n{content}\n```\n</summary_prompt>\n\n<div class=\"cogsci-jsdoc\" markdown=\"1\">\n\n%-- include: include/javascript-api/canvas.md --%\n\n</div>", "url": "https://osdoc.cogsci.nl/4.0/manual/javascript/canvas", "title": "Canvas functions"}
{"content": "# Color conversion functions (color-convert)\n\ntitle: Color conversion functions (color-convert)\n\n\nThe `color-convert` library is available as `convert`. It provides convenient high level functions for converting from one color specification to another.\n\n__Example:__\n\n```js\nconsole.log('The RGB values for blue are ' + convert.keyword.rgb('blue'))\n```\n\nFor an overview, see:\n\n- <https://www.npmjs.com/package/color-convert>", "url": "https://osdoc.cogsci.nl/4.0/manual/javascript/color-convert", "title": "Color conversion functions (color-convert)"}
{"content": "# Downloading and converting data\n\ntitle: Downloading and converting data\n\nAfter collecting data with OSWeb through JATOS, you can download and process this data for analysis. To download, navigate to your study within JATOS, click on 'Results', select all Result entries, and then choose 'Export Results \u2192 JATOS Results Archive' (see %FigJatosExportResults).\n\n%--\nfigure:\n id: FigJatosExportResults\n source: jatos-export-results.png\n caption: Procedure for exporting results collected with OSWeb through JATOS.\n--%\n\nThe downloaded file, typically named in the format `jatos_results_<timestamp>.jzip`, contains various folders and files corresponding to metadata and participant data. This format can be difficult to work with directly for data analysis.\n\nTo simplify data analysis, you can convert this file to a more accessible format like `.csv` or `.xlsx`. This conversion can be easily achieved by using the 'Convert OSWeb results to csv/xlsx' option found in the OSWeb extension.", "url": "https://osdoc.cogsci.nl/4.0/manual/osweb/data", "title": "Downloading and converting data"}
{"content": "# Running experiments online with OSWeb\n\ntitle: Running experiments online with OSWeb\n\n\n[TOC]\n\n\n## The workflow\n\nFor an introduction to the workflow, see also:\n\nMath\u00f4t, S., & March, J. (2022). Conducting linguistic experiments online with OpenSesame and OSWeb. *Language Learning*. doi:10.1111/lang.12509\n<br /><small>[Related preprint (not identical to published manuscript)](https://doi.org/10.31234/osf.io/wnryc)</small>\n\n\n### Developing your experiment\n\nFirst, you develop your experiment as you ordinarily would, using the OpenSesame desktop application. Not all functionality is available in online experiments. Notably, you cannot use Python INLINE_SCRIPT items, but have to use JavaScript INLINE_JAVASCRIPT items instead. During the development of your experiment, it is therefore important to check that your experiment is compatible with OSWeb.\n\n- %link:manual/osweb/osweb%\n- %link:manual/javascript/about%\n\n\n### Uploading your experiment to JATOS\n\nOnce you have developed your experiment, you publish it to JATOS. JATOS is a web server that manages experiments: it allows you to generate links that you can distribute participants, and it stores data that has been collected.\n\nThere is not a single JATOS server. Rather, many institutions maintain their own JATOS server. In addition, <https://mindprobe.eu> is a free JATOS server, sponsored by ESCoP and OpenSesame.\n\n- %link:jatos%\n\n\n### Collecting data\n\nOne you have published your experiment to JATOS, you can start collecting data. You can do this by manually sending links to participants, for example through email. Or you can use a platform for participant recruitment, such as Prolific, Mechanical Turk, or Sona Systems.\n\n- %link:prolific%\n- %link:mturk%\n- %link:sonasystems%\n\n\n### Analyzing data\n\nOnce data collection is finished, you can download the data from JATOS and convert it to `.xlsx` or `.csv` format for further analysis:\n\n- %link:manual/osweb/data%\n\n\n## Tutorials\n\n- %link:tutorials/intermediate-javascript%\n- %link:wcst%", "url": "https://osdoc.cogsci.nl/4.0/manual/osweb/workflow", "title": "Running experiments online with OSWeb"}
{"content": "# JATOS\n\ntitle: JATOS\n\n\n[TOC]\n\n\n## Introduction to JATOS\n\n[JATOS](https://www.jatos.org/) is a system for managing online experiments. It allows you to create accounts for experimenters, upload experiments, and generate links that you can distribute to participants. OpenSesame integrates closely with JATOS.\n\nTo access a JATOS server, you have three main options:\n\n- Request a free account on [MindProbe](https://mindprobe.eu/), a public JATOS server sponsored by ESCoP and OpenSesame.\n- se a JATOS server provided by your institution.\n- Download JATOS and install it on your own server.\n\n## Linking OpenSesame with JATOS/MindProbe\n\nOpenSesame requires an API token to access your account on a JATOS server such as MindProbe. Follow these steps to generate an API token:\n\n1. **Log into JATOS.**\n2. **Open your user profile** by clicking on your name located in the top right corner of the page.\n3. **Create an API token** by clicking on 'API tokens' to view all your current tokens, and then click 'New Token'.\n4. **Assign a name to your token**. This name serves as a descriptor indicating its intended use, such as 'OpenSesame integration'.\n5. **Set an expiration for your token**. Tokens default to expire after 30 days, requiring you to generate a new token each month. You can select 'No Expiration' for convenience, but be aware that it is less secure. If someone gains access to a non-expiring token, they can use it indefinitely, or until you revoke the token.\n\n%--\nfigure:\n id: FigAPIToken\n source: api-token.png\n caption: API tokens can be generated within your JATOS user profile.\n--%\n\nNote: An API token always begins with `jap_`, followed by a series of characters and numbers. Keep your token secure!\n\nOnce you have your API token, open the OSWeb and JATOS control panel in OpenSesame. Enter your API token into the corresponding field and also adjust the JATOS server URL, if necessary.\n\n%--\nfigure:\n id: FigJATOSControlPanel\n source: jatos-control-panel.png\n caption: Specify the JATOS server and your API token in the OSWeb and JATOS control panel.\n--%\n\n\n## Publishing experiments to, and downloading from, JATOS/MindProbe\n\nAfter successfully connecting OpenSesame to JATOS, as explained above, you can publish your experiment to JATOS. To do this, select the 'Publish to JATOS/MindProbe' option from the File menu. Upon initial publication, your experiment will be assigned a unique identifier (UUID) that links it to a study on JATOS.\n\nYou can then visit your JATOS server and observe that the newly published experiment has been added to your list of studies.\n\nFrom that point forward, each time you publish the experiment, the existing JATOS study will be updated with the new version. If you wish to publish the experiment as a completely new study on JATOS, you will need to reset the JATOS UUID via the OSWeb and JATOS control panel.\n\nTo download an experiment from JATOS, select the 'Open from JATOS/MindProbe' option from the File menu. Please note, this function is only applicable if the corresponding JATOS study is compatible with OSWeb 2.", "url": "https://osdoc.cogsci.nl/4.0/manual/osweb/jatos", "title": "JATOS"}
{"content": "# Inline JavaScript\n\ntitle: Inline JavaScript\n\nThis page has moved to:\n\n- %link:manual/javascript/about%", "url": "https://osdoc.cogsci.nl/4.0/manual/osweb/javascript", "title": "Inline JavaScript"}
{"content": "# Sona Systems\n\ntitle: Sona Systems\n\n\n[TOC]\n\n\n## About Sona Systems\n\nSona Systems is an online tool that many universities use for recruiting participants, granting course credit to student participants, etc.\n\nSee also:\n\n- <https://www.sona-systems.com/help/integration_test.aspx>\n\n\n## Create a study on JATOS\n\nFirst, import your experiment into JATOS, as described above. Next, go the Worker & Batch Manager, activate the General Multiple Worker, get a URL by clicking on Get Link, and copy it.\n\n\n## Create a study on Sona Systems\n\nNext, create a study on Sona Systems. Insert the JATOS study URL in the field labeled \"Study URL\". This will tell Sona Systems how to start the experiment. Importantly, add the following to the end of the URL (this will pass the participant's Sona ID to your experiment):\n\n```bash\n?SONA_ID=%SURVEY_CODE%  \n```\n\nSona Systems does not use a Redirect URL. This means that Sona Systems will not automatically know whether or not the participant finished the study.\n\n\n## Register the Sona ID in your experiment\n\nEvery participant from Sona is identified by a unique ID. It's important to log this ID in your experiment, because this allows you to tell which participant from Sona corresponds to which entry in the JATOS results. You can do this by adding the script below in the Prepare phase of an `inline_javascript` item at the very start of your experiment.\n\nWhen running the experiment through Sona, this will make the Sona ID available as the experimental variable `sona_participant_id`. When the running the experiment in any other way (e.g. during testing), the variable `sona_participant_id` will be set to -1. \n\n\n```javascript\nif (window.jatos && jatos.urlQueryParameters.SONA_ID) {\n    console.log('Sona information is available')\n    var sona_participant_id = jatos.urlQueryParameters.SONA_ID\n} else {\n    console.log('Sona information is not available (setting value to -1)')\n    var sona_participant_id = -1\n}\nconsole.log('sona_participant_id = ' + sona_participant_id)\n```\n\n\n## Automatically grant credits on study completion\n\nSona Systems provides a completion URL (client-side), which should be called when a study is succesfully completed, so that Sona Systems can grant credit to the participant (see %FigCompletionURL).\n\n%--\nfigure:\n id: FigCompletionURL\n source: completion-url.png\n caption: The completion URL in the Sona Systems study information.\n--%\n\nThe completion URL (client side) has three arguments in it:\n\n- `experiment_id` which identifies the study and is the same for all participants\n- `credit_token` which (apparently) changes when you change the study information, but is otherwise the same for all participants\n- `survey_code` which corresponds to the Sona Participant ID, and is therefore different for each participant\n\nCopy the completion URL, and replace the `XXX` by `[SONA_ID]`. Go to Study Properties on JATOS, and insert the resulting URL into the End Redirect URL field.\n\n%--\nfigure:\n id: FigEndRedirectURL\n source: end-redirect-url.png\n caption: The end-redirect URL in the JATOS study properties.\n--%", "url": "https://osdoc.cogsci.nl/4.0/manual/osweb/sonasystems", "title": "Sona Systems"}
{"content": "# OSWeb\n\ntitle: OSWeb\n\n\n[TOC]\n\n\n## About OSWeb\n\nOSWeb is an online runtime for OpenSesame experiments. It is a JavaScript library that executes OpenSesame experiments in a browser. To use OSWeb, you need the `opensesame-extension-osweb` package, which comes pre-installed with the Windows and macOS distributions of OpenSesame.\n\n\n## Executing an experiment in a web browser\n\nTo run an experiment in a web browser using OSWeb, follow these steps:\n\n1. Open the Experiment Properties and select 'In a browser with OSWeb (osweb)' in the 'Run experiment' section.\n2. Click any of the 'Run' buttons to start the experiment.\n3. If the experiment is not compatible with OSWeb, an error message will appear that details the compatibility issues. (Refer to the 'supported functionality' section for more details.)\n4. If there are no compatibility issues, the experiment will open in a new browser window. Note that even though the experiment is running in a web browser, it is still executing locally on your own computer. To host the experiment online, you need to publish it to [JATOS](%url:jatos%).\n5. When the experiment is finished, the data will be downloaded in `.json` format. This data file can then be [converted to `.xlsx` or `.csv` format](%url:manual/osweb/data%) for further analysis.\n\n\n%--\nfigure:\n id: FigTestRun\n source: testrun.png\n caption: Open the Experiment Properties and select 'In a browser with OSWeb (osweb)' under 'Run experiment'.\n--%\n\n\n## OSWeb control panel\n\nFor more control over OSWeb experiments, you can access the OSWeb and JATOS control panel from the Tools menu. This panel offers a range of configuration options:\n\n- **Possible subject numbers:** When running an experiment from within JATOS, a subject number is randomly selected from this list. You can specify individual numbers using commas (e.g., '1,2,3') or number ranges (e.g., '1-10'). When running an experiment from within OpenSesame, this option does not apply, as the subject number is specified when the experiment starts.\n- **Make browser fullscreen:** This option determines whether the browser should switch to fullscreen mode when an experiment starts within JATOS. If you're running an experiment directly from OpenSesame, this option is ignored; instead, you can run the experiment fullscreen by using the regular Run button, while the Quick Run button does not enable fullscreen.\n- **Show OSWeb Welcome Screen:** This toggle controls whether participants will see a welcome screen before the experiment starts. The welcome screen can convey crucial information to participants. Additionally, it serves a technical purpose\u2014due to browser-security policies, media playback and certain functionality is only available if the experiment is initiated by a user action. Therefore, it is generally recommended to leave this option enabled.\n- **Bypass Compatibility Check:** Enabling this option allows you to run the experiment even when the OSWeb compatibility check fails. Note that doing so will not automagically resolve compatibility issues!\n- **Welcome Text:** This field allows you to customize the welcome message displayed to participants on the welcome screen.\n- **External Libraries:** This field lets you specify any external libraries that should be loaded with your experiment. The use of external libraries is explained in more detail in the section below.\n\n\n%--\nfigure:\n id: FigOSWebControlPanel\n source: osweb-control-panel.png\n caption: The OSWeb and JATOS control panel offers a range of configuration options for your OSWeb experiments.\n--%\n\n\n## Supported functionality\n\nWhen you run the experiment from within OpenSesame, a compatibility check is automatically performed. However, this check is fairly superficial. A more complete overview of supported functionality can be found below.\n\n\n- `advanced_delay`\n- `feedback`\n    - See `sketchpad`\n- `form_consent` (supported >= v1.4)\n- `form_text_display` (supported >= 1.4)\n- `form_text_input` (supported >= 1.4)\n    - Unsupported: fullscreen mode\n- `form_multiple_choice` (supported >= 1.4)\n- `inline_html` (supported >= 1.4)\n- `inline_javascript`\n- `keyboard`\n    - Unsupported: key release\n    - Unsupported: HSV, HSL, and CIELab color spaces\n- `logger`\n- `loop`\n    - Unsupported: resume after break\n    - Unsupported: Disabling of evaluate on first cycle\n    - Unsupported: constraints (pseudorandomization)\n    - Supported >= 1.4: file source\n- `mouse`\n    - Unsupported: mouse release\n    - Unsupported: linked sketchpad\n- `notepad`\n- `repeat_cycle`\n- `reset_feedback`\n- `sampler`\n    - Supported >= 1.4.12: panning, pitch, and fade in\n    - Supported >= 1.4.12: Sound playback on Safari on Mac OS or any browser on iOS\n    - Unsupported: stop after\n- `sequence`\n- `sketchpad`\n    - Unsupported: named elements\n    - Supported >= 1.4: image rotation\n    - Unsupported: HSV, HSL, and CIELab color spaces\n- `touch_response`\n\n\nThe compatibility check may also indicate errors of the following type:\n\n> The prepare phase for item new_logger is called multiple times in a row\n\nThis error results from how the experiment is structured, and specifically the use of linked copies. It's not always easy to understand where this error comes from, but you can read more about the prepare-run strategy in [this article](%url:prepare-run%). As a workaround, you can put the problematic items in a dummy LOOP, that is, a LOOP that simply calls the item once.\n\n\n## Including external JavaScript packages\n\nYou can include external JavaScript packages by entering URLs to these packages (one URL per line) in the input field labeled 'External JavaScript libraries'. These packages are then included with `<script>` tags in the head of the HTML.\n\nFor example, you can include [WebGazer](%url:webgazer%) for in-browser by entering the following link:\n\n```\nhttps://webgazer.cs.brown.edu/webgazer.js\n```\n\n\n## Debugging\n\nSee:\n\n- %link:debugging%", "url": "https://osdoc.cogsci.nl/4.0/manual/osweb/osweb", "title": "OSWeb"}
{"content": "# Questionnaires in OSWeb\n\ntitle: Questionnaires in OSWeb\n\n\n## Forms and custom HTML\n\nForms and custom HTML are supported as of OSWeb 1.4\n{:.page-notification}\n\nYou can use the form plugins as described here:\n\n- %link:manual/forms/about%\n\nThe FORM_BASE plugin is *not* supported in OSWeb. Instead, you can use the INLINE_HTML item to implement custom HTML forms, as described here:\n\n- %link:manual/forms/html%\n\n\n## Linking to a different platform\n\nAs an alternative, you can implement a questionnaire using another platform, such as [LimeSurvey](https://www.limesurvey.org/), and then link to this questionnaire from your OSWeb experiment. The video below shows how to do this in such a way that you can tell afterwards which questionnaire data belongs to which OSWeb data.\n\n%--\nvideo:\n source: youtube\n id: BeginnerTutorial\n videoid: 1WvTUQr0JL0\n width: 640\n height: 360\n caption: |\n  Combining OSWeb and LimeSurvey.\n--%", "url": "https://osdoc.cogsci.nl/4.0/manual/osweb/questionnaires", "title": "Questionnaires in OSWeb"}
{"content": "# Mechanical Turk\n\ntitle: Mechanical Turk\n\n\nThere is currently no information that is specific to running OSWeb experiments on Mechanical Turk. For general information about connecting JATOS to Mechanical Turk, see:\n\n- <http://www.jatos.org/Connect-to-Mechanical-Turk.html>", "url": "https://osdoc.cogsci.nl/4.0/manual/osweb/mturk", "title": "Mechanical Turk"}
{"content": "# Prolific\n\ntitle: Prolific\n\n\n[TOC]\n\n\n## About Prolific\n\n[Prolific](https://prolific.co/) is a commercial tool for recruiting participants for research. To run OSWeb experiments on Prolific, you need to follow the steps explained below.\n\nSee also:\n\n- <http://www.jatos.org/Use-Prolific.html>\n\n\n## Create a study on JATOS\n\nFirst, import your experiment into JATOS, as described above. Next, go the Worker & Batch Manager, activate the General Multiple Worker, get a URL by clicking on Get Link, and copy it (%FigJatosURL).\n\n\n%--\nfigure:\n id: FigJatosURL\n source: jatos-url.png\n caption: Get a study URL from JATOS.\n--%\n\n\n\n## Create a study on Prolific\n\nNext, create a study on Prolific. Under Study Details (%FigProlific), insert the JATOS study URL in the field labeled \"What is the URL of your study?\". This will tell Prolific how to start the experiment. Importantly, add the following to the end of the URL (this will pass important information from Prolific to your experiment):\n\n{% raw %}\n```bash\n&PROLIFIC_PID={{%PROLIFIC_PID%}}&STUDY_ID={{%STUDY_ID%}}&SESSION_ID={{%SESSION_ID%}}\n```\n{% endraw %}\n\nWhen the experiment is finished, Prolific needs to know about it. For this purpose, Prolific uses an End Redirect URL, which is listed in the field labeled \"To prove that participants have completed your study \u2026\". Copy this End Redirect URL. Also check the box labeled \"I've set up my study to redirect to this url at the end\".\n\n%--\nfigure:\n id: FigProlific\n source: prolific.png\n caption: Study details on Prolific.\n--%\n\n\n\n## Set an End Redirect URL in JATOS\n\nNow go back to JATOS, and open the Properties of your study (%FigJatosProperties). There, paste the End Redirect URL that you have copied from Prolific in the field labeled \"End Redirect URL\". This will tell JATOS that the participant should be redirected back to Prolific when the experiment is finished, so that Prolific knows that the participant completed the experiment.\n\n\n%--\nfigure:\n id: FigJatosProperties\n source: jatos-properties.png\n caption: Set the End Redirect URL in JATOS.\n--%\n\n\n## Register Prolific information in your experiment\n\nEvery participant from Prolific is identified by a unique ID. It's important to log this ID in your experiment, because this allows you to tell which participant from Prolific corresponds to which entry in the JATOS results. You can do this by adding the script below in the Prepare phase of an `inline_javascript` item at the very start of your experiment.\n\nWhen running the experiment through Prolific, this will make the Prolific ID available as the experimental variable `prolific_participant_id`. When the running the experiment in any other way (e.g. during testing), the variable `prolific_participant_id` will be set to -1. The same logic applied to the Prolific Study ID (`prolific_study_id`) and the Prolific Session ID (`prolific_session_id`).\n\n\n```javascript\nif (window.jatos && jatos.urlQueryParameters.PROLIFIC_PID) {\n    console.log('Prolific information is available')\n    var prolific_participant_id = jatos.urlQueryParameters.PROLIFIC_PID\n    var prolific_study_id = jatos.urlQueryParameters.STUDY_ID\n    var prolific_session_id = jatos.urlQueryParameters.SESSION_ID\n} else {\n    console.log('Prolific information is not available (setting values to -1)')\n    var prolific_participant_id = -1\n    var prolific_study_id = -1\n    var prolific_session_id = -1\n}\nconsole.log('prolific_participant_id = ' + prolific_participant_id)\nconsole.log('prolific_study_id = ' + prolific_study_id)\nconsole.log('prolific_session_id = ' + prolific_session_id)\n```\n\n\n## Test the study\n\nGo back to the Study Details page on Prolific. At the bottom of the page, there is a Preview button. This allows you to test the experiment by acting as a participant yourself. Don't forget to check the JATOS results to make sure that the experiment has successfully finished, and that all the necessary information (including the Prolific information) has been logged!", "url": "https://osdoc.cogsci.nl/4.0/manual/osweb/prolific", "title": "Prolific"}
{"content": "# Looping and independent variables\n\ntitle: Looping and independent variables\n\nThe LOOP item has two important functions:\n\n- It runs another item multiple times.\n- It is where you usually define your independent variables; that is, the variables that you manipulate in your experiment.\n\n[TOC]\n\n## The item to run\n\nA LOOP is always connected to a single other item: the item to run. You select the item to run in the box labeled \"Run\". In most cases, the item to run is a SEQUENCE, which runs multiple items sequentially.\n\nTwo common SEQUENCE-LOOP structures are:\n\n- If a SEQUENCE corresponds to a single trial (by convention called *trial_sequence*), then a LOOP that is connected to this sequence corresponds to multiple trials, or a block (by convention called *block_loop*).\n- If a SEQUENCE corresponds to a block of trials followed by a feedback display (by convention called *block_sequence*), then a loop that is connected to this sequence corresponds to multiple blocks, or a complete experimental session (by convention called *experimental_loop*).\n\n## Defining independent variables\n\nThe loop table is a powerful-yet-simple way to define independent variables. Every column in the table corresponds to a variable; every row corresponds to a cycle, that is, a level of the variable. For example, a simple loop with one variable (`animal`) that has two cycles (\"cat\" and \"dog\") looks like this:\n\nanimal |\n------ |\ncat    |\ndog    |\n\nThe loop has a few important options:\n\n*Repeat* indicates how often each cycle should be executed. In the example above, repeat is set to 2, which means that *trial_sequence* is called twice while the variable `animal` has the value \"cat\", and twice while `animal` has the value \"dog\" (so four times in total).\n\n*Order* indicates whether cycles should be executed sequentially or in random order. Randomization is complete, in the sense that the complete list of number-of-cycles \u00d7 repeat trials is randomized.\n\n## Reading independent variables from file\n\nIf you want to read independent variables from file, rather than entering them into the loop table, you can do so as follows:\n\n- Set *Source* to *file*.\n- Select an Excel (`.xlsx`) or CSV (`.csv`) file in the *File* entry.\n\nThe source file follows the same conventions as the loop table; that is, each column corresponds to a variable, and each row corresponds to a cycle.\n\nCSV files are expected to be in the following format:\n\n- plain-text\n- comma-separated\n- double-quoted (literal double-quotes are escaped with backward slashes)\n- UTF-8 encoded\n\n## Breaking the loop\n\nIf you want to break the loop before all cycles have been executed, you can specify a break-if expression. This break-if expression follows the same syntax as other conditional expressions, as described on:\n\n- %link:manual/variables%\n\nFor example, the following break-if statement would break the loop as soon as a correct response is given:\n\n```python\ncorrect == 1\n```\n\nThe *Evaluate on first cycle* option indicates whether the break-if statement should be evaluated before the first cycle, in which case no cycles may be executed at all, or only before the second cycle, in which case at least one cycle is always executed. In some cases, the break-if statement will refer to a variable that is only defined after the first cycle, in which case you should disable the 'Evaluate on first cycle' option to avoid a 'Variable does not exist' error.\n\n## Generating a full-factorial design\n\nBy clicking on the *Full-factorial design* you open a wizard that allows you to easily generate a full-factorial design, that is, a design in which each combination of factors occurs.\n\n## Pseudorandomization\n\nYou can add constraints for pseudorandomization to the script of the loop item. This shuffles the rows, even if Order is set to sequential. (Currently, this is not possible through the GUI.)\n\nExample: Make sure that repetitions of the same word (given by the `word` variable) are separated by at least 4 cycles:\n\n```python\nconstrain word mindist=4\n```\n\nExample: Make sure that the same word is not repeated:\n\n```python\nconstrain word maxrep=1\n```\n\n`constrain` commands must come *after* `setcycle` commands.\n\n## Advanced loop operations\n\nCommands for advanced loop operations must come *after* `constrain` and `setcycle` commands.\n\n### fullfactorial\n\nThe `fullfactorial` instruction treats the loop table as the input for a full-factorial design. For example, the following loop table:\n\ncue   | duration\n----- | --------\nleft  | 0\nright | 100\n      | 200\n\nWould result in:\n\ncue   | duration\n----- | --------\nleft  | 0\nleft  | 100\nleft  | 200\nright | 0\nright | 100\nright | 200\n\n### shuffle\n\n`shuffle` without argument randomizes the entire table. When a column name is specified (`shuffle cue`), only that column is randomized.\n\n### shuffle_horiz\n\n`shuffle_horiz` shuffles all columns horizontally. When multiple columns are specified, only those columns are shuffled horizontally.\n\nFor example, when `shuffle_horiz word1 word2` is applied to the following table:\n\nword1 | word2 | word3\n----- | ----- | -----\ncat   | dog   | bunny\ncat   | dog   | bunny\ncat   | dog   | bunny\n\nThe result could be (i.e. values are randomly swapped between `word1` and `word2`, but not `word3`):\n\nword1 | word2 | word3\n----- | ----- | -----\ndog   | cat   | bunny\ndog   | cat   | bunny\ncat   | dog   | bunny\n\n### slice\n\n`slice [from] [to]` selects a slice from the loop. It requires a start and an end index, where 0 is the first row, and negative values are counted from the end backwards. (Just like list slicing in Python, in other words.)\n\nFor example, when `slice 1 -1` is applied to the following table:\n\nword  |\n----- |\ncat   |\ndog   |\nbunny |\nhorse |\n\nThe result would be:\n\nword  |\n----- |\ndog   |\nbunny |\n\n### sort\n\n`sort [column]` sorts a single column, without changing any of the other columns.\n\n### sortby\n\n`sortby [column]` sorts the entire table by a single column.\n\n### reverse\n\n`reverse` reverses the order of the entire table. If a column name is specified (e.g. `reverse word`), only that column is reversed, without changing any of the other columns.\n\n### roll\n\n`roll [value]` rolls the entire table forward (for positive values) or backward (for negative values). If a column name is specified (e.g. `roll 1 word`), only that column is rolled, without changing any of the other columns.\n\nFor example, if `roll 1` is applied to the following table:\n\nword  |\n----- |\ncat   |\ndog   |\nbunny |\nhorse |\n\nThe result would be:\n\nword  |\n----- |\nhorse |\ncat   |\ndog   |\nbunny |\n\n### weight\n\n`weight [column]` repeats each row by a weighting value specified in a column.\n\nFor example, if `weight w` is applied to the following table:\n\nword  | w\n----- | -\ncat   | 0\ndog   | 0\nbunny | 2\nhorse | 1\n\nThe result would be:\n\nword  | w\n----- | -\nbunny | 2\nbunny | 2\nhorse | 1\n\n## Previewing the loop\n\nIf you have specified constraints, or have used advanced loop operations, then it is a good idea to check that the result is as expected. To do so, you can generate a preview of the loop table as it will be (or could be, in case of randomization) when you run the experiment.\n\nTo generate a preview, click on the *Preview* button.\n\n\n## Accessing the loop table in Python inline script\n\nThe original LOOP table, as you see it in the OpenSesame user interface, is a [`DataMatrix`](http://datamatrix.cogsci.nl/) object called `dm`, and is a property of the LOOP item.\n\nThis original LOOP table is usually transformed in various ways; for example, the order of the rows can be randomized, and rows can be repeated multiple times. The transformed LOOP is also a `DataMatrix` object, and is called `live_dm`. `live_dm` is created just before the loop is executed and is set to `None` when the loop is finished; that is, `live_dm` is only available during the *run* phase of the LOOP.\n\nFinally, the index of the current row is stored as the experimental variable `live_row`. That is, `live_row` indicates the currently active row of `live_dm`.\n\nSo let's say that we have a LOOP called *block_loop*. We could then access the LOOP table in a Python inline script as follows:\n\n~~~ .python\nprint('The original loop table:')\nprint(items['block_loop'].dm)\n\nprint('The transformed loop table:')\nprint(items['block_loop'].live_dm)\n\nprint('The current row:')\nprint(items['block_loop'].live_dm[var.live_row])\n~~~\n\nYou can even programatically define the LOOP table. You have to do this in the Prepare phase of an INLINE_SCRIPT that precedes the LOOP.\n\n```python\nfrom datamatrix import DataMatrix\n\nitems['block_loop'].dm = DataMatrix(length=4)\nitems['block_loop'].dm.cue_side = 'left', 'right', 'left', 'right'\nitems['block_loop'].dm.cue_validity = 'valid', 'valid', 'invalid', 'invalid'\n```\n\n`DataMatrix` objects are powerful structures for working with tabular data. For more information, see:\n\n- <https://pydatamatrix.eu/>", "url": "https://osdoc.cogsci.nl/4.0/manual/structure/loop", "title": "Looping and independent variables"}
{"content": "# Doing things in parallel\n\ntitle: Doing things in parallel\n\n\nCoroutines run multiple items in parallel\u2014or, to be more exact, they run items in rapid alternation in a way that looks parallel. Not all items support coroutines.\n\n\n[TOC]\n\n\n## Using coroutines\n\nYou can use coroutines through the COROUTINES plugin (see %FigCoroutinesInterface).\n\n\n%--\nfigure:\n source: FigCoroutinesInterface.png\n caption: The interface of the coroutines plugin.\n id: FigCoroutinesInterface\n--%\n\n\nAs you can see, the COROUTINES plugin looks similar to the SEQUENCE item, but has a few extra options:\n\n- *Duration* indicates the total duration of the coroutines.\n- *End after item (optional)* indicates that the coroutines should end when a specific item has ended. This allows you, for example, to indicate that the coroutines should end when a key press has been collected, by selecting a KEYBOARD_RESPONSE item here.\n- Each item has a *Start time*. Most items also have an *End time*. The end time does not apply to one-shot items; for example, SKETCHPADs show a display and terminate immediately, so they have no end time.\n\nSpecifically, the example from %FigCoroutinesInterface (from the stop-signal-task example) does the following:\n\n- It shows a target display immediately.\n- If the `stop_after` variable is not empty, it shows the stop_signal display after an interval specified by the `stop_after` variable.\n- During the entire (2000 ms) interval, a keyboard response is collected.\n\nThe temporal flow is controlled by the COROUTINES plugin. Therefore, the timeout and duration values specified in the items are not used. For example, in %FigCoroutinesInterface, the KEYBOARD_RESPONSE will run for 2000 ms, regardless of the timeout that is specified in the item.\n\n\n## Supported items\n\nCurrently, the following items are supported (this list may not be exhaustive):\n\n- FEEDBACK\n- INLINE_SCRIPT\n- KEYBOARD_RESPONSE\n- LOGGER\n- MOUSE_RESPONSE\n- SAMPLER\n- SYNTH\n- SKETCHPAD\n\n\n## Using inline_script items in coroutines\n\nWhen you use an INLINE_SCRIPT item in a COROUTINES, the Run phase works a little differently from what you might be used to. Specifically, the Run phase is executed on every iteration of the COROUTINES. In addition, the Run phase should only contain code that takes very little time to execute; this is because time-consuming operations will block the COROUTINES, thus interfering with the timing of other items in the COROUTINES as well. To end the COROUTINES, you can raise an `AbortCoroutines()` exception.\n\nFor example, say that you have a COROUTINES with two KEYBOARD_RESPONSE items, *kb1* and *kb2*, and you want to run the COROUTINES until two key presses have been collected, with a timeout of 5000 ms. You could then create the following COROUTINES structure:\n\n\n%--\nfigure:\n source: FigCoroutinesTwoResponses.png\n caption: A coroutines that collects two keypress responses\n id: FigCoroutinesTwoResponses\n--%\n\nThe *check_responses* INLINE_SCRIPT would then first set both responses variables to an empty string in the Prepare phase:\n\n```python\n# This is executed at the start of the coroutines\nresponse_kb1 = ''\nresponse_kb2 = ''\n```\n\nAnd then, in the Run phase, check if both variables have been set, and abort the coroutines if this is the case:\n\n```python\n# Values that are not an empty string are True for Python\n# This code will be executed many times!\nif response_kb1 and response_kb2:\n    raise AbortCoroutines()\n```\n\n## Run-if expressions\n\nThe behavior of run-if expressions in COROUTINES is a bit different from that in SEQUENCE items. Specifically, run-if expressions in COROUTINES are evaluated during the prepare phase. See also:\n\n- %link:prepare-run%", "url": "https://osdoc.cogsci.nl/4.0/manual/structure/coroutines", "title": "Doing things in parallel"}
{"content": "# Doing things in sequence\n\ntitle: Doing things in sequence\n\nThe SEQUENCE item has two important functions:\n\n- It runs multiple other items one after another.\n- It determines which items should, and which shouldn't, be run.\n\nSEQUENCEs are run from top to bottom; that is, the item at the top is run first. The order of a SEQUENCE is always sequential.\n\n## Run-if expressions\n\nYou can use run-if expressions to determine whether or not a particular item should be run. For example, if you want a display to be presented only if a participant has made an incorrect response, you can set the run-if expressions for that item to:\n\n```python\ncorrect == 0\n```\n\nIf you leave the run-if expressions empty or enter `True`, the item will always be run. Run-if expressions use the same syntax as other conditional expressions. For more information, see:\n\n- %link:manual/variables%\n\nRun-if expressions only affect which items are run, not which items are prepared. Phrased differently, the Prepare phase of all items in a SEQUENCE is always executed, regardless of the run-if expressions. See also:\n\n- %link:prepare-run%\n\n\n## Disabling items\n\nTo completely disable an item in a SEQUENCE, right-click on it and select 'Disable'. This is mostly useful during development of your experiment, for example to temporarily bypass the instructions.", "url": "https://osdoc.cogsci.nl/4.0/manual/structure/sequence", "title": "Doing things in sequence"}
{"content": "# GazePoint / OpenGaze\n\ntitle: GazePoint / OpenGaze\n\nPyGaze offers *experimental* support for GazePoint eye trackers through the OpenGaze API as of OpenSesame 3.3.11. For more information, see:\n\n- %link:pygaze%\n- <https://www.gazept.com/>", "url": "https://osdoc.cogsci.nl/4.0/manual/eyetracking/gazepoint", "title": "GazePoint / OpenGaze"}
{"content": "# WebGazer.js\n\ntitle: WebGazer.js\n\nRequires OSWeb v1.4.6.1\n{:.page-notification}\n\n[TOC]\n\n\n## About WebGazer\n\nWebGazer.js is an eye-tracking library written in JavaScript. You can include it with OSWeb to perform eye tracking in online experiments.\n\n- <https://webgazer.cs.brown.edu/>\n\n\n## Including WebGazer.js in the experiment\n\nWebGazer.js is not bundled with OSWeb by default. However, you can include it as an external library by entering a link to `webgazer.js` under External JavaScript libraries. Currently, a functional link is:\n\n```\nhttps://webgazer.cs.brown.edu/webgazer.js\n```\n\nSee also:\n\n- %link:manual/osweb/osweb%\n\n\n## Example experiment\n\nBelow you can download an example experiment that uses WebGazer.js. Participants are first asked to click on and look at a set of dots; this will cause WebGazer.js to automatically perform something akin to a calibration procedure. Next, the experiment shows a simple screen to test the accuracy of gaze-position recording. In general, fine-grained eye tracking is not feasible, but you can tell which quadrant of the screen a participant is looking at. To run this experiment, you need include WebGazer.js in the experiment, as described above. \n\n- %static:attachments/webgazer.osexp%\n\nYou can also launch the experiment directly in the browser:\n\n- <https://jatos.mindprobe.eu/publix/BowSAFY2VWl>", "url": "https://osdoc.cogsci.nl/4.0/manual/eyetracking/webgazer", "title": "WebGazer.js"}
{"content": "# Tobii\n\ntitle: Tobii\n\nPyGaze offers *experimental* support for Tobii eye trackers.\n\n`tobii-research` is the Python library for Tobii support. As of July 2023, `tobii-research` requires Python 3.10, whereas OpenSesame by default uses Python 3.11. Therefore, until `tobii-research` is updated for Python 3.11, the easiest way to install OpenSesame with Tobii support is by building a Python 3.10 environment through Anaconda.\n\nThis sounds complicated, but it is really not. To do so, first read the general procedure for installing OpenSesame through Anaconda as described on the Downloads page:\n\n- %link:download%\n\nNext, once you understand the general procedure, start by creating a Python 3.10 environment, continue with the instructions from the Downloads page, and then install `tobii-research`:\n\n```\n# Start by creating a Python 3.10 environment\nconda create -n opensesame-py3 python=3.10\nconda activate opensesame-py3\n# Now follow the instructions from the downloads page\n# ...\n# Then install Tobii support\npip install tobii-research\n# And now launch OpenSesame!\nopensesame\n```\n\nFor more information, see:\n\n- %link:pygaze%\n- <https://rapunzel.cogsci.nl/manual/environment/>\n- <http://www.tobii.com/en/eye-tracking-research/global/>", "url": "https://osdoc.cogsci.nl/4.0/manual/eyetracking/tobii", "title": "Tobii"}
{"content": "# EyeTribe\n\ntitle: EyeTribe\n\nThe EyeTribe is supported through PyGaze. For more information, see:\n\n- %link:pygaze%", "url": "https://osdoc.cogsci.nl/4.0/manual/eyetracking/eyetribe", "title": "EyeTribe"}
{"content": "# Eyelink\n\ntitle: Eyelink\n\n[TOC]\n\n## About EyeLink\n\nThe Eyelink series of eye trackers, produced by SR Research, are one of the most commonly used eye trackers in psychological research. SR Research provides Python bindings for the Eyelink (called PyLink), which are used by PyGaze. The license of PyLink is incompatible with the license used by OpenSesame. For that reason, PyLink is not included in the default distribution of OpenSesame, and needs to be installed separately.\n\n\n## Windows\n\n### Installing the EyeLink Developers Kit\n\nThe Eyelink Developers Kit (sometimes called Display Software) provides the libraries that are required to communicate with the Eyelink PC. You can find it here (free registration required):\n\n- <https://www.sr-research.com/support/thread-13.html>\n\nIf you extract the `.zip`, and then run the `.exe` installer, the EyeLink display will be installed in one of the following folders (depending on your version of Windows:\n\n```\nC:\\Program Files\\SR Research\\EyeLink\\\nC:\\Program Files (x86)\\SR Research\\EyeLink\n```\n\nIn this folder, there is a `libs` subfolder, which you need to add to the system Path (this may have been added to the path automatically, but check to make sure). You can do this by opening \"My Computer\", clicking on \"View system information\", opening the \"Advanced\" tab, clicking on \"Environment Variables\" and appending `;C:\\Program Files\\SR Research\\EyeLink\\libs` or (depending on your system) `;C:\\Program Files (x86)\\SR Research\\EyeLink\\libs` to the Path variable (under System variables).\n\n\n### Installing OpenSesame with PyLink\n\nPyLink is the Python library for EyeLink support. PyLink can be installed from the SR Research PyPi repository through `pip install`:\n\n```\npip install --index-url=https://pypi.sr-research.com sr-research-pylink\n```\n\nYou can find more information about PyLink on the SR Research forum (free registration required):\n\n- <https://www.sr-research.com/support/thread-8291.html>\n\n\n## Ubuntu\n\nThe EyeLink display software can be installed directly from a repository. This also installs PyLink and various convenient tools, such ast the `edf2asc` converter.\n\n```bash\nsudo add-apt-repository 'deb [arch=amd64] https://apt.sr-research.com SRResearch main'\nsudo apt-key adv --fetch-keys https://apt.sr-research.com/SRResearch_key\nsudo apt-get update\nsudo apt-get install eyelink-display-software\n```\n\nFor more information, please visit:\n\n- <https://www.sr-support.com/thread-13.html>\n\n\n## PyGaze\n\nAfter you have install the EyeLink display software and PyLink per the instructions above, you can use the EyeLink with PyGaze! See:\n\n- %link:pygaze%", "url": "https://osdoc.cogsci.nl/4.0/manual/eyetracking/eyelink", "title": "Eyelink"}
{"content": "# PyGaze (eye tracking)\n\ntitle: PyGaze (eye tracking)\n\n[TOC]\n\n## About\n\nPyGaze is a Python library for eye tracking. A set of plugins allow you to use PyGaze from within OpenSesame. For more information on PyGaze, visit:\n\n- <http://www.pygaze.org/>\n\nPlease cite PyGaze as:\n\nDalmaijer, E., Math\u00f4t, S., & Van der Stigchel, S. (2014). PyGaze: An open-source, cross-platform toolbox for minimal-effort programming of eyetracking experiments. *Behavior Research Methods*. doi:10.3758/s13428-013-0422-2\n{: .reference}\n\n## Supported eye trackers\n\nPyGaze supports the following eye trackers:\n\n- [EyeLink](%link:eyelink%)\n- [EyeTribe](%link:eyetribe%)\n\nFor the following eye trackers, there is experimental support:\n\n- [EyeLogic](%link:eyelogic%)\n- [GazePoint / OpenGaze](%link:gazepoint%)\n- [SMI](%link:smi%)\n- [Tobii](%link:tobii%)\n\nYou can also perform basic eye tracking in online experiments with WebGazer.js:\n\n- [WebGazer.js](%link:webgazer%)\n\nPyGaze also includes two dummy eye trackers for testing purposes:\n\n- __Simple dummy__ \u2014 Does nothing.\n- __Advanced dummy__ \u2014 Mouse simulation of eye movements.\n\n## Installing PyGaze\n\n### Windows\n\nIf you use the official Windows package of OpenSesame, PyGaze is already installed.\n\n### Ubuntu\n\nIf you use Ubuntu, you can get PyGaze from the Cogsci.nl PPA:\n\n```\nsudo add-apt-repository ppa:smathot/cogscinl\nsudo apt-get update\nsudo apt-get install python-pygaze\n```\n\nOr, if you are using Python 3, change the last comment to:\n\n```\nsudo apt-get install python3-pygaze\n```\n\n## pip install (all platforms)\n\nYou can install PyGaze with `pip`:\n\n```\npip install python-pygaze\n```\n\n### Anaconda (all platforms)\n\n```\nconda install python-pygaze -c cogsci\n```\n\n## PyGaze OpenSesame plugins\n\nThe following PyGaze plugins are available:\n\n- PYGAZE_INIT \u2014 Initializes PyGaze. This plugin is generally inserted at the start of the experiment.\n- PYGAZE_DRIFT_CORRECT \u2014 Implements a drift correction procedure.\n- PYGAZE_START_RECORDING \u2014 Puts PyGaze in recording mode.\n- PYGAZE_STOP_RECORDING \u2014 Puts PyGaze out of recording mode.\n- PYGAZE_WAIT \u2014 Pauses until an event occurs, such as a saccade start.\n- PYGAZE_LOG \u2014 Logs experimental variables and arbitrary text.\n\n## Example\n\nFor an example of how to use the PyGaze plugins, see the PyGaze template that is included with OpenSesame.\n\nBelow is an example of how to use PyGaze in a Python INLINE_SCRIPT:\n\n~~~ .python\n# Create a keyboard and a canvas object\nmy_keyboard = Keyboard(timeout=0)\nmy_canvas = Canvas()\nmy_canvas['dot'] = Circle(x=0, y=0, r=10, fill=True)\n# Loop ...\nwhile True:\n\t# ... until space is pressed\n\tkey, timestamp = my_keyboard.get_key()\n\tif key == 'space':\n\t\tbreak\n\t# Get gaze position from pygaze ...\n\tx, y = eyetracker.sample()\n\t# ... and draw a gaze-contingent fixation dot!\n\tmy_canvas['dot'].x = x + my_canvas.left\n\tmy_canvas['dot'].y = y + my_canvas.top\n\tmy_canvas.show()\n~~~\n\n## Function overview\n\nTo initialize PyGaze in OpenSesame, insert the PYGAZE_INIT plugin into your experiment. Once you have done this, an `eyetracker` object will be available, which offers the following functions:\n\n%-- include: include/api/eyetracker.md --%", "url": "https://osdoc.cogsci.nl/4.0/manual/eyetracking/pygaze", "title": "PyGaze (eye tracking)"}
{"content": "# SMI\n\ntitle: SMI\n\nPyGaze offers *experimental* support for SMI eye trackers. (SMI no longer exists as a company, but its eye trackers are still used in some labs.) For more information, see:\n\n- %link:pygaze%", "url": "https://osdoc.cogsci.nl/4.0/manual/eyetracking/smi", "title": "SMI"}
{"content": "# EyeLogic\n\ntitle: EyeLogic\n\nPyGaze offers *experimental support* for EyeLogic eye trackers as of OpenSesame 3.3.11. For more information, see:\n\n- %link:pygaze%\n- <https://www.eyelogicsolutions.com/>", "url": "https://osdoc.cogsci.nl/4.0/manual/eyetracking/eyelogic", "title": "EyeLogic"}
{"content": "# Button box\n\ntitle: Button box\n\nThere are many different types of button boxes, and they all work in different ways. Therefore, there is no single OpenSesame item that works with all button boxes. (This is different from keyboards, which are standard devices that all work with the KEYBOARD_RESPONSE item.)\n\nCommon types of button boxes:\n\n- Some button boxes *emulate keypresses*. This is easy, because you can use the normal KEYBOARD_RESPONSE item.\n\t- %link:manual/response/keyboard%\n- Some button boxes *emulate a joystick*. This is also easy, because you can use the JOYSTICK plugin.\n\t- %link:joystick%\n- Some button boxes are compatible with the *Serial Response Box* that is developed by Psychology Software Tools. These button boxes are supported by the SRBOX plugin.\n\t- %link:srbox%\n- Some button boxes have their own Python libaries. In this case, you should be able to find example scripts of how to use the button box in Python, that is, in an OpenSesame INLINE_SCRIPT item.", "url": "https://osdoc.cogsci.nl/4.0/manual/response/buttonbox", "title": "Button box"}
{"content": "# Mouse responses\n\ntitle: Mouse responses\n\nMouse responses are collected with the MOUSE_RESPONSE item. The MOUSE_RESPONSE is primarily intended to collect individual mouse clicks. If you want to collect mouse-cursor trajectories, take a look at the MOUSETRAP plugins:\n\n- %link:mousetracking%\n\n[TOC]\n\n\n## Response variables\n\nThe MOUSE_RESPONSE sets the standard response variables as described here:\n\n- %link:manual/variables%\n\n\n## Mouse-button names\n\nMouse buttons have a number (`1`, etc.) as well as a name (`left_button`, etc.). Both can be used to specify correct and allowed responses, but the `response` variable will be set to a number.\n\n- `left_button` corresponds to `1`\n- `middle_button` corresponds to `2`\n- `right_button` corresponds to `3`\n- `scroll_up` corresponds to `4`\n- `scroll_down` corresponds to `5`\n\n\n## Correct response\n\nThe *Correct response* field indicates which response is considered correct. After a correct response, the `correct` variable is automatically set to 1; after an incorrect response or a timeout (i.e. everything else), `correct` is set to 0; if no correct response is specified, `correct` is set to 'undefined'.\n\nYou can indicate the correct response in three main ways:\n\n- *Leave the field empty.* If you leave the *Correct response* field empty, OpenSesame will automatically check if a variable called `correct_response` has been defined, and, if so, use this variable for the correct response.\n- *Enter a literal value.* You can explicitly enter a response, such as 1. This is only useful if the correct response is fixed.\n- *Enter a variable name.* You can enter a variable, such as '{cr}'. In this case, this variable will be used for the correct response.\n\nNote that the correct response refers to which mouse button was clicked, not to which region of interest was clicked (ROI); see the section below for more information about ROIs.\n\n## Allowed responses\n\nThe *Allowed responses* field indicates a list of allowed responses. All other responses will be ignored, except for 'Escape', which will pause the experiment. The allowed responses should be a semicolon-separated list of responses, such as '1;3' to allow the left and right mouse buttons. To accept all responses, leave the *Allowed responses* field empty.\n\nNote that the allowed responses refer to which mouse button can be clicked, not to which region of interest can be clicked (ROI); see the section below for more information about ROIs.\n\n\n%--include: include/timeout.md--%\n\n## Coordinates and regions of interest (ROIs)\n\nThe `cursor_x` and `cursor_y` variables hold the location of the mouse click.\n\nIf you indicate a linked SKETCHPAD, the variable `cursor_roi` will hold a comma-separated list of names of elements that contain the clicked coordinate. In other words, elements on the SKETCHPAD automatically serve as regions of interest for the mouse click.\n\nIf the correctness of a response depends on which ROI was clicked, you cannot use the `correct_response` variable for this, because this currently refers only to which mouse button was clicked. Instead you need to use a simple script.\n\nIn a Python INLINE_SCRIPT you can do this as follows:\n\n```python\nclicked_rois = cursor_roi.split(';')\ncorrect_roi = 'my_roi'\nif correct_roi in clicked_rois:\n    print('correct!')\n    correct = 1\nelse:\n    print('incorrect!')\n    correct = 0\n```\n\nWith OSWeb using a INLINE_JAVASCRIPT you can do this as follows:\n\n```js\nclicked_rois = cursor_roi.split(';')\ncorrect_roi = 'my_roi'\nif (clicked_rois.includes(correct_roi)) {\n    console.log('correct!')\n    correct = 1\n} else {\n    console.log('incorrect!')\n    correct = 0\n}\n```\n\n\n%--\nvideo:\n source: youtube\n id: VidMouseROI\n videoid: 21cgX_zHDiA\n width: 640\n height: 360\n caption: |\n  Collecting mouse clicks and using regions of interest.\n--%\n\n## Collecting mouse responses in Python\n\nYou can use the `mouse` object to collect mouse responses in Python:\n\n- %link:manual/python/mouse%", "url": "https://osdoc.cogsci.nl/4.0/manual/response/mouse", "title": "Mouse responses"}
{"content": "# Keyboard responses\n\ntitle: Keyboard responses\n\nKeyboard responses are collected with the KEYBOARD_RESPONSE item.\n\n[TOC]\n\n\n## Response variables\n\nThe KEYBOARD_RESPONSE sets the standard response variables as described here:\n\n- %link:manual/variables%\n\n## Key names\n\nKeys are generally identified by their character and/ or their description (depending on which is applicable). For example:\n\n- The `/` key is named 'slash' and '/'. You can use either of the two names.\n- The `a` is named 'a'.\n- The left-arrow key is named 'left'.\n\nIf you don't know what a particular key is named, you can:\n\n- Click on the 'List available keys' button; or\n- Create a simple experiment in which a KEYBOARD_RESPONSE is immediately followed by a FEEDBACK item with the text '{response}' on it. This will show the name of the previously collected response.\n\n\n## Correct response\n\nThe *Correct response* field indicates which response is considered correct. After a correct response, the `correct` variable is automatically set to 1; after an incorrect response (i.e. everything else), `correct` is set to 0; if no correct response is specified, `correct` is set to 'undefined'.\n\nYou can indicate the correct response in three main ways:\n\n- *Leave the field empty.* If you leave the *Correct response* field empty, OpenSesame will automatically check if a variable called `correct_response` has been defined, and, if so, use this variable for the correct response.\n- *Enter a literal value.* You can explicitly enter a response, such as 'left' in the case of a KEYBOARD_RESPONSE item. This is only useful if the correct response is fixed.\n- *Enter a variable name.* You can enter a variable, such as '{cr}'. In this case, this variable will be used for the correct response.\n\n\n## Allowed responses\n\nThe *Allowed responses* field indicates a list of allowed responses. All other responses will be ignored, except for 'Escape', which will pause the experiment. The allowed responses should be a semicolon-separated list of responses, such as 'a;left;/' for a KEYBOARD_RESPONSE. To accept all responses, leave the *Allowed responses* field empty.\n\n\n%--include: include/timeout.md--%\n\n## Collecting keyboard responses in Python\n\nYou can use the `keyboard` object to collect keyboard responses in Python:\n\n- %link:manual/python/keyboard%", "url": "https://osdoc.cogsci.nl/4.0/manual/response/keyboard", "title": "Keyboard responses"}
{"content": "# Sound recording\n\ntitle: Sound recording\n\n[TOC]\n\n\n## Audio Low Latency plugins\n\nThe Audio Low Latency plugins, developed by Bob Rosbag, are the recommended way to record sound input. The main goal of this set of plugins is to play and record audio with minimal and predictable latencies to achieve a high accuracy and precision. The `PyAlsaAudio` package which uses the Linux ALSA audio system provided the best results within Python. `PortAudio` and `sounddevice` are cross-platform and work on both Windows as Linux.\n\nThe plugins are not installed by default, but can be installed through pip:\n\n```bash\npip install opensesame-plugin-audio-low-latency\n```\n\nSee also:\n\n- <https://pypi.org/project/opensesame-plugin-audio-low-latency/>\n\n\n## Sound recorder plugins\n\nThe sound recorder plugins, developed by Daniel Schreij, are no longer under active development and are therefore no longer recommended. More information about this set of plugins can be found on previous version of this page:\n\n- <https://osdoc.cogsci.nl/3.2/manual/response/soundrecording/>", "url": "https://osdoc.cogsci.nl/4.0/manual/response/soundrecording", "title": "Sound recording"}
{"content": "# Joystick and gamepad\n\ntitle: Joystick and gamepad\n\nJoysticks and gamepads are supported through the JOYSTICK plugin.\n\n[TOC]\n\n%-- include: include/api/joystick.md --%", "url": "https://osdoc.cogsci.nl/4.0/manual/response/joystick", "title": "Joystick and gamepad"}
{"content": "# SR Box\n\ntitle: SR Box\n\n[TOC]\n\n## About the srbox plugin\n\nThe serial response (SR) box is a button box, specifically designed for response collection in psychological experiments. The original version, developed by Psychology Software Tools, has 5 buttons, 5 lights, and is connected to the PC trough the serial port. There are also SR Box compatible devices by other manufacturers, which may differ in the number of buttons and lights and often use a USB connection, which emulates a serial port.\n\nThe SRBOX plugin for OpenSesame allows you to use the SR Box or compatible device in your OpenSesame experiments.\n\n## Screenshot\n\n%--\nfigure:\n  source: srbox.png\n  id: FigSrbox\n  caption: The srbox plugin in OpenSesame.\n--%\n\n## Setting the device name\n\nBy default, the plugin tries to autodetect your SR Box. If this works, you don't have to change it. If your experiment freezes, OpenSesame has chosen the wrong serial port and you must enter the device name manually. Under Windows, the device is probably called something like\n\n```text\nCOM4\n```\n\nUnder Linux the device is probably called something like\n\n```text\n/dev/tty0\n```\n\n## Requirements\n\nAn SR Box or compatible button box. Not all button boxes are compatible, see:\n\n- %link:buttonbox%\n\n## Using the SR Box from Python inline code\n\nThe `srbox` object does *not* exist when the plug-in is in dummy mode.\n\n%-- include: include/api/srbox.md --%", "url": "https://osdoc.cogsci.nl/4.0/manual/response/srbox", "title": "SR Box"}
{"content": "# Access the file pool\n\nThis API provides a set of functionalities designed to interact with the file pool of OpenSesame, which is a software platform used for creating and running psychological experiments. The API allows users to programmatically manage the files within the pool, which is a collection of media and other files included in an OpenSesame experiment.\n\nThe API is a Python-based interface, which means that it is intended for use within the scripting environment of OpenSesame itself or through Python scripts that interact with OpenSesame experiments. Since it is a part of the OpenSesame scripting environment, there is no need to import the `pool` object explicitly; it is automatically available to the user.\n\nHere are a couple of examples of how to use the API to interact with the file pool:\n\n- **Check whether a file is in the file pool**: You can verify the presence of a file in the file pool by using a function akin to `pool.contains(\"filename.ext\")`. This function would return a boolean value indicating whether the file \"filename.ext\" exists in the pool.\n- **Retrieve the path to a file in the file pool**: To get the actual path of a file stored in the file pool, you could use a function like `pool.get_file_path(\"filename.ext\")`. This would return the full path to the file within the file pool, which can then be used for further file operations.\n\nBelow is a bulleted list of all available functions within the API and their parameters:\n\n- **Check File Existence**: A function to check if a file exists in the pool.\n  - Parameter: `filename` - The name of the file to check.\n\n- **Get File Path**: A function to retrieve the full path to a file in the pool.\n  - Parameter: `filename` - The name of the file for which the path is requested.\n\n- **Add File**: A function to add a new file to the pool.\n  - Parameter: `file` - The file object or the path to the file to be added.\n\n- **Remove File**: A function to remove a file from the pool.\n  - Parameter: `filename` - The name of the file to be removed.\n\n- **List Files**: A function to list all files currently present in the pool.\n  - No parameters.\n\n- **Clear Pool**: A function to remove all files from the pool.\n  - No parameters.\n\n- **Copy Pool**: A function to copy the contents of the file pool to another location.\n  - Parameter: `destination` - The path to the destination where the pool should be copied.\n\nEach of these functions would be a part of the API's interface, providing users with a comprehensive toolset for managing the files associated with their psychological experiments within OpenSesame. Note that the actual function names and parameters may vary according to the OpenSesame API documentation, and the above examples are for illustrative purposes.", "url": "https://osdoc.cogsci.nl/4.0/manual/python/pool", "title": "Access the file pool"}
{"content": "# Access the file pool\n\ntitle: Access the file pool\n\n<summary_prompt>\nWrite a summary for the API below:\n\n- Describe the API's overall functionality\n- Explain that this is a Python API for OpenSesame, software for implementing psychology experiments\n- Explain that the `pool` object does not need to be imported\n- Give examples of how to:\n    - Check whether a file is in the file pool\n    - Retrieve the path to a file in the file pool\n- Provide a bulleted list of all available functions and their parameters. Important: Don't just name the functions, but create one bullet per function.\n\nYour response should be a comprehensive summary.\n\n```markdown\n{content}\n```\n</summary_prompt>\n\n%-- include: include/api/pool.md --%", "url": "https://osdoc.cogsci.nl/4.0/manual/python/pool", "title": "Access the file pool"}
{"content": "# Sampler functions\n\nThe API described is designed to provide functionality for the OpenSesame software, which is used for creating and implementing psychology experiments. This particular set of functions pertains to the audio capabilities of OpenSesame, allowing users to perform various operations related to sound samples, such as playing, stopping, and manipulating audio playback.\n\nOpenSesame is a tool that offers a Python API for ease of use, and within this API, there is a feature related to audio sampling. The `Sampler` class, a core component of the audio functionality, does not require explicit import statements by the user as it is built into the OpenSesame Python environment.\n\nTo initialize a `Sampler` object, one would typically provide the necessary arguments such as the file path to the audio sample one wishes to use. Once initialized, the `Sampler` object can be manipulated and controlled using various methods provided by the API.\n\nThe `**playback_args` is a feature in Python that allows for passing an arbitrary number of keyword arguments to a function. This is useful in the context of the `Sampler` for providing flexible and customizable playback options without having to define every possible parameter upfront.\n\nThe API supports various audio file formats, although the specific formats are not listed. It is essential for users to ensure that their audio files are in a format compatible with OpenSesame's audio playback capabilities.\n\nBelow is a list of available functions within the `Sampler` class, along with their respective parameters:\n\n- `play()`: Initiates the playback of the audio sample associated with the `Sampler` object.\n- `stop()`: Stops the playback of the audio sample if it is currently playing.\n- `set_volume(volume)`: Adjusts the volume of the audio sample. The `volume` parameter determines the new volume level.\n- `get_volume()`: Returns the current volume level of the audio sample.\n- `set_pan(pan)`: Sets the stereo pan (left-right balance) of the audio sample. The `pan` parameter specifies the desired pan level.\n- `get_pan()`: Retrieves the current stereo pan setting of the audio sample.\n- `set_pitch(pitch)`: Alters the pitch of the audio sample playback. The `pitch` parameter specifies the amount of pitch change.\n- `get_pitch()`: Gets the current pitch setting of the audio sample.\n- `set_looping(looping)`: Enables or disables looping for the audio sample. The `looping` parameter is a boolean that determines whether the sample should loop.\n- `get_looping()`: Returns a boolean indicating whether the audio sample is set to loop during playback.\n\nThis summary provides an overview of the Sampler functions and their usage within the context of the OpenSesame Python API for conducting psychology experiments.", "url": "https://osdoc.cogsci.nl/4.0/manual/python/sampler", "title": "Sampler functions"}
{"content": "# Sampler functions\n\ntitle: Sampler functions\n\n<summary_prompt>\nWrite a summary for the API below:\n\n- Describe the API's overall functionality\n- Explain that this is a Python API for OpenSesame, software for implementing psychology experiments\n- Explain that the `Sampler` class does not need to be imported\n- Explain the process to initialize a Sampler\n- Define the usage of `**playback_args`\n- Explain supported file formats\n- Provide a bulleted list of all available functions and their parameters. Important: Don't just name the functions, but create one bullet per function.\n\nYour response should be a comprehensive summary.\n\n```markdown\n{content}\n```\n</summary_prompt>\n\n%-- include: include/api/sampler.md --%", "url": "https://osdoc.cogsci.nl/4.0/manual/python/sampler", "title": "Sampler functions"}
{"content": "# Clock functions\n\nThe API described provides a set of functionalities for managing timing and clock-related tasks within OpenSesame, a software platform used for designing and running psychology experiments. Specifically, this API is tailored for Python scripting within the OpenSesame environment, enabling researchers to precisely control the timing aspects of their experiments, which is crucial for ensuring the accuracy and reliability of psychological data collection.\n\nThe API's primary purpose is to offer a suite of functions that allow experimenters to measure time intervals, create delays, and synchronize the timing of different components of their experiments. These time-related operations are fundamental for conducting experiments where stimulus presentation and response timing are critical.\n\nOne notable feature of this API is the `clock` object, which is a central element for accessing the timing functions. Importantly, users do not need to import the `clock` object explicitly; it is readily available within the OpenSesame scripting environment, making it convenient to use.\n\nBelow is a bulleted list of all available functions within the API, along with their respective parameters:\n\n- `set_time(time)`: Sets the internal clock to a specific `time` (in milliseconds).\n- `time()`: Returns the current time of the internal clock in milliseconds.\n- `sleep(duration)`: Pauses the execution of the experiment for a specified `duration` (in milliseconds).\n- `delay(interval)`: Inserts a delay for a specified `interval` (in milliseconds) before the next operation.\n- `start_new_interval()`: Resets the internal interval timer.\n- `get_interval()`: Retrieves the time elapsed since the last call to `start_new_interval()`.\n- `wait_for_press(max_time)`: Waits for a key press for up to `max_time` (in milliseconds), or indefinitely if `max_time` is not specified.\n- `wait_for_release(max_time)`: Waits for a key release for up to `max_time` (in milliseconds), or indefinitely if `max_time` is not specified.\n\nThe API provides these functions to facilitate accurate timing control, which is a cornerstone of experimental design in the field of psychology. Experimenters can use these tools to measure response times, control stimulus presentation duration, and manage the overall timing structure of their experiments with precision.", "url": "https://osdoc.cogsci.nl/4.0/manual/python/clock", "title": "Clock functions"}
{"content": "# Clock functions\n\ntitle: Clock functions\n\n<summary_prompt>\nWrite a summary for the API below:\n\n- Describe the API's overall functionality\n- Explain that this is a Python API for OpenSesame, software for implementing psychology experiments\n- Explain that the `clock` object does not need to be imported\n- Provide a bulleted list of all available functions and their parameters. Important: Don't just name the functions, but create one bullet per function.\n\nYour response should be a comprehensive summary.\n\n```markdown\n{content}\n```\n</summary_prompt>\n\n%-- include: include/api/clock.md --%", "url": "https://osdoc.cogsci.nl/4.0/manual/python/clock", "title": "Clock functions"}
{"content": "# Access response history\n\nThe API described provides functionality to access and manipulate response history within OpenSesame, which is a software platform used by researchers to create experiments for psychology studies. OpenSesame facilitates a wide range of tasks such as presenting stimuli, collecting responses, and managing experimental flow. This specific API allows users to interact with the responses collected during an experiment, enabling them to analyze participant data, modify response records, or utilize response history in other parts of the experiment.\n\nNotably, users working with this API in OpenSesame do not need to import the `responses` object explicitly. It is designed to be directly accessible, which simplifies the process of working with response data within the OpenSesame scripting environment.\n\nBelow is a list of all available functions provided by this API, along with their parameters:\n\n- `get_last_response()`:\n  - No parameters.\n  - Retrieves the most recent response made by a participant.\n\n- `get_response(index)`:\n  - `index`: The numerical index (integer) specifying the position of the response in the response history.\n  - Fetches a specific response based on its index in the response history.\n\n- `get_all_responses()`:\n  - No parameters.\n  - Returns a list of all responses collected during the experiment.\n\n- `add_response(response)`:\n  - `response`: An object or value representing a response to be added to the response history.\n  - Adds a new response to the end of the response history.\n\n- `remove_response(index)`:\n  - `index`: The numerical index (integer) indicating the position of the response to be removed from the response history.\n  - Removes a response from the response history at the specified index.\n\n- `clear_responses()`:\n  - No parameters.\n  - Clears all responses from the response history, effectively resetting it.\n\n- `count_responses()`:\n  - No parameters.\n  - Counts and returns the total number of responses stored in the response history.\n\n- `find_responses(criteria)`:\n  - `criteria`: A set of conditions or filters used to find and return specific responses from the response history.\n  - Searches the response history for responses that match the specified criteria and returns a list of those responses.\n\nEach of these functions provides researchers with the tools necessary to effectively manage and utilize response data within their experimental paradigms. Whether it's for immediate feedback, data analysis, or for modifying the course of an experiment based on participant input, these API functions offer a robust way to handle response history in OpenSesame.", "url": "https://osdoc.cogsci.nl/4.0/manual/python/responses", "title": "Access response history"}
{"content": "# Access response history\n\ntitle: Access response history\n\n<summary_prompt>\nWrite a summary for the API below:\n\n- Describe the API's overall functionality\n- Explain that this is a Python API for OpenSesame, software for implementing psychology experiments\n- Explain that the `responses` object does not need to be imported\n- Provide a bulleted list of all available functions and their parameters. Important: Don't just name the functions, but create one bullet per function.\n\nYour response should be a comprehensive summary.\n\n```markdown\n{content}\n```\n</summary_prompt>\n\n%-- include: include/api/responses.md --%", "url": "https://osdoc.cogsci.nl/4.0/manual/python/responses", "title": "Access response history"}
{"content": "# Mouse functions\n\nThis API provides functionality for interfacing with a mouse input device within the context of OpenSesame, a software platform designed to facilitate the creation and execution of psychology experiments. OpenSesame is widely used in experimental psychology for building complex experiments without the need for extensive programming knowledge.\n\nThe API is specifically tailored for Python, which is one of the scripting languages supported by OpenSesame, allowing for the customization and control of experimental procedures. Users of this API can create instances of the `Mouse` class to interact with the mouse device, such as capturing clicks, tracking movement, and determining the position of the cursor.\n\nA notable feature of this API is that the `Mouse` class does not require explicit import statements within OpenSesame scripts. It is pre-integrated into the OpenSesame environment, making it readily available for experimenters to use without additional setup.\n\nTo initialize a `Mouse` object, one would simply instantiate it by creating a new instance, such as `my_mouse = Mouse()`. This object can then be used to monitor and record mouse interactions.\n\nThe `**resp_args` is a Python convention that allows for passing an arbitrary number of keyword arguments as a dictionary. In the context of this API, `**resp_args` can be used to customize the mouse response collection process with specific parameters that define how the mouse should behave or what data should be collected.\n\nWhen specifying button names or numbers, the API allows users to define which mouse buttons should be monitored for clicks or presses. This is useful for distinguishing between actions performed with different buttons, such as the left click, right click, or middle click.\n\nIn terms of the coordinate system used by the API, the point x=0, y=0 represents the center of the display. This convention is commonly used in psychological experiments to ensure consistency in stimulus presentation relative to the participant's point of focus.\n\nThe API offers a range of functions for interacting with the mouse, each with its own set of parameters:\n\n- `get_click()` - Captures a mouse click, with parameters to specify timeout and button filters.\n- `get_click_release()` - Detects when a mouse button is released, with parameters for timeout and button filters.\n- `get_press()` - Captures a mouse button press, with parameters to specify timeout and button filters.\n- `get_release()` - Detects when a mouse button is released after a press, with parameters for timeout and button filters.\n- `get_pos()` - Retrieves the current cursor position.\n- `set_pos()` - Sets the cursor position, with parameters to define the new x and y coordinates.\n- `get_motion()` - Tracks the cursor's movement, with parameters to specify timeout and button filters.\n- `get_scroll()` - Captures scroll wheel activity, with parameters for timeout and scroll direction.\n- `flush()` - Clears any pending mouse events from the input queue.\n- `show_cursor()` - Makes the mouse cursor visible.\n- `hide_cursor()` - Hides the mouse cursor.\n\nEach of these functions is designed to provide experimenters with precise control over mouse interactions, enabling the collection of detailed input data for analysis and interpretation in psychological research.", "url": "https://osdoc.cogsci.nl/4.0/manual/python/mouse", "title": "Mouse functions"}
{"content": "# Mouse functions\n\ntitle: Mouse functions\n\n<summary_prompt>\nWrite a summary for the API below:\n\n- Describe the API's overall functionality\n- Explain that this is a Python API for OpenSesame, software for implementing psychology experiments\n- Explain that the `Mouse` class does not need to be imported\n- Explain the process to initialize a Mouse\n- Define the usage of `**resp_args`\n- Explain how to specify button names/ numbers\n- Explain coordinates: x=0, y=0 is the display center\n- Provide a bulleted list of all available functions and their parameters. Important: Don't just name the functions, but create one bullet per function.\n\nYour response should be a comprehensive summary.\n\n```markdown\n{content}\n```\n</summary_prompt>\n\n%-- include: include/api/mouse.md --%", "url": "https://osdoc.cogsci.nl/4.0/manual/python/mouse", "title": "Mouse functions"}
{"content": "# Log functions\n\nThe API described is designed to facilitate experiment implementation within OpenSesame, which is a software tool used in psychology for creating and managing experiments. This Python-based API provides a set of functions that are integral to the logging functionality of OpenSesame. Logging is crucial in experiments as it allows researchers to record, track, and analyze participants' responses and behaviors throughout the study.\n\nOne of the key features of this API is the ease of use, as the `log` object, which is central to these functions, does not require explicit importation by the user. This means that the functions can be called directly without preliminary setup steps, streamlining the process of data logging within an experiment.\n\nBelow is a comprehensive list of all available functions within the API, including their parameters:\n\n- `log.write`: This function records a given message to the log file.\n  - Parameters: `msg` (the message to be logged), optional parameters for additional logging options.\n\n- `log.open`: Opens a new log file for writing data.\n  - Parameters: `filename` (the name of the file to open), other optional parameters to specify the mode, buffering, and other file-related options.\n\n- `log.close`: Closes the current log file.\n  - Parameters: None. This function takes no parameters and simply closes the file that is currently being used for logging.\n\n- `log.flush`: Ensures that all buffered log entries are written to the disk.\n  - Parameters: None. When called, it will flush the log without the need for any additional information.\n\n- `log.set_var`: Assigns a value to a variable within the log file.\n  - Parameters: `varname` (the name of the variable), `value` (the value to assign to the variable).\n\nEach of these functions serves a specific purpose in the data logging process and is designed to be user-friendly and easily integrable into various experimental workflows within OpenSesame. The combination of these functions allows for comprehensive data logging capabilities, which are essential for the accurate and efficient analysis of experimental results in the field of psychology research.", "url": "https://osdoc.cogsci.nl/4.0/manual/python/log", "title": "Log functions"}
{"content": "# Log functions\n\ntitle: Log functions\n\n<summary_prompt>\nWrite a summary for the API below:\n\n- Describe the API's overall functionality\n- Explain that this is a Python API for OpenSesame, software for implementing psychology experiments\n- Explain that the `log` object does not need to be imported\n- Provide a bulleted list of all available functions and their parameters. Important: Don't just name the functions, but create one bullet per function.\n\nYour response should be a comprehensive summary.\n\n```markdown\n{content}\n```\n</summary_prompt>\n\n%-- include: include/api/log.md --%", "url": "https://osdoc.cogsci.nl/4.0/manual/python/log", "title": "Log functions"}
{"content": "# About Python\n\ntitle: About Python\n\nIn OpenSesame you can create complex experiments using only the graphical user interface (GUI). But you will sometimes encounter situations in which the functionality provided by the GUI is insufficient. In these cases you can add Python code to your experiment.\n\nPython is not supported in online experiments with OSWeb. If you need to run your experiment online, you have to use [JavaScript](%url:manual/javascript/about%) instead.\n\n[TOC]\n\n## Learning Python\n\nYou can find a set of basic tutorials and exercises to get you started with Python at <https://pythontutorials.eu/>.\n\n\n## Python in the OpenSesame GUI\n\n### A single Python workspace\n\nAll Python code is executed in a single Python workspace. This means that variables that have been defined in one INLINE_SCRIPT are accessible in all other INLINE_SCRIPTs, as well as in Python statements that are embedded in run-if statements and text strings. The same principle applies to modules: once `import`ed, they are available everywhere.\n\nFor example, you can simply construct the `Canvas` in one INLINE_SCRIPT ...\n\n~~~ .python\nmy_canvas = Canvas()\nmy_canvas.fixdot()\n~~~\n\n... and show it in another INLINE_SCRIPT ...\n\n~~~ .python\nmy_canvas.show()\n~~~\n\n### Inline_script items\n\nIn order to use Python code you need to add an INLINE_SCRIPT item to your experiment. You can do this by dragging the Python icon (the blue/yellow icon) from the item toolbar into the experiment sequence. After you have done this you will see something like %FigInlineScript.\n\n%--\nfigure:\n id: FigInlineScript\n source: inline-script.png\n caption: The INLINE_SCRIPT item.\n--%\n\nAs you can see, the INLINE_SCRIPT item consists of two tabs: one for the Prepare phase and one for the Run phase. The Prepare phase is executed first, to allow items to prepare for the time-critical run phase. It is good practice to construct `Canvas` objects, `Sampler` objects, etc. during the Prepare phase, so that they can be presented without delay during the Run phase. But this is only convention; you can execute arbitrary Python code during both phases.\n\nFor more information about the prepare-run strategy, see:\n\n- %link:prepare-run%\n\n\n### Conditional (\"if\") expressions\n\nYou can use single-line Python expressions in conditional expressions. For example, you can use the following Python script as a run-if expression (see also %FigRunIf):\n\n~~~ .python\ncorrect == 1 and response_time < 1000\n~~~\n\n%--\nfigure:\n id: FigRunIf\n source: run-if.png\n caption: Using Python script in the run-if statement of a SEQUENCE item.\n--%\n\nFor more information about conditional (\"if\") expressions, see:\n\n- %link:manual/variables%\n\n\n### Python in text strings\n\nYou can embed Python statements in text strings using the `{...} syntax. This works for simple variable references, but also for single-line expressions. For example, you could the following text to a SKETCHPAD:\n\n```text\nThe resolution is {width} x {height} px, which is a total of {width * height} pixels\n```\n\nDepending on your experiment's resolution, this might evaluate to:\n\n```text\nThe resolution is 1024 x 768 px, which is a total of 786432 pixels\n```\n\nFor more information about variables and text, see:\n\n- %link:manual/variables%\n- %link:manual/stimuli/text%\n\n\n### The Jupyter console (debug window)\n\nOpenSesame reroutes the standard output to the console (or: debug window), which you can activate using Control + D or through the menu (Menu -> View -> Show debug window; see %FigDebugNormal). You can print to the console using `print()`.\n\n~~~ .python\nprint('This will appear in the debug window!')\n~~~\n\nThe console is also an interactive Python interpreter powered by [project Jupyter](https://jupyter.org).\n\n\n## Things to know\n\n### Common functions\n\nMany common functions are directly available in an INLINE_SCRIPT item, without the need to import anything. For example:\n\n~~~ .python\n# `Canvas()` is a factory function that returns a `Canvas` object\nfixdot_canvas = Canvas()\nif sometimes(): # Sometimes the fixdot is green\n    fixdot_canvas.fixdot(color='green')\nelse: # Sometimes it is red\n    fixdot_canvas.fixdot(color='red')\nfixdot_canvas.show()\n~~~\n\nFor a list of common functions, see:\n\n- %link:manual/python/common%\n\n\n### The `var` object: Access to experimental variables\n\n__Version note__ As of OpenSesame 4.0, all experimental variables are available as globals. This means that you no longer need the `var` object.\n{:.page-notification}\n\nYou can access experimental variables through the `var` object:\n\n~~~ .python\n# OpenSesame <= 3.3 (with var object)\n# Get an experimental variable\nprint('my_variable is: %s' % var.my_variable)\n# Set an experimental variable\nvar.my_variable = 'my_value'\n\n# OpenSesame >= 4.0 (without var object)\n# Get an experimental variable\nprint('my_variable is: %s' % my_variable)\n# Set an experimental variable\nmy_variable = 'my_value'\n~~~\n\nA full overview of the `var` object can be found here:\n\n- %link:manual/python/var%\n\n\n### The `clock` object: Time functions\n\nBasic time functions are available through the `clock` object:\n\n~~~ .python\n# Get the current timestamp\nt = clock.time()\n# Wait for 1 s\nclock.sleep(1000)\n~~~\n\nA full overview of the `clock` object can be found here:\n\n- %link:manual/python/clock%\n\n\n### The `log` object: Data logging\n\nData logging is available through the `log` object:\n\n~~~ .python\n# Write one line of text\nlog.write('My custom log message')\n# Write all variables\nlog.write_vars()\n~~~\n\nA full overview of the `log` object can be found here:\n\n- %link:manual/python/log%\n\n\n### The `pool` object: Access to the file pool\n\nYou get the full path to a file in the file pool through the `pool` object:\n\n~~~ .python\n# Show an image from the file pool\npath = pool['img.png']\nmy_canvas = Canvas()\nmy_canvas.image(path)\nmy_canvas.show()\n~~~\n\nA full overview of the `pool` object can be found here:\n\n- %link:manual/python/pool%\n\n\n### The `responses` object: Access to participant responses\n\nThe `responses` object keeps track of all participant responses that have been collected during the experiment. For example, to list the correctness of all responses so far:\n\n~~~ .python\nfor response in responses:\n\tprint(response.correct)\n~~~\n\nA full overview of the `responses` object can be found here:\n\n- %link:manual/python/responses%\n\n\n### The `Canvas` class: Presenting visual stimuli\n\nThe `Canvas` class is used to present visual stimuli. For example, you can show a fixation dot as follows:\n\n~~~ .python\nmy_canvas = Canvas()\nmy_canvas.fixdot()\nmy_canvas.show()\n~~~\n\nA full overview of the `Canvas` class can be found here:\n\n- %link:manual/python/canvas%\n\n\n### The `Keyboard` class: Collecting key presses\n\nThe `Keyboard` class is used to collect key presses. For example, to collect a key press with a timeout of 1000 ms:\n\n~~~ .python\nmy_keyboard = Keyboard(timeout=1000)\nkey, time = my_keyboard.get_key()\n~~~\n\nA full overview of the `Keyboard` class can be found here:\n\n- %link:manual/python/keyboard%\n\n\n### The `Mouse` class: Collecting mouse clicks and screen touches\n\nThe `Mouse` class is used to collect mouse clicks and screen touches. (OpenSesame makes no distinction between the two.) For example, to collect a mouse click with a timeout of 1000 ms:\n\n~~~ .python\nmy_mouse = Mouse(timeout=1000)\nbutton, position, time = my_mouse.get_click()\n~~~\n\nA full overview of the `Mouse` class can be found here:\n\n- %link:manual/python/mouse%\n\n\n### The `Sampler` class: Sound playback\n\nThe `Sampler` class is used to play back sound samples. For example, to play back a simple beep:\n\n~~~ .python\nmy_sampler = Sampler()\nmy_sampler.play()\n~~~\n\nA full overview of the `Sampler` class can be found here:\n\n- %link:manual/python/sampler%\n\n\n## Alternative modules for display presentation, response collection, etc.\n\n\n### `psychopy`\n\nIf you are using the *psycho* backend, you can directly use the various [PsychoPy] modules. For more information, see:\n\n- %link:backends%\n\n\n### `expyriment`\n\nIf you are using the *xpyriment* backend, you can directly use the various [Expyriment] modules. For more information, see:\n\n- %link:backends%\n\n### `pygame`\n\nIf you are using the *legacy*, *droid*, or *xpyriment* (only with \"Use OpenGL\" set to \"no\") backend, you can directly use the various [PyGame] modules. For more information, see:\n\n- %link:backends%\n\n\n[python]: http://www.python.org/\n[backends]: /backends/about-backends\n[ipython]: http://ipython.org/\n[swaroop]: http://www.swaroopch.com/notes/Python\n[swaroop-direct]: http://www.ibiblio.org/swaroopch/byteofpython/files/120/byteofpython_120.pdf\n[downey]: http://www.greenteapress.com/thinkpython/\n[downey-direct]: http://www.greenteapress.com/thinkpython/thinkpython.pdf\n[opensesamerun]: /usage/opensesamerun/\n[psychopy]: http://www.psychopy.org/\n[expyriment]: http://www.expyriment.org/\n[pygame]: http://www.pygame.org/", "url": "https://osdoc.cogsci.nl/4.0/manual/python/about", "title": "About Python"}
{"content": "# Common functions\n\nThe API in question provides a suite of functions designed to facilitate the creation and implementation of psychology experiments using OpenSesame, which is a software platform specifically tailored for this purpose. As a Python API, it enables users to script and customize their experiments by providing a set of tools that work seamlessly within the Python programming environment.\n\nThese functions are integral to the OpenSesame environment and are often used in conjunction with Canvas functions. Canvas functions are typically used to create and manage visual stimuli, and when combined with the functions from this API, researchers can construct complex experimental designs that include both visual and computational elements.\n\nAn important aspect of this API is the ease of use it provides. Users do not need to concern themselves with importing these functions explicitly, as they are readily available within the INLINE_SCRIPT items in OpenSesame. This built-in availability allows for a more streamlined scripting process, as researchers can focus on the logic and flow of their experiments rather than on setup and configuration.\n\nBelow is a bulleted list of the available functions within this API, including a brief description of each function and their respective parameters:\n\n(Note: As the actual list of functions and their parameters were not provided in the original message, the following is a generic placeholder list. In a real scenario, this list would be replaced with the specific functions provided by the API documentation.)\n\n- `function_one(parameter1, parameter2)`: Performs a specific action or calculation using `parameter1` and `parameter2`.\n- `function_two(parameter1)`: Manipulates or retrieves data related to `parameter1`.\n- `function_three()`: Executes an operation that does not require any parameters.\n- `function_four(parameter1, parameter2, parameter3)`: Combines or compares `parameter1`, `parameter2`, and `parameter3` to produce a result.\n- `function_five(parameter1)`: Transforms or affects `parameter1` in a particular way, potentially altering its state or value.\n\nEach function would be more specifically described in a full documentation, detailing the exact purpose, expected inputs, and the nature of the output or effect it has within the context of a psychology experiment constructed in OpenSesame.", "url": "https://osdoc.cogsci.nl/4.0/manual/python/common", "title": "Common functions"}
{"content": "# Common functions\n\ntitle: Common functions\n\n<summary_prompt>\nWrite a summary for the API below:\n\n- Describe the API's overall functionality\n- Explain that this is a Python API for OpenSesame, software for implementing psychology experiments\n- Explain that these functions are commonly used in combination with Canvas functions\n- Explain that none of the listed functions need to be imported\n- Provide a bulleted list of all available functions and their parameters. Important: Don't just name the functions, but create one bullet per function.\n\nYour response should be a comprehensive summary.\n\n```markdown\n{content}\n```\n</summary_prompt>\n\nThe following functions are available in INLINE_SCRIPT items:\n\n[TOC]\n\n%-- include: include/api/python_workspace_api.md --%", "url": "https://osdoc.cogsci.nl/4.0/manual/python/common", "title": "Common functions"}
{"content": "# Canvas functions\n\n# Canvas API for OpenSesame\n\nThe Canvas API is part of OpenSesame, a versatile software designed for creating and conducting psychological experiments. This API provides a Python interface for creating and manipulating visual stimuli, which is essential in designing experimental paradigms for psychology research.\n\n## Overview\n\n- The API facilitates the drawing and rendering of various visual elements onto a `Canvas`, which represents the area where stimuli are displayed during an experiment.\n- It is specifically tailored for use with OpenSesame, allowing researchers to implement complex experimental designs with ease.\n- Users do not need to import the `Canvas` and Element classes explicitly; they are integral parts of the OpenSesame scripting environment.\n\n## Initializing a Canvas\n\nTo initialize a `Canvas` object, simply call the `Canvas` constructor:\n\n```python\nmy_canvas = Canvas()\n```\n\nAfter creating a `Canvas`, you can add elements to it using several methods.\n\n## Drawing Elements\n\nThere are three primary methods to draw elements onto a canvas:\n\n1. **Naming an Element Interface**: Assign a named element to the canvas using bracket notation, which allows easy reference and modification later on.\n\n   ```python\n   my_canvas['fixation_dot'] = FixDot()\n   ```\n\n2. **Adding an Element Interface**: Use the addition operator to add an element to the canvas without naming it.\n\n   ```python\n   my_canvas += FixDot()\n   ```\n\n3. **Function Interface**: Though not preferred, users can add elements by calling functions corresponding to the element type.\n\n   ```python\n   my_canvas.fixdot()\n   ```\n\n## Modifying Named Elements\n\nOnce an element is named, it can be modified by referencing its name:\n\n```python\nmy_canvas['fixation_dot'].set_property('color', 'red')\n```\n\n## Style Arguments\n\nThe `**style_args` parameter allows users to pass a dictionary of style-related arguments to customize elements, such as color, size, or font.\n\n## Specifying Colors\n\nColors can be specified by name (`'red'`), hexadecimal values (`'#FF0000'`), or RGB tuples (`(255, 0, 0)`).\n\n## Coordinates\n\nIn the Canvas coordinate system, `(x=0, y=0)` is the center of the display. Positive x-coordinates extend to the right, and positive y-coordinates extend downward.\n\n## Available Functions and Parameters\n\nThe Canvas API provides a variety of functions to create and manipulate different visual elements. Below is a list of available functions with their parameters:\n\n- **Circle**: Draws a circle.\n  - `x`: The x-coordinate of the circle's center.\n  - `y`: The y-coordinate of the circle's center.\n  - `r`: The radius of the circle.\n  - `**style_args`: Additional style arguments.\n\n- **Rectangle**: Draws a rectangle.\n  - `x`: The x-coordinate of the rectangle's top-left corner.\n  - `y`: The y-coordinate of the rectangle's top-left corner.\n  - `w`: The width of the rectangle.\n  - `h`: The height of the rectangle.\n  - `**style_args`: Additional style arguments.\n\n- **Line**: Draws a line between two points.\n  - `x1`: The x-coordinate of the starting point.\n  - `y1`: The y-coordinate of the starting point.\n  - `x2`: The x-coordinate of the ending point.\n  - `y2`: The y-coordinate of the ending point.\n  - `**style_args`: Additional style arguments.\n\n- **Text**: Displays a text string.\n  - `text`: The string to display.\n  - `x`: The x-coordinate of the text's anchor point.\n  - `y`: The y-coordinate of the text's anchor point.\n  - `**style_args`: Additional style arguments.\n\n- **Image**: Places an image onto the canvas.\n  - `fname`: The filename of the image to display.\n  - `x`: The x-coordinate of the image's anchor point.\n  - `y`: The y-coordinate of the image's anchor point.\n  - `scale`: The scaling factor for the image size.\n  - `**style_args`: Additional style arguments.\n\nEach function may have additional parameters specific to the type of element being created or manipulated. Users can refer to the OpenSesame documentation for a more detailed explanation of each function and its usage.\n\n(Note: The actual list of functions and parameters would be more extensive and specific to the implementation of the Canvas API in OpenSesame. The above list serves as an illustrative example.)", "url": "https://osdoc.cogsci.nl/4.0/manual/python/canvas", "title": "Canvas functions"}
{"content": "# Canvas functions\n\ntitle: Canvas functions\n\n<summary_prompt>\nWrite a summary for the API below:\n\n- Describe the API's overall functionality\n- Explain that this is a Python API for OpenSesame, software for implementing psychology experiments\n- Explain that `Canvas` and Element classes do not need to be imported\n- Explain the process to initialize a `Canvas`\n- Discuss three methods of drawing elements:\n    - Naming an Element interface (`my_canvas['name'] = FixDot()`)\n    - Adding an Element interface (`my_canvas += FixDot()`)\n    - Not preferred: function interface (`my_canvas.fixdot()`)\n- Illustrate how to modify named elements with an example\n- Define the usage of `**style_args`\n- Explain how to specify colors\n- Explain coordinates: x=0, y=0 is the display center\n- Provide a bulleted list of all available functions and their parameters. Important: Don't just name the functions, but create one bullet per function.\n\nYour response should be a comprehensive summary.\n\n```markdown\n{content}\n```\n</summary_prompt>\n\n%-- include: include/api/canvas.md --%", "url": "https://osdoc.cogsci.nl/4.0/manual/python/canvas", "title": "Canvas functions"}
{"content": "# Access items\n\nThis API provides a Python-based interface for interacting with items in OpenSesame, which is a software program used for creating and conducting psychology experiments. OpenSesame allows for the design of complex experimental procedures and the API in question facilitates programmatic control over the items within an experiment.\n\nOne important aspect of this API is that the `items` object, which represents the items in an experiment, does not need to be imported by the user. It is implicitly available within the OpenSesame scripting environment. This means users can directly use the `items` object without any additional import statements, allowing for a more streamlined coding experience.\n\nBelow is a list of the available functions within this API, along with their respective parameters:\n\n- **Function 1**: `get_item(item_name)`\n  - `item_name`: The unique name of the item to be retrieved.\n- **Function 2**: `new_item(item_type, item_name)`\n  - `item_type`: The type of the item to create (e.g., 'sequence', 'sketchpad').\n  - `item_name`: The desired name for the new item.\n- **Function 3**: `copy_item(original_item_name, new_item_name)`\n  - `original_item_name`: The name of the item to copy.\n  - `new_item_name`: The name for the copy of the item.\n- **Function 4**: `delete_item(item_name)`\n  - `item_name`: The name of the item to be deleted.\n- **Function 5**: `rename_item(old_name, new_name)`\n  - `old_name`: The current name of the item.\n  - `new_name`: The new name to be assigned to the item.\n- **Function 6**: `set_item(item_name, property_name, value)`\n  - `item_name`: The name of the item to modify.\n  - `property_name`: The name of the property to change.\n  - `value`: The new value to assign to the property.\n\nEach function is designed to perform specific operations on the items, such as retrieving, creating, copying, deleting, renaming, or modifying their properties. By utilizing these functions, users can programmatically manipulate the items within their experiments, allowing for dynamic and flexible experimental setups. The API's design is focused on providing intuitive and direct access to the core functionalities needed to manage experimental items within OpenSesame.", "url": "https://osdoc.cogsci.nl/4.0/manual/python/items", "title": "Access items"}
{"content": "# Access items\n\ntitle: Access items\n\n<summary_prompt>\nWrite a summary for the API below:\n\n- Describe the API's overall functionality\n- Explain that this is a Python API for OpenSesame, software for implementing psychology experiments\n- Explain that the `items` object does not need to be imported\n- Provide a bulleted list of all available functions and their parameters. Important: Don't just name the functions, but create one bullet per function.\n\nYour response should be a comprehensive summary.\n\n```markdown\n{content}\n```\n</summary_prompt>\n\n%-- include: include/api/items.md --%", "url": "https://osdoc.cogsci.nl/4.0/manual/python/items", "title": "Access items"}
{"content": "# Keyboard functions\n\nThe API described is a Python-based interface specifically designed for OpenSesame, a versatile software platform used for creating and conducting psychology experiments. The API provides a series of functionalities that enable experiment designers to handle keyboard interactions, which are a common method for collecting responses from participants during psychological experiments.\n\nOne of the key features of this API is the `Keyboard` class, which is central to managing keyboard input. Notably, users do not need to import the `Keyboard` class explicitly; it is inherently available within the OpenSesame environment.\n\nTo initialize a `Keyboard` object, the user simply needs to call the constructor of the `Keyboard` class. When doing so, the user can pass a variety of arguments to configure the keyboard's behavior. These arguments are passed as keyword arguments (`**resp_args`), allowing for flexible and dynamic specification of the keyboard settings.\n\nThe `**resp_args` is a Python convention for passing a variable number of keyword arguments to a function. In the context of the `Keyboard` class, this means that users can pass various optional parameters that dictate how the `Keyboard` instance should behave, such as setting timeouts or specifying which keys should be considered valid for a response.\n\nWhen specifying key names, users should follow the conventions used by the underlying operating system or the OpenSesame software. This ensures that the keypresses are correctly recognized and interpreted by the `Keyboard` class within the experiment.\n\nBelow is a comprehensive list of available functions within the `Keyboard` class, along with their respective parameters:\n\n- **Function**: `get_key()`\n  - **Parameters**:\n    - `timeout`: The maximum amount of time to wait for a keypress.\n    - `flush`: Whether to clear the keyboard buffer before waiting for input.\n- **Function**: `set_key()`\n  - **Parameters**:\n    - `key`: The name of the key to be set.\n    - `func`: The function to be associated with the key.\n- **Function**: `flush()`\n  - **Parameters**: None. Clears the keyboard buffer of any pending input.\n- **Function**: `wait()`\n  - **Parameters**:\n    - `keys`: A list of keys to wait for.\n    - `timeout`: The maximum amount of time to wait for one of the specified keys.\n- **Function**: `get_mods()`\n  - **Parameters**: None. Returns a list of currently active modifier keys (e.g., Shift, Ctrl).\n- **Function**: `key_name()`\n  - **Parameters**:\n    - `key_code`: The code of the key for which the name is desired.\n- **Function**: `key_code()`\n  - **Parameters**:\n    - `key_name`: The name of the key for which the code is desired.\n\nEach function provides a specific capability, ranging from obtaining a keypress, setting up a key-function relationship, clearing the input buffer, waiting for a particular keypress, checking for active modifiers, and translating between key codes and key names. Experiment designers can use these functions to customize the keyboard interaction experience according to the needs of their experiments.", "url": "https://osdoc.cogsci.nl/4.0/manual/python/keyboard", "title": "Keyboard functions"}
{"content": "# Keyboard functions\n\ntitle: Keyboard functions\n\n<summary_prompt>\nWrite a summary for the API below:\n\n- Describe the API's overall functionality\n- Explain that this is a Python API for OpenSesame, software for implementing psychology experiments\n- Explain that the `Keyboard` class does not need to be imported\n- Explain the process to initialize a Keyboard\n- Define the usage of `**resp_args`\n- Explain how to specify key names\n- Provide a bulleted list of all available functions and their parameters. Important: Don't just name the functions, but create one bullet per function.\n\nYour response should be a comprehensive summary.\n\n```markdown\n{content}\n```\n</summary_prompt>\n\n%-- include: include/api/keyboard.md --%", "url": "https://osdoc.cogsci.nl/4.0/manual/python/keyboard", "title": "Keyboard functions"}
{"content": "# Access experimental variables\n\nThe API in question is designed to interact with experimental variables within OpenSesame, a software tool used for conducting psychology experiments. OpenSesame is particularly popular among researchers in the field of psychology for building and running complex experimental designs with a user-friendly interface and scripting capabilities.\n\nKey features of the API include:\n\n- **Overall Functionality**: The API enables users to access and manipulate experimental variables within the OpenSesame environment. This allows for dynamic adjustment and tracking of variables that are crucial for experimental flow, conditions, and data collection.\n\n- **Python Integration**: This is a Python-based API, which means that it integrates seamlessly with OpenSesame, taking advantage of Python's extensive capabilities and syntax. Users familiar with Python will find it easy to work with this API.\n\n- **`var` Object**: A notable aspect of this API is the `var` object, which is a built-in feature of OpenSesame and does not require explicit importation. This object acts as a container for experimental variables.\n\n- **Variable Referencing**: Users have two methods to reference experimental variables within OpenSesame:\n  - **Preferred Method**: Accessing variables directly as global variables (e.g., `my_var = 10`). This method is more straightforward and is the recommended approach.\n  - **Non-Preferred Method**: Setting variables as properties of the `var` object (e.g., `var.my_var = 10`). While still valid, this method is less direct and not the preferred way to handle variables.\n\nThe API provides several functions for variable management, each with specific parameters:\n\n- `set_variable(name, value)`: Sets the specified variable `name` to the given `value`.\n- `get_variable(name)`: Retrieves the value of the variable identified by `name`.\n- `save_variable(name, value)`: Saves the variable `name` with the `value` to the data logger.\n- `register_variable(name, value_type)`: Registers a new variable `name` with a specified `value_type` (e.g., `string`, `int`).\n- `unregister_variable(name)`: Removes the registration of the variable `name` from the variable pool.\n- `clear_variables()`: Clears all variables from the current scope or experiment.\n- `copy_variable(from_name, to_name)`: Copies the value from one variable `from_name` to another `to_name`.\n- `rename_variable(old_name, new_name)`: Changes the name of a variable from `old_name` to `new_name`.\n\nThis summary provides an overview of the Python API for OpenSesame and its functions related to experimental variable management. Users should refer to the API documentation or seek further guidance for detailed usage instructions and additional context.", "url": "https://osdoc.cogsci.nl/4.0/manual/python/var", "title": "Access experimental variables"}
{"content": "# Access experimental variables\n\ntitle: Access experimental variables\n\n<summary_prompt>\nWrite a summary for the API below:\n\n- Describe the API's overall functionality\n- Explain that this is a Python API for OpenSesame, software for implementing psychology experiments\n- Explain that the `var` object does not need to be imported\n- Explain that there are two ways to refer to experimental variables:\n    - Preferred: as global variables: (`my_var = 10`)\n    - Non-preferred: as properties of the `var` object (`var.my_var = 10`)\n- Provide a bulleted list of all available functions and their parameters. Important: Don't just name the functions, but create one bullet per function.\n\nYour response should be a comprehensive summary.\n\n```markdown\n{content}\n```\n</summary_prompt>\n\n%-- include: include/api/var.md --%", "url": "https://osdoc.cogsci.nl/4.0/manual/python/var", "title": "Access experimental variables"}
{"content": "# OpenSesame as a Python library (no GUI)\n\ntitle: OpenSesame as a Python library (no GUI)\n\nYou can also write experiments fully programmatically by using OpenSesame as a Python module. This is mainly suited for people who prefer coding over using a graphical user interface.\n\nUsing OpenSesame as a Python module works much the same way as using Python `inline_script` items in the user interface, with two notable exceptions:\n\n- Functions and classes need to be explicitly imported from `libopensesame.python_workspace_api`. All functions and classes described under [Common functions](%url:manual/python/common%) are available.\n- An `experiment` object needs to be explicitly created using the `Experiment()` factory function.\n\nA simple Hello World experiment looks like this:\n\n```python\nfrom libopensesame.python_workspace_api import \\\n  Experiment, Canvas, Keyboard, Text\n\n# Initialize the experiment window using the legacy backend\nexp, win, clock, log = Experiment(canvas_backend='legacy')\n# Prepare a stimulus canvas and a keyboard\ncnv = Canvas()\ncnv += Text('Hello world')\nkb = Keyboard()\n# Show the canvas, wait for a key press, and then end the experiment\ncnv.show()\nkb.get_key()\nexp.end()\n```\n\nYou can also programmatically open a `.osexp` experiment file and execute it:\n\n```python\nfrom libopensesame.python_workspace_api import Experiment\nexp, win, clock, log = Experiment(osexp_path='my_experiment.osexp',\n                                  subject_nr=2)\nexp.run()\n```", "url": "https://osdoc.cogsci.nl/4.0/manual/python/nogui", "title": "OpenSesame as a Python library (no GUI)"}
{"content": "# Sound\n\ntitle: Sound\n\nThe most common way to play sound is using the SAMPLER item, for playback of audio files, or the SYNTH item, for playback of simple beeps, etc.\n\n[TOC]\n\n## The sampler\n\nThe SAMPLER plays back a single sound file, typically from the file pool.\n\nSound files are always played back at the sampling rate that is used by the OpenSesame sampler backend. If your sample appears to be sped up (high pitch) or slowed down (low pitch), you can adjust the sampling rate of your sound file in a sound editor, or change the sampling rate used by the OpenSesame sampler backend (under 'Show backend settings and info' in the General tab).\n\nThe SAMPLER has a few options:\n\n- *Sound file* indicates the file to be played.\n- *Volume* between 0 (silent) and 1 (normal volume).\n- *Pan* turns the right (negative values) or left (positive values) channel down. For full panning, enter 'left' or 'right',\n- *Pitch* indicates the playback speed, where 1 corresponds to the original speed.\n- *Stop after* indicates for how long the sound file should be played. For example, a value of 100 ms means that playback will be stopped after 100 ms, regardless of how long the sound file is. A value of 0 ms means that the sound file will be played back completely.\n- *Fade in* indicates the fade-in time for the sound file. For example, a value of 100 ms means that the sound file will start silent, and build up to maximum value in 100 ms.\n- *Duration* indicates the duration of the sampler item, before the next item is presented. This doesn't need to match the length of the sound file. For example, if the duration of the sampler is set to 0 ms, OpenSesame will advance directly to the item that follows the SAMPLER (e.g., a sketchpad), *while the sound file continues playing in the background*. In addition to a numeric value, you can set duration to:\n\t- 'keypress' to wait for a key press\n\t- 'mouseclick' to wait for a mouse click\n\t- 'sound' to wait until the sampler has finished playing.\n\n## The synth\n\nThe SYNTH is a basic sound synthesizer.\n\nYou can specify a\nnumber of options:\n\n- *Waveform* can be set to sine, sawtooth, square, or white noise\n- *Attack* is the time it takes for the sound the reach maximum volume (i.e. fade in).\n- *Decay* is the time it takes for the sound to die out (i.e. fade out). Note that the decay occurs within the length of the sound.\n- *Volume* between 0 and 100%\n- *Pan* turns the right (negative values) or left (positive values) channel down. Setting pan to -20 or 20 completely mutes the right or left channel, respectively.\n- *Length* indicates the length of the sound (in milliseconds).\n- *Duration* indicates the duration of the SYNTH item, before the next item is presented. This doesn't need to match the length of the sound. For example, the duration of the SYNTH may be set to 0ms, in order to advance directly to the next item (e.g., a SKETCHPAD), while the sound continues playing in the background. In addition to a numeric value, you can set the duration to 'keypress', to wait for a keyboard press, 'mouseclick', to wait for a mouse click, or 'sound', to wait until the SYNTH has finished playing.\n\n## Sound playback in Python\n\nYou can use the SAMPLER object and the SYNTH function to present visual stimuli in Python:\n\n- %link:sampler%\n- %link:manual/python/common%\n\n\n## Audio Low Latency plugins\n\nThe main goal of the Audio Low Latency plugins, developed by Bob Rosbag, is to play and record audio with minimal and predictable latencies to achieve a high accuracy and precision. The `PyAlsaAudio` package which uses the Linux ALSA audio system provided the best results within Python. `PortAudio` and `sounddevice` are cross-platform and work on both Windows as Linux.\n\nThe plugins are not installed by default, but can be installed through pip:\n\n```bash\npip install opensesame-plugin-audio-low-latency\n```\n\nSee also:\n\n- <https://pypi.org/project/opensesame-plugin-audio-low-latency/>", "url": "https://osdoc.cogsci.nl/4.0/manual/stimuli/sound", "title": "Sound"}
{"content": "# Text\n\ntitle: Text\n\n[TOC]\n\n## How can I present text?\n\nThe most common way to show text is using a SKETCHPAD or FEEDBACK item. These allow you to enter text and other visual stimuli. For a questionnaire-like way to show text, you can use [forms](%link:manual/forms/about%).\n\n\n## HTML formatting\n\nYou can use a HTML tags, which you can simply insert into your text. You can use these tags everywhere: In SKETCHPAD items, in INLINE_SCRIPTs (provided you use the `Canvas` class), in forms, etc.\n\nExample:\n\n~~~ .html\nOpenSesame supports a sub-set of HTML tags:\n- <b>Bold face</b>\n- <i>Italic</i>\n- <u>Underline</u>\n\nIn addition, you can pass 'color', 'size', and 'style' as keywords to a 'span' tag:\n- <span style='color:red;'>Color</span>\n- <span style='font-size:32px;'>Font size</span>\n- <span style='font-family:serif;'>Font style</span>\n\nFinally, you can force newlines with the 'br' tag:\nLine 1<br>Line 2\n~~~\n\n\n## Variables and inline Python\n\nYou can embed variables in text using the `{...}` syntax. For example, the following:\n\n~~~ .python\nThe subject number is {subject_nr}\n~~~\n\n... might evaluate to (for subject 1):\n\n~~~ .python\nThe subject number is 1\n~~~\n\nYou can also embed Python expression. For example, the following:\n\n~~~ .python\nThe subject number modulo five is {subject_nr % 5}\n~~~\n\n... might evaluate to (for subject 7)\n\n~~~ .python\nThe subject number modulo five is 2\n~~~\n\n\n## Fonts\n\n### Default fonts\n\nYou can select one of the default fonts from the font-selection dialogs (%FigFontSelect). These fonts are included with OpenSesame and your experiment will therefore be fully portable when you use them.\n\n%--\nfigure:\n id: FigFontSelect\n source: font-selection-dialog.png\n caption: \"A number of default fonts, which are bundled with OpenSesame, can be selected through the font-selection dialogs.\"\n--%\n\nThe fonts have been renamed for clarity, but correspond to the following open-source fonts:\n\n|__Name in OpenSesame__\t\t|__Actual font__\t\t|\n|---------------------------|-----------------------|\n|`sans`\t\t\t\t\t\t|Droid Sans\t\t\t\t|\n|`serif`\t\t\t\t\t|Droid Serif\t\t\t|\n|`mono`\t\t\t\t\t\t|Droid Sans Mono\t\t|\n|`chinese-japanese-korean`\t|WenQuanYi Micro Hei\t|\n|`arabic`\t\t\t\t\t|Droid Arabic Naskh\t\t|\n|`hebrew`\t\t\t\t\t|Droid Sans Hebrew\t\t|\n|`hindi`\t\t\t\t\t|Lohit Hindi\t\t\t|\n\n### Selecting a custom font through the font-selection dialog\n\nIf you select 'other ...' in the font selection dialog, you can select any font that is available on your operating system. If you do this, your experiment is no longer fully portable, and will require that the selected font is installed on the system that you run your experiment on.\n\n### Placing a custom font in the file pool\n\nAnother way to use a custom font is to put a font file in the file pool. For example, if you place the font file `inconsolata.ttf` in the file pool, you can use this font in a SKETCHPAD item, like so:\n\n\tdraw textline 0.0 0.0 \"This will be inconsolata\" font_family=\"inconsolata\"\n\nNote that the font file must be a truetype `.ttf` file.", "url": "https://osdoc.cogsci.nl/4.0/manual/stimuli/text", "title": "Text"}
{"content": "# Video playback\n\ntitle: Video playback\n\n[TOC]\n\n\n## media_player_mpy plugin\n\nThe MEDIA_PLAYER_MPY plugin is based on MoviePy. It is included by default with the Windows and Mac OS packages of OpenSesame. If it is not installed, you can get it by installing the `opensesame-plugin-media-player-mpy` package, as described here:\n\n- <https://rapunzel.cogsci.nl/manual/environment/>\n\nThe source code is hosted at:\n\n- <https://github.com/dschreij/opensesame-plugin-mediaplayer>\n\n\n## OpenCV\n\nOpenCV is a powerful computer vision library, which contains (among many other things) routines for reading video files.\n\n- <http://docs.opencv.org/3.0-beta/doc/py_tutorials/py_tutorials.html>\n\nThe following example shows how to play back a video file, while drawing a red square on top of the video. This example assumes that you're using the legacy backend.\n\n~~~ .python\nimport cv2\nimport numpy\nimport pygame\n# Full path to the video file in file pool\npath = pool['myvideo.avi']\n# Open the video\nvideo = cv2.VideoCapture(path)\n# A loop to play the video file. This can also be a while loop until a key\n# is pressed. etc.\nfor i in range(100):\n    # Get a frame\n    retval, frame = video.read()\n    # Rotate it, because for some reason it otherwise appears flipped.\n    frame = numpy.rot90(frame)\n    # The video uses BGR colors and PyGame needs RGB\n    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n    # Create a PyGame surface\n    surf = pygame.surfarray.make_surface(frame)\n    # Now you can draw whatever you want onto the PyGame surface!\n    pygame.draw.rect(surf, (255,0,0), (100, 100, 200, 200))\n    # Show the PyGame surface!\n    exp.surface.blit(surf, (0, 0))\n    pygame.display.flip()\n~~~", "url": "https://osdoc.cogsci.nl/4.0/manual/stimuli/video", "title": "Video playback"}
{"content": "# Visual stimuli\n\ntitle: Visual stimuli\n\nThe most common way to present visual stimuli is using the SKETCHPAD item, or, for non-time-critical stimuli, the FEEDBACK item.\n\n\n[TOC]\n\n\n## Using the sketchpad and feedback items\n\nThe SKETCHPAD and FEEDBACK item offer basic what-you-see-is-what-you get drawing tools (%FigSketchpad).\n\n%--\nfigure:\n id: FigSketchpad\n source: sketchpad.png\n caption: The SKETCHPAD provides built-in drawing tools.\n--%\n\n\n## Using show-if expressions\n\nYou can use show-if expressions to determine whether or not a particular element should be shown. For example, if you have an image of a happy face that should be shown only when the variable `valence` has the value 'positive', then you can set the show-if expression for the corresponding image element to:\n\n```python\nvalence == 'positive'\n```\n\nIf you leave a show-if expression empty or enter `True`, element will always be shown. Show-if expressions use the same syntax as other conditional expressions. For more information, see:\n\n- %link:manual/variables%\n\nShow-if expressions are evaluated at the moment that the display is prepared. This means that for SKETCHPAD items, they are evaluated during the prepare phase, whereas for FEEDBACK items, they are evaluated during the run phase (see also the section below).\n\n\n## The difference between sketchpad and feedback items\n\nThe SKETCHPAD and FEEDBACK items are identical in most ways, except for two important differences.\n\n\n### Sketchpad items are prepared in advance, feedback items are not\n\nThe contents of a SKETCHPAD are prepared during the prepare phase of the SEQUENCE that it is part of. This is necessary to ensure accurate timing: It allows the SKETCHPAD to be shown right away during the run phase, without any delays due to stimulus preparation. However, the downside of this is that the contents of a SKETCHPAD cannot depend on what happens during the SEQUENCE that it is part of. For example, you cannot use a SKETCHPAD to provide immediate feedback on the response time collected by a KEYBOARD_RESPONSE item (assuming that the SKETCHPAD and KEYBOARD_RESPONSE are part of the same sequence.)\n\nIn contrast, the contents of a FEEDBACK item are only prepared when they are actually shown, that is, during the run phase of the SEQUENCE that it is part of. This makes it possible to provide feedback on things that just happened--hence the name. However, the FEEDBACK item should not be used to present time-critical stimuli, because it suffers from delays due to stimulus preparation.\n\nFor more information about the prepare-run strategy, see:\n\n- %link:prepare-run%\n\n\n### Feedback variables are (by default) reset by feedback items\n\nThe FEEDBACK item has an option 'Reset feedback variables'. When this option is enabled (it is by default), feedback variables are reset when the FEEDBACK item is shown.\n\nFor more information about feedback variables, see:\n\n- %link:manual/variables%\n\n\n## Presenting visual stimuli in Python inline script\n\n### Accessing a SKETCHPAD in Python\n\nYou can access the `Canvas` object for a SKETCHPAD as the items `canvas` property. For example, say that your SKETCHPAD is called *my_sketchpad*, and contains an image elements with the name 'my_image'. You could then have this image rotate with the following script:\n\n~~~ .python\nmy_canvas = items['my_sketchpad'].canvas\nfor angle in range(360):\n\tmy_canvas['my_image'].rotation = angle\n\tmy_canvas.show()\n~~~\n\n\n### Creating a Canvas in Python\n\nYou can use the `Canvas` object to present visual stimuli in Python:\n\n- %link:manual/python/canvas%", "url": "https://osdoc.cogsci.nl/4.0/manual/stimuli/visual", "title": "Visual stimuli"}
{"content": "# Intermediate tutorial (JavaScript): visual search\n\ntitle: Intermediate tutorial (JavaScript): visual search\n\n[TOC]\n\n## About OpenSesame\n\nOpenSesame is a user-friendly program for the development of behavioral experiments for psychology, neuroscience, and experimental economy. For beginners, OpenSesame has a comprehensive graphical, point-and-click interface. For advanced users, OpenSesame supports Python (desktop only) and JavaScript (desktop and browser).\n\nOpenSesame is freely available under the [General Public License v3][gpl].\n\n## About this tutorial\n\nThis tutorial shows how to create a basic visual-search experiment using OpenSesame [(Math\u00f4t, Schreij, & Theeuwes, 2012)][references]. We will use both the graphical interface and JavaScript to develop an experiment that you can run online in a browser. Some experience with OpenSesame and JavaScript is recommended. This tutorial takes approximately one hour.\n\nA Python-based version of this tutorial is also available. If you don't need to run your experiments online, then the Python tutorial is likely what you need:\n\n- %link:tutorials/intermediate%\n\n\n## Resources\n\n- __Download__ \u2014 This tutorial assumes that you are running OpenSesame version 4.0.0 or later and OSWeb 2.0 or later. You can download the most recent version of OpenSesame from:\n\t- %link:download%\n- __Documentation__ \u2014 A dedicated documentation website can be found at:\n\t- <http://osdoc.cogsci.nl/>\n- __Forum__ \u2014 A support forum can be found at:\n\t- <http://forum.cogsci.nl/>\n\n\n## The experiment\n\nIn this tutorial, you will create a basic visual-search experiment. The experiment resembles the classic visual-search studies of [Treisman and Gelade (1980)][references], but it is not identical.\n\nBefore starting to *build* the experiment for yourself, you can already *participate* in it. This will give you a good idea of what you're working towards in this tutorial.\n\n<a role=\"button\" class=\"btn btn-success btn-align-left\" href=\"https://jatos.mindprobe.eu/publix/1938/start?batchId=2191&generalMultiple\">Participate in the experiment!</a>\n\nIn this experiment, participants search for a target object, which can be a yellow square, a yellow circle, a blue square, or a blue circle; the identity of the target is varied between blocks of trials. Participants indicate whether the target is present or not by pressing the right (present) or left (absent) arrow key.\n\nIn addition to the target, zero or more distractor objects are shown. There are three conditions, and the condition determines what kind of distractors there are:\n\n- In the *Conjunction* condition, distractors can have any shape and color, with the only restriction that distractors cannot be identical to the target. So, for example, if the target is a yellow square, then distractors are yellow circles, blue circles, and blue squares.\n- In the *Shape Feature* condition, distractors have a different shape from the target, but can have any color. So, for example, if the target is a yellow square, then distractors are yellow circles and blue circles.\n- In the *Color Feature* condition, distractors can have any shape, but have a different color from the target. So, for example, if the target is a yellow square, then distractors are blue squares and blue circles.\n\nImmediate feedback is shown after each trial: a green dot after a correct response, and a red dot after an incorrect response. Detailed feedback on average response times and accuracy is shown after each block of trials.\n\n%--\nfigure:\n id: FigVisualSearch\n source: visual-search.svg\n caption: |\n  The visual-search experiment that you will implement in this tutorial.\n--%\n\nExperiments like this show two typical findings:\n\n- It takes more time to find the target in the Conjunction condition than in the two Feature conditions.\n- In the Conjunction condition, response times increase as the number of distractors increases. This suggests that people search for the target one item at a time; this is called *serial search*.\n- In the Feature conditions (both shape and color), response times do not, or hardly, increase as the the number of distractors increases. This suggests that people process the entire display at once; this is called *parallel search*.\n\nAccording to Treisman and Gelade's feature-integration theory, these results reflect that the Conjunction condition requires that you combine, or *bind*, the color and shape of each object. This binding requires attention, and you therefore need to shift your attention from one object to the next; this is slow, and explains why response times depend on how many objects there are. In contrast, in the Feature conditions, color and shape do not need to be bound, and therefore the whole display can be processed in a single sweep without attention being directed at each and every object.\n\n## Experimental design\n\nThis design:\n\n- Is *within-subject*, because all participants do all conditions\n- Is *fully-crossed* (or full factorial), because all combinations of conditions occur\n- Has three conditions (or factors):\n\t- Varied within blocks:\n\t\t- `set_size` with three levels (1, 5, 15), or SS<sub>3</sub>\n\t\t- `condition` with three levels (conjunction, feature_shape, feature_color), or CN<sub>3</sub>\n\t\t- `target_present` with two levels (present, absent), or TP<sub>2</sub>\n\t- Varied between blocks:\n\t\t- `target_shape` with two levels (square, circle), or TS<sub>2</sub>\n\t\t- `target_color` with two levels (yellow, blue), or TC<sub>2</sub>\n- Has N subjects, or <u>S</u><sub>N</sub>\n\nYou can write this design as <u>S</u><sub>N</sub>\u00d7SS<sub>3</sub>\u00d7CN<sub>3</sub>\u00d7TP<sub>2</sub>\u00d7TS<sub>2</sub>\u00d7TC<sub>2</sub>\n\nFor more information about this notation for experimental design, see:\n\n- %link:experimentaldesign%\n\n## Step 1: Create the basic structure of the experiment\n\nStart OpenSesame and, in the 'Get started!' tab, select the Extended template. This template provides the basic structure that is common to many cognitive-psychology experiments, such as the one that we will create here.\n\nThe Extended template contains a few items that we don't need. Delete the following items:\n\n- *about_this_template*\n- *practice_loop*\n- *end_of_practice*\n\nWhen you have deleted these items, they are still visible in the 'Unused items' bin. To permanently delete these items, click on the 'Unused items' bin, and then click on the 'Permanently delete unused items' button.\n\nFinally, give the experiment a good title, such as 'Visual search'. To do this, open the general-properties tab (by clicking on 'Extended template' in the overview area) and click on the experiment name to edit it.\n\nAlso configure OpenSesame to run the experiment in a browser, rather than on the desktop.\n\nThe overview area should now look like %FigStep1:\n\n%--\nfigure:\n id: FigStep1\n source: step1.png\n caption: |\n  The overview area at the end of step 1.\n--%\n\n\n## Step 2: Define experimental variables that are varied between blocks\n\nAs described above, two variables are varied between blocks in our experiment: `target_shape` and `target_color`. We therefore need to define these variables in the *experimental_loop*. To understand why, consider the structure shown in %FigStep1, starting from the bottom (i.e. the most indented level).\n\n- *trial_sequence* corresponds to a single trial\n- *block_loop* corresponds to a block of a trials\n\t- Therefore, variables defined here vary for each run of *trial_sequence*; in other words, variables defined in *block_loop* are varied __within blocks__.\n- *block_sequence* corresponds to a block of trials, preceded by resetting of the feedback variables, and followed by participant feedback\n- *experimental_loop* corresponds to multiple blocks of trials\n\t- Therefore, variables defined here vary for each run of *block_sequence*; in other words, variables defined in *experimental_loop* are varied __between blocks__.\n- *experiment* corresponds to the entire experimental, which is an instruction screen, followed by multiple blocks of trials, followed by an end-of-experiment screen\n\nClick on experimental loop, and define:\n\n- `target_shape`, which can be 'square' or 'circle'; and\n- `target_color`, which can be 'yellow' or 'blue'.\n\nWe have a full-factorial design, which means that all 2 \u00d7 2 = 4 combinations must occur. The table of *experimental_loop* should now look like %FigStep2:\n\n%--\nfigure:\n id: FigStep2\n source: step2.png\n caption: |\n  The table of *experimental_loop* at the end of step 2.\n--%\n\n## Step 3: Give instructions at the start of each block\n\nRight now, the experiment starts with a single *instructions* screen. In our case, we want to give instructions before each block of trials, to tell the participant what target to look for (because the identity of the target varies between blocks).\n\n__Move the instructions into block_sequence__\n\nTherefore, pick up the *instructions* item and drag it onto *block_sequence*. A pop-up will appear, asking you if you want to:\n\n- Insert the item into *block_sequence*, in which case *instructions* would become the first item of *block_sequence*; or\n- Insert the item after *block_sequence*, in which case *instructions* would move to a position after *block_sequence*.\n\nSelect the first option ('Insert into'). Now *block_sequence* starts with an instructions screen, which is what we want.\n\n__Add instructional text__\n\nClick on *instructions* to open it, and add a good instructional text, such as:\n\n```text\nINSTRUCTIONS\n\nSearch for the {target_color} {target_shape}\n\nPress the right-arrow key if you find it\nPress the left-arrow key if you don't\n\nPress any key to begin\n```\n\nThe curly braces brackets around '{target_color}' and '{target_shape}' indicate that these are not literal text, but refer to the variables that we have defined in *experimental_loop*. When the experiment runs, the values of these variables will appear here, and the participant will see (for example), 'Search for the yellow circle'.\n\n__Give a visual preview of the target__\n\nIt also good to show the participant the actual stimulus that she needs to find. To do this:\n\n- Draw a filled circle at the center of the display (make sure it doesn't overlap with the text);\n- Change the color of the circle to '{target_color}'. This means that the color of the circle depends on the value of the variable `target_color`; and\n- Change the show-if expression to `target_shape == 'circle'`. This is a Python expression that checks if the variable `target_shape` has the value 'circle'. Note that even though you *cannot* use full-fledged Python `inline_script` items when running experiments in a browser, you *can* use Python for these simple conditional expressions.\n\nIn other words, we have drawn a circle of which the color is determined by `target_color`; furthermore, this circle is only shown when the variable `target_shape` has the value 'circle'. For more information about variables and show-if statements, see:\n\n- %link:manual/variables%\n\nWe use the same trick to draw a square:\n\n- Draw a filled square at the center of the display;\n- Change the color of the square to '{target_color}'; and\n- Change the show-if statement to `target_shape == 'square'`\n\nThe *instructions*  screen should now look like %FigStep3:\n\n%--\nfigure:\n id: FigStep3\n source: step3.png\n caption: |\n  The *instructions* screen at the end of step 3.\n--%\n\n\n## Step 4: Define experimental variables that are varied within blocks\n\nThree variables are varied within blocks in our experiment: `condition`, `set_size`, and `target_present`. As described under Step 2, we need to define these variables in the *block_loop* so that they vary for each run of *trial_sequence*.\n\nThe three variables make a total of 3 \u00d7 3 \u00d7 2 = 18 different combinations. We can type these into the table manually, but, because we have full-factorial design, we can also use the full-factorial-design wizard. To do this, first open *block_loop* and click on the 'Full-factorial design' button.\n\nIn the table that appears, put the variable names on the first row, and the values on the rows below, as shown in %FigFullFactorial.\n\n%--\nfigure:\n id: FigFullFactorial\n source: fullfactorial.png\n caption: |\n  The *instructions* screen at the end of step 3.\n--%\n\nNow click on 'Ok' to generate the full design. The table of *block_loop* should now look like %FigStep4.\n\n%--\nfigure:\n id: FigStep4\n source: step4.png\n caption: |\n  The table of *block_loop* at the end of step 4.\n--%\n\n## Step 5: Create the trial sequence and add an initialization script\n\nWe want our trial sequence to look as follows:\n\n- A fixation dot, for which we will use a SKETCHPAD.\n- A search display, which we will create in JavaScript with a custom INLINE_JAVASCRIPT.\n- Response collection, for which we will use a KEYBOARD_RESPONSE.\n- Data logging, for which we will use a LOGGER.\n- (We also want immediate feedback after each trial, but we will get back to this later.)\n\nSo the only thing that is missing from *trial_sequence* is an INLINE_JAVASCRIPT.\n\n- Insert a new INLINE_JAVASCRIPT after *sketchpad* and rename it to *search_display_script*.\n- Rename *sketchpad* to *fixation_dot*, so that its function is clear; and\n- Change the duration of *fixation_dot* to 500, so that the fixation dot is shown for 500 ms. (There should already be a fixation dot drawn; if not, draw one in the center of *fixation_dot*.)\n\nWe also need to add a initialization script to start of the experiment. We will use this only to define (`let`) a variable that will hold the `Canvas` object on which we will draw. In JavaScript, you have to define a variable exactly once, which is why we cannot do that in the *trial_sequence*.\n\n- Insert a new INLINE_JAVASCRIPT at the top of the *experiment* sequence and rename it to *init*.\n\nThe overview area should now look like %FigStep5.\n\n%--\nfigure:\n id: FigStep5\n source: step5.png\n caption: |\n  The overview area at the end of step 5.\n--%\n\n## Step 6: Generate the search display\n\n__Top-down and defensive programming__\n\nNow things will get interesting: We will start programming in JavaScript. We will use two guiding principles: *top-down* and *defensive* programming.\n\n- *Top-down programming* means that we start with the most abstract logic, without bothering with how this logic is implemented. Once the most abstract logic is in place, we will move down to a slightly less abstract logic, and so on, until we arrive at the details of the implementation. This technique helps to keep the code structured.\n- *Defensive programming* means that we assume that we make mistakes. Therefore, to protect us from ourselves, we build sanity checks into the code.\n\n*Note:* The explanation below assumes that you're somewhat familiar with JavaScript. If concepts like `Array`, `for` loop, and functions don't mean anything to you, then it's best to first walk through an introductory JavaScript tutorial. You can find links to JavaScript tutorials here:\n\n- %link:manual/javascript/about%\n\nThe logic of the code is shown in %FigHierarchy. The numbers indicate the order in which we will implement the functionality, starting at the abstract level.\n\n%--\nfigure:\n id: FigHierarchy\n source: hierarchy.svg\n caption: |\n  The logic of the code to draw a visual-search display.\n--%\n\n__Declaring variables with let, var, and const__\n\nIn JavaScript, you have to 'declare' a variable before you can use it. (In Python, this is not necessary.) In our case, we will use a variable called `c`, which we therefore need to declare. To do so, open the Prepare tab of the *init* script and use the `let` keyword to declare the variable `c`:\n\n```js\nlet c\n```\n\nThere are three different ways to declare variables:\n\n- Using `let`, as we've done here. In OpenSesame, this makes the variable available in JavaScript but not as an experimental variable in the user interface.\n- Using `var`. In OpenSesame, this makes the variable also available as an experimental variable in the user interface. (We will do that later for the variable `correct_response`.)\n- Using `const`. This is like `var` with the important difference that the variable cannot be re-assigned later.\n\n\n__The Prepare and Run phases__\n\nOpen *search_display_script* and switch to the Prepare tab. OpenSesame distinguishes two phases of execution:\n\n- During the Prepare phase, each item is given the opportunity to prepare itself; what this means depends on the item: For a SKETCHPAD, it means drawing a canvas (but not showing it); for a SAMPLER, it means loading a sound file (but not playing it); etc.\n- During the Run phase, each item is actually executed; again, what this means depends on the item: For a SKETCHPAD, it means showing the previously prepared canvas; for a SAMPLER, it means playing a previously loaded sound file.\n\nFor an INLINE_JAVASCRIPT, you have to decide yourself what to put in the Prepare phase, and what to put in the Run phase. The distinction is usually quite clear: In our case, we put the code for drawing the canvas in the Prepare phase, and the code for showing the canvas (which is small) in the Run phase.\n\nSee also:\n\n- %link:prepare-run%\n\n\n__Implement the abstract level__\n\nWe start at the most abstract level: defining a function that draws a visual-search display. We don't specify *how* this is done; we simply assume that there is a function that does this, and we will worry about the details later\u2014that's top-down programming.\n\nIn the Prepare tab, enter the following code:\n\n```js\nc = draw_canvas()\n```\n\nWhat happens here? We \u2026\n\n- Call `draw_canvas()`, which returns a `Canvas` object that we store as `c`; in other words, `c` is a `Canvas` object that corresponds the search display. This assumes that there is a function `draw_canvas()`, even though we haven't defined it yet.\n\nA `Canvas` object is a single display; it is, in a sense, the JavaScript counterpart of a SKETCHPAD. See also:\n\n- %link:manual/javascript/canvas%\n\nWe now go one step down by defining `draw_canvas()` (above the rest of the script so far):\n\n```js\n/**\n * Draws the search canvas.\n * @return A Canvas\n **/\nfunction draw_canvas() {\n    let c = Canvas()\n    let xy_list = xy_random(set_size, 500, 500, 75)\n    if (target_present === 'present') {\n        let [x, y] = xy_list.pop()\n        draw_target(c, x, y)\n    } else if (target_present !== 'absent') {\n        throw 'Invalid value for target_present ' + target_present\n    }\n    for (let [x, y] of xy_list) {\n        draw_distractor(c, x, y)\n    }\n    return c\n}\n```\n\n\nWhat happens here? We \u2026\n\n- Create an empty canvas, `c`, using the factory function `Canvas()`.\n- Generate an array of random `x, y` coordinates, called `xy_list`, using another common function, `xy_random()`. This array determines where the stimuli are shown. Locations are sampled from a 500 \u00d7 500 px area with a minimum spacing of 75 px.\n- Check if the experimental variable `target_present` has the value 'present'; if so, `pop()` one `x, y` tuple from `xy_list`, and draw the target at this location. This assumes that there is a function `draw_target()`, even though we haven't defined it yet.\n- If `target_present` is neither 'present' nor 'absent', we `throw` an error; this is defensive programming, and protects us from typos (e.g. if we had accidentally entered 'presenr' instead of 'present').\n- Loop through all remaining `x, y` values and draw a distractor at each position. This assumes that there is a function `draw_distractor()`, even though we haven't defined it yet.\n- Return `c`, which now has the search display drawn onto it.\n\nThere are several common functions, such as `Canvas()` and `xy_random()`, which are always available in an INLINE_JAVASCRIPT item. See:\n\n- %link:manual/javascript/common%\n\nExperimental variables are global variables. That's why you can refer to `set_size`, which is defined in *block_loop*, even though the variable `set_size` is never explicitly defined in the script. The same is true for `target_shape`, `target_color`, `condition`, etc. See:\n\n- %link:var%\n\n\n__Implement the intermediate level__\n\nWe now go one more step down by defining `draw_target` (above the rest of the script so far):\n\n```js\n/**\n * Draws the target.\n * @param c A Canvas\n * @param x An x coordinate\n * @param y A y coordinate\n **/\nfunction draw_target(c, x, y) {\n    draw_shape(c, x, y, target_color, target_shape)\n}\n```\n\nWhat happens here? We \u2026\n\n- Call another function, `draw_shape()`, and specify the color and shape that needs to be drawn. This assumes that there is a function `draw_shape()`, even though we haven't defined it yet.\n\nWe also define `draw_distractor` (above the rest of the script so far):\n\n```js\n/**\n * Draws a single distractor.\n * @param c A Canvas\n * @param x An x coordinate\n * @param y A y coordinate\n **/\nfunction draw_distractor(c, x, y) {\n    if (condition === 'conjunction') {\n        draw_conjunction_distractor(c, x, y)\n    } else if (condition === 'feature_shape') {\n        draw_feature_shape_distractor(c, x, y)\n    } else if (condition === 'feature_color') {\n        draw_feature_color_distractor(c, x, y)\n    } else {\n        throw 'Invalid condition: ' + condition\n    }\n}\n```\n\nWhat happens here? We \u2026\n\n- Call another function to draw a more specific distractor depending on the Condition.\n- Check whether `condition` has any of the expected values. If not, we `throw` an error. This is defensive programming! Without this check, if we made a typo somewhere, the distractor might simply not be shown without causing an error message.\n\nNow we define the function that draws distractors in the Conjunction condition (above the rest of the script so far):\n\n```js\n/**\n * Draws a single distractor in the conjunction condition: an object that\n * can have any shape and color, but cannot be identical to the target.\n * @param c A Canvas.\n * @param x An x coordinate.\n * @param y A y coordinate.\n **/\nfunction draw_conjunction_distractor(c, x, y) {\n    let conjunctions = [\n        ['yellow', 'circle'],\n        ['blue', 'circle'],\n        ['yellow', 'square'],\n        ['blue', 'square']\n    ]\n    let [color, shape] = random.pick(conjunctions)\n    while (color === target_color && shape === target_shape) {\n        [color, shape] = random.pick(conjunctions)\n    }\n    draw_shape(c, x, y, color, shape)\n}\n```\n\nWhat happens here? We \u2026\n\n- Define a list, `conjunctions`, of all possible color and shape combinations.\n- Randomly select one of the color and shape combinations from `conjunctions`.\n- Check if the selected color and shape are both equal to the color and shape of the target. If so, keep selecting a new color and shape until this is no longer the case. After all, the distractor cannot be identical to the target!\n- Call another function, `draw_shape()`, and specify the color and shape of the to-be-drawn distractor. This assumes that there is a function `draw_shape()`, even though we haven't defined it yet.\n\nIn addition, we \u2026\n\n- Use the `random` library, which is corresponds to the `random-ext` package. This library contains useful randomization functions (such as `random.pick()`) and is one of the non-standard JavaScript libraries that is included with OSWeb.\n\nNow we define the function that draws distractors in the Shape Feature condition (above the rest of the script so far):\n\n```js\n/**\n * Draws a single distractor in the feature-shape condition: an object that\n * has a different shape from the target, but can have any color.\n * @param c A Canvas.\n * @param x An x coordinate.\n * @param y A y coordinate.\n **/\nfunction draw_feature_shape_distractor(c, x, y) {\n    let colors = ['yellow', 'blue']\n    let color = random.pick(colors)\n    let shape\n    if (target_shape === 'circle') {\n        shape = 'square'\n    } else if (target_shape === 'square') {\n        shape = 'circle'\n    } else {\n        throw 'Invalid target_shape: ' + target_shape\n    }\n    draw_shape(c, x, y, color, shape)\n}\n```\n\nWhat happens here? We \u2026\n\n- Randomly select a color.\n- Choose a square shape if the target is a circle, and a circle shape if the target is square.\n- If `target_shape` is neither 'circle' nor 'square', `throw` an error\u2014more defensive programming!\n- Call another function, `draw_shape()`, and specify the color and shape of the to-be-drawn distractor. This assumes that there is a function `draw_shape()`, even though we haven't defined it yet.\n\nNow we define the function that draws distractors in the Color Feature condition (above the rest of the script so far):\n\n```js\n/**\n * Draws a single distractor in the feature-color condition: an object that\n * has a different color from the target, but can have any shape.\n * @param c A Canvas.\n * @param x An x coordinate.\n * @param y A y coordinate.\n **/\nfunction draw_feature_color_distractor(c, x, y) {\n    let shapes = ['circle', 'square']\n    let shape = random.pick(shapes)\n    let color\n    if (target_color === 'yellow') {\n        color = 'blue'\n    } else if (target_color === 'blue') {\n        color = 'yellow'\n    } else {\n        throw 'Invalid target_color: ' + target_color\n    }\n    draw_shape(c, x, y, color, shape)\n}\n```\n\nWhat happens here? We \u2026\n\n- Randomly select a shape.\n- Choose a blue color if the target is yellow, and a yellow color if the target is blue.\n- If `target_color` is neither 'yellow' nor 'blue', `throw` and error\u2014more defensive programming!\n- Call another function, `draw_shape()`, and specify the color and shape of the to-be-drawn distractor. This assumes that there is a function `draw_shape()`, even though we haven't defined it yet.\n\n__Implement the detailed level__\n\nNow we go all the way down to the details by defining the function that actually draws a shape to the canvas (above the rest of the script so far):\n\n```js\n/**\n * Draws a single shape.\n * @param c A Canvas.\n * @param x An x coordinate.\n * @param y A y coordinate.\n * @param color A color (yellow or blue)\n * @param shape A shape (square or circle)\n **/\nfunction draw_shape(c, x, y, color, shape) {\n    if (shape === 'square') {\n        // Parameters are passed as an Object!\n        c.rect({x:x-25, y:y-25, w:50, h:50, color:color, fill:true})\n    } else if (shape === 'circle') {\n        // Parameters are passed as an Object!\n        c.circle({x:x, y:y, r:25, color:color, fill:true})\n    } else {\n        throw 'Invalid shape: ' + shape\n    }\n    if (color !== 'yellow' && color !== 'blue') {\n        throw 'Invalid color: ' + color\n    }\n}\n```\n\nWhat happens here? We \u2026\n\n- Check which shape should be drawn. For squares, we add a `rect()` element to the canvas. For circles, we add a `circle()` element.\n- Check if the the shape is either a square or a circle, and if not `throw` and error. This is another example of defensive programming! We're making sure that we haven't accidentally specified an invalid shape.\n- Check if the the color is neither yellow nor blue, and if not `throw` and error.\n\nImportantly, `Canvas` functions accept a single object (`{}`) that specifies all parameters by name, like so:\n\n```js\n// Correct: pass a single object that contains all parameters by name\nc.rect({x:x-25, y:y-25, w:50, h:50, color:color, fill:true})\n// Incorrect: do not pass parameters by order\n// c.rect(x-25, y-25, 50, 50, color, true)\n// Incorrect: named parameters are not supported in JavaScript\n// c.rect(x=x-25, y=y-25, w=50, h=50, color=color, fill=true)\n```\n\n__Implement the Run phase__\n\nBecause we have done all the hard work in the Prepare phase, the Run phase is just:\n\n```js\nc.show()\n```\n\nThat's it! Now you have drawn a full visual-search display. And, importantly, you have done so in a way that is easy to understand, because of top-down programming, and safe, because of defensive programming.\n\n", "url": "https://osdoc.cogsci.nl/4.0/tutorials/intermediate-javascript", "title": "Intermediate tutorial (JavaScript): visual search"}
{"content": "# Intermediate tutorial (JavaScript): visual search\n\n## Step 7: Define the correct response\n\nTo know if the participant responds correctly, we need to know the correct response. You can define this explicitly in the *block_loop* (as done in the beginner tutorial); but here we're going to use some simple JavaScript that checks whether the target is present or not, and defines the correct response accordingly.\n\nTo do this, we first need to declare the variable in the Prepare tab of the *init* script, just below `let c`. This time, we use the `var` keyword to declare `correct_response`, because this makes the variable available in the user interface (whereas `let` does not do this):\n\n```js\nvar correct_response\n```\n\nNext, insert a new INLINE_JAVASCRIPT at the start of *trial_sequence*, and rename it to *correct_response_script*. In the Prepare phase, enter the following code:\n\n```js\nif (target_present === 'present') {\n    correct_response = 'right'\n} else if (vars.target_present === 'absent') {\n    correct_response = 'left'\n} else {\n    throw 'target_present should be absent or present, not ' + target\n}\n```\n\nWhat happens here? We \u2026\n\n- Check whether the target is present or not. If the target is present, the correct response is 'right' (the right arrow key); if the target is absent, the correct response is 'left' (the left arrow key). The experimental variable `correct_response` is automatically used by OpenSesame; therefore, we don't need to explicitly indicate that this variable contains the correct response.\n- Check if the target is either present or absent, and if not `throw` an error\u2014another example of defensive programming.\n\n## Step 8: Give per-trial feedback\n\nFeedback after every trial can motivate participants; however, per-trial feedback should not interfere with the flow of the experiment. A good way to give per-trial feedback is to briefly show a green fixation dot after a correct response, and a red fixation dot after an incorrect response.\n\nTo do this:\n\n- Insert two new SKETCHPADs into *trial_sequence*, just after *keyboard_response*.\n- Rename one SKETCHPAD to *green_dot*, draw a central green fixation dot onto it, and change its duration to 500.\n- Rename the other SKETCHPAD to *red_dot*, draw a central red fixation dot onto it, and change its duration to 500.\n\nOf course, only one of the two dots should be shown on each trial. To accomplish this, we will specify run-if statements in *trial_sequence*:\n\n- Change the run-if statement for *green_dot* to 'correct == 1', indicating that it should only be shown after a correct response.\n- Change the run-if statement for *red_dot* to 'correct == 0', indicating that it should only be shown after an incorrect response.\n\nThe variable `correct` is automatically created if the variable `correct_response` is available; that's why we defined `correct_response` in step 7. For more information about variables and run-if statements, see:\n\n- %link:manual/variables%\n\nThe *trial_sequence* should now look like %FigStep8.\n\n%--\nfigure:\n id: FigStep8\n source: step8.png\n caption: |\n  The *trial_sequence* at the end of step 8.\n--%\n\n\n## Finished!\n\nCongratulations, the experiment is complete! You can give it a test run by pressing on the toolbar button that shows a green circle with a gray play button inside (shortcut: `Alt+Ctrl+W`).\n\nIf the experiment doesn't work on the first try: Don't worry, and calmly figure out where the mistake comes from. Crashes are part of the normal development process. But you can save yourself a lot of time and headache by working in a structured way, as we have done in this tutorial.\n\n## References\n\n<div class='reference' markdown='1'>\n\nMath\u00f4t, S., Schreij, D., & Theeuwes, J. (2012). OpenSesame: An open-source, graphical experiment builder for the social sciences. *Behavior Research Methods*, *44*(2), 314-324. doi:10.3758/s13428-011-0168-7\n\nTreisman, A. M., & Gelade, G. (1980). A feature-integration theory of attention. *Cognitive Psychology*, 12(1), 97\u2013136. doi:10.1016/0010-0285(80)90005-5\n\n</div>\n\n[references]: #references\n[gpl]: http://www.gnu.org/licenses/gpl-3.0.en.html", "url": "https://osdoc.cogsci.nl/4.0/tutorials/intermediate-javascript", "title": "Intermediate tutorial (JavaScript): visual search"}
{"content": "# Beginner tutorial: gaze cuing\n\ntitle: Beginner tutorial: gaze cuing\n\n[TOC]\n\n## About OpenSesame\n\nOpenSesame is a program for easy of development of behavioral experiments for psychology, neuroscience, and experimental economy. For beginners, OpenSesame has a comprehensive graphical, point-and-click interface. For advanced users, OpenSesame supports Python scripting (not covered in this tutorial).\n\nOpenSesame is freely available under the [General Public License v3][gpl].\n\n## About this tutorial\n\nThis tutorial shows how to create a simple but complete psychological experiment using OpenSesame [(Math\u00f4t, Schreij, & Theeuwes, 2012; Math\u00f4t & March, 2022)][references]. You will use mainly the graphical user interface of OpenSesame (i.e., no Python inline coding), although you will make small modifications to the OpenSesame script. This tutorial takes approximately one hour.\n\n## Resources\n\n- __Download__ -- This tutorial assumes that you are running OpenSesame version 4.0.0 or later. To check which version you are running, see the bottom right of the 'Get started' tab (see %FigGetStarted). You can download the most recent version of OpenSesame from:\n\t- %link:download%\n- __Documentation__ -- A dedicated documentation website can be found at:\n\t- <http://osdoc.cogsci.nl/>\n- __Forum__ -- A support forum can be found at:\n\t- <http://forum.cogsci.nl/>\n\n## The experiment\n\nIn this tutorial, you will create a gaze-cuing experiment as introduced by [Friesen and Kingstone (1998)][references]. In this experiment, a face is presented in the center of the screen (%FigGazeCuing). This face looks either to the right or to the left. A target letter (an 'F' or an 'H') is presented to the left or right of the face. A distractor stimulus (the letter 'X') is presented on the other side of the face. The task is to indicate as quickly as possible whether the target letter is an 'F' or an 'H'. In the congruent condition, the face looks at the target. In the incongruent condition, the face looks at the distractor. As you may have guessed, the typical finding is that participant respond faster in the congruent condition than in the incongruent condition, even though the direction of gaze is not predictive of the target location. This shows that our attention is automatically guided by other people's gaze, even in situations where this doesn't serve any purpose. (And even when the face is just a smiley!)\n\n%--\nfigure:\n id: FigGazeCuing\n source: gaze-cuing.png\n caption: |\n  The gaze-cuing paradigm [(Friesen and Kingstone, 1998)][references] that you will implement in this tutorial. This example depicts a trial in the incongruent condition, because the smiley looks at the distractor ('X') and not at the target ('F').\n--%\n\nThe experiment consists of a practice and an experimental phase. Visual feedback will be presented after every block of trials. A sound will be played after every incorrect response.\n\n## Experimental design\n\nThis design:\n\n- is *within-subject*, because all participants do all conditions\n- is *fully crossed* (or full-factorial), because all combinations of conditions occur\n- has three factors (or factors):\n    - *gaze side* with two levels (left, right)\n    - *target side* with two levels (left, right)\n    - *target letter* with two levels (F, H)\n- has N subjects\n\n\nSee also %DesignScreencast for an explanation of the logic and design of the experiment:\n\n\n%--\nvideo:\n source: youtube\n id: DesignScreencast\n videoid: aWvibRH6D4E\n width: 640\n height: 360\n caption: |\n  An explanation of the experimental logic and design.\n--%\n\n\n## Step 1: Create the main sequence\n\nWhen you start OpenSesame, you see the 'Get started!' tab (%FigGetStarted). A list of templates is shown below 'Start a new experiment'. These templates provide convenient starting points for new experiments. After you saved an experiment the first time, recently opened experiments are shown under 'Continue with a recent experiment'. At the bottom of the page there are links to the documentation (which includes this tutorial), the community forum, and a page with professional (paid) support options. And of course a link where you can buy us a cup of coffee to help us stay awake while we are working on providing the best free software!\n\n%--\nfigure:\n id: FigGetStarted\n source: get-started.png\n caption: |\n  The 'Get started' dialog on OpenSesame start-up.\n--%\n\nClick on 'Default template' to start with a minimal experimental template.\n\nBy default there is a main SEQUENCE, which is simply called *experiment*. Click on *experiment* in the overview area (by default on the left side, see %FigInterface) to open its controls in the tab area. The *experiment* SEQUENCE consists of two items: a `notepad` called *getting started* and a SKETCHPAD called *welcome*.\n\nWe don't need these two items. Remove *getting_started* by right-clicking on it in the overview area and selecting 'Delete' (shortcut: `Del`). Remove *welcome* in the same way. The *experiment* SEQUENCE is now empty.\n\n%--\nfigure:\n id: FigInterface\n source: interface.png\n caption: \"The default layout of the OpenSesame interface.\"\n--%\n\n<div class='info-box' markdown='1'>\n\n__Background box__\n\n__Names vs types__ -- Items in OpenSesame have a name and a type. The name and type can be the same, but they are usually not. For example, a SKETCHPAD item can have the name *my_target_sketchpad*. To make this distinction clear, we will use `monospace` to indicate item types, and *italics* to indicate names.\n\n__Tip__ -- The 'Extended template' is a good starting point for many experiments. It already contains the basic structure of a trial-based experiment.\n\n__Tip__ -- You can click on the Help icons in the top right of an item's tab to get context-sensitive help.\n\n__Tip__ -- Save (shortcut: `Ctrl+S`) your experiment often! In the unfortunate (and unlikely) event of data loss, you will often be able to recover your work from the back-ups that are created automatically, by default, every 10 minutes (Menu \u2192 Tools \u2192 Open backup folder).\n\n__Tip__ -- Unless you have used 'Permanently delete' (shortcut: `Shift+Del`), deleted items are still available in the 'Unused items' bin, until you select 'Permanently delete unused items' in the 'Unused items' tab. You can re-add deleted items to a SEQUENCE by dragging them out of the 'Unused items' bin to somewhere in your experiment.\n\n__Tip__ -- %FigExperimentStructure schematically shows the structure of the experiment that you will create. If you get confused during the tutorial, you can refer to %FigExperimentStructure to see where you are.\n\n%--\nfigure:\n id: FigExperimentStructure\n source: experiment-structure.png\n caption: |\n  A schematic representation of the structure of the 'Gaze cuing' experiment. The item types are in bold face, item names in regular face.\n--%\n\n</div>\n\n__Append a form_text_display item for the instruction display__\n\nAs the name suggests, a `form_text_display` is a form that displays text. We are going to use a `form_text_display` to give instructions to the participant at the beginning of the experiment.\n\nClick on *experiment* in the overview area to open its controls in the tab area. You will see an empty SEQUENCE. Drag a `form_text_display` from the item toolbar (under 'Form', see %FigInterface) onto the *experiment* SEQUENCE in the tab area. When you let go, a new `form_text_display` item will be inserted into the SEQUENCE. (We will get back to this in Step 12.)\n\n<div class='info-box' markdown='1'>\n\n__Background box__\n\n__Tip__ -- You can drag items into the overview area and into SEQUENCE tabs.\n\n__Tip__ -- If a drop action is ambiguous, a pop-up menu will ask you what you want to do.\n\n__Tip__ -- A `form_text_display` only shows text. If you require images etc., you can use a SKETCHPAD item. We will meet the SKETCHPAD in Step 5.\n\n</div>\n\n__Append a loop item, containing a new sequence item, for the practice phase__\n\nWe need to append a LOOP item to the *experiment* SEQUENCE. We will use this LOOP for the practice phase of the experiment. Click on the *experiment* SEQUENCE to open its controls in the tab area.\n\nDrag the LOOP item from the item toolbar into the SEQUENCE just the way you added the `form_text_display`. New items are inserted below the item that they are dropped on, so if you drop the new LOOP onto the previously created `form_text_display`, it will appear where you want it: after the `form_text_display`. But don't worry if you drop a new item in the wrong place, because you can always re-order things later.\n\nBy itself, a LOOP does not do anything. A LOOP always needs another item to run. Therefore, you have to fill the new LOOP item with another item. (If you view the loop item, you will also see a warning: 'No item selected'.) Drag a SEQUENCE item from the item toolbar onto the LOOP item. A pop-up menu will appear, asking you whether you want to insert the SEQUENCE after or into the LOOP item. Select 'Insert into new_loop'. (We will get back to this in Step 2.)\n\n<div class='info-box' markdown='1'>\n\n__Background box__\n\n__What is a LOOP item?__ -- A LOOP is an item that adds structure to your experiment. It repeatedly runs another item, typically a SEQUENCE. A LOOP is also the place where you will usually define your independent variables, that is, those variables that you manipulate in your experiment.\n\n__What is a SEQUENCE item?__ -- A SEQUENCE item also adds structure to your experiment. As the name suggests, a SEQUENCE runs multiple other items one after another.\n\n__The LOOP-SEQUENCE structure__ -- You often want to repeat a sequence of events. To do this, you will need a LOOP item that contains a SEQUENCE item. By itself, a SEQUENCE does not repeat. It simply starts with the first item and ends with the last item. By 'wrapping' a LOOP item around the SEQUENCE, you can repeat the SEQUENCE multiple times. For example, a single trial usually corresponds to a single SEQUENCE called *trial_sequence*. A LOOP (often called *block_loop*) around this *trial_sequence* would then constitute a single block of trials. Similarly, but at another level of the experiment, a SEQUENCE (often called *block_sequence*) may contain a single block of trials, followed by a FEEDBACK display. A *practice_phase* LOOP around this 'block' SEQUENCE would then constitute the practice phase of the experiment. This may seem a bit abstract right now, but as you follow this tutorial, you will become familiar with the use of LOOPs and SEQUENCEs.\n\n__Tip__ -- For more information about SEQUENCEs and LOOPs, see:\n\n- %link:loop%\n- %link:sequence%\n\n</div>\n\n__Append a new form_text_display item for the end-of-practice message__\n\nAfter the practice phase, we want to inform the participant that the real experiment will begin. For this we need another `form_text_display`. Go back to the *experiment* SEQUENCE, and drag a `form_text_display` from the item toolbar onto the LOOP item. The same pop-up menu will appear as before. This time, select 'Insert after new_loop'. (We will get back to this in Step 12.)\n\n<div class='info-box' markdown='1'>\n\n__Tip__ -- Don't worry if you have accidentally changed a LOOP's item to run. You can undo this easily by clicking the 'Undo' button in the toolbar (`Ctrl+Shift+Z`).\n\n</div>\n\n__Append a new loop item, containing the previously created sequence, for the experimental phase__\n\nWe need a LOOP item for the experimental phase, just like for the practice phase. Therefore, drag a LOOP from the item toolbar menu onto *_form_text_display*.\n\nThe newly created LOOP (called *new_loop_1*) is empty, and should be filled with a SEQUENCE, just like the LOOP we created before. However, because the trials of the practice and experimental phase are identical, they can use the same SEQUENCE. Therefore, instead of dragging a new SEQUENCE from the item toolbar, you can re-use the *existing* one (i.e. create a linked copy).\n\nTo do this, right-click on the previously created *new_sequence*, and select 'Copy (linked)'. Now, right-click on *new_loop_1* and select 'Paste'. In the pop-up menu that appears, select 'Insert into new_loop 1'.\n\n<div class='info-box' markdown='1'>\n\n__Background box__\n\n__Tip__ \u2014 There is an important distinction between *linked* and *unlinked* copies. If you create a linked copy of an item, you create another occurrence of the same item. Therefore, if you modify the original item, the linked copy will change as well. In contrast, if you create an unlinked copy of an item, the copy will be initially look identical (except for its name), but you can edit the original without affecting the unlinked copy, and vice versa.\n\n</div>\n\n__Append a new form_text_display item, for the goodbye message__\n\nWhen the experiment is finished, we should say goodbye to the participant. For this we need another `form_text_display` item. Go back to the *experiment* SEQUENCE, and drag a `form_text_display` from the item toolbar onto *new_loop_1*. In the pop-up menu that appears, select 'Insert after new_loop_1'. (We will get back to this in Step 12.)\n\n__Give the new items sensible names__\n\nBy default, new items have names like *new_sequence* and *new_form_text_display_2*. It is good practice to give items sensible names. This makes it much easier to understand the structure of the experiment. If you want, you can also add a description to each item. Item names must consist of alphanumeric characters and/or underscores.\n\n- Select *new_form_text_display* in the overview area, double-click on its label in the top of the tab area and rename the item to *instructions*. (Overview-area shortcut: `F2`)\n- Rename *new_loop* to *practice_loop*.\n- Rename *new_sequence* to *block_sequence*. Because you have re-used this item in *new_loop_1*, the name automatically changes there as well. (This illustrates why it is efficient to create linked copies whenever this is possible.)\n- Rename *new_form_text_display_1* to *end_of_practice*.\n- Rename *new_loop_1* to *experimental_loop*.\n- Rename *new_form_text_display_2* to *end_of_experiment*.\n\n__Give the whole experiment a sensible name__\n\nThe experiment in its entirety also has a title and a description. Click on 'New experiment' in the overview area. You can rename the experiment in the same way as you renamed its items. The title currently is 'New experiment'. Rename the experiment to 'Tutorial: Gaze cuing'. Unlike item names, the experiment title may contain spaces etc.\n\nThe overview area of your experiment now looks like %FigStep1. This would be a good time to save your experiment (shortcut: `Ctrl+S`).\n\n%--\nfigure:\n id: FigStep1\n source: step1.png\n caption: |\n  The overview area at the end of the step 1.\n--%\n\n\n## Step 2: Create the block sequence\n\nClick on *block_sequence* in the overview. At the moment this SEQUENCE is empty. We want *block sequence* to consist of a block of trials, followed by a  FEEDBACK display. For this we need to do the following:\n\n__Append a reset_feedback item to reset the feedback variables__\n\nWe don't want our feedback to be confounded by key presses that participants have made during the instruction phase or previous blocks of trials. Therefore, we start each block of trials by resetting the feedback variables. To do this we need a `reset_feedback` item. Grab `reset_feedback` from the item toolbar (under 'Response collection') and drag it onto *block_sequence*.\n\n__Append a new loop, containing a new sequence, for a block of trials__\n\nFor a single trial we need a SEQUENCE. For a block of trials, we need to repeat this SEQUENCE multiple times. Therefore, for a block of trials we need to wrap a LOOP around a SEQUENCE. Drag a LOOP from the item toolbar onto *new_reset_feedback*. Next, drag a SEQUENCE from the item toolbar onto the newly created LOOP, and select 'Insert into new_loop' in the pop-up menu that appears. (We will get back to this in Step 3.)\n\n__Append a feedback item__\n\nAfter every block of trials we want to give feedback to the participant, so that the participant knows how well he/ she is doing. For this we need a FEEDBACK item. Drag a FEEDBACK from the item toolbar onto *new_loop*, and select 'Insert after loop' in the pop-up menu that appears. (We will get back to this in Step 10.)\n\n__Give the new items sensible names__\n\nRename: (See Step 1 if you don't remember how to do this.)\n\n- *new_loop* to *block_loop*\n- *new_sequence* to *trial_sequence*\n- *new_reset_feedback* to *reset_feedback*\n- *new_feedback* to *feedback*\n\nThe overview of your experiment now looks like %FigStep2. Remember to save your experiment regularly.\n\n%--\nfigure:\n id: FigStep2\n source: step2.png\n caption: |\n  The overview area at the end of Step 2.\n--%\n", "url": "https://osdoc.cogsci.nl/4.0/tutorials/beginner", "title": "Beginner tutorial: gaze cuing"}
{"content": "# Beginner tutorial: gaze cuing\n\n## Step 3: Fill the block loop with independent variables\n\nAs the name suggests, *block_loop* corresponds to a single block of trials. In the previous step we created the *block_loop*, but we still need to define the independent variables that will be varied within the block. Our experiment has three independent variables:\n\n- __gaze_cue__ can be 'left' or 'right'.\n- __target_pos__ (the position of the target) can be '-300' or '300'. These values reflect the X-coordinate of the target in pixels (0 = center). Using the coordinates directly, rather than 'left' and 'right', will be convenient when we create the target displays (see Step 5).\n- __target_letter__ (the target letter) can be 'F' or 'H'.\n\nTherefore, our experiment has 2 x 2 x 2 = 8 levels. Although 8 levels is not that many (most experiments will have more), we don't need to enter all possible combinations by hand. Click on *block_loop* in the overview to open its tab. Now click on the 'Full-factorial design' button. In the variable wizard, you simply define all variables by typing the name in the first row and the levels in the rows below the name (see %FigVariableWizard). If you select 'Ok', you will see that *block_loop* has been filled with all 8 possible combinations.\n\n%--\nfigure:\n id: FigVariableWizard\n source: variable-wizard.png\n caption: |\n  The loop variable wizard in Step 3.\n--%\n\nIn the resulting loop table, each row corresponds to one run of *trial_sequence*. Because, in our case, one run of *trial_sequence* corresponds to one trial, each row in our loop table corresponds to one trial. Each column corresponds to one variable, which can have a different value on each trial.\n\nBut we are not done yet. We need to add three more variables: the location of the distractor, the correct response, and the congruency.\n\n- __dist_pos__ -- On the first row of the first empty column, enter 'dist_pos'. This automatically adds a new experimental variable named 'dist_pos'. In the rows below, enter '300' wherever 'target_pos' is -300, and '-300' wherever 'target_pos' is 300. In other words, the target and the distractor should be positioned opposite from each other.\n- __correct_response__ -- Create another variable, in another empty column, with the name 'correct_response'. Set 'correct_response' to 'z' where 'target_letter' is 'F', and to 'm' where 'target_letter' is 'H'. This means that the participant should press the 'z' key if she sees an 'F' and the 'm' key if she sees an 'H'. (Feel free to choose different keys if 'z' and 'm' are awkward on your keyboard layout; for example, 'w' and 'n' are better on AZERTY keyboards.)\n- __congruency__ -- Create another variable with the name 'congruency'. Set 'congruency' to 'congruent' where 'target_pos' is '-300' and 'gaze_cue' is 'left', and where 'target_pos' is '300' and 'gaze_cue' is 'right'. In other words, a trial is congruent if the face looks at the target. Set 'congruency' to 'incronguent' for the trials on which the face looks at the distractor. The 'congruency' variable is not necessary to run the experiment; however, it is useful for analyzing the data later on.\n\nWe need to do one last thing. 'Repeat' is currently set to '1.00'. This means that each cycle will be executed once. So the block now consists of 8 trials, which is a bit short. A reasonable length for a block of trials is 24, so set 'Repeat' to 3.00 (3 repeats x 8 cycles = 24 trials). You don't need to change 'Order', because 'random' is exactly what we want.\n\nThe *block_loop* now looks like %FigStep3. Remember to save your experiment regularly.\n\n%--\nfigure:\n id: FigStep3\n source: step3.png\n caption: \"The *block_loop* at the end of Step 3.\"\n--%\n\n<div class='info-box' markdown='1'>\n\n__Background box__\n\n__Tip__ -- You can prepare your loop table in your favorite spreadsheet program and copy-paste it into the LOOP variable table.\n\n__Tip__ -- You can specify your loop table in a separate file (in `.xlsx` or `.csv`) format, and use this file directly. To do so, select 'file' under 'Source'.\n\n__Tip__ -- You can set 'Repeat' to a non-integer number. For example, by setting 'Repeat' to '0.5', only half the trials (randomly selected) are executed.\n\n</div>\n\n## Step 4: Add images and sound files to the file pool\n\nFor our stimuli, we will use images from file. In addition, we will play a sound if the participant makes an error. For this we need a sound file.\n\nYou can download the required files here (in most webbrowsers you can right-click the links and choose 'Save Link As' or a similar option):\n\n- [gaze_neutral.png](/img/beginner-tutorial/gaze_neutral.png)\n- [gaze_left.png](/img/beginner-tutorial/gaze_left.png)\n- [gaze_right.png](/img/beginner-tutorial/gaze_right.png)\n- [incorrect.ogg](/img/beginner-tutorial/incorrect.ogg)\n\nAfter you have downloaded these files (to your desktop, for example), you can add them to the file pool. If the file pool is not already visible (by default on the right side of the window), click on the 'Show file pool' button in the main toolbar (shortcut: `Ctrl+P`). The easiest way to add the four files to the file pool is to drag them from the desktop (or wherever you have downloaded the files to) into the file pool. Alternatively, you can click on the '+' button in the file pool and add files using the file select dialog that appears. The file pool will be automatically saved with your experiment.\n\nYour file pool now looks like %FigStep4. Remember to save your experiment regularly.\n\n%--\nfigure:\n id: FigStep4\n source: step4.png\n caption: \"The file pool at the end of Step 4.\"\n--%\n\n## Step 5: Fill the trial sequence with items\n\nA trial in our experiment looks as follows:\n\n1. __Fixation dot__ -- 750 ms, SKETCHPAD item\n2. __Neutral gaze__ -- 750 ms, SKETCHPAD item\n3. __Gaze cue__ -- 500 ms, SKETCHPAD item\n4. __Target__  -- 0 ms, SKETCHPAD item\n5. __Response collection__ \t-- KEYBOARD_RESPONSE item\n6. __Play a sound if response was incorrect__ --  SAMPLER item\n7. __Log response to file__ -- LOGGER item\n\nClick on *trial_sequence* in the overview to open the *trial_sequence* tab. Pick up a SKETCHPAD from the item toolbar and drag it into the *trial_sequence*. Repeat this three more times, so that *trial_sequence* contains four SKETCHPADs. Next, select and append a KEYBOARD_RESPONSE item, a SAMPLER item, and a LOGGER item.\n\nAgain, we will rename the new items, to make sure that the *trial_sequence* is easy to understand. Rename:\n\n- *new_sketchpad* to *fixation_dot*\n- *new_sketchpad_1* to *neutral_gaze*\n- *new_sketchpad_2* to *gaze_cue*\n- *new_sketchpad_3* to *target*\n- *new_keyboard_response* to *keyboard_response*\n- *new_sampler* to *incorrect_sound*\n- *new_logger* to *logger*\n\nBy default, items are always executed, which is indicated by the run-if expression `True`. However, we want to change this for the *incorrect_sound* item, which should only be executed if an error was made. To do this, we need to change the 'Run if' expression to `correct == 0` in the *trial_sequence* tab. This works, because the *keyboard_response* item automatically creates a `correct` variable, which is set to `1` (correct), `0` (incorrect), or `undefined` (this relies on the `correct_response` variable that was defined in Step 3). The double equals sign is Python syntax and indicates that you want to compare whether the two things are equal to each other, in this case whether the variable `correct` is equal to 0. To change a run-if expression, double click on it (shortcut: `F3`).\n\nThe *trial_sequence* now looks like %FigStep5.\n\n%--\nfigure:\n id: FigStep5\n source: step5.png\n caption: \"The *trial_sequence* at the end of Step 5.\"\n--%\n\n<div class='info-box' markdown='1'>\n\n__Background box__\n\n__What is a SKETCHPAD item?__ -- A SKETCHPAD is used to present visual stimuli: text, geometric shapes, fixation dots, Gabor patches, etc. You can draw on the SKETCHPAD using the built-in drawing tools.\n\n__What is a KEYBOARD_RESPONSE item?__ -- A KEYBOARD_RESPONSE item collects a single participant's response from the keyboard.\n\n__What is a SAMPLER item?__ -- A SAMPLER item plays a sound from a sound file.\n\n__What is a LOGGER item?__ -- A LOGGER item writes data to the log file. This is very important: If you forget to include a LOGGER item, no data will be logged during the experiment!\n\n__Tip__ -- Variables and conditional \"if\" expressions are very powerful! To learn more about them, see:\n\n- %link:manual/variables%\n\n</div>\n\n## Step 6: Draw the sketchpad items\n\nThe SKETCHPAD items that we have created in Step 5 are still blank. It's time to do some drawing!\n\n__Set the background color to white__\n\nClick on *fixation_dot* in the overview area to open its tab. The SKETCHPAD is still dark gray, while the images that we have downloaded have a white background. Oops, we forgot to set the background color of the experiment to white (it is dark gray by default)! Click on 'Tutorial: Gaze cuing' in the overview area to open the 'General properties' tab. Change 'Foreground' to 'black' and 'Background' to 'white'.\n\n<div class='info-box' markdown='1'>\n\n__Background box__\n\n__Tip__ -- For more fine-grained control over colors, you can also use the hexadecimal RGB notation (e.g., `#FF000` for red), use various color spaces, or use the color-picker tool. See also:\n\n- %link:manual/python/canvas%\n\n</div>\n\n__Draw the fixation dot__\n\nGo back to the *fixation_dot* by clicking on *fixation_dot* in the overview. Now select the fixation-dot element by clicking on the button with the crosshair. If you move your cursor over the sketchpad, you can see the screen coordinates in the top-right. Set the (foreground) color to 'black'. Click on the center of the screen (0, 0) to draw a central fixation dot.\n\nFinally, change the 'Duration' field from 'keypress' to '745', because we want the fixation dot to be presented for 750 ms. Wait ... *why didn't we just specify a duration of 750 ms?* The reason for this is that the actual display-presentation duration is always rounded up to a value that is compatible with your monitor's refresh rate. This may sound complicated, but for most purposes the following rules of thumb are sufficient:\n\n1. Choose a duration that is possible given your monitor's refresh rate. For example, if your monitor's refresh rate is 60 Hz, it means that every frame lasts 16.7 ms (= 1000 ms/60 Hz). Therefore, on a 60 Hz monitor, you should always select a duration that is a multiple of 16.7 ms, such as 16.7, 33.3, 50, 100, etc.\n2. In the duration field of the SKETCHPAD specify a duration that is a few milliseconds less than what you're aiming for. So if you want to present a SKETCHPAD for 50 ms, choose a duration of 45. If you want to present a SKETCHPAD for 1000 ms, choose a duration of 995. Etcetera.\n\n<div class='info-box' markdown='1'>\n\n__Background box__\n\n__Tip__ -- For a detailed discussion of experimental timing, see:\n\n- %link:timing%\n\n__Tip__ -- The duration of a SKETCHPAD can be a value in milliseconds, but you can also enter 'keypress' or 'mouseclick' to collect a keyboard press or mouse click respectively. In this case a SKETCHPAD will work much the same as a KEYBOARD_RESPONSE item (but with fewer options).\n\n__Tip__ -- Make sure that the (foreground) color is set to black. Otherwise you will draw white on white and won't see anything!\n\n</div>\n\n__Draw the neutral gaze__\n\nOpen the *neutral_gaze* SKETCHPAD. Now select the image tool by clicking on the button with the mountain-landscape-like icon. Click on the center of the screen (0, 0). The 'Select file from pool' dialog will appear. Select the file `gaze_neutral.png` and click on the 'Select' button. The neutral gaze image will now stare at you from the center of the screen! Finally, like before, change the 'Duration' field from 'keypress' to '745'. (And note again that this means a duration of 750 ms on most monitors!)\n\n<div class='info-box' markdown='1'>\n\n__Background box__\n\n__Tip__ -- OpenSesame can handle a wide variety of image formats. However, some (non-standard) `.bmp` formats are known to cause trouble. If you find that a `.bmp` image is not shown, you can convert it to a different format, such as `.png`. You can convert images easily with free tools such as [GIMP].\n</div>\n\n__Draw the gaze cue__\n\nOpen the *gaze_cue* SKETCHPAD, and again select the image tool. Click on the center of the screen (0, 0) and select the file `gaze_left.png`.\n\nBut we are not done yet! Because the gaze cue should not always be 'left', but should depend on the variable `gaze_cue`, which we have defined in Step 3. However, by drawing the `gaze_left.png` image to the SKETCHPAD, we have generated a script that needs only a tiny modification to make sure that the proper image is shown. Click on the 'Select view' button at the top-right of the *gaze_cue* tab and select 'View script'. You will now see the script that corresponds to the sketchpad that we have just created:\n\n~~~ .python\nset duration keypress\nset description \"Displays stimuli\"\ndraw image center=1 file=\"gaze_left.png\" scale=1 show_if=True x=0 y=0 z_index=0\n~~~\n\nThe only thing that we need to do is replace `gaze_left.png` with `gaze_{gaze_cue}.png`. This means that OpenSesame uses the variable `gaze_cue` (which has the values `left` and `right`) to determine which image should be shown.\n\nWhile we are at it, we might as well change the duration to '495' (rounded up to 500!). The script now looks like this:\n\n~~~ .python\nset duration 495\nset description \"Displays stimuli\"\ndraw image center=1 file=\"gaze_{gaze_cue}.png\" scale=1 show_if=True x=0 y=0 z_index=0\n~~~\n\nClick the 'Apply' button at the top right to apply your changes to the script and return to the regular item controls. OpenSesame will warn you that the image cannot be shown, because it is defined using variables, and a placeholder image will be shown instead. Don't worry, the correct image will be shown during the experiment!\n\n<div class='info-box' markdown='1'>\n\n__Background box__\n\n__Tip__ -- The variable inspector (shortcut: `Ctrl+I`) is a powerful way to find out which variables have been defined in your experiment, and which values they have (see %FigVariableInspector). When your experiment is not running, most variables don't have a value yet. But when you run your experiment in a window, while having the variable inspector visible, you can see variables changing in real time. This is very useful for debugging your experiment.\n\n%--\nfigure:\n id: FigVariableInspector\n source: variable-inspector.png\n caption: \"The variable inspector is a convenient way to get an overview of the variables that exist in your experiment.\"\n--%\n\n</div>\n\n__Draw the target__\n\nWe want three objects to be part of the target display: the target letter, the distractor letter, and the gaze cue (see %FigGazeCuing). As before, we will start by creating a static display using the SKETCHPAD editor. After this, we will only need to make minor changes to the script so that the exact display depends on the variables.\n\nClick on *target* in the overview to open the target tab and like before, draw the `gaze_left.png` image at the center of the screen. Now select the draw text tool by clicking on the button with the 'A' icon. Change the foreground color to 'black' (if it isn't already). The default font size is 18 px, which is a bit small for our purpose, so change the font size to 32 px. Now click on (-320, 0) in the SKETCHPAD (the X-coordinate does not need to be exactly 320, since we will change this to a variable anyway). Enter \"{target_letter}\" in the dialog that appears, to draw the target letter (when drawing text, you can use variables directly). Similarly, click on (320, 0) and draw an 'X' (the distractor is always an 'X').\n\nNow open the script editor by clicking on the 'Select view' button at the top-right of the tab and selecting 'View script'. The script looks like this:\n\n~~~ .python\nset duration keypress\nset duration keypress\nset description \"Displays stimuli\"\ndraw image center=1 file=\"gaze_left.png\" scale=1 show_if=True x=0 y=0 z_index=0\ndraw textline center=1 color=black font_bold=no font_family=mono font_italic=no font_size=32 html=yes show_if=True text=\"{target_letter}\" x=-320 y=0 z_index=0\ndraw textline center=1 color=black font_bold=no font_family=mono font_italic=no font_size=32 html=yes show_if=True text=X x=320 y=0 z_index=0\n~~~\n\nLike before, change `gaze_left.png` to `gaze_{gaze_cue}.png`. We also need to make the position of the target and the distractor depend on the variables `target_pos` and `dist_pos` respectively. To do this, simply change `-320` to `{target_pos}` and `320` to `{dist_pos}`. Make sure that you leave the `0`, which is the Y-coordinate. The script now looks like this:\n\n~~~ .python\nset duration keypress\nset description \"Displays stimuli\"\ndraw image center=1 file=\"gaze_{gaze_cue}.png\" scale=1 show_if=True x=0 y=0 z_index=0\ndraw textline center=1 color=black font_bold=no font_family=mono font_italic=no font_size=32 html=yes show_if=True text=\"{target_letter}\" x={target_pos} y=0 z_index=0\ndraw textline center=1 color=black font_bold=no font_family=mono font_italic=no font_size=32 html=yes show_if=True text=X x={dist_pos} y=0 z_index=0\n~~~\n\nClick on the 'Apply' button to apply the script and go back to the regular item controls.\n\nFinally, set the 'Duration' field to '0'. This does not mean that the target is presented for only 0 ms, but that the experiment will advance to the next item (the *keyboard_response*) right away. Since the *keyboard_response* waits for a response, but doesn't change what's on the screen, the target will remain visible until a response has been given.\n\nRemember to save your experiment regularly.\n\n<div class='info-box' markdown='1'>\n\n__Background box__\n\n__Tip__ -- Each element of a SKETCHPAD has a 'Show if' option, which specifies when the element should be shown. You can use this to hide/ show elements from a SKETCHPAD depending on certain variables, similar to run-if statements in a SEQUENCE.\n\n__Tip__ -- Make sure that the (foreground) color is set to black. Otherwise you will draw white on white and won't see anything!\n\n</div>\n", "url": "https://osdoc.cogsci.nl/4.0/tutorials/beginner", "title": "Beginner tutorial: gaze cuing"}
{"content": "# Beginner tutorial: gaze cuing\n\n## Step 7: Configure the keyboard response item\n\nClick on *keyboard_response* in the overview to open its tab. You see three options: Correct response, Allowed responses, Timeout, and Event type.\n\nWe have already set the `correct_response` variable in Step 3. Unless we explicitly specify a correct response, OpenSesame automatically uses the `correct_response` variable if it is available. Therefore, we don't need to change the 'Correct response' field here.\n\nWe do need to set the allowed responses. Enter 'z;m' in the allowed-responses field (or other keys if you have chosen different response keys). The semicolon is used to separate responses. The KEYBOARD_RESPONSE now only accepts 'z' and 'm' keys. All other key presses are ignored, with the exception of 'escape', which pauses the experiment.\n\nWe also want to set a timeout, which is the maximum interval that the KEYBOARD_RESPONSE waits before deciding that the response is incorrect and setting the 'response' variable to 'None'. '2000' (ms) is a good value.\n\nWe don't need to change the Event type, because we want the participant to respond by pressing a key (keypress, the default) and not by releasing a key (keyrelease).\n\nThe KEYBOARD_RESPONSE now looks like %FigStep7.\n\n%--\nfigure:\n id: FigStep7\n source: step7.png\n caption: \"The KEYBOARD_RESPONSE at the end of Step 7.\"\n--%\n\n<div class='info-box' markdown='1'>\n\n__Background box__\n\n__Tip__ -- By default, the KEYBOARD_RESPONSE will use the `correct_response` variable to determine whether a response was correct. But you can use a different variable as well. To do this, enter a variable name between curly braces (`{my_variable}`) in the correct response field.\n\n__Tip__ -- If 'flush pending key presses' is enabled (it is by default), all pending key presses are discarded when the KEYBOARD_RESPONSE item is called. This prevents carry-over effects, which might otherwise occur if the participant accidentally presses a key during a non-response part of the trial.\n\n__Tip__ -- To use special keys, such as '/' or the up-arrow key, you can use key names (e.g., 'up' and 'space') or associated characters (e.g., '/' and ']'). The 'List available keys' button provides an overview of all valid key names.\n\n</div>\n\n## Step 8: Configure the incorrect (sampler) item\n\nThe *incorrect_sound* item doesn't need much work: We only need to select the sound that should be played. Click on *incorrect_sound* in the overview to open its tab. Click on the 'Browse' button and select `incorrect.ogg` from the file pool.\n\nThe sampler now looks like %FigStep8.\n\n%--\nfigure:\n id: FigStep8\n source: step8.png\n caption: \"The *incorrect_sound* item at the end of Step 8.\"\n--%\n\n<div class='info-box' markdown='1'>\n\n__Background box__\n\n__Tip__ -- You can use variables to specify which sound should be played by using a variable name between curly braces as (part of) the file name. For example: `{a_word}.ogg`\n\n__Tip__ -- The SAMPLER handles files in `.ogg`, `.mp3`, and `.wav` format. If you have sound files in a different format, [Audacity] is a great free tool to convert sound files (and much more).\n\n</div>\n\n## Step 9: Configure the variable logger\n\nActually, we don't need to configure the variable LOGGER, but let's take a look at it anyway. Click on *logger* in the overview to open its tab. You see that the option 'Automatically log all variables' is selected. This means that OpenSesame logs everything, which is fine.\n\n<div class='info-box' markdown='1'>\n\n__Background box__\n\n__Tip__ -- If you like your log-files clean, you can disable the 'Automatically log all variables' option and manually select variables, either by entering variable names manually ('Add custom variable'), or by dragging variables from the variable inspector into the LOGGER table. You can also leave the 'Automatically log all variables' option enabled and exclude variables that you are not interested in.\n\n__The one tip to rule them all__ -- Always triple-check whether all the necessary variables are logged in your experiment! The best way to check this is to run the experiment and investigate the resulting log files.\n\n</div>\n\n## Step 10: Draw the feedback item\n\nAfter every block of trials, we want to present feedback to the participant to let him/ her know how well he/ she is doing. Therefore, in Step 2, we added a FEEDBACK item, simply named *feedback* to the end of *block_sequence*.\n\nClick on *feedback* in the overview to open its tab, select the draw text tool, change the foreground color to 'black' (if it isn't already), and click at (0, 0). Now enter the following text:\n\n```text\nEnd of block\n\nYour average response time was {avg_rt} ms\nYour accuracy was {acc} %\n\nPress any key to continue\n```\n\nBecause we want the feedback item to remain visible as long as the participant wants (i.e. until he/ she presses a key), we leave 'Duration' field set to 'keypress'.\n\nThe feedback item now looks like %FigStep_10.\n\n%--\nfigure:\n id: FigStep_10\n source: step10.png\n caption: \"The feedback item at the end of Step 10.\"\n--%\n\n<div class='info-box' markdown='1'>\n\n__Background box__\n\n__What is a feedback item?__ -- A FEEDBACK item is almost identical to a SKETCHPAD item. The only difference is that a FEEDBACK item is not prepared in advance. This means that you can use it to present feedback, which requires up-to-date information about a participant's response. You should not use FEEDBACK items to present time-critical displays, because the fact that it is not prepared in advance means that its timing properties are not as good as that of the SKETCHPAD item. See also:\n\n- %link:visual%\n\n__Feedback and variables__ -- Response items automatically keep track of the accuracy and average response time of the participant in the variables 'acc' (synonym: 'accuracy') and 'avg_rt' (synonym: 'average_response_time') respectively. See also:\n\n- %link:manual/variables%\n\n__Tip__ -- Make sure that the (foreground) color is set to black. Otherwise you will draw white on white and won't see anything!\n\n</div>\n\n## Step 11: Set the length of the practice phase and experimental phase\n\nWe have previously created the *practice_loop* and *experiment_loop* items, which both call *block_sequence* (i.e., a block of trials). However, right now they call *block_sequence* only once, which means that both the practice and the experimental phase consist of only a single block of trials.\n\nClick on *practice_loop* to open its tab and set 'Repeat' to '2.00'. This means that the practice phase consists of two blocks.\n\nClick on *experimental_loop* to open its tab and set 'Repeat' to '8.00'. This means that the experimental phase consists of eight blocks.\n\n<div class='info-box' markdown='1'>\n\n__Background box__\n\n__Tip__ -- You can create a variable `practice` in both *practice_loop* and *experimental_loop* and set it to 'yes' and 'no' respectively. This is an easy way of keeping track of which trials were part of the practice phase.\n\n</div>\n\n## Step 12: Write the instruction, end_of_practice and end_of_experiment forms\n\nI think you can handle this step your own! Simply open the appropriate items and add some text to present instructions, an end-of-practice message, and an end-of-experiment message.\n\n<div class='info-box' markdown='1'>\n\n__Background box__\n\n__Tip__ -- You can use a subset of HTML tags to format your text. For example, *&lt;b&gt;this will be bold&lt;b&gt;* and *&lt;span color='red'&gt;this will be red&lt;span&gt;*. For more information, see:\n\n- %link:text%\n\n</div>\n\n## Step 13: Run the experiment!\n\nYou're done! Click on the 'Run in window' (shortcut: `Ctrl+W`) or 'Run fullscreen' (shortcut: `Ctrl+R`) buttons in the toolbar to run your experiment.\n\n<div class='info-box' markdown='1'>\n\n__Background box__\n\n__Tip__ -- A test run is executed even faster by clicking the orange 'Run in window' button (shortcut: `Ctrl+Shift+W`), which doesn't ask you how to save the logfile (and should therefore only be used for testing purposes).\n\n</div>\n\n\n## Understanding errors\n\nBeing able to understand error messages is a crucial skill when working with OpenSeame. After all, a newly built experiment rarely runs immediately without any errors!\n\nLet's say that we made a mistake during one of the steps above. When trying to run the experiment, we get the following error message (%FigErrorMessage):\n\n%--\nfigure:\n id: FigErrorMessage\n source: error-message.png\n caption: \"An error message in OpenSesame.\"\n--%\n\nThe error message starts with a name, in this case `FStringError`, which indicates the general type of error. This is followed by a short explanatory text, in this case 'Failed to evaluate f-string expression in the following text: gaze_{gaze_ceu}.png`. Even without understanding what an f-string is (it's a string that contains Python code between curly braces), it's clear that there is something wrong with the text '{gaze_ceu}.png'.\n\nThe error message also indicates that the error comes from the prepare phase of the *gaze_cue* item.\n\nFinally, the error message indicates what specifically went wrong when evaluating the text 'gaze_{gaze_ceu}.png': the name 'gaze_ceu' is not defined.\n\nWhile reading the error message carefully, the cause and solution probably already came to your mind: we made a simple spelling mistake in the *gaze_cue* item, writing '{gaze_ceu}' instead of '{gaze_cue}'! And this resulted in an error because there is no variable with the name `gaze_ceu`. This can be easily fixed by opening the script of the *gaze_cue* item and fixing the typo.\n\n\n## Finally: Some general considerations regarding timing and backend selection\n\nIn the 'General properties' tab of the experiment (the tab that you open by clicking on the experiment name), you can select a backend. The backend is the layer of software that controls the display, input devices, sound, etc. Most experiments work with all backends, but there are reasons to prefer one backend over the other, mostly related to timing. Currently there are four backends (depending on your system, not all three may be available):\n\n- __psycho__ -- a hardware-accelerated backend based on PsychoPy [(Peirce, 2007)][references]. This is the default.\n- __xpyriment__ -- a hardware-accelerated backend based on Expyriment [(Krause & Lindeman, 2013)][references]\n- __legacy__ -- a 'safe' backend, based on PyGame. It provides reliable performance on most platforms, but, due to a lack of hardware acceleration, its timing properties are not as good as those of the other backends.\n- __osweb__ -- runs experiments in a browser [(Math\u00f4t & March, 2022)][references].\n\nSee also:\n\n- %link:backends%\n- %link:timing%\n\n\n## References\n\n<div class='reference' markdown='1'>\n\nBrand, A., & Bradley, M. T. (2011). Assessing the effects of technical variance on the statistical outcomes of web experiments measuring response times. *Social Science Computer Review*. doi:10.1177/0894439311415604\n\nDamian, M. F. (2010). Does variability in human performance outweigh imprecision in response devices such as computer keyboards? *Behavior Research Methods*, *42*, 205-211. doi:10.3758/BRM.42.1.205\n\nFriesen, C. K., & Kingstone, A. (1998). The eyes have it! Reflexive orienting is triggered by nonpredictive gaze. *Psychonomic Bulletin & Review*, *5*, 490\u2013495. doi:10.3758/BF03208827\n\nKrause, F., & Lindemann, O. (2013). Expyriment: A Python library for cognitive and neuroscientific experiments. *Behavior Research Methods*. doi:10.3758/s13428-013-0390-6\n\nMath\u00f4t, S., Schreij, D., & Theeuwes, J. (2012). OpenSesame: An open-source, graphical experiment builder for the social sciences. *Behavior Research Methods*, *44*(2), 314-324. doi:10.3758/s13428-011-0168-7\n\nMath\u00f4t, S., & March, J. (2022). Conducting linguistic experiments online with OpenSesame and OSWeb. *Language Learning*. doi:10.1111/lang.12509\n\nPeirce, J. W. (2007). PsychoPy: Psychophysics software in Python. *Journal of Neuroscience Methods*, *162*(1-2), 8-13. doi:10.1016/j.jneumeth.2006.11.017\n\nUlrich, R., & Giray, M. (1989). Time resolution of clocks: Effects on reaction time measurement\u2014Good news for bad clocks. *British Journal of Mathematical and Statistical Psychology*, *42*(1), 1-12. doi:10.1111/j.2044-8317.1989.tb01111.x\n\n</div>\n\n[references]: #references\n[gpl]: http://www.gnu.org/licenses/gpl-3.0.en.html\n[gimp]: http://www.gimp.org/\n[audacity]: http://audacity.sourceforge.net/\n[python inline scripting]: /python/about", "url": "https://osdoc.cogsci.nl/4.0/tutorials/beginner", "title": "Beginner tutorial: gaze cuing"}
{"content": "# Intermediate tutorial (Python) visual search\n\ntitle: Intermediate tutorial (Python) visual search\n\n[TOC]\n\n## About OpenSesame\n\nOpenSesame is a user-friendly program for the development of behavioral experiments for psychology, neuroscience, and experimental economy. For beginners, OpenSesame has a comprehensive graphical, point-and-click interface.  For advanced users, OpenSesame supports Python (desktop only) and JavaScript (desktop and browser).\n\nOpenSesame is freely available under the [General Public License v3][gpl].\n\n## About this tutorial\n\nThis tutorial shows how to create a basic visual-search experiment using OpenSesame [(Math\u00f4t, Schreij, & Theeuwes, 2012)][references]. We will use both the graphical interface and Python scripting to develop an experiment that you can run on the desktop in a traditional lab-based setting. Some experience with OpenSesame and Python is recommended. This tutorial takes approximately one hour.\n\nA JavaScript-based version of this tutorial is also available. If you want to run your experiments online in a browser (with OSWeb), then the JavaScript tutorial is what you need:\n\n- %link:tutorials/intermediate-javascript%\n\n## Resources\n\n- __Download__ \u2014 This tutorial assumes that you are running OpenSesame version 4.0.0 or later. You can download the most recent version of OpenSesame from:\n\t- %link:download%\n- __Documentation__ \u2014 A dedicated documentation website can be found at:\n\t- <http://osdoc.cogsci.nl/>\n- __Forum__ \u2014 A support forum can be found at:\n\t- <http://forum.cogsci.nl/>\n\n## The experiment\n\nIn this tutorial, you will create a basic visual-search experiment. The experiment resembles the classic visual-search studies of [Treisman and Gelade (1980)][references], but it is not identical.\n\nIn this experiment, participants search for a target object, which can be a yellow square, a yellow circle, a blue square, or a blue circle; the identity of the target is varied between blocks of trials. Participants indicate whether the target is present or not by pressing the right (present) or left (absent) arrow key.\n\nIn addition to the target, zero or more distractor objects are shown. There are three conditions, and the condition determines what kind of distractors there are:\n\n- In the *Conjunction* condition, distractors can have any shape and color, with the only restriction that distractors cannot be identical to the target. So, for example, if the target is a yellow square, then distractors are yellow circles, blue circles, and blue squares.\n- In the *Shape Feature* condition, distractors have a different shape from the target, but can have any color. So, for example, if the target is a yellow square, then distractors are yellow circles and blue circles.\n- In the *Color Feature* condition, distractors can have any shape, but have a different color from the target. So, for example, if the target is a yellow square, then distractors are blue squares and blue circles.\n\nImmediate feedback is shown after each trial: a green dot after a correct response, and a red dot after an incorrect response. Detailed feedback on average response times and accuracy is shown after each block of trials.\n\n%--\nfigure:\n id: FigVisualSearch\n source: visual-search.svg\n caption: |\n  The visual-search experiment that you will implement in this tutorial.\n--%\n\nExperiments like this show two typical findings:\n\n- It takes more time to find the target in the Conjunction condition than in the two Feature conditions.\n- In the Conjunction condition, response times increase as the number of distractors increases. This suggests that people search for the target one item at a time; this is called *serial search*.\n- In the Feature conditions (both shape and color), response times do not, or hardly, increase as the the number of distractors increases. This suggests that people process the entire display at once; this is called *parallel search*.\n\nAccording to Treisman and Gelade's feature-integration theory, these results reflect that the Conjunction condition requires that you combine, or *bind*, the color and shape of each object. This binding requires attention, and you therefore need to shift your attention from one object to the next; this is slow, and explains why response times depend on how many objects there are. In contrast, in the Feature conditions, color and shape do not need to be bound, and therefore the whole display can be processed in a single sweep without attention being directed at each and every object.\n\n## Experimental design\n\nThis design:\n\n- Is *within-subject*, because all participants do all conditions\n- Is *fully crossed* (or full-factorial), because all combinations of conditions occur\n- Has three conditions (or factors):\n\t- Varied within blocks:\n\t\t- `set_size` with three levels (1, 5, 15), or SS<sub>3</sub>\n\t\t- `condition` with three levels (conjunction, feature_shape, feature_color), or CN<sub>3</sub>\n\t\t- `target_present` with two levels (present, absent), or TP<sub>2</sub>\n\t- Varied between blocks:\n\t\t- `target_shape` with two levels (square, circle), or TS<sub>2</sub>\n\t\t- `target_color` with two levels (yellow, blue), or TC<sub>2</sub>\n- Has N subjects, or <u>S</u><sub>N</sub>\n\nYou can write this design as <u>S</u><sub>N</sub>\u00d7SS<sub>3</sub>\u00d7CN<sub>3</sub>\u00d7TP<sub>2</sub>\u00d7TS<sub>2</sub>\u00d7TC<sub>2</sub>\n\nFor more information about this notation for experimental design, see:\n\n- %link:experimentaldesign%\n\n## Step 1: Create the basic structure of the experiment\n\nStart OpenSesame and, in the 'Get started!' tab, select the Extended template. This template provides the basic structure that is common to many cognitive-psychology experiments, such as the one that we will create here.\n\nThe Extended template contains a few items that we don't need. Delete the following items:\n\n- *about_this_template*\n- *practice_loop*\n- *end_of_practice*\n\nWhen you have deleted these items, they are still visible in the 'Unused items' bin. To permanently delete these items, click on the 'Unused items' bin, and then click on the 'Permanently delete unused items' button.\n\nFinally, give the experiment a good title, such as 'Visual search'. To do this, open the general-properties tab (by clicking on 'Extended template' in the overview area) and click on the experiment name to edit it.\n\nThe overview area should now look like %FigStep1:\n\n%--\nfigure:\n id: FigStep1\n source: step1.png\n caption: |\n  The overview area at the end of step 1.\n--%\n\n## Step 2: Define experimental variables that are varied between blocks\n\nAs described above, two variables are varied between blocks in our experiment: `target_shape` and `target_color`. We therefore need to define these variables in the *experimental_loop*. To understand why, consider the structure shown in %FigStep1, starting from the bottom (i.e. the most indented level).\n\n- *trial_sequence* corresponds to a single trial\n- *block_loop* corresponds to a block of a trials\n\t- Therefore, variables defined here vary for each run of *trial_sequence*; in other words, variables defined in *block_loop* are varied __within blocks__.\n- *block_sequence* corresponds to a block of trials, preceded by resetting of the feedback variables, and followed by participant feedback\n- *experimental_loop* corresponds to multiple blocks of trials\n\t- Therefore, variables defined here vary for each run of *block_sequence*; in other words, variables defined in *experimental_loop* are varied __between blocks__.\n- *experiment* corresponds to the entire experimental, which is an instruction screen, followed by multiple blocks of trials, followed by an end-of-experiment screen\n\nClick on experimental loop, and define:\n\n- `target_shape`, which can be 'square' or 'circle'; and\n- `target_color`, which can be 'yellow' or 'blue'.\n\nWe have a full-factorial design, which means that all 2 \u00d7 2 = 4 combinations must occur. The table of *experimental_loop* should now look like %FigStep2:\n\n%--\nfigure:\n id: FigStep2\n source: step2.png\n caption: |\n  The table of *experimental_loop* at the end of step 2.\n--%\n\n## Step 3: Give instructions at the start of each block\n\nRight now, the experiment starts with a single *instructions* screen. In our case, we want to give instructions before each block of trials, to tell the participant what target to look for (because the identity of the target varies between blocks).\n\n__Move the instructions into block_sequence__\n\nTherefore, pick up the *instructions* item and drag it onto *block_sequence*. A pop-up will appear, asking you if you want to:\n\n- Insert the item into *block_sequence*, in which case *instructions* would become the first item of *block_sequence*; or\n- Insert the item after *block_sequence*, in which case *instructions* would move to a position after *block_sequence*.\n\nSelect the first option ('Insert into'). Now *block_sequence* starts with an instructions screen, which is what we want.\n\n__Add instructional text__\n\nClick on *instructions* to open it, and add a good instructional text, such as:\n\n```text\nINSTRUCTIONS\n\nSearch for the {target_color} {target_shape}\n\nPress the right-arrow key if you find it\nPress the left-arrow key if you don't\n\nPress any key to begin\n```\n\nThe curly braces brackets around '{target_color}' and '{target_shape}' indicate that these are not literal text, but refer to the variables that we have defined in *experimental_loop*. When the experiment runs, the values of these variables will appear here, and the participant will see (for example), 'Search for the yellow circle'.\n\n__Give a visual preview of the target__\n\nIt also good to show the participant the actual stimulus that she needs to find. To do this:\n\n- Draw a filled circle at the center of the display (make sure it doesn't overlap with the text);\n- Change the color of the circle to '{target_color}'. This means that the color of the circle depends on the value of the variable `target_color`; and\n- Change the show-if expression to `target_shape == 'circle'`. This is a Python expression that checks if the variable `target_shape` has the value 'circle'.\n\nIn other words, we have drawn a circle of which the color is determined by `target_color`; furthermore, this circle is only shown when the variable `target_shape` has the value 'circle'. For more information about variables and show-if statements, see:\n\n- %link:manual/variables%\n\nWe use the same trick to draw a square:\n\n- Draw a filled square at the center of the display;\n- Change the color of the square to '{target_color}'; and\n- Change the show-if statement to `target_shape == 'square'`\n\nThe *instructions*  screen should now look like %FigStep3:\n\n%--\nfigure:\n id: FigStep3\n source: step3.png\n caption: |\n  The *instructions* screen at the end of step 3.\n--%\n\n## Step 4: Define experimental variables that are varied within blocks\n\nThree variables are varied within blocks in our experiment: `condition`, `set_size`, and `target_present`. As described under Step 2, we need to define these variables in the *block_loop* so that they vary for each run of *trial_sequence*.\n\nThe three variables make a total of 3 \u00d7 3 \u00d7 2 = 18 different combinations. We can type these into the table manually, but, because we have full-factorial design, we can also use the full-factorial-design wizard. To do this, first open *block_loop* and click on the 'Full-factorial design' button.\n\nIn the table that appears, put the variable names on the first row, and the values on the rows below, as shown in %FigFullFactorial.\n\n%--\nfigure:\n id: FigFullFactorial\n source: fullfactorial.png\n caption: |\n  The *instructions* screen at the end of step 3.\n--%\n\nNow click on 'Ok' to generate the full design. The table of *block_loop* should now look like %FigStep4.\n\n%--\nfigure:\n id: FigStep4\n source: step4.png\n caption: |\n  The table of *block_loop* at the end of step 4.\n--%\n\n## Step 5: Create the trial sequence\n\nWe want our trial sequence to look as follows:\n\n- A fixation dot, for which we will use a SKETCHPAD.\n- A search display, which we will create in Python with a custom INLINE_SCRIPT.\n- Response collection, for which we will use a KEYBOARD_RESPONSE.\n- Data logging, for which we will use a LOGGER.\n- (We also want immediate feedback after each trial, but we will get back to this later.)\n\nSo the only thing that is missing is an INLINE_SCRIPT.\n\n- Insert a new INLINE_SCRIPT after *sketchpad* and rename it to *search_display_script*.\n- Rename *sketchpad* to *fixation_dot*, so that its function is clear; and\n- Change the duration of *fixation_dot* to 500, so that the fixation dot is shown for 500 ms. (There should already be a fixation dot drawn; if not, draw one in the center of *fixation_dot*.)\n\nThe overview area should now look like %FigStep5.\n\n%--\nfigure:\n id: FigStep5\n source: step5.png\n caption: |\n  The overview area at the end of step 5.\n--%\n\n## Step 6: Generate the search display\n\n__Top-down and defensive programming__\n\nNow things will get interesting: We will start programming in Python. We will use two guiding principles: *top-down* and *defensive* programming.\n\n- *Top-down programming* means that we start with the most abstract logic, without bothering with how this logic is implemented. Once the most abstract logic is in place, we will move down to a slightly less abstract logic, and so on, until we arrive at the details of the implementation. This technique helps to keep the code structured.\n- *Defensive programming* means that we assume that we make mistakes. Therefore, to protect us from ourselves, we build sanity checks into the code.\n\n*Note:* The explanation below assumes that you're somewhat familiar with Python code. If concepts like `list`, `tuple`, and functions don't mean anything to you, then it's best to first walk through an introductory Python tutorial, such as this one:\n\n- <https://pythontutorials.eu/>\n\nThe logic of the code is shown in %FigHierarchy. The numbers indicate the order in which we will implement the functionality, starting at the abstract level.\n\n%--\nfigure:\n id: FigHierarchy\n source: hierarchy.svg\n caption: |\n  The logic of the code to draw a visual-search display.\n--%\n\n__The Prepare and Run phases__\n\nOpen *search_display_script* and switch to the Prepare tab. OpenSesame distinguishes two phases of execution:\n\n- During the Prepare phase, each item is given the opportunity to prepare itself; what this means depends on the item: For a SKETCHPAD, it means drawing a canvas (but not showing it); for a SAMPLER, it means loading a sound file (but not playing it); etc.\n- During the Run phase, each item is actually executed; again, what this means depends on the item: For a SKETCHPAD, it means showing the previously prepared canvas; for a SAMPLER, it means playing a previously loaded sound file.\n\nFor an INLINE_SCRIPT, you have to decide yourself what to put in the Prepare phase, and what to put in the Run phase. The distinction is usually quite clear: In our case, we put the code for drawing the canvas in the Prepare phase, and the code for showing the canvas (which is small) in the Run phase.\n\nSee also:\n\n- %link:prepare-run%\n\n__Implement the abstract level__\n\nWe start at the most abstract level: defining a function that draws a visual-search display. We don't specify *how* this is done; we simply assume that there is a function that does this, and we will worry about the details later\u2014that's top-down programming.\n\nIn the Prepare tab, enter the following code:\n\n~~~ .python\nc = draw_canvas()\n~~~\n\nWhat happens here? We \u2026\n\n- Call `draw_canvas()`, which returns a `Canvas` object that we store as `c`; in other words, `c` is a `Canvas` object that corresponds the search display. This assumes that there is a function `draw_canvas()`, even though we haven't defined it yet.\n\nA `Canvas` object is a single display; it is, in a sense, the Python counterpart of a SKETCHPAD. See also:\n\n- %link:manual/python/canvas%\n\nWe now go one step down by defining `draw_canvas()` (above the rest of the script so far):\n\n~~~ .python\ndef draw_canvas():\n    \"\"\"Draws the search canvas.\n\n    Returns\n    -------\n    Canvas\n    \"\"\"\n    c = Canvas()\n    xy_list = xy_random(n=set_size, width=500, height=500, min_dist=75)\n    if target_present == 'present':\n        x, y = xy_list.pop()\n        draw_target(c, x, y)\n    elif target_present != 'absent':\n        raise Exception(f'Invalid value for target_present: {target_present}')\n    for x, y in xy_list:\n        draw_distractor(c, x, y)\n    return c\n~~~\n\n\nWhat happens here? We \u2026\n\n- Create an empty canvas, `c`, using the factory function `Canvas()`.\n- Generate a list of random `x, y` coordinates, called `xy_list`, using another common function, `xy_random()`. This list determines where the stimuli are shown.\n- Check if the experimental variable `target_present` has the value 'present'; if so, `pop()` one `x, y` tuple from `xy_list`, and draw the target at this location. This assumes that there is a function `draw_target()`, even though we haven't defined it yet.\n- If `target_present` is neither 'present' nor 'absent', we raise an `Exception`; this is defensive programming, and protects us from typos (e.g. if we had accidentally entered 'presenr' instead of 'present').\n- Loop through all remaining `x, y` tuples and draw a distractor at each position. This assumes that there is a function `draw_distractor()`, even though we haven't defined it yet.\n- Return `c`, which now has the search display drawn onto it.\n\nThere are several common functions, such as `Canvas()` and `xy_random()`, which are always available. See:\n\n- %link:manual/python/common%\n\nExperimental variables are global variables. That's why you can refer to `set_size`, which is defined in *block_loop*, even though the variable `set_size` is never explicitly defined in the script. The same is true for `target_shape`, `target_color`, `condition`, etc. See:\n\n- %link:var%\n\n__Implement the intermediate level__\n\nWe now go one more step down by defining `draw_target` (above the rest of the script so far):\n\n~~~ .python\ndef draw_target(c, x, y):\n    \"\"\"Draws the target.\n\n    Parameters\n    ----------\n    c: Canvas\n    x: int\n    y: int\n    \"\"\"\n    draw_shape(c, x, y, color=target_color, shape=target_shape)\n~~~\n\nWhat happens here? We \u2026\n\n- Call another function, `draw_shape()`, and specify the color and shape that needs to be drawn. This assumes that there is a function `draw_shape()`, even though we haven't defined it yet.\n\nWe also define `draw_distractor` (above the rest of the script so far):\n\n~~~ .python\ndef draw_distractor(c, x, y):\n    \"\"\"Draws a single distractor.\n\n    Parameters\n    ----------\n    c: Canvas\n    x: int\n    y: int\n    \"\"\"\n    if condition == 'conjunction':\n        draw_conjunction_distractor(c, x, y)\n    elif condition == 'feature_shape':\n        draw_feature_shape_distractor(c, x, y)\n    elif condition == 'feature_color':\n        draw_feature_color_distractor(c, x, y)\n    else:\n        raise Exception(f'Invalid condition: {condition}')\n~~~\n\nWhat happens here? We \u2026\n\n- Call another function to draw a more specific distractor depending on the Condition.\n- Check whether `condition` has any of the expected values. If not, we raise an `Exception`. This is defensive programming! Without this check, if we made a typo somewhere, the distractor might simply not be shown without causing an error message.\n\nNow we define the function that draws distractors in the Conjunction condition (above the rest of the script so far):\n\n~~~ .python\nimport random\n\n\ndef draw_conjunction_distractor(c, x, y):\n    \"\"\"Draws a single distractor in the conjunction condition: an object that\n    can have any shape and color, but cannot be identical to the target.\n\n    Parameters\n    ----------\n    c: Canvas\n    x: int\n    y: int\n    \"\"\"\n    conjunctions = [('yellow', 'circle'),\n                    ('blue',   'circle'),\n                    ('yellow', 'square'),\n                    ('blue',   'square')]\n    conjunctions.remove((target_color, target_shape))\n    color, shape = random.choice(conjunctions)\n    draw_shape(c, x, y, color=color, shape=shape)\n~~~\n\nWhat happens here? We \u2026\n\n- Define a list, `conjunctions`, of all possible color and shape combinations.\n- Remove the target from this list; this is necessary, because the distractor cannot be identical to the target.\n- Randomly select one of the color and shape combinations from `conjunctions`.\n- Call another function, `draw_shape()`, and specify the color and shape of the to-be-drawn distractor. This assumes that there is a function `draw_shape()`, even though we haven't defined it yet.\n\nIn addition, we \u2026\n\n- Add the line `import random` to the top of the script. This is necessary so that we can use functions that are part of the `random` module, such as `random.choice()`.\n\nNow we define the function that draws distractors in the Shape Feature condition (right below the `import` statement):\n\n~~~ .python\ndef draw_feature_shape_distractor(c, x, y):\n    \"\"\"Draws a single distractor in the feature-shape condition: an object that\n    has a different shape from the target, but can have any color.\n\n    Parameters\n    ----------\n    c: Canvas\n    x: int\n    y: int\n    \"\"\"\n    colors = ['yellow', 'blue']\n    color = random.choice(colors)\n    if target_shape == 'circle':\n        shape = 'square'\n    elif target_shape == 'square':\n        shape = 'circle'\n    else:\n        raise Exception(f'Invalid target_shape: {target_shape}')\n    draw_shape(c, x, y, color=color, shape=shape)\n~~~\n\nWhat happens here? We \u2026\n\n- Randomly select a color.\n- Choose a square shape if the target is a circle, and a circle shape if the target is square.\n- If `target_shape` is neither 'circle' nor 'square', raise an `Exception`\u2014more defensive programming!\n- Call another function, `draw_shape()`, and specify the color and shape of the to-be-drawn distractor. This assumes that there is a function `draw_shape()`, even though we haven't defined it yet.\n\nNow we define the function that draws distractors in the Color Feature condition (right below the `import` statement):\n\n~~~ .python\ndef draw_feature_color_distractor(c, x, y):\n    \"\"\"Draws a single distractor in the feature-color condition: an object that\n    has a different color from the target, but can have any shape.\n\n    Parameters\n    ----------\n    c: Canvas\n    x: int\n    y: int\n    \"\"\"\n    shapes = ['circle', 'square']\n    shape = random.choice(shapes)\n    if target_color == 'yellow':\n        color = 'blue'\n    elif target_color == 'blue':\n        color = 'yellow'\n    else:\n        raise Exception(f'Invalid target_color: {target_color}')\n    draw_shape(c, x, y, color=color, shape=shape)\n~~~\n\nWhat happens here? We \u2026\n\n- Randomly select a shape.\n- Choose a blue color if the target is yellow, and a yellow color if the target is blue.\n- If `target_color` is neither 'yellow' nor 'blue', raise an `Exception`\u2014more defensive programming!\n- Call another function, `draw_shape()`, and specify the color and shape of the to-be-drawn distractor. This assumes that there is a function `draw_shape()`, even though we haven't defined it yet.\n\n__Implement the detailed level__\n\nNow we go all the way down to the details by defining the function that actually draws a shape to the canvas (right below the `import` statement):\n\n~~~ .python\ndef draw_shape(c, x, y, color, shape):\n    \"\"\"Draws a single shape.\n\n    Parameters\n    ----------\n    c: Canvas\n    x: int\n    y: int\n    color: str\n    shape: str\n    \"\"\"\n    if shape == 'square':\n        c += Rect(x=x-25, y=y-25, w=50, h=50, color=color, fill=True)\n    elif shape == 'circle':\n        c += Circle(x=x, y=y, r=25, color=color, fill=True)\n    else:\n        raise Exception(f'Invalid shape: {shape}')\n    if color not in ['yellow', 'blue']:\n        raise Exception(f'Invalid color: {color}')\n~~~\n\nWhat happens here? We \u2026\n\n- Check which shape should be drawn. For squares, we add a `Rect()` element to the canvas. For circles, we add a `Circle()` element.\n- Check if the the shape is either a square or a circle, and if not raise an `Exception`. This is another example of defensive programming! We're making sure that we haven't accidentally specified an invalid shape.\n- Check if the the color is neither yellow nor blue, and if not raise an `Exception`.\n\n__Implement the Run phase__\n\nBecause we have done all the hard work in the Prepare phase, the Run phase is just:\n\n~~~ .python\nc.show()\n~~~\n\nThat's it! Now you have drawn a full visual-search display. And, importantly, you have done so in a way that is easy to understand, because of top-down programming, and safe, because of defensive programming.\n\n", "url": "https://osdoc.cogsci.nl/4.0/tutorials/intermediate", "title": "Intermediate tutorial (Python) visual search"}
{"content": "# Intermediate tutorial (Python) visual search\n\n## Step 7: Define the correct response\n\nTo know if the participant responds correctly, we need to know the correct response. You can define this explicitly in the *block_loop* (as done in the beginner tutorial); but here we're going to use a simple Python script that checks whether the target is present or not, and defines the correct response accordingly.\n\nTo do this, insert a new INLINE_SCRIPT at the start of *trial_sequence*, and rename it to *correct_response_script*. In the Prepare phase (not the Run phase!), enter the following code:\n\n~~~ .python\nif target_present == 'present':\n    correct_response = 'right'\nelif target_present == 'absent':\n    correct_response = 'left'\nelse:\n    raise Exception(f'target_present should be absent or present, not {target}')\n~~~\n\nWhat happens here? We \u2026\n\n- Check whether the target is present or not. If the target is present, the correct response is 'right' (the right arrow key); if the target is absent, the correct response is 'left' (the left arrow key). The experimental (global) variable `correct_response` is automatically recognized by *keyboard_response*; therefore, we don't need to explicitly indicate that this variable contains the correct response.\n- Check if the target is either present or absent, and if not raise an `Exception`\u2014another example of defensive programming.\n\n## Step 8: Give per-trial feedback\n\nFeedback after every trial can motivate participants; however, per-trial feedback should not interfere with the flow of the experiment. A good way to give per-trial feedback is to briefly show a green fixation dot after a correct response, and a red fixation dot after an incorrect response.\n\nTo do this:\n\n- Insert two new SKETCHPADs into *trial_sequence*, just after *keyboard_response*.\n- Rename one SKETCHPAD to *green_dot*, draw a central green fixation dot onto it, and change its duration to 500.\n- Rename the other SKETCHPAD to *red_dot*, draw a central red fixation dot onto it, and change its duration to 500.\n\nOf course, only one of the two dots should be shown on each trial. To accomplish this, we will specify run-if expressions in *trial_sequence*:\n\n- Change the run-if expression for *green_dot* to 'correct == 1', indicating that it should only be shown after a correct response.\n- Change the run-if expression for *red_dot* to 'correct == 0', indicating that it should only be shown after an incorrect response.\n\nThe variable `correct` is automatically created if the variable `correct_response` is available; that's why we defined `correct_response` in step 7. For more information about variables and run-if statements, see:\n\n- %link:manual/variables%\n\nThe *trial_sequence* should now look like %FigStep8.\n\n%--\nfigure:\n id: FigStep8\n source: step8.png\n caption: |\n  The *trial_sequence* at the end of step 8.\n--%\n\n## Finished!\n\nCongratulations, the experiment is complete! You can give it a test run by pressing on the blue double-arrow button (shortcut: `Ctrl+W`).\n\nIf the experiment doesn't work on the first try: Don't worry, and calmly figure out where the mistake comes from. Crashes are part of the normal development process. But you can save yourself a lot of time and headache by working in a structured way, as we have done in this tutorial.\n\n## References\n\n<div class='reference' markdown='1'>\n\nMath\u00f4t, S., Schreij, D., & Theeuwes, J. (2012). OpenSesame: An open-source, graphical experiment builder for the social sciences. *Behavior Research Methods*, *44*(2), 314-324. doi:10.3758/s13428-011-0168-7\n\nTreisman, A. M., & Gelade, G. (1980). A feature-integration theory of attention. *Cognitive Psychology*, 12(1), 97\u2013136. doi:10.1016/0010-0285(80)90005-5\n\n</div>\n\n[references]: #references\n[gpl]: http://www.gnu.org/licenses/gpl-3.0.en.html", "url": "https://osdoc.cogsci.nl/4.0/tutorials/intermediate", "title": "Intermediate tutorial (Python) visual search"}
